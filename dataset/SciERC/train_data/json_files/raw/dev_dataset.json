[
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "computing optical flow , shape , motion , lighting , and albedo",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the object of the verb 'presents', depending on 'presents' in the phrase 'presents an algorithm'. Entity 2 ('computing optical flow, shape, motion, lighting, and albedo') is the object of the preposition 'for', depending on 'for' in the phrase 'for computing optical flow, shape, motion, lighting, and albedo'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "algorithm → for → computing",
        "sentence": "This paper presents an algorithm for computing optical flow, shape, motion, lighting, and albedo.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'presents' with 'This paper'. Entity 2 ('computing optical flow, shape, motion, lighting, and albedo') is the object of the preposition 'for', depending on 'for' in the phrase 'for computing optical flow, shape, motion, lighting, and albedo'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "image sequence",
                "Material"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('image sequence') is the object of the preposition 'from', depending on 'from' in the phrase 'from an image sequence'. Entity 2 ('algorithm') is the direct object, depending on the verb 'presents' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'presents' and the preposition 'from'.",
        "sdp_path_text": "sequence → from → computing → for → algorithm",
        "sentence": "An algorithm computes from an image sequence.",
        "sentence_llm_dp_info": "Entity 1 ('image sequence') is the object of the preposition 'from', depending on 'from' in the phrase 'from an image sequence'. Entity 2 ('algorithm') is the subject, depending on the verb 'computes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'from an image sequence'."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "rigidly-moving Lambertian object",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the object, depending on the verb 'presents' with 'This paper'. Entity 2 ('rigidly-moving Lambertian object') is the object of the preposition 'of', depending on 'image sequence'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'algorithm' is described as being used to compute properties (including those of the 'rigidly-moving Lambertian object') from an image sequence.",
        "sdp_path_text": "algorithm → for → computing → from → sequence → of → object",
        "sentence": "This paper presents an algorithm for computing properties from a sequence of a rigidly-moving Lambertian object.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the object, depending on 'presents' with 'This paper'. Entity 2 ('rigidly-moving Lambertian object') is the object of the preposition 'of', depending on 'sequence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the purpose and components of the algorithm."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "distant illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the object, depending on the verb 'presents' with 'This paper'. Entity 2 ('distant illumination') is the object of the preposition 'under', depending on 'under' in the phrase 'under distant illumination'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'algorithm' is described as being used under conditions specified by 'distant illumination'.",
        "sdp_path_text": "algorithm → for → computing → from → sequence → under → illumination",
        "sentence": "The algorithm computes from an image sequence under distant illumination.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'computes'. Entity 2 ('distant illumination') is the object of the preposition 'under', depending on 'under' in the phrase 'under distant illumination'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that modifies the conditions under which the algorithm computes."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "computing optical flow , shape , motion , lighting , and albedo",
                "Task"
            ],
            [
                "image sequence",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('computing optical flow, shape, motion, lighting, and albedo') is the object of the preposition 'for', depending on 'algorithm'. Entity 2 ('image sequence') is the object of the preposition 'from', depending on 'from' in the phrase 'from an image sequence'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrases modifying different aspects of the algorithm described in the sentence.",
        "sdp_path_text": "computing → from → sequence",
        "sentence": "The algorithm computes optical flow, shape, motion, lighting, and albedo from an image sequence.",
        "sentence_llm_dp_info": "Entity 1 ('computing optical flow, shape, motion, lighting, and albedo') is the object of the verb 'computes', depending on 'algorithm'. Entity 2 ('image sequence') is the object of the preposition 'from', depending on 'computing optical flow, shape, motion, lighting, and albedo'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "computing optical flow , shape , motion , lighting , and albedo",
                "Task"
            ],
            [
                "rigidly-moving Lambertian object",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('computing optical flow, shape, motion, lighting, and albedo') is the object of the preposition 'for', depending on 'algorithm'. Entity 2 ('rigidly-moving Lambertian object') is the object of the preposition 'of', depending on 'sequence'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the components and conditions of the image sequence being analyzed.",
        "sdp_path_text": "computing → from → sequence → of → object",
        "sentence": "Computing optical flow, shape, motion, lighting, and albedo from a sequence of a rigidly-moving Lambertian object.",
        "sentence_llm_dp_info": "Entity 1 ('computing optical flow, shape, motion, lighting, and albedo') is the subject, depending on the preposition 'from'. Entity 2 ('rigidly-moving Lambertian object') is the object of the preposition 'from', depending on 'from' in the phrase 'from a sequence of a rigidly-moving Lambertian object'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' and the noun 'sequence'."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "computing optical flow , shape , motion , lighting , and albedo",
                "Task"
            ],
            [
                "distant illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('computing optical flow, shape, motion, lighting, and albedo') is the object of the preposition 'for', depending on 'algorithm'. Entity 2 ('distant illumination') is the object of the preposition 'under', depending on 'sequence'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the conditions and goals of the algorithm presented in the paper.",
        "sdp_path_text": "computing → from → sequence → under → illumination",
        "sentence": "Computing optical flow, shape, motion, lighting, and albedo from an image sequence under distant illumination.",
        "sentence_llm_dp_info": "Entity 1 ('computing optical flow, shape, motion, lighting, and albedo') is the subject, depending on the preposition 'from' which connects it to the object 'image sequence'. Entity 2 ('distant illumination') is the object of the preposition 'under', depending on 'under' in the phrase 'under distant illumination'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the prepositions 'from' and 'under' that describe the conditions and source of the computation."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "rigidly-moving Lambertian object",
                "Material"
            ],
            [
                "image sequence",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rigidly-moving Lambertian object') is the object of the preposition 'of', depending on 'of' in the phrase 'of a rigidly-moving Lambertian object'. Entity 2 ('image sequence') is the subject complement, depending on 'from' in the phrase 'from an image sequence'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger prepositional structure that modifies the main clause.",
        "sdp_path_text": "object → of → sequence",
        "sentence": "A rigidly-moving Lambertian object is captured in an image sequence.",
        "sentence_llm_dp_info": "Entity 1 ('rigidly-moving Lambertian object') is the subject, depending on the verb 'captured'. Entity 2 ('image sequence') is the object, depending on the preposition 'in' which is part of the phrase 'in an image sequence'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in an image sequence' where Entity 1 is captured in Entity 2."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "image sequence",
                "Material"
            ],
            [
                "distant illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('image sequence') is the object of the preposition 'from', depending on 'computing'. Entity 2 ('distant illumination') is the complement of the preposition 'under', depending on 'object'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the conditions and inputs for the algorithm presented in the paper.",
        "sdp_path_text": "sequence → under → illumination",
        "sentence": "An image sequence is under distant illumination.",
        "sentence_llm_dp_info": "Entity 1 ('image sequence') is the subject, depending on the verb 'is'. Entity 2 ('distant illumination') is the complement, depending on the preposition 'under'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'under' which indicates the condition or environment in which the 'image sequence' exists."
    },
    {
        "raw_sentence": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination .",
        "ner_pair": [
            [
                "distant illumination",
                "OtherScientificTerm"
            ],
            [
                "rigidly-moving Lambertian object",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('distant illumination') is the complement of the preposition 'under', depending on the noun 'object'. Entity 2 ('rigidly-moving Lambertian object') is the object of the preposition 'of', depending on the noun 'sequence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger noun phrase describing the conditions and properties of the image sequence.",
        "sdp_path_text": "illumination → under → sequence → of → object",
        "sentence": "The algorithm computes properties from an image sequence of a rigidly-moving Lambertian object under distant illumination.",
        "sentence_llm_dp_info": "Entity 1 ('distant illumination') is the complement, depending on the preposition 'under' which modifies 'sequence'. Entity 2 ('rigidly-moving Lambertian object') is the object of the preposition 'of', depending on 'image sequence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying 'image sequence'."
    },
    {
        "raw_sentence": "The problem is formulated in a manner that subsumes structure from motion , multi-view stereo , and photo-metric stereo as special cases .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "motion",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'formulated'. Entity 2 ('motion') is part of the compound noun 'structure from motion', which is an element in a list introduced by 'that subsumes'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause that describes how the problem is formulated.",
        "sdp_path_text": "problem → formulated → in → manner → subsumes → from → motion",
        "sentence": "The problem is formulated in a manner that subsumes motion.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'formulated'. Entity 2 ('motion') is the object of the relative clause, depending on 'subsumes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formulated' and the relative clause introduced by 'that'."
    },
    {
        "raw_sentence": "The problem is formulated in a manner that subsumes structure from motion , multi-view stereo , and photo-metric stereo as special cases .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "multi-view stereo",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'formulated'. Entity 2 ('multi-view stereo') is part of a list of objects, depending on 'subsumes' in the phrase 'that subsumes structure from motion, multi-view stereo, and photo-metric stereo'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'subsumes'.",
        "sdp_path_text": "problem → formulated → in → manner → subsumes → from → motion → stereo",
        "sentence": "The problem is formulated in a manner that subsumes multi-view stereo.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'formulated'. Entity 2 ('multi-view stereo') is the object of the relative clause, depending on 'subsumes'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'formulated' and the verb 'subsumes'."
    },
    {
        "raw_sentence": "The problem is formulated in a manner that subsumes structure from motion , multi-view stereo , and photo-metric stereo as special cases .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "photo-metric stereo",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'formulated'. Entity 2 ('photo-metric stereo') is part of a list of items, depending on the conjunction 'and' which links it to 'structure from motion' and 'multi-view stereo' as elements of the prepositional phrase 'as special cases'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase indicating that the problem formulation includes 'photo-metric stereo' among other methods as special cases.",
        "sdp_path_text": "problem → formulated → in → manner → subsumes → from → motion → stereo → stereo",
        "sentence": "The problem is formulated in a manner that subsumes photo-metric stereo as a special case.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'formulated'. Entity 2 ('photo-metric stereo') is the object of the preposition 'as', depending on 'as' in the phrase 'as a special case'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'as a special case' which modifies how the problem is formulated."
    },
    {
        "raw_sentence": "The problem is formulated in a manner that subsumes structure from motion , multi-view stereo , and photo-metric stereo as special cases .",
        "ner_pair": [
            [
                "motion",
                "Material"
            ],
            [
                "multi-view stereo",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motion') is part of the compound noun 'structure from motion', which is the object of the preposition 'from', depending on 'subsumes'. Entity 2 ('multi-view stereo') is a noun, depending on 'subsumes' as one of the elements in the list of items being subsumed. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'subsumes'.",
        "sdp_path_text": "motion → stereo",
        "sentence": "Structure from motion and multi-view stereo are subsumed as special cases.",
        "sentence_llm_dp_info": "Entity 1 ('motion') is part of the compound noun 'structure from motion', depending on 'from' with 'structure'. Entity 2 ('multi-view stereo') is a noun, depending on 'and' which connects it to 'structure from motion'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects of the clause and are listed as being subsumed together."
    },
    {
        "raw_sentence": "The problem is formulated in a manner that subsumes structure from motion , multi-view stereo , and photo-metric stereo as special cases .",
        "ner_pair": [
            [
                "motion",
                "Material"
            ],
            [
                "photo-metric stereo",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motion') is part of a compound noun, depending on 'structure' in the phrase 'structure from motion'. Entity 2 ('photo-metric stereo') is the object of a preposition, depending on 'as' in the phrase 'as special cases'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of special cases mentioned in the sentence.",
        "sdp_path_text": "motion → stereo → stereo",
        "sentence": "The problem subsumes structure from motion and photo-metric stereo as special cases.",
        "sentence_llm_dp_info": "Entity 1 ('motion') is part of the compound noun 'structure from motion', depending on 'from' as a prepositional object. Entity 2 ('photo-metric stereo') is also an object, depending on 'and' which connects it to 'structure from motion'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of the list of special cases mentioned in the sentence."
    },
    {
        "raw_sentence": "The problem is formulated in a manner that subsumes structure from motion , multi-view stereo , and photo-metric stereo as special cases .",
        "ner_pair": [
            [
                "multi-view stereo",
                "Material"
            ],
            [
                "photo-metric stereo",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-view stereo') is a noun, depending on 'subsumes' with a conjunction relation, coordinated with 'structure from motion' and 'photo-metric stereo'. Entity 2 ('photo-metric stereo') is also a noun, depending on 'subsumes' with a conjunction relation, coordinated with 'structure from motion' and 'multi-view stereo'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a list of items that are subsumed by the formulation of the problem.",
        "sdp_path_text": "stereo → stereo",
        "sentence": "The problem subsumes multi-view stereo and photo-metric stereo as special cases.",
        "sentence_llm_dp_info": "Entity 1 ('multi-view stereo') is the first conjunct, depending on the conjunction 'and' with 'photo-metric stereo'. Entity 2 ('photo-metric stereo') is the second conjunct, also depending on the conjunction 'and' with 'multi-view stereo'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and', indicating they are part of a coordinated structure listed as examples of what the problem subsumes."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the object of the preposition 'as', depending on 'cues'. Entity 2 ('algorithm') is the subject, depending on the verb 'utilizes'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'utilizes' and the preposition 'as'.",
        "sdp_path_text": "variation → utilizes → algorithm",
        "sentence": "The algorithm utilizes spatial and temporal intensity variation.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the object, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('algorithm') is the subject, depending on the verb 'utilizes'. There is a direct dependency between Entity 1 and Entity 2, as 'algorithm' utilizes 'spatial and temporal intensity variation'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "cues",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('cues') is the object, depending on the preposition 'as' in the phrase 'as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' where 'algorithm' utilizes 'cues'.",
        "sdp_path_text": "algorithm → utilizes → as → cues",
        "sentence": "The algorithm utilizes cues for reconstruction.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('cues') is the object, depending on 'utilizes' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, as 'cues' is the direct object of the verb 'utilizes' which is governed by 'algorithm'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "former",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('former') is an appositive, depending on 'cues' with the preposition 'as'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related through the use of 'cues' where 'former' specifies one type of cue that the 'algorithm' utilizes.",
        "sdp_path_text": "algorithm → utilizes → constrains → former",
        "sentence": "The algorithm utilizes the former to constrain flow.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('former') is the object of the preposition 'the', depending on 'to' in the phrase 'to constrain flow'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' where 'the former' serves as the object being utilized by the 'algorithm'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "flow",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('flow') is the object, depending on the verb 'constrains' in the clause 'the former constrains flow'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence of dependencies involving 'utilizes', 'cues', and 'constrains'.",
        "sdp_path_text": "algorithm → utilizes → constrains → flow",
        "sentence": "The algorithm utilizes cues that constrain flow.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('flow') is the object, depending on the verb 'constrain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'utilizes' and 'constrain'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('latter') is an appositive, depending on 'cues' and further specifying one of the types of cues mentioned. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the description of the cues used by the algorithm.",
        "sdp_path_text": "algorithm → utilizes → constrains → constrains → latter",
        "sentence": "The algorithm utilizes the latter to constrain surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('latter') is the object of the preposition 'the', depending on 'to' in the phrase 'to constrain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the prepositional phrase 'to constrain surface orientation'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'the latter'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where the algorithm's utilization of cues affects the constraints on surface orientation.",
        "sdp_path_text": "algorithm → utilizes → constrains → constrains → orientation",
        "sentence": "The algorithm utilizes cues that constrain surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('surface orientation') is the object, depending on 'constrain' with 'cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of dependencies involving 'utilizes' and 'constrain'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "cues",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('cues') is the object, depending on the preposition 'as' in the phrase 'as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' where 'cues' serves as the object of what the 'algorithm' utilizes.",
        "sdp_path_text": "algorithm → utilizes → as → cues",
        "sentence": "{\n  \"Simplified sentence\": \"The algorithm utilizes cues for dense reconstruction.\"\n} \n\nHowever, to better reflect the relationship between \"algorithm\" and \"cues\" as indicated by the SDP, a more precise simplification would be:\n\n{\n  \"Simplified sentence\": \"The algorithm utilizes both spatial and temporal intensity variation as cues.\"\n}",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('cues') is the object, depending on 'utilizes' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, where 'cues' serves as the direct object of the verb 'utilizes'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'utilizes'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the enabling relationship established by the verb 'enables'.",
        "sdp_path_text": "algorithm → utilizes → constrains → enables → reconstruction",
        "sentence": "The algorithm enables dense reconstruction of both textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'enables'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on 'enables' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 enables Entity 2."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "cues",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'as' in the phrase 'as cues'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 serves as the specific type or instance of Entity 2.",
        "sdp_path_text": "variation → utilizes → as → cues",
        "sentence": "The algorithm utilizes spatial and temporal intensity variation as cues.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject complement, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'as' in the phrase 'as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "former",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('former') is an appositive, depending on 'cues' and referring back to 'spatial intensity variation'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where 'former' specifies part of 'spatial and temporal intensity variation'.",
        "sdp_path_text": "variation → utilizes → constrains → former",
        "sentence": "Spatial and temporal intensity variation constrains the former.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'constrains'. Entity 2 ('former') is the object, depending on the verb 'constrains'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 acts as the agent that constrains Entity 2."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "flow",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('flow') is the object, depending on 'constrains' with 'the former'. There is no direct dependency between Entity 1 and Entity 2; however, they are indirectly connected through the logical structure of the sentence, where Entity 1 serves as a cue that constrains Entity 2.",
        "sdp_path_text": "variation → utilizes → constrains → flow",
        "sentence": "Spatial and temporal intensity variation constrains flow.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'constrains'. Entity 2 ('flow') is the object, depending on 'constrains' with 'spatial and temporal intensity variation'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 acts as the agent that constrains Entity 2."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('latter') is an appositive, depending on the noun 'cues' and further elaborates on one of the types of cues mentioned. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as parts of the same list of cues used by the algorithm.",
        "sdp_path_text": "variation → utilizes → constrains → constrains → latter",
        "sentence": "The algorithm utilizes spatial and temporal intensity variation, which constrains the latter.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the object, depending on the verb 'utilizes' with 'The algorithm'. Entity 2 ('latter') is the subject of the relative clause, depending on 'constrains' with 'which'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the relative pronoun 'which' that refers back to Entity 1, indicating that Entity 2 ('latter') is constrained by Entity 1."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on 'utilizes' with 'algorithm'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'latter'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where Entity 1 is used as a cue that, among other things, constrains Entity 2.",
        "sdp_path_text": "variation → utilizes → constrains → constrains → orientation",
        "sentence": "Spatial and temporal intensity variation constrains surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'constrains'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'spatial and temporal intensity variation'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 acts as the agent that constrains Entity 2."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "cues",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'as' in the phrase 'as cues'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is used as Entity 2 in the sentence.",
        "sdp_path_text": "variation → utilizes → as → cues",
        "sentence": "The algorithm utilizes spatial and temporal intensity variation as cues.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject complement, depending on 'utilizes' with 'algorithm'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'as' in the phrase 'as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "spatial and temporal intensity variation",
                "OtherScientificTerm"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the object of the verb 'utilizes', depending on 'algorithm'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object of the verb 'enables', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of a causal relationship where the utilization of Entity 1 (as cues) enables the action that leads to Entity 2.",
        "sdp_path_text": "variation → utilizes → constrains → enables → reconstruction",
        "sentence": "Spatial and temporal intensity variation constrains and enables dense reconstruction of textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('spatial and temporal intensity variation') is the subject, depending on the verbs 'constrains' and 'enables'. Entity 2 ('dense reconstruction of textured and texture-less surfaces') is the object, depending on the verbs 'constrains' and 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'constrains' and 'enables'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "cues",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on 'constrains' with 'flow'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'utilizes' in the phrase 'utilizes ... as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'former' refers back to one of the 'cues' mentioned earlier.",
        "sdp_path_text": "former → constrains → utilizes → as → cues",
        "sentence": "The former constrains flow as a cue utilized by the algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'as' in the phrase 'as a cue'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'as'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "cues",
                "Generic"
            ],
            [
                "flow",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cues') is the object, depending on 'utilizes' with 'algorithm'. Entity 2 ('flow') is the object, depending on 'constrains' with 'former'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'cues' are described as being used to constrain different aspects, including 'flow'.",
        "sdp_path_text": "cues → as → utilizes → constrains → flow",
        "sentence": "Cues utilized by the algorithm constrain flow.",
        "sentence_llm_dp_info": "Entity 1 ('cues') is the subject, depending on the verb 'utilized'. Entity 2 ('flow') is the object, depending on the verb 'constrain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'utilized' and 'constrain' which describe the actions involving both entities."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "latter",
                "Generic"
            ],
            [
                "cues",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on 'constrains' with 'surface orientation'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'utilizes' in the phrase 'utilizes ... as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'latter' refers back to one of the 'cues' mentioned earlier.",
        "sdp_path_text": "latter → constrains → constrains → utilizes → as → cues",
        "sentence": "The latter constrains surface orientation, which is utilized as a cue.",
        "sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on the verb 'constrains'. Entity 2 ('cues') is the object, depending on the preposition 'as' with 'utilized'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'which is utilized as a cue'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "cues",
                "Generic"
            ],
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cues') is the object of the preposition 'as', depending on 'utilizes' with 'algorithm'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'the latter'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'cues' are described as constraining different aspects, one of which is 'surface orientation'.",
        "sdp_path_text": "cues → as → utilizes → constrains → constrains → orientation",
        "sentence": "The algorithm utilizes cues that constrain surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('cues') is the object of the verb 'utilizes', depending on 'algorithm'. Entity 2 ('surface orientation') is the object of the verb 'constrain', depending on 'cues'. There is a direct dependency between Entity 1 and Entity 2, as 'surface orientation' is constrained by 'cues'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "cues",
                "Generic"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cues') is the object, depending on the verb 'utilizes' with 'algorithm'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on the verb 'enables' with 'combining both cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause 'combining both cues enables dense reconstruction of both textured and texture-less surfaces'.",
        "sdp_path_text": "cues → as → utilizes → constrains → enables → reconstruction",
        "sentence": "Utilizing both types of cues enables dense reconstruction of both textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('cues') is the object of the preposition 'of', depending on 'types'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables', which indicates that the utilization of the cues facilitates the dense reconstruction."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "flow",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains' with 'flow'. Entity 2 ('flow') is the object, depending on 'constrains' with 'former'. There is a direct dependency between Entity 1 and Entity 2, where 'former' acts as the subject that constrains 'flow'.",
        "sdp_path_text": "former → constrains → flow",
        "sentence": "The former constrains flow.",
        "sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains'. Entity 2 ('flow') is the object, depending on the verb 'constrains'. There is a direct dependency between Entity 1 and Entity 2, where 'former' acts as the agent that performs the action of constraining on 'flow'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "latter",
                "Generic"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on 'constrains' with 'flow'. Entity 2 ('latter') is the subject, depending on 'constrains' with 'surface orientation'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated subjects in the context of the sentence, each describing a different aspect of the cues used by the algorithm.",
        "sdp_path_text": "former → constrains → constrains → latter",
        "sentence": "The former constrains flow, and the latter constrains surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on 'constrains' with 'flow'. Entity 2 ('latter') is the subject, depending on 'constrains' with 'surface orientation'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of similar clauses in the sentence."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains' with 'flow'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'the latter'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses that describe different aspects of the algorithm's functionality.",
        "sdp_path_text": "former → constrains → constrains → orientation",
        "sentence": "The former constrains surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains'. Entity 2 ('surface orientation') is the object, depending on the verb 'constrains'. There is a direct dependency between Entity 1 and Entity 2, where 'former' acts as the agent that performs the action of constraining on 'surface orientation'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "cues",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains' with 'flow'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'utilizes' in the phrase 'utilizes ... as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'former' refers back to one of the 'cues' mentioned earlier.",
        "sdp_path_text": "former → constrains → utilizes → as → cues",
        "sentence": "The former constrains flow as one of the cues utilized by the algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'as' in the phrase 'as one of the cues'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as one of the cues'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on the verb 'constrains' with 'flow'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on the verb 'enables' with 'combining both cues'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, connected through the context provided by the conjunction 'and' and the shared subject 'combining both cues'.",
        "sdp_path_text": "former → constrains → enables → reconstruction",
        "sentence": "The former constrains flow, enabling dense reconstruction of both textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('former') is the subject, depending on 'constrains' with 'flow'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object of the verb 'enabling', depending on 'enabling'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enabling' which shows that the action of Entity 1 enables the process described by Entity 2."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "flow",
                "OtherScientificTerm"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('flow') is the object, depending on 'constrains' with 'the former'. Entity 2 ('latter') is the subject, depending on 'constrains' with 'surface orientation'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a larger structure where 'the former' and 'the latter' refer back to 'spatial' and 'temporal intensity variation', respectively.",
        "sdp_path_text": "flow → constrains → constrains → latter",
        "sentence": "The latter constrains flow.",
        "sentence_llm_dp_info": "Entity 1 ('flow') is the object, depending on the verb 'constrains'. Entity 2 ('latter') is the subject, depending on the verb 'constrains'. There is a direct dependency between Entity 1 and Entity 2, as 'latter' is the agent that performs the action of constraining 'flow'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "flow",
                "OtherScientificTerm"
            ],
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('flow') is the object, depending on 'constrains' with 'the former'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'the latter'. There is no direct dependency between Entity 1 and Entity 2, but they are both constrained by different aspects of the intensity variation (spatial for flow, temporal for surface orientation).",
        "sdp_path_text": "flow → constrains → constrains → orientation",
        "sentence": "Flow constrains surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('flow') is the subject, depending on the verb 'constrains'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'flow'. There is a direct dependency between Entity 1 and Entity 2, where 'flow' directly constrains 'surface orientation'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "flow",
                "OtherScientificTerm"
            ],
            [
                "cues",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('flow') is the object, depending on 'constrains' with 'the former'. Entity 2 ('cues') is the subject, depending on 'utilizes' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence, where 'cues' are described as being used by the algorithm, and one of these cues ('the former') constrains 'flow'.",
        "sdp_path_text": "flow → constrains → utilizes → as → cues",
        "sentence": "The algorithm utilizes cues that constrain flow.",
        "sentence_llm_dp_info": "Entity 1 ('flow') is the object, depending on the verb 'constrain'. Entity 2 ('cues') is the subject, depending on the verb 'utilizes' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, as 'cues' constrains 'flow'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "flow",
                "OtherScientificTerm"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('flow') is the object, depending on 'constrains' with 'the former'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the subject, depending on 'enables' with 'combining both cues'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same discourse, where the constraints on flow (among other things) contribute to the enabling conditions for the dense reconstruction mentioned.",
        "sdp_path_text": "flow → constrains → enables → reconstruction",
        "sentence": "Flow constrains and enables dense reconstruction of both textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('flow') is the subject, depending on the verb 'constrains' and 'enables'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on 'enables' with 'flow'. There is a direct dependency between Entity 1 and Entity 2, as 'flow' enables the 'dense reconstruction of both textured and texture-less surfaces'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "latter",
                "Generic"
            ],
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on the verb 'constrains' in the clause 'the latter constrains surface orientation'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'latter'. There is a direct dependency between Entity 1 and Entity 2, where 'latter' acts as the subject that constrains 'surface orientation'.",
        "sdp_path_text": "latter → constrains → orientation",
        "sentence": "The latter constrains surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on the verb 'constrains'. Entity 2 ('surface orientation') is the object, depending on 'constrains' with 'latter'. There is a direct dependency between Entity 1 and Entity 2, where 'latter' acts as the agent that constrains 'surface orientation'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "latter",
                "Generic"
            ],
            [
                "cues",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on 'constrains' with 'the latter constrains surface orientation'. Entity 2 ('cues') is the object of the preposition 'as', depending on 'utilizes' in the phrase 'utilizes both spatial and temporal intensity variation as cues'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the description of different aspects of the cues utilized by the algorithm.",
        "sdp_path_text": "latter → constrains → constrains → utilizes → as → cues",
        "sentence": "The latter constrains surface orientation, which is utilized as a cue.",
        "sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on 'constrains' with the verb 'constrains'. Entity 2 ('cues') is the object, depending on 'as' with the verb 'utilized'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of dependencies involving 'constrains', 'orientation', 'utilized', and 'as'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "latter",
                "Generic"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on the verb 'constrains' in the clause 'the latter constrains surface orientation'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object, depending on the verb 'enables' in the clause 'combining both cues enables dense reconstruction of both textured and texture-less surfaces'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same larger context where 'both cues' (including the 'latter') enable the 'dense reconstruction of both textured and texture-less surfaces'.",
        "sdp_path_text": "latter → constrains → constrains → enables → reconstruction",
        "sentence": "The latter constrains surface orientation, enabling dense reconstruction of both textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('latter') is the subject, depending on the verb 'constrains'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object of the verb 'enabling', depending on 'enabling' in the phrase 'enabling dense reconstruction...'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'constrains' and 'enabling'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            [
                "cues",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('surface orientation') is the object, depending on 'constrains' with 'the latter'. Entity 2 ('cues') is the subject, depending on 'utilizes' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence, where 'cues' influence the constraints on 'surface orientation'.",
        "sdp_path_text": "orientation → constrains → constrains → utilizes → as → cues",
        "sentence": "The algorithm utilizes cues that constrain surface orientation.",
        "sentence_llm_dp_info": "Entity 1 ('surface orientation') is the object, depending on the verb 'constrain'. Entity 2 ('cues') is the subject, depending on the verb 'utilizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'utilizes' and 'constrain'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "surface orientation",
                "OtherScientificTerm"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('surface orientation') is the object, depending on the verb 'constrains' with 'the latter'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the subject, depending on the verb 'enables' with 'combining both cues'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the broader context described in the sentence, where different cues constrain or enable certain processes.",
        "sdp_path_text": "orientation → constrains → constrains → enables → reconstruction",
        "sentence": "Constraining surface orientation enables dense reconstruction of both textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('surface orientation') is the object of the verb 'constraining', which modifies the verb 'enables'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object of the verb 'enables', depending on 'enables' in the sentence. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables'."
    },
    {
        "raw_sentence": "The algorithm utilizes both spatial and temporal intensity variation as cues : the former constrains flow and the latter constrains surface orientation ; combining both cues enables dense reconstruction of both textured and texture-less surfaces .",
        "ner_pair": [
            [
                "cues",
                "Generic"
            ],
            [
                "dense reconstruction of both textured and texture-less surfaces",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cues') is the object of the preposition 'as', depending on 'utilizes' with 'algorithm'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the object of the verb 'enables', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause 'combining both cues enables dense reconstruction of both textured and texture-less surfaces'.",
        "sdp_path_text": "cues → as → utilizes → constrains → enables → reconstruction",
        "sentence": "Utilizing cues enables dense reconstruction of textured and texture-less surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('cues') is the object of the verb 'enables', depending on 'enables' in the phrase 'enables dense reconstruction'. Entity 2 ('dense reconstruction of both textured and texture-less surfaces') is the direct object, depending on 'enables' as the action that it enables. There is a direct dependency between Entity 1 and Entity 2, as 'cues' enables the 'dense reconstruction of both textured and texture-less surfaces'."
    },
    {
        "raw_sentence": "The algorithm works by iteratively estimating affine camera parameters , illumination , shape , and albedo in an alternating fashion .",
        "ner_pair": [
            [
                "estimating affine camera parameters , illumination , shape , and albedo",
                "Method"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimating affine camera parameters, illumination, shape, and albedo') is part of the manner in which the action is performed, depending on the verb 'works' with 'algorithm'. Entity 2 ('algorithm') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 1 describes the process that the Entity 2 performs.",
        "sdp_path_text": "estimating → by → works → algorithm",
        "sentence": "The algorithm works by estimating affine camera parameters, illumination, shape, and albedo.",
        "sentence_llm_dp_info": "Entity 1 ('estimating affine camera parameters, illumination, shape, and albedo') is the object of the preposition 'by', depending on 'works' in the phrase 'works by'. Entity 2 ('algorithm') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' which indicates the means by which the algorithm operates."
    },
    {
        "raw_sentence": "Past work of generating referring expressions mainly utilized attributes of objects and binary relations between objects .",
        "ner_pair": [
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            [
                "binary relations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('referring expressions') is the object of the preposition 'of', depending on 'work'. Entity 2 ('binary relations') is the object of the preposition 'between', depending on 'objects'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what past work has utilized.",
        "sdp_path_text": "expressions → generating → of → work → utilized → attributes → relations",
        "sentence": "Generating referring expressions utilized binary relations.",
        "sentence_llm_dp_info": "Entity 1 ('referring expressions') is the object of the verb 'Generating', depending on 'Generating'. Entity 2 ('binary relations') is the object of the verb 'utilized', depending on 'utilized'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'referring expressions' being generated and 'binary relations' being utilized in the process."
    },
    {
        "raw_sentence": "We conducted psychological experiments with 42 subjects to collect referring expressions in such situations , and built a generation algorithm based on the results .",
        "ner_pair": [
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            [
                "generation algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('referring expressions') is the object, depending on 'collect' with 'experiments'. Entity 2 ('generation algorithm') is the object, depending on 'built' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the experiments and the algorithm development.",
        "sdp_path_text": "expressions → collect → conducted → built → algorithm",
        "sentence": "We built a generation algorithm based on collected referring expressions.",
        "sentence_llm_dp_info": "Entity 1 ('referring expressions') is the object of the preposition 'on', depending on 'based'. Entity 2 ('generation algorithm') is the object, depending on the verb 'built'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on collected referring expressions'."
    },
    {
        "raw_sentence": "The evaluation using another 23 subjects showed that the proposed method could effectively generate proper referring expressions .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the object of the verb 'proposed', depending on 'proposed' in the phrase 'the proposed method'. Entity 2 ('referring expressions') is the object of the verb 'generate', depending on 'generate' in the phrase 'generate proper referring expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'generate' which is part of the clause describing the capability of the method.",
        "sdp_path_text": "method → generate → expressions",
        "sentence": "The proposed method could effectively generate referring expressions.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the object of the verb 'proposed', depending on 'proposed' in the phrase 'The proposed method'. Entity 2 ('referring expressions') is the object, depending on 'generate' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'generate'."
    },
    {
        "raw_sentence": "An entity-oriented approach to restricted-domain parsing is proposed .",
        "ner_pair": [
            [
                "entity-oriented approach",
                "Method"
            ],
            [
                "restricted-domain parsing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('entity-oriented approach') is the subject, depending on the verb 'proposed'. Entity 2 ('restricted-domain parsing') is the object of the preposition 'to', depending on 'to' in the phrase 'to restricted-domain parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.",
        "sdp_path_text": "approach → to → parsing",
        "sentence": "An entity-oriented approach is proposed for restricted-domain parsing.",
        "sentence_llm_dp_info": "Entity 1 ('entity-oriented approach') is the subject, depending on the verb 'proposed'. Entity 2 ('restricted-domain parsing') is the object of the preposition 'for', depending on 'for' in the phrase 'for restricted-domain parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "In this approach , the definitions of the structure and surface representation of domain entities are grouped together .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "structure and surface representation of domain entities",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the preposition 'In' which indicates the context or method. Entity 2 ('structure and surface representation of domain entities') is the object of the preposition 'of', depending on 'definitions'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'are grouped together' which describes how the definitions (including those of Entity 2) are organized within the context of Entity 1.",
        "sdp_path_text": "approach → In → grouped → definitions → of → representation",
        "sentence": "In this approach, the definitions of the structure and surface representation of domain entities are grouped together.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the preposition 'In' at the beginning of the sentence. Entity 2 ('structure and surface representation of domain entities') is the object of the preposition 'of', depending on 'definitions'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun 'definitions' and the prepositional phrases 'In this approach' and 'of the structure and surface representation of domain entities'."
    },
    {
        "raw_sentence": "Like semantic grammar , this allows easy exploitation of limited domain semantics .",
        "ner_pair": [
            [
                "semantic grammar",
                "Method"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('semantic grammar') is part of a comparative construction, depending on 'Like' at the beginning of the sentence. Entity 2 ('this') is the subject, depending on the verb 'allows'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of comparison and the action that 'this' enables.",
        "sdp_path_text": "grammar → Like → allows → this",
        "sentence": "Like semantic grammar, this allows easy exploitation.",
        "sentence_llm_dp_info": "Entity 1 ('semantic grammar') is the subject complement, depending on the preposition 'Like' with 'this'. Entity 2 ('this') is the subject, depending on the verb 'allows'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'Like semantic grammar'."
    },
    {
        "raw_sentence": "Like semantic grammar , this allows easy exploitation of limited domain semantics .",
        "ner_pair": [
            [
                "semantic grammar",
                "Method"
            ],
            [
                "limited domain semantics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('semantic grammar') is part of a comparison, depending on the verb 'allows' with the subject 'this'. Entity 2 ('limited domain semantics') is the object of the preposition 'of', depending on 'exploitation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is allowed by the subject 'this'.",
        "sdp_path_text": "grammar → Like → allows → exploitation → of → semantics",
        "sentence": "Semantic grammar allows easy exploitation of limited domain semantics.",
        "sentence_llm_dp_info": "Entity 1 ('semantic grammar') is the subject, depending on the verb 'allows'. Entity 2 ('limited domain semantics') is the object of the preposition 'of', depending on 'exploitation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allows' and the prepositional phrase 'of limited domain semantics'."
    },
    {
        "raw_sentence": "Like semantic grammar , this allows easy exploitation of limited domain semantics .",
        "ner_pair": [
            [
                "this",
                "Generic"
            ],
            [
                "limited domain semantics",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('this') is the subject, depending on the verb 'allows'. Entity 2 ('limited domain semantics') is the object of the preposition 'of', depending on 'exploitation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'allows' and the prepositional phrase 'of limited domain semantics'.",
        "sdp_path_text": "this → allows → exploitation → of → semantics",
        "sentence": "This allows easy exploitation of limited domain semantics.",
        "sentence_llm_dp_info": "Entity 1 ('this') is the subject, depending on the verb 'allows'. Entity 2 ('limited domain semantics') is the object of the preposition 'of', depending on 'exploitation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allows' and the prepositional phrase 'of limited domain semantics'."
    },
    {
        "raw_sentence": "In addition , it facilitates fragmentary recognition and the use of multiple parsing strategies , and so is particularly useful for robust recognition of extra-grammatical input .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "multiple parsing strategies",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'facilitates'. Entity 2 ('multiple parsing strategies') is the object of the preposition 'of', depending on 'use' in the phrase 'the use of multiple parsing strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'facilitates' and the prepositional phrase 'of multiple parsing strategies'.",
        "sdp_path_text": "addition → In → facilitates → recognition → use → of → strategies",
        "sentence": "It facilitates the use of multiple parsing strategies.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'facilitates'. Entity 2 ('multiple parsing strategies') is the object, depending on 'use' in the phrase 'use of multiple parsing strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'facilitates' and the phrase 'use of'."
    },
    {
        "raw_sentence": "In addition , it facilitates fragmentary recognition and the use of multiple parsing strategies , and so is particularly useful for robust recognition of extra-grammatical input .",
        "ner_pair": [
            [
                "fragmentary recognition",
                "Task"
            ],
            [
                "multiple parsing strategies",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('fragmentary recognition') is part of the conjunction, depending on 'facilitates' with 'it'. Entity 2 ('multiple parsing strategies') is the object of the preposition 'of', depending on 'use' in the phrase 'the use of multiple parsing strategies'. There is no direct dependency between Entity 1 and Entity 2, but both are facilitated by the subject 'it'.",
        "sdp_path_text": "recognition → use → of → strategies",
        "sentence": "Fragmentary recognition facilitates the use of multiple parsing strategies.",
        "sentence_llm_dp_info": "Entity 1 ('fragmentary recognition') is the subject, depending on the verb 'facilitates'. Entity 2 ('multiple parsing strategies') is the object, depending on the preposition 'of' in the phrase 'use of multiple parsing strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'facilitates' and the prepositional phrase 'use of'."
    },
    {
        "raw_sentence": "In addition , it facilitates fragmentary recognition and the use of multiple parsing strategies , and so is particularly useful for robust recognition of extra-grammatical input .",
        "ner_pair": [
            [
                "fragmentary recognition",
                "Task"
            ],
            [
                "recognition of extra-grammatical input",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('fragmentary recognition') is part of the list of objects, depending on the verb 'facilitates' with 'it'. Entity 2 ('recognition of extra-grammatical input') is the subject complement, depending on the adjective 'useful' with 'is'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence structure, with Entity 1 being facilitated and Entity 2 being described as useful.",
        "sdp_path_text": "recognition → facilitates → is → useful → for → recognition",
        "sentence": "Fragmentary recognition facilitates useful recognition of extra-grammatical input.",
        "sentence_llm_dp_info": "Entity 1 ('fragmentary recognition') is the subject, depending on the verb 'facilitates'. Entity 2 ('recognition of extra-grammatical input') is the object, depending on the verb 'facilitates'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 facilitates Entity 2."
    },
    {
        "raw_sentence": "In addition , it facilitates fragmentary recognition and the use of multiple parsing strategies , and so is particularly useful for robust recognition of extra-grammatical input .",
        "ner_pair": [
            [
                "multiple parsing strategies",
                "Method"
            ],
            [
                "recognition of extra-grammatical input",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multiple parsing strategies') is the object of the preposition 'of', depending on 'use'. Entity 2 ('recognition of extra-grammatical input') is the object of the preposition 'for', depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the usefulness of the subject.",
        "sdp_path_text": "strategies → of → use → recognition → facilitates → is → useful → for → recognition",
        "sentence": "Multiple parsing strategies facilitate recognition of extra-grammatical input.",
        "sentence_llm_dp_info": "Entity 1 ('multiple parsing strategies') is the subject, depending on the verb 'facilitate'. Entity 2 ('recognition of extra-grammatical input') is the object, depending on the verb 'facilitate'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 facilitates Entity 2."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "entity-oriented language definition",
                "OtherScientificTerm"
            ],
            [
                "control structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'samples'. Entity 2 ('control structure') is the object of the preposition 'for', depending on 'parser'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of items being presented in the sentence.",
        "sdp_path_text": "definition → from → samples → presented → along → with → structure",
        "sentence": "Samples from an entity-oriented language definition are presented along with a control structure.",
        "sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'Samples'. Entity 2 ('control structure') is the object of the preposition 'with', depending on 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence describing what is presented."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "entity-oriented language definition",
                "OtherScientificTerm"
            ],
            [
                "entity-oriented parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'samples'. Entity 2 ('entity-oriented parser') is the object of the preposition 'for', depending on 'structure'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.",
        "sdp_path_text": "definition → from → samples → presented → along → with → structure → for → parser",
        "sentence": "Samples from an entity-oriented language definition are presented along with a control structure for an entity-oriented parser.",
        "sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'Samples'. Entity 2 ('entity-oriented parser') is the object of the preposition 'for', depending on 'structure'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence's structure, describing different aspects of the presentation."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "entity-oriented language definition",
                "OtherScientificTerm"
            ],
            [
                "parsing strategies",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'samples'. Entity 2 ('parsing strategies') is part of a list of items, depending on 'that' which modifies 'strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence, which discusses various aspects of an entity-oriented approach.",
        "sdp_path_text": "definition → from → samples → presented → along → with → structure → strategies",
        "sentence": "Samples from an entity-oriented language definition are presented along with parsing strategies.",
        "sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'Samples'. Entity 2 ('parsing strategies') is the object of the preposition 'with', depending on 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure related to what is being presented."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "entity-oriented language definition",
                "OtherScientificTerm"
            ],
            [
                "control structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'samples'. Entity 2 ('control structure') is the object of the preposition 'for', depending on 'parser'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of items presented in the sentence.",
        "sdp_path_text": "definition → from → samples → presented → along → with → structure",
        "sentence": "Samples from an entity-oriented language definition are presented along with a control structure.",
        "sentence_llm_dp_info": "Entity 1 ('entity-oriented language definition') is the object of the preposition 'from', depending on 'Samples'. Entity 2 ('control structure') is the object of the preposition 'with', depending on 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence's main clause, which describes what is presented."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "control structure",
                "OtherScientificTerm"
            ],
            [
                "entity-oriented parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('control structure') is the object of the preposition 'for', depending on 'for' in the phrase 'for an entity-oriented parser'. Entity 2 ('entity-oriented parser') is the noun modifier, depending on 'for' in the same phrase. There is a direct dependency between Entity 1 and Entity 2, as 'entity-oriented parser' modifies and specifies 'control structure'.",
        "sdp_path_text": "structure → for → parser",
        "sentence": "A control structure is presented for an entity-oriented parser.",
        "sentence_llm_dp_info": "Entity 1 ('control structure') is the subject, depending on the verb 'presented'. Entity 2 ('entity-oriented parser') is the object of the preposition 'for', depending on 'for' in the phrase 'for an entity-oriented parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "control structure",
                "OtherScientificTerm"
            ],
            [
                "parsing strategies",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('control structure') is the object of the preposition 'for', depending on 'parser' in the phrase 'for an entity-oriented parser'. Entity 2 ('parsing strategies') is the subject, depending on the verb 'use' in the clause 'that use the control structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' where 'parsing strategies' uses 'control structure'.",
        "sdp_path_text": "structure → strategies",
        "sentence": "A control structure is used by parsing strategies.",
        "sentence_llm_dp_info": "Entity 1 ('control structure') is the subject, depending on the verb 'is used'. Entity 2 ('parsing strategies') is the agent, depending on the preposition 'by' which modifies the verb 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction where 'parsing strategies' is the agent performing the action on 'control structure'."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "entity-oriented parser",
                "Method"
            ],
            [
                "parsing strategies",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('entity-oriented parser') is part of the object complement, depending on the preposition 'for' within the phrase 'a control structure for an entity-oriented parser'. Entity 2 ('parsing strategies') is the subject of the relative clause, depending on the verb 'use' within the phrase 'that use the control structure'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of the control structure in the sentence.",
        "sdp_path_text": "parser → for → structure → strategies",
        "sentence": "An entity-oriented parser uses control structure for parsing strategies.",
        "sentence_llm_dp_info": "Entity 1 ('entity-oriented parser') is the subject, depending on the verb 'uses'. Entity 2 ('parsing strategies') is the object, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'parsing strategies' is the direct object of the verb 'uses' which is governed by 'entity-oriented parser'."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "control structure",
                "OtherScientificTerm"
            ],
            [
                "entity-oriented parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('control structure') is the object of the preposition 'for', depending on 'for' in the phrase 'for an entity-oriented parser'. Entity 2 ('entity-oriented parser') is the noun modifier, depending on 'for' in the same phrase. There is a direct dependency between Entity 1 and Entity 2, as 'entity-oriented parser' modifies 'control structure'.",
        "sdp_path_text": "structure → for → parser",
        "sentence": "A control structure is presented for an entity-oriented parser.",
        "sentence_llm_dp_info": "Entity 1 ('control structure') is the subject, depending on the verb 'presented'. Entity 2 ('entity-oriented parser') is the object of the preposition 'for', depending on 'for' in the phrase 'for an entity-oriented parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses .",
        "ner_pair": [
            [
                "control structure",
                "OtherScientificTerm"
            ],
            [
                "parsing strategies",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('control structure') is the object of the preposition 'for', depending on 'parser' in the phrase 'for an entity-oriented parser'. Entity 2 ('parsing strategies') is the subject, depending on the verb 'use' in the phrase 'that use the control structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' where Entity 2 uses Entity 1.",
        "sdp_path_text": "structure → strategies",
        "sentence": "A control structure is used by parsing strategies.",
        "sentence_llm_dp_info": "Entity 1 ('control structure') is the subject, depending on the verb 'used'. Entity 2 ('parsing strategies') is the object of the preposition 'by', depending on 'by' in the phrase 'by parsing strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' which indicates that Entity 2 uses Entity 1."
    },
    {
        "raw_sentence": "A parser incorporating the control structure and the parsing strategies is currently under implementation .",
        "ner_pair": [
            [
                "control structure",
                "OtherScientificTerm"
            ],
            [
                "parser",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('control structure') is part of a compound noun, depending on 'incorporating' with 'parser'. Entity 2 ('parser') is the subject, depending on the verb 'is' in the phrase 'is currently under implementation'. There is a direct dependency between Entity 1 and Entity 2, as 'control structure' is incorporated into the 'parser'.",
        "sdp_path_text": "structure → incorporating → parser",
        "sentence": "A parser incorporates the control structure.",
        "sentence_llm_dp_info": "Entity 1 ('control structure') is the object, depending on 'incorporates' with 'parser'. Entity 2 ('parser') is the subject, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, where 'parser' incorporates 'control structure'."
    },
    {
        "raw_sentence": "A parser incorporating the control structure and the parsing strategies is currently under implementation .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "parsing strategies",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'is' in the phrase 'is currently under implementation'. Entity 2 ('parsing strategies') is part of a compound noun, depending on 'and' which connects it to 'control structure'. There is no direct dependency between Entity 1 and Entity 2; however, both are components of the object being incorporated into the parser.",
        "sdp_path_text": "parser → incorporating → structure → strategies",
        "sentence": "A parser incorporating parsing strategies is under implementation.",
        "sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'is' in the phrase 'is under implementation'. Entity 2 ('parsing strategies') is the object of the verb 'incorporating', depending on 'incorporating' in the phrase 'incorporating parsing strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporating'."
    },
    {
        "raw_sentence": "A parser incorporating the control structure and the parsing strategies is currently under implementation .",
        "ner_pair": [
            [
                "control structure",
                "OtherScientificTerm"
            ],
            [
                "parsing strategies",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('control structure') is the object of the preposition 'the', depending on 'incorporating'. Entity 2 ('parsing strategies') is also the object of the preposition 'the', depending on 'incorporating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the compound object being incorporated by the parser.",
        "sdp_path_text": "structure → strategies",
        "sentence": "A parser incorporating control structure and parsing strategies is under implementation.",
        "sentence_llm_dp_info": "Entity 1 ('control structure') is part of a compound noun, depending on 'incorporating' with 'parser'. Entity 2 ('parsing strategies') is also part of a compound noun, depending on 'incorporating' with 'parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of what the parser incorporates."
    },
    {
        "raw_sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB- and describes two parsing algorithms that interpret it .",
        "ner_pair": [
            [
                "formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-",
                "Task"
            ],
            [
                "parsing algorithms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the verb 'summarizes', depending on 'summarizes' with 'This paper'. Entity 2 ('parsing algorithms') is the subject of the clause 'that interpret it', depending on the verb 'interpret'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where Entity 1 is summarized, and Entity 2 interprets it.",
        "sdp_path_text": "formalism → summarizes → describes → algorithms",
        "sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions and describes parsing algorithms.",
        "sentence_llm_dp_info": "Entity 1 ('formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the verb 'summarizes', depending on 'summarizes' in the clause 'summarizes the formalism of Category Cooccurrence Restrictions and describes parsing algorithms'. Entity 2 ('parsing algorithms') is the object of the verb 'describes', depending on 'describes' in the same clause. There is no direct dependency between Entity 1 and Entity 2; both are objects of different verbs in the same sentence."
    },
    {
        "raw_sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB- and describes two parsing algorithms that interpret it .",
        "ner_pair": [
            [
                "formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-",
                "Task"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the verb 'summarizes', depending on 'summarizes' with 'This paper'. Entity 2 ('it') is the object of the relative clause, depending on 'interpret' with 'parsing algorithms'. There is no direct dependency between Entity 1 and Entity 2; however, 'it' refers back to 'formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-' in the context of the sentence.",
        "sdp_path_text": "formalism → summarizes → describes → algorithms",
        "sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions and describes algorithms.",
        "sentence_llm_dp_info": "Entity 1 ('formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the verb 'summarizes', depending on 'summarizes' with 'This paper'. Entity 2 ('it') is not present in the given sentence. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 does not appear in the sentence.\"\n\nNote: Since \"it\" (Entity 2) is not mentioned in the sentence, there cannot be any dependency relationship involving \"it\". If you intended to refer to another part of the sentence or a different entity, please provide the correct details."
    },
    {
        "raw_sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB- and describes two parsing algorithms that interpret it .",
        "ner_pair": [
            [
                "Category Cooccurrence Restrictions -LRB- CCRs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "parsing algorithms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the preposition 'of', depending on 'formalism'. Entity 2 ('parsing algorithms') is the subject, depending on the verb 'describe'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence's main clause, with Entity 1 being described in terms of its formalism and Entity 2 being the subject of an action (described).",
        "sdp_path_text": "-RRB- → of → formalism → summarizes → describes → algorithms",
        "sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions and describes parsing algorithms.",
        "sentence_llm_dp_info": "Entity 1 ('Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the preposition 'of', depending on 'formalism'. Entity 2 ('parsing algorithms') is the object, depending on the verb 'describes'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects in the sentence, related through the main clause structure involving the verbs 'summarizes' and 'describes'."
    },
    {
        "raw_sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions -LRB- CCRs -RRB- and describes two parsing algorithms that interpret it .",
        "ner_pair": [
            [
                "Category Cooccurrence Restrictions -LRB- CCRs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the preposition 'of', depending on 'summarizes' in the phrase 'summarizes the formalism of'. Entity 2 ('it') is the object, depending on 'interpret' with 'parsing algorithms'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the context provided by the sentence, where 'it' refers back to the formalism of 'Category Cooccurrence Restrictions (CCRs)'.",
        "sdp_path_text": "-RRB- → of → formalism → summarizes → describes → algorithms",
        "sentence": "This paper summarizes the formalism of Category Cooccurrence Restrictions and describes parsing algorithms that interpret it.",
        "sentence_llm_dp_info": "Entity 1 ('Category Cooccurrence Restrictions -LRB- CCRs -RRB-') is the object of the preposition 'of', depending on 'formalism'. Entity 2 ('it') is the object, depending on 'interpret' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'interpret' which refers back to the formalism described earlier."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "CCRs",
                "OtherScientificTerm"
            ],
            [
                "Boolean conditions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('Boolean conditions') is the predicative complement, depending on the copular verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as 'Boolean conditions' directly describes what 'CCRs' are.",
        "sdp_path_text": "CCRs → are → conditions",
        "sentence": "CCRs are Boolean conditions.",
        "sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the copula 'are'. Entity 2 ('Boolean conditions') is the predicate nominative, also depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, established through the copula 'are'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "CCRs",
                "OtherScientificTerm"
            ],
            [
                "local trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('local trees') is the object of the preposition 'in', depending on 'in' in the phrase 'in local trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that modifies the noun 'conditions'.",
        "sdp_path_text": "CCRs → are → conditions → on → cooccurrence → of → categories → in → trees",
        "sentence": "CCRs are conditions on the cooccurrence of categories in local trees.",
        "sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('local trees') is the object of the preposition 'in', depending on 'in' in the phrase 'in local trees'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in local trees'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "CCRs",
                "OtherScientificTerm"
            ],
            [
                "statement of generalizations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('statement of generalizations') is the object of the relative clause, depending on 'which allow' in the phrase 'which allow the statement of generalizations'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the relative clause introduced by 'which'.",
        "sdp_path_text": "CCRs → are → conditions → allow → statement",
        "sentence": "CCRs are conditions that allow the statement of generalizations.",
        "sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('statement of generalizations') is the object of the preposition 'of', depending on 'allow' in the phrase 'allow the statement of generalizations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'allow'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "CCRs",
                "OtherScientificTerm"
            ],
            [
                "syntax formalisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('syntax formalisms') is the object of the preposition 'in', depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the function and uniqueness of CCRs in comparison to other syntax formalisms.",
        "sdp_path_text": "CCRs → are → conditions → allow → statement → of → generalizations → captured → in → formalisms",
        "sentence": "CCRs are conditions that allow the statement of generalizations not captured in other syntax formalisms.",
        "sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'are'. Entity 2 ('syntax formalisms') is the object of the preposition 'in', depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing what CCRs allow."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "Boolean conditions",
                "OtherScientificTerm"
            ],
            [
                "local trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Boolean conditions') is the subject complement, depending on 'are' with 'CCRs'. Entity 2 ('local trees') is the object of the preposition 'in', depending on 'in' in the phrase 'in local trees'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Boolean conditions' are described as being on the cooccurrence of categories in 'local trees'.",
        "sdp_path_text": "conditions → on → cooccurrence → of → categories → in → trees",
        "sentence": "Boolean conditions are on the cooccurrence of categories in local trees.",
        "sentence_llm_dp_info": "Entity 1 ('Boolean conditions') is the subject, depending on the verb 'are'. Entity 2 ('local trees') is the object of the preposition 'in', depending on 'in' in the phrase 'in local trees'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'on the cooccurrence of categories in local trees'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "Boolean conditions",
                "OtherScientificTerm"
            ],
            [
                "statement of generalizations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Boolean conditions') is the subject complement, depending on 'are' with 'CCRs'. Entity 2 ('statement of generalizations') is the object, depending on 'allow' with 'which'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "conditions → allow → statement",
        "sentence": "Boolean conditions allow the statement of generalizations.",
        "sentence_llm_dp_info": "Entity 1 ('Boolean conditions') is the subject, depending on the verb 'allow'. Entity 2 ('statement of generalizations') is the object of the preposition 'of', depending on 'statement'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allow' and the prepositional phrase 'the statement of generalizations'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "Boolean conditions",
                "OtherScientificTerm"
            ],
            [
                "syntax formalisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Boolean conditions') is the subject complement, depending on 'are' with 'CCRs'. Entity 2 ('syntax formalisms') is the object, depending on 'captured' with 'can not be'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the sentence.",
        "sdp_path_text": "conditions → allow → statement → of → generalizations → captured → in → formalisms",
        "sentence": "Boolean conditions allow the statement of generalizations not captured in syntax formalisms.",
        "sentence_llm_dp_info": "Entity 1 ('Boolean conditions') is the subject, depending on the verb 'allow'. Entity 2 ('syntax formalisms') is the object of the preposition 'in', depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'not captured in syntax formalisms'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "local trees",
                "OtherScientificTerm"
            ],
            [
                "statement of generalizations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('local trees') is the object of the preposition 'in', depending on 'conditions'. Entity 2 ('statement of generalizations') is the object of the relative clause, depending on 'allow'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'local trees' are part of the conditions that allow the 'statement of generalizations'.",
        "sdp_path_text": "trees → in → categories → of → cooccurrence → on → conditions → allow → statement",
        "sentence": "Conditions on the cooccurrence of categories in local trees allow the statement of generalizations.",
        "sentence_llm_dp_info": "Entity 1 ('local trees') is the object of the preposition 'in', depending on 'cooccurrence'. Entity 2 ('statement of generalizations') is the object, depending on the verb 'allow'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'local trees' contribute to the conditions that 'allow the statement of generalizations'."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "local trees",
                "OtherScientificTerm"
            ],
            [
                "syntax formalisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('local trees') is the object of the preposition 'in', depending on 'conditions'. Entity 2 ('syntax formalisms') is the object of the preposition 'in', depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader structure describing the conditions and capabilities of CCRs.",
        "sdp_path_text": "trees → in → categories → of → cooccurrence → on → conditions → allow → statement → of → generalizations → captured → in → formalisms",
        "sentence": "Conditions on the cooccurrence of categories in local trees allow the statement of generalizations not captured in syntax formalisms.",
        "sentence_llm_dp_info": "Entity 1 ('local trees') is part of the prepositional phrase 'in local trees', functioning as the object of the preposition 'in', and depends on 'cooccurrence'. Entity 2 ('syntax formalisms') is the object of the preposition 'in', appearing in the phrase 'in syntax formalisms', and depends on 'captured'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms .",
        "ner_pair": [
            [
                "statement of generalizations",
                "OtherScientificTerm"
            ],
            [
                "syntax formalisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('statement of generalizations') is the object of the relative clause, depending on 'allow' with 'CCR'. Entity 2 ('syntax formalisms') is the object of the preposition 'in', depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what CCRs enable and how they differ from other approaches.",
        "sdp_path_text": "statement → of → generalizations → captured → in → formalisms",
        "sentence": "Statement of generalizations cannot be captured in syntax formalisms.",
        "sentence_llm_dp_info": "Entity 1 ('statement of generalizations') is the subject, depending on the verb 'captured'. Entity 2 ('syntax formalisms') is the object, depending on the preposition 'in', which is part of the phrase 'in syntax formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'captured' and the preposition 'in'."
    },
    {
        "raw_sentence": "The use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements .",
        "ner_pair": [
            [
                "CCRs",
                "OtherScientificTerm"
            ],
            [
                "syntactic descriptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'leads'. Entity 2 ('syntactic descriptions') is the object, depending on 'formulated' with 'CCRs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leads' and the participle 'formulated'.",
        "sdp_path_text": "CCRs → of → use → leads → to → descriptions",
        "sentence": "The use of CCRs leads to syntactic descriptions.",
        "sentence_llm_dp_info": "Entity 1 ('CCRs') is the object of the preposition 'of', depending on 'use'. Entity 2 ('syntactic descriptions') is the complement of the verb 'leads', depending on 'leads' in the phrase 'leads to syntactic descriptions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leads'."
    },
    {
        "raw_sentence": "The use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements .",
        "ner_pair": [
            [
                "CCRs",
                "OtherScientificTerm"
            ],
            [
                "restrictive statements",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCRs') is the object of the preposition 'of', depending on 'use'. Entity 2 ('restrictive statements') is the object, depending on 'formulated' with 'descriptions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'leads' and the subsequent clause describing the effect of using CCRs.",
        "sdp_path_text": "CCRs → of → use → leads → to → descriptions → formulated → with → statements",
        "sentence": "The use of CCRs leads to descriptions formulated with restrictive statements.",
        "sentence_llm_dp_info": "Entity 1 ('CCRs') is the subject, depending on the verb 'leads'. Entity 2 ('restrictive statements') is the object, depending on 'formulated' with 'descriptions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leads' and the noun 'descriptions'."
    },
    {
        "raw_sentence": "The use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements .",
        "ner_pair": [
            [
                "restrictive statements",
                "OtherScientificTerm"
            ],
            [
                "syntactic descriptions",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('restrictive statements') is the object, depending on the verb 'formulated'. Entity 2 ('syntactic descriptions') is the subject, depending on the verb 'formulated'. There is a direct dependency between Entity 1 and Entity 2, as 'syntactic descriptions' are the subject being 'formulated' with 'restrictive statements'.",
        "sdp_path_text": "statements → with → formulated → descriptions",
        "sentence": "Restrictive statements are used to formulate syntactic descriptions.",
        "sentence_llm_dp_info": "Entity 1 ('restrictive statements') is the subject, depending on the verb 'are used'. Entity 2 ('syntactic descriptions') is the object, depending on the verb 'formulate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formulate' which is part of the clause 'to formulate syntactic descriptions'."
    },
    {
        "raw_sentence": "The paper shows how conventional algorithms for the analysis of context free languages can be adapted to the CCR formalism .",
        "ner_pair": [
            [
                "context free languages",
                "Material"
            ],
            [
                "algorithms",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('context free languages') is the object of the preposition 'of', depending on 'analysis'. Entity 2 ('algorithms') is the subject, depending on 'shows' with 'The paper'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'adapted' and the prepositional phrase 'for the analysis of context free languages'.",
        "sdp_path_text": "languages → of → analysis → for → algorithms",
        "sentence": "Algorithms for the analysis of context free languages can be adapted to the CCR formalism.",
        "sentence_llm_dp_info": "Entity 1 ('context free languages') is the object of the preposition 'of', depending on 'analysis'. Entity 2 ('algorithms') is the subject, depending on the verb 'can be adapted'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for the analysis of context free languages' which modifies 'algorithms'."
    },
    {
        "raw_sentence": "The paper shows how conventional algorithms for the analysis of context free languages can be adapted to the CCR formalism .",
        "ner_pair": [
            [
                "algorithms",
                "Generic"
            ],
            [
                "CCR formalism",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithms') is the object of the preposition 'for', depending on 'analysis'. Entity 2 ('CCR formalism') is the object of the preposition 'to', depending on 'adapted'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what can be adapted.",
        "sdp_path_text": "algorithms → adapted → to → formalism",
        "sentence": "Algorithms can be adapted to the CCR formalism.",
        "sentence_llm_dp_info": "Entity 1 ('algorithms') is the subject, depending on the verb 'adapted'. Entity 2 ('CCR formalism') is the object of the preposition 'to', depending on 'to' in the phrase 'to the CCR formalism'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "The paper shows how conventional algorithms for the analysis of context free languages can be adapted to the CCR formalism .",
        "ner_pair": [
            [
                "context free languages",
                "Material"
            ],
            [
                "CCR formalism",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('context free languages') is the object of the preposition 'of', depending on 'analysis'. Entity 2 ('CCR formalism') is the object, depending on 'adapted'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'adapted' which indicates that the analysis methods for Entity 1 can be modified for use with Entity 2.",
        "sdp_path_text": "languages → of → analysis → for → algorithms → adapted → to → formalism",
        "sentence": "Algorithms for analyzing context free languages can be adapted to the CCR formalism.",
        "sentence_llm_dp_info": "Entity 1 ('context free languages') is the object of the preposition 'for', depending on 'Algorithms'. Entity 2 ('CCR formalism') is the object of the preposition 'to', depending on 'adapted'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure related to the adaptation of algorithms."
    },
    {
        "raw_sentence": "Special attention is given to the part of the parser that checks the fulfillment of logical well-formedness conditions on trees .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "logical well-formedness conditions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parser') is part of the noun phrase, depending on 'part' with the preposition 'of' in the phrase 'part of the parser'. Entity 2 ('logical well-formedness conditions') is the object of the preposition 'on', depending on 'checks' in the phrase 'checks the fulfillment of logical well-formedness conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'checks' and the preposition 'on'.",
        "sdp_path_text": "parser → of → part → checks → fulfillment → of → conditions",
        "sentence": "The parser checks the fulfillment of logical well-formedness conditions.",
        "sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'checks'. Entity 2 ('logical well-formedness conditions') is the object, depending on the preposition 'of', which is part of the phrase 'of logical well-formedness conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'checks' and the preposition 'of'."
    },
    {
        "raw_sentence": "Special attention is given to the part of the parser that checks the fulfillment of logical well-formedness conditions on trees .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parser') is the object of the preposition 'of', depending on 'part'. Entity 2 ('trees') is the object of the preposition 'on', depending on 'conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the structure of the sentence.",
        "sdp_path_text": "parser → of → part → checks → fulfillment → of → conditions → on → trees",
        "sentence": "The parser checks the fulfillment of conditions on trees.",
        "sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'checks'. Entity 2 ('trees') is the object, depending on the preposition 'on' in the phrase 'on trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'checks' and the preposition 'on'."
    },
    {
        "raw_sentence": "Special attention is given to the part of the parser that checks the fulfillment of logical well-formedness conditions on trees .",
        "ner_pair": [
            [
                "logical well-formedness conditions",
                "OtherScientificTerm"
            ],
            [
                "trees",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('logical well-formedness conditions') is the object of the preposition 'of', depending on 'checks' in the clause 'that checks the fulfillment of logical well-formedness conditions'. Entity 2 ('trees') is the object of the preposition 'on', depending on 'conditions' in the phrase 'conditions on trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.",
        "sdp_path_text": "conditions → on → trees",
        "sentence": "Logical well-formedness conditions are checked on trees.",
        "sentence_llm_dp_info": "Entity 1 ('logical well-formedness conditions') is the subject, depending on the verb 'checked'. Entity 2 ('trees') is the object, depending on the preposition 'on' in the phrase 'on trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'checked' and the preposition 'on'."
    },
    {
        "raw_sentence": "We present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent corpora .",
        "ner_pair": [
            [
                "text mining method",
                "Method"
            ],
            [
                "synonymous expressions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('text mining method') is the object, depending on the verb 'present'. Entity 2 ('synonymous expressions') is the object of the preposition 'for', depending on 'for' in the phrase 'for finding synonymous expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'for finding synonymous expressions'.",
        "sdp_path_text": "method → for → finding → expressions",
        "sentence": "We present a text mining method for finding synonymous expressions.",
        "sentence_llm_dp_info": "Entity 1 ('text mining method') is the object of the preposition 'for', depending on 'present' with 'We'. Entity 2 ('synonymous expressions') is the object of the preposition 'for', depending on 'finding' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'for finding synonymous expressions'."
    },
    {
        "raw_sentence": "We present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent corpora .",
        "ner_pair": [
            [
                "distributional hypothesis",
                "OtherScientificTerm"
            ],
            [
                "text mining method",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('distributional hypothesis') is the object of the preposition 'on', depending on the preposition 'on' in the phrase 'based on the distributional hypothesis'. Entity 2 ('text mining method') is the object of the preposition 'for', depending on 'for' in the phrase 'for finding synonymous expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the purpose and basis of the method presented.",
        "sdp_path_text": "hypothesis → on → based → expressions → finding → for → method",
        "sentence": "We present a text mining method based on the distributional hypothesis for finding synonymous expressions.",
        "sentence_llm_dp_info": "Entity 1 ('distributional hypothesis') is the object of the preposition 'on', depending on the preposition 'on' in the phrase 'based on the distributional hypothesis'. Entity 2 ('text mining method') is the object, depending on the verb 'present' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on the distributional hypothesis'."
    },
    {
        "raw_sentence": "We present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent corpora .",
        "ner_pair": [
            [
                "synonymous expressions",
                "OtherScientificTerm"
            ],
            [
                "distributional hypothesis",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('synonymous expressions') is the object of the preposition 'for', depending on 'finding'. Entity 2 ('distributional hypothesis') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose and basis of the method presented.",
        "sdp_path_text": "expressions → based → on → hypothesis",
        "sentence": "Synonymous expressions are found based on the distributional hypothesis.",
        "sentence_llm_dp_info": "Entity 1 ('synonymous expressions') is the subject, depending on the verb 'found'. Entity 2 ('distributional hypothesis') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the distributional hypothesis'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on the distributional hypothesis'."
    },
    {
        "raw_sentence": "This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author 's text as a coherent corpus .",
        "ner_pair": [
            [
                "methodology",
                "Generic"
            ],
            [
                "accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methodology') is the object of the verb 'proposes', depending on 'proposes' with 'This paper'. Entity 2 ('accuracy') is the object of the verb 'improve', depending on 'improve' in the phrase 'to improve the accuracy'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "methodology → improve → accuracy",
        "sentence": "This paper proposes a new methodology to improve accuracy.",
        "sentence_llm_dp_info": "Entity 1 ('methodology') is the object of the verb 'proposes', depending on 'proposes' with 'This paper'. Entity 2 ('accuracy') is the object, depending on 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'methodology' is proposed to improve 'accuracy'."
    },
    {
        "raw_sentence": "This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author 's text as a coherent corpus .",
        "ner_pair": [
            [
                "term aggregation system",
                "Method"
            ],
            [
                "methodology",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('term aggregation system') is the object of the preposition 'of', depending on 'accuracy'. Entity 2 ('methodology') is the direct object, depending on 'proposes' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the preposition 'of'.",
        "sdp_path_text": "system → of → accuracy → improve → methodology",
        "sentence": "The methodology aims to improve the accuracy of the term aggregation system.",
        "sentence_llm_dp_info": "Entity 1 ('term aggregation system') is the object, depending on 'of' with 'accuracy'. Entity 2 ('methodology') is the subject, depending on 'aims' with 'the'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the preposition 'of'."
    },
    {
        "raw_sentence": "This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author 's text as a coherent corpus .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "term aggregation system",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('accuracy') is the object, depending on 'improve' with 'methodology'. Entity 2 ('term aggregation system') is the object of the preposition 'of', depending on 'of' in the phrase 'of a term aggregation system'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'accuracy' is being improved for the 'term aggregation system'.",
        "sdp_path_text": "accuracy → of → system",
        "sentence": "The accuracy of the term aggregation system is improved.",
        "sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'is improved'. Entity 2 ('term aggregation system') is the object of the preposition 'of', depending on 'of' in the phrase 'of the term aggregation system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'."
    },
    {
        "raw_sentence": "According to our assumption , most of the words with similar context features in each author 's corpus tend not to be synonymous expressions .",
        "ner_pair": [
            [
                "similar context features",
                "OtherScientificTerm"
            ],
            [
                "synonymous expressions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('similar context features') is the object of the preposition 'with', depending on 'words'. Entity 2 ('synonymous expressions') is the complement of the negated verb 'tend', depending on 'not to be'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the structure of the sentence, where the presence of 'similar context features' influences the tendency regarding 'synonymous expressions'.",
        "sdp_path_text": "features → with → words → of → most → tend → be → expressions",
        "sentence": "Words with similar context features tend not to be synonymous expressions.",
        "sentence_llm_dp_info": "Entity 1 ('similar context features') is the object of the preposition 'with', depending on 'Words'. Entity 2 ('synonymous expressions') is the complement of the verb 'be', depending on 'not to be'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the tendency of words."
    },
    {
        "raw_sentence": "Our proposed method improves the accuracy of our term aggregation system , showing that our approach is successful .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'improves'. Entity 2 ('accuracy') is the object, depending on 'improves' with 'method'. There is a direct dependency between Entity 1 and Entity 2, where 'method' is the agent performing the action that affects 'accuracy'.",
        "sdp_path_text": "method → improves → accuracy",
        "sentence": "Our proposed method improves the accuracy.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'improves'. Entity 2 ('accuracy') is the object, depending on the verb 'improves'. There is a direct dependency between Entity 1 and Entity 2, as 'method' directly influences 'accuracy' through the verb 'improves'."
    },
    {
        "raw_sentence": "Our proposed method improves the accuracy of our term aggregation system , showing that our approach is successful .",
        "ner_pair": [
            [
                "term aggregation system",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('term aggregation system') is the object of the preposition 'of', depending on 'accuracy'. Entity 2 ('method') is the subject, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'improves', which indicates that the method affects the accuracy of the term aggregation system.",
        "sdp_path_text": "system → of → accuracy → improves → method",
        "sentence": "The method improves the accuracy of the term aggregation system.",
        "sentence_llm_dp_info": "Entity 1 ('term aggregation system') is the object of the preposition 'of', depending on 'accuracy'. Entity 2 ('method') is the subject, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' which affects the 'accuracy' of Entity 1."
    },
    {
        "raw_sentence": "Our proposed method improves the accuracy of our term aggregation system , showing that our approach is successful .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "approach",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on 'improves'. Entity 2 ('approach') is the subject complement, depending on 'is' in the clause 'our approach is successful'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the success described in the sentence.",
        "sdp_path_text": "method → improves → showing → is → approach",
        "sentence": "Our method improves, showing our approach is successful.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'improves'. Entity 2 ('approach') is the subject complement, depending on the verb 'is' in the clause 'our approach is successful'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the success described in the sentence."
    },
    {
        "raw_sentence": "Our proposed method improves the accuracy of our term aggregation system , showing that our approach is successful .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "term aggregation system",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('accuracy') is the object, depending on 'improves' with 'method'. Entity 2 ('term aggregation system') is the object of the preposition 'of', depending on 'of' in the phrase 'of our term aggregation system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves'.",
        "sdp_path_text": "accuracy → of → system",
        "sentence": "The accuracy of the term aggregation system is improved.",
        "sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'is improved'. Entity 2 ('term aggregation system') is the object of the preposition 'of', depending on 'of' in the phrase 'of the term aggregation system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'."
    },
    {
        "raw_sentence": "Our proposed method improves the accuracy of our term aggregation system , showing that our approach is successful .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "approach",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('accuracy') is the object, depending on 'improves' with 'method'. Entity 2 ('approach') is the subject, depending on 'is' with 'successful'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the sentence where the method improves accuracy, and the success of the approach is highlighted.",
        "sdp_path_text": "accuracy → improves → showing → is → approach",
        "sentence": "The method improves accuracy, showing the approach is successful.",
        "sentence_llm_dp_info": "Entity 1 ('accuracy') is the object, depending on 'improves' with 'The method'. Entity 2 ('approach') is the subject, depending on 'is' (copula) with 'successful'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the effectiveness of the method described."
    },
    {
        "raw_sentence": "Our proposed method improves the accuracy of our term aggregation system , showing that our approach is successful .",
        "ner_pair": [
            [
                "term aggregation system",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('term aggregation system') is the object of the preposition 'of', depending on 'accuracy'. Entity 2 ('approach') is the subject, depending on 'is' with 'successful'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verb 'improves' and the conjunction 'that' which introduces a clause describing the success of the approach.",
        "sdp_path_text": "system → of → accuracy → improves → showing → is → approach",
        "sentence": "The term aggregation system's accuracy improvement shows the approach is successful.",
        "sentence_llm_dp_info": "Entity 1 ('term aggregation system') is part of the possessive noun phrase, depending on 'accuracy' with the possessive modifier 'system’s'. Entity 2 ('approach') is the subject complement, depending on 'is' with 'successful'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sentence structure where the improvement of the accuracy of Entity 1 demonstrates the success of Entity 2."
    },
    {
        "raw_sentence": "In this work , we present a technique for robust estimation , which by explicitly incorporating the inherent uncertainty of the estimation procedure , results in a more efficient robust estimation algorithm .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "robust estimation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('technique') is the subject, depending on 'present' with 'we'. Entity 2 ('robust estimation') is part of a noun phrase, depending on 'for' in the phrase 'for robust estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "technique → for → estimation",
        "sentence": "We present a technique for robust estimation.",
        "sentence_llm_dp_info": "Entity 1 ('technique') is the direct object, depending on the verb 'present'. Entity 2 ('robust estimation') is the object of the preposition 'for', depending on 'for' in the phrase 'for robust estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "In this work , we present a technique for robust estimation , which by explicitly incorporating the inherent uncertainty of the estimation procedure , results in a more efficient robust estimation algorithm .",
        "ner_pair": [
            [
                "inherent uncertainty of the estimation procedure",
                "OtherScientificTerm"
            ],
            [
                "technique",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('inherent uncertainty of the estimation procedure') is the object of the preposition 'of', depending on 'incorporating'. Entity 2 ('technique') is the subject, depending on 'present' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporating' and the preposition 'of'.",
        "sdp_path_text": "uncertainty → incorporating → by → results → technique",
        "sentence": "The technique incorporates the inherent uncertainty of the estimation procedure to result in a more efficient robust estimation algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('inherent uncertainty of the estimation procedure') is the object of the preposition 'of', depending on 'incorporates' which is part of the verb phrase describing what the 'technique' does. Entity 2 ('technique') is the subject, depending on the verb 'incorporates'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 1 is incorporated by Entity 2 through the verb 'incorporates'."
    },
    {
        "raw_sentence": "In this work , we present a technique for robust estimation , which by explicitly incorporating the inherent uncertainty of the estimation procedure , results in a more efficient robust estimation algorithm .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "efficient robust estimation algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('technique') is the subject, depending on 'present' with 'we'. Entity 2 ('efficient robust estimation algorithm') is the subject complement, depending on 'results' with 'technique'. There is a direct dependency between Entity 1 and Entity 2, as the 'technique' leads to the 'efficient robust estimation algorithm' through the verb 'results'.",
        "sdp_path_text": "technique → results → in → algorithm",
        "sentence": "The technique results in an efficient robust estimation algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('technique') is the subject, depending on the verb 'results'. Entity 2 ('efficient robust estimation algorithm') is the complement, depending on the preposition 'in' with 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'results' and the preposition 'in'."
    },
    {
        "raw_sentence": "In this work , we present a technique for robust estimation , which by explicitly incorporating the inherent uncertainty of the estimation procedure , results in a more efficient robust estimation algorithm .",
        "ner_pair": [
            [
                "robust estimation",
                "Task"
            ],
            [
                "inherent uncertainty of the estimation procedure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust estimation') is part of the object of the preposition 'for', depending on 'technique'. Entity 2 ('inherent uncertainty of the estimation procedure') is the object of the preposition 'of', depending on 'incorporating'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of the technique being described.",
        "sdp_path_text": "estimation → for → technique → results → by → incorporating → uncertainty",
        "sentence": "The technique for robust estimation results by incorporating the inherent uncertainty of the estimation procedure.",
        "sentence_llm_dp_info": "Entity 1 ('robust estimation') is part of the noun phrase 'technique for robust estimation', depending on 'for' which modifies 'technique'. Entity 2 ('inherent uncertainty of the estimation procedure') is the object of the preposition 'the', forming the prepositional phrase 'of the estimation procedure', and it is also the complement of the verb 'incorporating'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger context where 'robust estimation' is the target of the technique, and 'inherent uncertainty of the estimation procedure' is what is being incorporated into the results."
    },
    {
        "raw_sentence": "In this work , we present a technique for robust estimation , which by explicitly incorporating the inherent uncertainty of the estimation procedure , results in a more efficient robust estimation algorithm .",
        "ner_pair": [
            [
                "inherent uncertainty of the estimation procedure",
                "OtherScientificTerm"
            ],
            [
                "efficient robust estimation algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('inherent uncertainty of the estimation procedure') is the object of the preposition 'of', depending on 'incorporating'. Entity 2 ('efficient robust estimation algorithm') is the object, depending on 'results in'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the outcome of the technique presented.",
        "sdp_path_text": "uncertainty → incorporating → by → results → in → algorithm",
        "sentence": "Incorporating the inherent uncertainty of the estimation procedure results in a more efficient robust estimation algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('inherent uncertainty of the estimation procedure') is the subject complement, depending on the verb 'incorporating'. Entity 2 ('efficient robust estimation algorithm') is the object complement, depending on the verb 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verbs 'incorporating' and 'results'."
    },
    {
        "raw_sentence": "In addition , we build on recent work in randomized model verification , and use this to characterize the ` non-randomness ' of a solution .",
        "ner_pair": [
            [
                "randomized model verification",
                "Task"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('randomized model verification') is the object of the preposition 'in', depending on 'work'. Entity 2 ('this') is the object of the verb 'use', depending on 'use' in the phrase 'use this to characterize'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence.",
        "sdp_path_text": "verification → in → work → on → build → use → this",
        "sentence": "We build on recent work in randomized model verification and use this to characterize the 'non-randomness' of a solution.",
        "sentence_llm_dp_info": "Entity 1 ('randomized model verification') is the object of the preposition 'in', depending on the verb 'build'. Entity 2 ('this') is the subject, depending on the verb 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "strategies",
                "Generic"
            ],
            [
                "robust estimation procedure",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('strategies') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('robust estimation procedure') is the object of the preposition 'in', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'results' which indicates the outcome of combining the strategies mentioned.",
        "sdp_path_text": "strategies → of → combination → results → in → procedure",
        "sentence": "The combination of strategies results in a robust estimation procedure.",
        "sentence_llm_dp_info": "Entity 1 ('strategies') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('robust estimation procedure') is the subject complement, depending on 'results in'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'results in' and the noun 'combination'."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "strategies",
                "Generic"
            ],
            [
                "RANSAC techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('strategies') is part of the subject complement, depending on 'combination' in the phrase 'combination of these two strategies'. Entity 2 ('RANSAC techniques') is the object of the preposition 'over', depending on 'speed-up' in the phrase 'speed-up over existing RANSAC techniques'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "strategies → of → combination → results → in → procedure → provides → up → over → techniques",
        "sentence": "The combination of strategies results in a procedure that provides a speed-up over RANSAC techniques.",
        "sentence_llm_dp_info": "Entity 1 ('strategies') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('RANSAC techniques') is the object of the preposition 'over', depending on 'speed-up'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the outcome of the combination of strategies."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "strategies",
                "Generic"
            ],
            [
                "prior information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('strategies') is part of the subject, depending on 'combination' with 'of' in the phrase 'combination of these two strategies'. Entity 2 ('prior information') is the object of the preposition 'information', depending on 'requiring' in the clause 'requiring no prior information'. There is no direct dependency between Entity 1 and Entity 2; both are involved in different clauses of the sentence.",
        "sdp_path_text": "strategies → of → combination → results → in → procedure → provides → requiring → information",
        "sentence": "The combination of strategies results in a procedure that requires no prior information.",
        "sentence_llm_dp_info": "Entity 1 ('strategies') is part of the noun phrase 'combination of strategies', where it is the object of the preposition 'of', depending on 'combination'. Entity 2 ('prior information') is the object of the preposition 'no', depending on 'requires' in the clause 'that requires no prior information'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "strategies",
                "Generic"
            ],
            [
                "sampling process",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('strategies') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('sampling process') is the object of the preposition 'to', depending on 'requiring'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the main clause structure.",
        "sdp_path_text": "strategies → of → combination → results → in → procedure → provides → requiring → guide → process",
        "sentence": "The combination of strategies results in a procedure that requires no prior information to guide the sampling process.",
        "sentence_llm_dp_info": "Entity 1 ('strategies') is part of the noun phrase 'combination of strategies', which is the subject, depending on the verb 'results'. Entity 2 ('sampling process') is the object of the preposition 'the', within the larger noun phrase 'the sampling process', which itself is the object of the verb 'guide'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'results' and the prepositional phrase 'to guide the sampling process'."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "RANSAC techniques",
                "Method"
            ],
            [
                "robust estimation procedure",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('RANSAC techniques') is the object of the preposition 'over', depending on 'speed-up'. Entity 2 ('robust estimation procedure') is the subject complement, depending on 'results' with 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly related through the context of comparison provided by 'speed-up'.",
        "sdp_path_text": "techniques → over → up → provides → procedure",
        "sentence": "The robust estimation procedure provides a significant speed-up over RANSAC techniques.",
        "sentence_llm_dp_info": "Entity 1 ('RANSAC techniques') is the complement of the preposition 'over', depending on 'over' in the phrase 'over RANSAC techniques'. Entity 2 ('robust estimation procedure') is the subject, depending on the verb 'provides'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'provides' which indicates that Entity 2 provides something (a significant speed-up) in comparison to Entity 1."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "robust estimation procedure",
                "Method"
            ],
            [
                "prior information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust estimation procedure') is the object of the preposition 'in', depending on 'results'. Entity 2 ('prior information') is the object of the preposition 'no', depending on 'requiring'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the outcomes of the strategies.",
        "sdp_path_text": "procedure → provides → requiring → information",
        "sentence": "The robust estimation procedure requires no prior information.",
        "sentence_llm_dp_info": "Entity 1 ('robust estimation procedure') is the subject, depending on the verb 'requires'. Entity 2 ('prior information') is the object, depending on 'requires' with 'robust estimation procedure'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly required by Entity 1."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "robust estimation procedure",
                "Method"
            ],
            [
                "sampling process",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust estimation procedure') is the object of the preposition 'in', depending on 'results'. Entity 2 ('sampling process') is the object of the preposition 'to', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "procedure → provides → requiring → guide → process",
        "sentence": "The robust estimation procedure requires no prior information to guide the sampling process.",
        "sentence_llm_dp_info": "Entity 1 ('robust estimation procedure') is the subject, depending on 'requires' as the main verb. Entity 2 ('sampling process') is the object of the preposition 'the', part of the noun phrase 'the sampling process', which is further modified by the verb phrase 'to guide'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'requires' and the prepositional phrase 'to guide the sampling process'."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "RANSAC techniques",
                "Method"
            ],
            [
                "prior information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('RANSAC techniques') is the object of the preposition 'over', depending on 'speed-up'. Entity 2 ('prior information') is the object of the preposition 'to', depending on 'requiring'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the benefits of the estimation procedure.",
        "sdp_path_text": "techniques → over → up → provides → requiring → information",
        "sentence": "RANSAC techniques require no prior information for a significant speed-up.",
        "sentence_llm_dp_info": "Entity 1 ('RANSAC techniques') is the subject, depending on the verb 'require'. Entity 2 ('prior information') is the object, depending on 'require' with 'RANSAC techniques'. There is a direct dependency between Entity 1 and Entity 2, as 'RANSAC techniques' requires 'prior information'.\" \n\nHowever, it's important to note that the sentence actually states that \"RANSAC techniques require no prior information,\" which implies that there is a negation involved. A more precise dependency analysis would be:\n\nEntity 1 ('RANSAC techniques') is the subject, depending on the verb 'require'. Entity 2 ('prior information') is the object of the negated requirement, depending on 'require' with 'RANSAC techniques'. There is a direct dependency between Entity 1 and Entity 2, but this dependency is negated, indicating that 'RANSAC techniques' do not require 'prior information'."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "RANSAC techniques",
                "Method"
            ],
            [
                "sampling process",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('RANSAC techniques') is the object of the preposition 'over', depending on 'speed-up'. Entity 2 ('sampling process') is the object of the preposition 'to', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "techniques → over → up → provides → requiring → guide → process",
        "sentence": "RANSAC techniques require no prior information to guide the sampling process.",
        "sentence_llm_dp_info": "Entity 1 ('RANSAC techniques') is the subject, depending on the verb 'require'. Entity 2 ('sampling process') is the object of the preposition 'to', depending on 'guide' in the phrase 'to guide the sampling process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'require' and the prepositional phrase 'to guide the sampling process'."
    },
    {
        "raw_sentence": "The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques , while requiring no prior information to guide the sampling process .",
        "ner_pair": [
            [
                "prior information",
                "OtherScientificTerm"
            ],
            [
                "sampling process",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('prior information') is the object of the preposition 'no', depending on 'requiring' with 'that'. Entity 2 ('sampling process') is the object of the preposition 'to', depending on 'guide' with 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requiring' and the preposition 'to'.",
        "sdp_path_text": "information → requiring → guide → process",
        "sentence": "Prior information is required to guide the sampling process.",
        "sentence_llm_dp_info": "Entity 1 ('prior information') is the subject, depending on the verb 'required'. Entity 2 ('sampling process') is the object of the preposition 'the', depending on 'guide' in the phrase 'to guide the sampling process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'guide'."
    },
    {
        "raw_sentence": "In particular , our algorithm requires , on average , 3-10 times fewer samples than standard RANSAC , which is in close agreement with theoretical predictions .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "RANSAC",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on 'requires' with 'our'. Entity 2 ('RANSAC') is the object of comparison, depending on 'than' in the comparative clause 'than standard RANSAC'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicating that the algorithm requires fewer samples compared to RANSAC.",
        "sdp_path_text": "algorithm → requires → samples → than → RANSAC",
        "sentence": "The algorithm requires fewer samples than RANSAC.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'requires'. Entity 2 ('RANSAC') is the object of comparison, depending on the comparative conjunction 'than'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure 'fewer samples than'."
    },
    {
        "raw_sentence": "In particular , our algorithm requires , on average , 3-10 times fewer samples than standard RANSAC , which is in close agreement with theoretical predictions .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "theoretical predictions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on 'requires' with 'our'. Entity 2 ('theoretical predictions') is the object, depending on 'agreement' with 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the agreement between the algorithm's performance and the theoretical predictions.",
        "sdp_path_text": "algorithm → requires → samples → is → in → agreement → with → predictions",
        "sentence": "The algorithm requires fewer samples in agreement with theoretical predictions.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'requires'. Entity 2 ('theoretical predictions') is the object of the preposition 'with', depending on 'agreement'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'in agreement with theoretical predictions'."
    },
    {
        "raw_sentence": "In particular , our algorithm requires , on average , 3-10 times fewer samples than standard RANSAC , which is in close agreement with theoretical predictions .",
        "ner_pair": [
            [
                "RANSAC",
                "Method"
            ],
            [
                "theoretical predictions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('RANSAC') is the object of the preposition 'than', depending on 'fewer'. Entity 2 ('theoretical predictions') is the object of the preposition 'with', depending on 'agreement'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of clauses that describe the performance and validation of the algorithm being discussed.",
        "sdp_path_text": "RANSAC → than → samples → is → in → agreement → with → predictions",
        "sentence": "RANSAC requires fewer samples, in agreement with theoretical predictions.",
        "sentence_llm_dp_info": "Entity 1 ('RANSAC') is the subject, depending on the verb 'requires'. Entity 2 ('theoretical predictions') is the object of the preposition 'with', depending on 'with' in the phrase 'in agreement with theoretical predictions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in agreement with'."
    },
    {
        "raw_sentence": "The efficiency of the algorithm is demonstrated on a selection of geometric estimation problems .",
        "ner_pair": [
            [
                "geometric estimation problems",
                "Task"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('geometric estimation problems') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('algorithm') is the object of the preposition 'of', depending on 'efficiency'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing what is being demonstrated.",
        "sdp_path_text": "problems → of → selection → on → demonstrated → efficiency → of → algorithm",
        "sentence": "The algorithm's efficiency is demonstrated on geometric estimation problems.",
        "sentence_llm_dp_info": "Entity 1 ('geometric estimation problems') is the object, depending on the preposition 'on', which modifies 'demonstrated'. Entity 2 ('algorithm') is part of the possessive noun phrase 'The algorithm's', modifying 'efficiency'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrated' and the preposition 'on'."
    },
    {
        "raw_sentence": "An attempt has been made to use an Augmented Transition Network as a procedural dialog model .",
        "ner_pair": [
            [
                "Augmented Transition Network",
                "Method"
            ],
            [
                "dialog model",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Augmented Transition Network') is the object of the preposition 'as', depending on 'use'. Entity 2 ('dialog model') is the complement of 'as', specifying what the 'Augmented Transition Network' is used as. There is a direct dependency between Entity 1 and Entity 2, as 'dialog model' is the complement that defines the role of 'Augmented Transition Network' in the sentence.",
        "sdp_path_text": "Network → use → as → model",
        "sentence": "An Augmented Transition Network has been used as a dialog model.",
        "sentence_llm_dp_info": "Entity 1 ('Augmented Transition Network') is the subject, depending on the verb 'used'. Entity 2 ('dialog model') is the complement, depending on the preposition 'as', which is part of the phrase 'as a dialog model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "device",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'appears to be'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and contribute to the description of the importance of the model in various respects.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → device",
        "sentence": "The development of a model appears to be important as a device.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('device') is the complement of the preposition 'as', depending on 'important'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the importance of the development of a model."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger structure where 'model' is discussed in the context of representing and using 'dialog schemata' among other aspects.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → device → represent → use → schemata",
        "sentence": "The development of a model is important as a device to represent and use dialog schemata.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('dialog schemata') is the object of the preposition 'to', depending on 'device'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause that describes the purpose of the model's development."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "conversation analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('conversation analysis') is the object of the preposition 'in', part of the phrase 'in empirical conversation analysis', which modifies 'schemata'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where the model is described as a device that represents and uses different dialog schemata proposed in empirical conversation analysis.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → device → represent → use → schemata → proposed → in → analysis",
        "sentence": "The development of a model is important for representing and using dialog schemata proposed in conversation analysis.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('conversation analysis') is the subject complement, depending on 'proposed'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause 'dialog schemata proposed in conversation analysis'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "device",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('device') is the subject complement, depending on 'be' in the clause 'appears to be important'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger structure where 'model' is described as being important in the context of being a 'device' for various purposes.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → device",
        "sentence": "The development of a model appears to be important as a device.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('device') is the complement of the preposition 'as', depending on 'important'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the importance of the model's development."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('verbal interaction') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the importance and uses of the model.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → as → device → represent → use → models → of → interaction",
        "sentence": "The development of a model appears important to represent and use models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'models' in the sentence."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "device",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'appears to be'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger context where 'model' is described as being important in several respects, one of which involves its role as a 'device'.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → device",
        "sentence": "The development of a model appears to be important as a device.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('device') is the complement of the preposition 'as', depending on 'important'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'appears' and the preposition 'as'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the importance of the model in representing and using different dialog schemata.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → device → represent → use → schemata",
        "sentence": "The development of a model is important for representing and using dialog schemata.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('dialog schemata') is the object of the preposition 'for', depending on 'important'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'is' and the prepositions 'of' and 'for'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development' in the phrase 'the development of such a model'. Entity 2 ('verbal interaction') is part of a compound noun, depending on 'models' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where both are part of the list of uses for the model described.",
        "sdp_path_text": "model → of → development → appears → be → in → respects → as → as → device → represent → use → models → of → interaction",
        "sentence": "The development of a model appears important to represent and use models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'model' is part of the 'development' and 'verbal interaction' is part of the 'models' that are represented and used."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'about', depending on 'about' in the phrase 'about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a larger structure where 'model' is described as a device that combines knowledge about various aspects, including 'task-oriented and goal-directed dialogs'.",
        "sdp_path_text": "model → of → development → appears → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "The development of a model combines knowledge about task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the object of the preposition 'of', depending on 'development'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing what the development of the model combines."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'device'. Entity 2 ('device') is the subject complement, depending on 'be' with 'appears'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'about dialog schemata' which modifies 'device'.\"\n\nThis analysis shows how 'dialog schemata' and 'device' are related within the context of the sentence, highlighting that while they do not directly depend on each other, they are part of a larger structure where 'dialog schemata' is one of the aspects that 'device' represents or uses.",
        "sdp_path_text": "schemata → use → represent → device",
        "sentence": "{\n  \"Simplified sentence\": \"Dialog schemata are used to represent and as a device.\"\n} \n\nHowever, this sentence could be clearer. Let's refine it further to maintain the relationship and clarity:\n\n{\n  \"Simplified sentence\": \"A device represents and uses dialog schemata.\"\n}",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object, depending on 'uses' with 'device'. Entity 2 ('device') is the subject, depending on the verb 'represents' and also 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'device' uses 'dialog schemata'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "conversation analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on 'appears' with 'important'. Entity 2 ('conversation analysis') is part of a noun phrase, depending on 'proposed' with 'schemata'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where 'device' is used to represent and use different dialog schemata proposed in 'conversation analysis'.",
        "sdp_path_text": "device → represent → use → schemata → proposed → in → analysis",
        "sentence": "A device represents and uses dialog schemata proposed in conversation analysis.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'represents' and also 'uses'. Entity 2 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'proposed' and the preposition 'in'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'dialog schemata'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'appears to be important'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the importance and uses of the model as a device.",
        "sdp_path_text": "models → use → represent → device → as → as → device",
        "sentence": "Models are used to represent and serve as devices.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'are used'. Entity 2 ('device') is the object of the preposition 'as', depending on 'serve' in the phrase 'serve as devices'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'serve' and the preposition 'as'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on 'be' (appears to be) with 'important'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger structure where 'device' is described as a tool for representing and using 'models of verbal interaction' among other things.",
        "sdp_path_text": "device → as → as → device → represent → use → models → of → interaction",
        "sentence": "A device represents and uses models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'represents' and also on the verb 'uses'. Entity 2 ('verbal interaction') is part of the noun phrase functioning as the object of the preposition 'of', which modifies 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'represents' and 'uses' and the noun 'models'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'about' in the phrase 'about dialog schemata'. Entity 2 ('device') is the subject, depending on the verb 'appears' with 'The development'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the prepositional phrase 'as a device to represent and to use different dialog schemata'.",
        "sdp_path_text": "schemata → use → represent → device",
        "sentence": "A device represents and uses dialog schemata.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object, depending on 'uses' with 'device'. Entity 2 ('device') is the subject, depending on the verbs 'represents' and 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'device' uses 'dialog schemata'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on 'be' (appears to be) with 'important'. Entity 2 ('verbal interaction') is the object, depending on 'of' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the verb 'represent'.",
        "sdp_path_text": "device → as → as → device → represent → use → models → of → interaction",
        "sentence": "A device represents and uses models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'represents' and also the subject of the verb 'uses'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'represents' and 'uses' and the noun 'models'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on 'be' (appears to be) and is modified by 'as a device to represent and to use different dialog schemata proposed in empirical conversation analysis; as a device to represent and to use models of verbal interaction; as a device combining knowledge about dialog schemata and about verbal interaction'. Entity 2 ('task-oriented and goal-directed dialogs') is the object, depending on 'with' in the phrase 'with knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which links the knowledge being combined.",
        "sdp_path_text": "device → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "A device combines knowledge about task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'combines'. Entity 2 ('task-oriented and goal-directed dialogs') is the object, depending on 'combines' with 'device'. There is a direct dependency between Entity 1 and Entity 2, as 'device' combines 'task-oriented and goal-directed dialogs'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "conversation analysis",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object, depending on 'use' and part of the prepositional phrase 'of different dialog schemata'. Entity 2 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause where 'dialog schemata' are described as being proposed in 'conversation analysis'.",
        "sdp_path_text": "schemata → proposed → in → analysis",
        "sentence": "Dialog schemata proposed in conversation analysis.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the verb 'proposed'. Entity 2 ('conversation analysis') is the object of the preposition 'in', depending on 'in' in the phrase 'in conversation analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'about' in the phrase 'about dialog schemata'. Entity 2 ('device') is the subject complement, depending on 'be' with 'appears'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of a larger structure where 'device' is used to describe something that represents and uses 'dialog schemata'.",
        "sdp_path_text": "schemata → use → represent → device",
        "sentence": "{\n  \"Simplified sentence\": \"Dialog schemata are used to represent and as a device.\"\n} \n\nHowever, this sentence can be further refined for clarity and grammatical correctness:\n\n{\n  \"Simplified sentence\": \"Dialog schemata are used as a device to represent.\"\n}",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the passive verb 'are used'. Entity 2 ('device') is the complement of the preposition 'as', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as' indicating the role of 'dialog schemata' as a 'device'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "models",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'of', depending on 'device'. Entity 2 ('models') is also the object of the preposition 'of', depending on 'device'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses that describe different aspects of the same 'device'.",
        "sdp_path_text": "schemata → use → represent → device → as → as → device → represent → use → models",
        "sentence": "Dialog schemata are used to represent and model verbal interactions.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the verb 'are used'. Entity 2 ('models') is part of the verb phrase 'to model', which is a predicate complement of 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'are used' and the conjunction 'and' that connects 'represent' and 'model'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about dialog schemata'. Entity 2 ('verbal interaction') is also the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a larger structure where they serve similar roles as objects of the preposition 'about'.",
        "sdp_path_text": "schemata → use → represent → device → as → as → device → represent → use → models → of → interaction",
        "sentence": "Dialog schemata and verbal interaction are used to represent and model interactions.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the verb 'are used'. Entity 2 ('verbal interaction') is coordinated with 'dialog schemata' through the conjunction 'and', also depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a coordinated subject."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'device'. Entity 2 ('device') is the subject complement, depending on the verb 'be' in the clause 'appears to be important'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'about' which links 'dialog schemata' to 'device'.",
        "sdp_path_text": "schemata → use → represent → device",
        "sentence": "A device represents and uses dialog schemata.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object, depending on the verb 'represents' with 'device'. Entity 2 ('device') is the subject, depending on the verbs 'represents' and 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'dialog schemata' is directly acted upon by 'device' in both representing and using."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge'. Entity 2 ('verbal interaction') is also the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the conjunction 'and' within the context of 'knowledge about'.",
        "sdp_path_text": "schemata → use → represent → device → as → as → device → represent → use → models → of → interaction",
        "sentence": "Dialog schemata and verbal interaction are used and represented as devices.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is a conjunct, depending on 'and' with 'verbal interaction'. Entity 2 ('verbal interaction') is also a conjunct, depending on 'and' with 'dialog schemata'. Both entities together form the subject of the sentence, depending on the verb 'are used'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated by the conjunction 'and'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about dialog schemata'. Entity 2 ('task-oriented and goal-directed dialogs') is also the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger structure describing the aspects that the knowledge combines.",
        "sdp_path_text": "schemata → use → represent → device → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "Dialog schemata are used to represent task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the passive verb 'are used'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'to', depending on 'represent' in the phrase 'to represent task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'represent'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "conversation analysis",
                "Method"
            ],
            [
                "device",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed' within the clause 'dialog schemata proposed in empirical conversation analysis'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'appears to be important as a device'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the larger sentence.",
        "sdp_path_text": "analysis → in → proposed → schemata → use → represent → device",
        "sentence": "A device represents and uses dialog schemata proposed in conversation analysis.",
        "sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed'. Entity 2 ('device') is the subject, depending on the verb 'represents' and also the subject of the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'represents' and 'uses' which describe actions related to the 'dialog schemata' proposed in 'conversation analysis'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "conversation analysis",
                "Method"
            ],
            [
                "models",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'analysis' in the phrase 'empirical conversation analysis'. Entity 2 ('models') is the object of the preposition 'of', depending on 'of' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing the importance of developing a model that can represent and use various aspects of dialogue and interaction.",
        "sdp_path_text": "analysis → in → proposed → schemata → use → represent → device → as → as → device → represent → use → models",
        "sentence": "Conversation analysis proposes schemata used to represent and use models.",
        "sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the subject, depending on the verb 'proposes'. Entity 2 ('models') is the object, depending on the verb 'propose' through the prepositional phrase 'used to represent and use models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'proposes' and the prepositional phrase."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "conversation analysis",
                "Method"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed' within the clause 'dialog schemata proposed in empirical conversation analysis'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses that describe aspects of the model's importance.",
        "sdp_path_text": "analysis → in → proposed → schemata → use → represent → device → as → as → device → represent → use → models → of → interaction",
        "sentence": "Conversation analysis proposes schemata to represent and use models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the subject, depending on the verb 'proposes'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of dependencies involving 'proposes', 'schemata', and 'models'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "conversation analysis",
                "Method"
            ],
            [
                "device",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'analysis' within the phrase 'empirical conversation analysis'. Entity 2 ('device') is the subject, depending on the preposition 'as' in the repeated structure 'as a device to...'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger clauses that describe the importance and functions of the model being discussed.",
        "sdp_path_text": "analysis → in → proposed → schemata → use → represent → device",
        "sentence": "A device is used to represent and use dialog schemata proposed in conversation analysis.",
        "sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed'. Entity 2 ('device') is the subject, depending on the verb 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'proposed' and the purpose clause introduced by 'to represent and use dialog schemata'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "conversation analysis",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'of', depending on 'device'. Entity 2 ('conversation analysis') is the object of the preposition 'in', depending on 'proposed'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause and related through the context provided by the sentence, where 'dialog schemata' are mentioned as being proposed in 'conversation analysis'.",
        "sdp_path_text": "schemata → proposed → in → analysis",
        "sentence": "Dialog schemata proposed in conversation analysis.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the verb 'proposed'. Entity 2 ('conversation analysis') is the object of the preposition 'in', depending on 'in' in the phrase 'in conversation analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "conversation analysis",
                "Method"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the object of the preposition 'in', depending on 'analysis' in the phrase 'empirical conversation analysis'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the importance of the model being discussed.",
        "sdp_path_text": "analysis → in → proposed → schemata → use → represent → device → as → as → device → represent → use → models → of → interaction",
        "sentence": "Conversation analysis proposes schemata to represent and use models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the subject, depending on the verb 'proposes'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'proposes' and the prepositional phrase 'of verbal interaction'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "conversation analysis",
                "Method"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conversation analysis') is part of a noun phrase, where it is the object of the preposition 'in', depending on 'proposed'. Entity 2 ('task-oriented and goal-directed dialogs') is also part of a noun phrase, where it is the object of the preposition 'with', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2; both are part of complex noun phrases that describe aspects of the model being discussed.",
        "sdp_path_text": "analysis → in → proposed → schemata → use → represent → device → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "Conversation analysis proposes schemata used in devices combining knowledge about task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('conversation analysis') is the subject, depending on the verb 'proposes'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'knowledge' and the preposition 'about'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'dialog schemata'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'as a device'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger structure where 'device' is used to describe how 'models' can be utilized in the context of the sentence.",
        "sdp_path_text": "models → use → represent → device → as → as → device",
        "sentence": "Models are used to represent and serve as devices.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'are used'. Entity 2 ('device') is the object of the preposition 'as', depending on 'serve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'serve' and the preposition 'as'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'appears' with the phrase 'The development of such a model appears to be important'. Entity 2 ('verbal interaction') is the object, depending on 'use' in the clause 'to use models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger structure where 'device' is used to represent and use models including those of 'verbal interaction'.",
        "sdp_path_text": "device → as → as → device → represent → use → models → of → interaction",
        "sentence": "A device represents and uses models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'represents' and also the subject of the verb 'uses'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'represents' and 'uses' and the prepositional phrase 'of verbal interaction'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'about' in the phrase 'about dialog schemata'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'appears to be'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'about' and the verb 'represent'.",
        "sdp_path_text": "schemata → use → represent → device",
        "sentence": "{\n  \"Simplified sentence\": \"Dialog schemata are used to represent and as a device.\"\n} \n\nHowever, this sentence can be further refined for better clarity and grammatical correctness:\n\n{\n  \"Simplified sentence\": \"Dialog schemata are used as a device to represent.\"\n}",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the verb 'are used'. Entity 2 ('device') is the object of the preposition 'as', depending on 'as' in the phrase 'as a device'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'appears' with the complement 'to be important'. Entity 2 ('verbal interaction') is the object, depending on 'use' in the phrase 'to use models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'of' in the context of describing the purpose of the device.",
        "sdp_path_text": "device → as → as → device → represent → use → models → of → interaction",
        "sentence": "A device represents and uses models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'represents' and 'uses'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'uses' and the prepositional phrase 'of verbal interaction'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on 'be' with 'appears'. Entity 2 ('task-oriented and goal-directed dialogs') is the object, depending on 'with' in the phrase 'with knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.",
        "sdp_path_text": "device → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "A device combines knowledge about task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'combines'. Entity 2 ('task-oriented and goal-directed dialogs') is the object, depending on 'combines' with 'device'. There is a direct dependency between Entity 1 and Entity 2, as 'device' combines 'task-oriented and goal-directed dialogs'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'device' in the phrase 'as a device to represent and to use models'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'interaction' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'of' and are part of the same list structure introduced by 'as a device to represent and to use'.",
        "sdp_path_text": "models → of → interaction",
        "sentence": "Models of verbal interaction are important.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'are'. Entity 2 ('verbal interaction') is the complement, depending on 'models' with the preposition 'of'. There is a direct dependency between Entity 1 and Entity 2, as 'verbal interaction' modifies 'models' through the preposition 'of'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'dialog schemata'. Entity 2 ('device') is the subject complement, depending on 'be' in the phrase 'as a device'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses that describe the importance of the development of the model.\"\n\nTo provide a more detailed breakdown:\n- \"models\" is part of the phrase \"different dialog schemata proposed in empirical conversation analysis,\" where it is the object of the preposition \"of.\"\n- \"device\" appears multiple times in the sentence, each time as a subject complement to the verb \"be\" (e.g., \"as a device to represent and to use different dialog schemata\"). Each instance of \"device\" is used to describe a function or purpose of the model being developed.\n\nThe entities \"models\" and \"device\" are not directly dependent on each other but are both integral to describing the various roles and significance of the model in the context of the sentence.",
        "sdp_path_text": "models → use → represent → device → as → as → device",
        "sentence": "Models are used as devices to represent and use dialog schemata and verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'are used'. Entity 2 ('device') is the object of the preposition 'as', depending on 'used' in the phrase 'used as devices'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the preposition 'as'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'device' in the phrase 'as a device to represent and to use models'. Entity 2 ('dialog schemata') is also the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about dialog schemata'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of representation and use in the context of devices and knowledge.",
        "sdp_path_text": "models → use → represent → device → as → as → device → represent → use → schemata",
        "sentence": "Models are used to represent and utilize dialog schemata.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'are used'. Entity 2 ('dialog schemata') is the object, depending on 'represent and utilize' with 'to'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'represent' and 'utilize' which describe actions performed on Entity 2 by Entity 1."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'device' in the phrase 'as a device to represent and to use models'. Entity 2 ('verbal interaction') is also the object of the preposition 'of', depending on 'interaction' in the phrase 'models of verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the preposition 'of' and are part of the same conceptual structure described in the sentence.",
        "sdp_path_text": "models → of → interaction",
        "sentence": "Models represent and use models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'represent' and also the object of the verb 'use'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of verbal interaction'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'of', depending on 'device'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the importance and uses of the model.",
        "sdp_path_text": "models → use → represent → device → as → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "Models are used as devices to represent task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'are used'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the verb 'represent', depending on 'to represent' in the phrase 'to represent task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'are used' and 'to represent'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('verbal interaction') is the object, depending on the preposition 'of' in the phrase 'models of verbal interaction'. Entity 2 ('device') is the subject, depending on the preposition 'as' in the phrase 'as a device'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'device' serves as a tool for representing and using 'models of verbal interaction'.",
        "sdp_path_text": "interaction → of → models → use → represent → device → as → as → device",
        "sentence": "A device represents and uses models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. Entity 2 ('device') is the subject, depending on the verbs 'represents' and 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the noun 'models'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about dialog schemata'. Entity 2 ('verbal interaction') is also the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but both are related to 'knowledge' through the preposition 'about'.",
        "sdp_path_text": "schemata → use → represent → device → as → as → device → represent → use → models → of → interaction",
        "sentence": "Dialog schemata and verbal interaction are represented and used as devices.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is part of a coordination, depending on the conjunction 'and' with 'verbal interaction'. Entity 2 ('verbal interaction') is also part of the coordination, depending on the conjunction 'and' with 'dialog schemata'. Both are subjects, depending on the verb 'are' in the clause 'are represented and used as devices'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'with', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the aspects of the model's importance.",
        "sdp_path_text": "interaction → of → models → use → represent → device → as → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "Verbal interaction models are used to represent task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('verbal interaction') is part of a compound noun 'verbal interaction models', which is the subject, depending on the verb 'are used'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'to', depending on 'represent' in the phrase 'to represent task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'represent'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "device",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge'. Entity 2 ('device') is the subject complement, depending on 'be' in the clause 'appears to be important'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same complex sentence structure where 'dialog schemata' is mentioned as one of the aspects that the 'device' represents and uses.",
        "sdp_path_text": "schemata → use → represent → device",
        "sentence": "A device represents and uses dialog schemata.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object, depending on 'represents' and 'uses' with 'device'. Entity 2 ('device') is the subject, depending on the verbs 'represents' and 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'device' performs actions (represents and uses) on 'dialog schemata'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'combining' and 'appears' in the clause 'The development of such a model appears to be important...'. Entity 2 ('verbal interaction') is part of the object, depending on the preposition 'about' in the phrase 'about verbal interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'device' is used in multiple contexts that include references to 'verbal interaction'.",
        "sdp_path_text": "device → as → as → device → represent → use → models → of → interaction",
        "sentence": "A device represents and uses models of verbal interaction.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'represents' and also on 'uses'. Entity 2 ('verbal interaction') is the object of the preposition 'of', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the prepositional phrase 'of verbal interaction'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "device",
                "Generic"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'appears' with 'to be important'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'about', depending on 'combining' in the phrase 'combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'about task-oriented and goal-directed dialogs' which modifies the noun 'knowledge'.",
        "sdp_path_text": "device → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "A device combines knowledge about task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('device') is the subject, depending on the verb 'combines'. Entity 2 ('task-oriented and goal-directed dialogs') is the object, depending on 'combines' with 'device'. There is a direct dependency between Entity 1 and Entity 2, as 'device' combines 'task-oriented and goal-directed dialogs'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge'. Entity 2 ('verbal interaction') is also the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2; both are related to 'knowledge' through the preposition 'about'.",
        "sdp_path_text": "schemata → use → represent → device → as → as → device → represent → use → models → of → interaction",
        "sentence": "Dialog schemata and verbal interaction are used and represented as devices.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is part of a coordination, depending on the conjunction 'and' with 'verbal interaction'. Entity 2 ('verbal interaction') is also part of the same coordination, depending on the conjunction 'and' with 'dialog schemata'. Both entities together form the subject of the sentence, depending on the verb 'are used'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "dialog schemata",
                "OtherScientificTerm"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about dialog schemata'. Entity 2 ('task-oriented and goal-directed dialogs') is also the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger structure where they serve similar roles as objects of the preposition 'about'.",
        "sdp_path_text": "schemata → use → represent → device → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "Dialog schemata are used to represent task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('dialog schemata') is the subject, depending on the verb 'are used'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'to', depending on 'represent' in the phrase 'to represent task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'represent'."
    },
    {
        "raw_sentence": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .",
        "ner_pair": [
            [
                "verbal interaction",
                "OtherScientificTerm"
            ],
            [
                "task-oriented and goal-directed dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('verbal interaction') is part of a compound noun, depending on 'models' with the preposition 'of' in the phrase 'models of verbal interaction'. Entity 2 ('task-oriented and goal-directed dialogs') is also part of a compound noun, depending on 'knowledge' with the preposition 'about' in the phrase 'knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2; both are related to different aspects of the sentence structure.",
        "sdp_path_text": "interaction → of → models → use → represent → device → as → as → respects → in → be → as → device → combining → with → knowledge → about → dialogs",
        "sentence": "Verbal interaction is represented and used in models that combine knowledge about task-oriented and goal-directed dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('verbal interaction') is the subject, depending on the verb 'is' in the clause 'is represented and used'. Entity 2 ('task-oriented and goal-directed dialogs') is the object of the preposition 'about', depending on 'knowledge' in the phrase 'knowledge about task-oriented and goal-directed dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase and the verb 'combine'."
    },
    {
        "raw_sentence": "A standard ATN should be further developed in order to account for the verbal interactions of task-oriented dialogs .",
        "ner_pair": [
            [
                "ATN",
                "Method"
            ],
            [
                "verbal interactions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ATN') is the subject, depending on 'developed' with 'should be further'. Entity 2 ('verbal interactions') is the object of the preposition 'for', depending on 'account for' in the phrase 'to account for the verbal interactions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'in order to account for'.",
        "sdp_path_text": "ATN → developed → in → order → account → for → interactions",
        "sentence": "ATN should be developed to account for verbal interactions.",
        "sentence_llm_dp_info": "Entity 1 ('ATN') is the subject, depending on the verb 'developed'. Entity 2 ('verbal interactions') is the object of the preposition 'for', depending on 'account' in the phrase 'to account for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to account for verbal interactions'."
    },
    {
        "raw_sentence": "A standard ATN should be further developed in order to account for the verbal interactions of task-oriented dialogs .",
        "ner_pair": [
            [
                "ATN",
                "Method"
            ],
            [
                "task-oriented dialogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ATN') is the subject complement, depending on 'developed' with 'should be further'. Entity 2 ('task-oriented dialogs') is the object of the preposition 'for', depending on 'for' in the phrase 'for the verbal interactions of task-oriented dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause introduced by 'in order to account for'.",
        "sdp_path_text": "ATN → developed → in → order → account → for → interactions → of → dialogs",
        "sentence": "ATN should be developed to account for the interactions of task-oriented dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('ATN') is the subject, depending on the verb 'developed'. Entity 2 ('task-oriented dialogs') is the object of the preposition 'for', depending on 'interactions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'to account for the interactions of task-oriented dialogs'."
    },
    {
        "raw_sentence": "A standard ATN should be further developed in order to account for the verbal interactions of task-oriented dialogs .",
        "ner_pair": [
            [
                "verbal interactions",
                "OtherScientificTerm"
            ],
            [
                "task-oriented dialogs",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('verbal interactions') is the object, depending on 'account' with 'in order to'. Entity 2 ('task-oriented dialogs') is the object of the preposition 'of', depending on 'of' in the phrase 'of task-oriented dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase describing what the ATN should account for.",
        "sdp_path_text": "interactions → of → dialogs",
        "sentence": "Verbal interactions occur in task-oriented dialogs.",
        "sentence_llm_dp_info": "Entity 1 ('verbal interactions') is the subject, depending on the verb 'occur'. Entity 2 ('task-oriented dialogs') is the object of the preposition 'in', depending on 'in' in the phrase 'in task-oriented dialogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'."
    },
    {
        "raw_sentence": "We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines .",
        "ner_pair": [
            [
                "unsupervised learning method",
                "Method"
            ],
            [
                "single-snippet answers",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object, depending on the verb 'present' with 'We'. Entity 2 ('single-snippet answers') is the object, depending on the verb 'produce' which is part of the method. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produce' indicating that the method (Entity 1) produces the answers (Entity 2).",
        "sdp_path_text": "method → produce → answers",
        "sentence": "We present an unsupervised learning method to produce single-snippet answers.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object of the verb 'present', depending on 'We'. Entity 2 ('single-snippet answers') is the object of the infinitive 'to produce', depending on 'produce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produce' which is part of the purpose clause 'to produce single-snippet answers'."
    },
    {
        "raw_sentence": "We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines .",
        "ner_pair": [
            [
                "unsupervised learning method",
                "Method"
            ],
            [
                "question answering systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object of the verb 'present', depending on 'We'. Entity 2 ('question answering systems') is the object of the relative clause 'that supplement Web search engines', depending on 'that'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, where Entity 1 is presented as a method used within the domain of Entity 2.",
        "sdp_path_text": "method → produce → systems",
        "sentence": "An unsupervised learning method produces answers for question answering systems.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the subject, depending on the verb 'produces'. Entity 2 ('question answering systems') is the object of the preposition 'for', depending on 'for' in the phrase 'for question answering systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines .",
        "ner_pair": [
            [
                "unsupervised learning method",
                "Method"
            ],
            [
                "Web search engines",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object, depending on 'present' with 'We'. Entity 2 ('Web search engines') is the object of the preposition 'supplement', depending on 'supplement' in the phrase 'that supplement Web search engines'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "method → produce → systems → supplement → engines",
        "sentence": "An unsupervised learning method produces answers for question answering systems that supplement Web search engines.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the subject, depending on the verb 'produces'. Entity 2 ('Web search engines') is the object of the relative clause, depending on 'supplement' in the phrase 'that supplement Web search engines'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the relative clause modifying the noun 'answers'."
    },
    {
        "raw_sentence": "We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines .",
        "ner_pair": [
            [
                "single-snippet answers",
                "OtherScientificTerm"
            ],
            [
                "question answering systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('single-snippet answers') is the object, depending on 'produce' which is part of the infinitive phrase 'to produce'. Entity 2 ('question answering systems') is the object of the relative clause, depending on 'that' which introduces the clause 'that supplement Web search engines'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence describing the function and application of the method presented.",
        "sdp_path_text": "answers → produce → systems",
        "sentence": "We present a method to produce single-snippet answers for question answering systems.",
        "sentence_llm_dp_info": "Entity 1 ('single-snippet answers') is the object, depending on the verb 'produce'. Entity 2 ('question answering systems') is the object of the preposition 'for', depending on 'for' in the phrase 'for question answering systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produce' and the preposition 'for'."
    },
    {
        "raw_sentence": "We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines .",
        "ner_pair": [
            [
                "single-snippet answers",
                "OtherScientificTerm"
            ],
            [
                "Web search engines",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('single-snippet answers') is the object, depending on the verb 'produce'. Entity 2 ('Web search engines') is the object of the relative clause, depending on 'supplement' in the phrase 'that supplement Web search engines'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "answers → produce → systems → supplement → engines",
        "sentence": "A method produces single-snippet answers to supplement Web search engines.",
        "sentence_llm_dp_info": "Entity 1 ('single-snippet answers') is the object, depending on the verb 'produces'. Entity 2 ('Web search engines') is the object of the preposition 'to', depending on 'to' in the phrase 'to supplement Web search engines'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the preposition 'to'."
    },
    {
        "raw_sentence": "We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines .",
        "ner_pair": [
            [
                "question answering systems",
                "Method"
            ],
            [
                "Web search engines",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('question answering systems') is the object of the relative clause, depending on 'that' which modifies 'systems'. Entity 2 ('Web search engines') is the object of the preposition 'to', depending on 'supplement' within the same relative clause. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the relative clause describing the function of the 'question answering systems'.",
        "sdp_path_text": "systems → supplement → engines",
        "sentence": "Question answering systems supplement Web search engines.",
        "sentence_llm_dp_info": "Entity 1 ('question answering systems') is the subject, depending on the verb 'supplement'. Entity 2 ('Web search engines') is the object, depending on 'supplement' with 'question answering systems'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 supplements Entity 2."
    },
    {
        "raw_sentence": "The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "on-line encyclopedias and dictionaries",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('on-line encyclopedias and dictionaries') is the object, depending on 'exploits' with 'method'. There is a direct dependency between Entity 1 and Entity 2, where 'method' exploits 'on-line encyclopedias and dictionaries'.",
        "sdp_path_text": "method → exploits → on",
        "sentence": "The method exploits on-line encyclopedias and dictionaries.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('on-line encyclopedias and dictionaries') is the object, depending on 'exploits' with 'method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' exploits 'on-line encyclopedias and dictionaries'."
    },
    {
        "raw_sentence": "The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "positive and negative definition examples",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('positive and negative definition examples') is the object of the relative clause, depending on 'generate' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'generate' and the preposition 'to' in the phrase 'to generate automatically an arbitrarily large number of positive and negative definition examples'.",
        "sdp_path_text": "method → exploits → generate → number → of → examples",
        "sentence": "The method generates positive and negative definition examples.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'generates'. Entity 2 ('positive and negative definition examples') is the direct object, depending on 'generates' with 'method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is generating 'positive and negative definition examples'."
    },
    {
        "raw_sentence": "The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "svm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('svm') is the object of the preposition 'to', depending on 'train' in the phrase 'to train an svm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the action of training the svm, which is part of the method's process.",
        "sdp_path_text": "method → exploits → generate → number → of → examples → used → train → svm",
        "sentence": "The method exploits resources to generate examples used to train an SVM.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('SVM') is the object of the preposition 'an', depending on 'train' in the phrase 'train an SVM'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of 'train'."
    },
    {
        "raw_sentence": "The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .",
        "ner_pair": [
            [
                "on-line encyclopedias and dictionaries",
                "Material"
            ],
            [
                "positive and negative definition examples",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('on-line encyclopedias and dictionaries') is the object of the preposition 'exploits', depending on 'exploits' with 'The method'. Entity 2 ('positive and negative definition examples') is the object of the verb 'generate', depending on 'generate' with 'to generate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described in the sentence, where Entity 1 is used to generate Entity 2.",
        "sdp_path_text": "on → exploits → generate → number → of → examples",
        "sentence": "The method exploits on-line encyclopedias and dictionaries to generate positive and negative definition examples.",
        "sentence_llm_dp_info": "Entity 1 ('on-line encyclopedias and dictionaries') is the object of the preposition 'exploits', depending on 'exploits' in the phrase 'exploits on-line encyclopedias and dictionaries'. Entity 2 ('positive and negative definition examples') is the object of the infinitive 'to generate', depending on 'generate' in the phrase 'to generate positive and negative definition examples'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the method does."
    },
    {
        "raw_sentence": "The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .",
        "ner_pair": [
            [
                "on-line encyclopedias and dictionaries",
                "Material"
            ],
            [
                "svm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('on-line encyclopedias and dictionaries') is the object of the preposition 'exploits', depending on 'exploits' in the phrase 'exploits on-line encyclopedias and dictionaries'. Entity 2 ('svm') is the object of the preposition 'train', depending on 'train' in the phrase 'train an svm'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence, where Entity 1 provides data that is used to train Entity 2.",
        "sdp_path_text": "on → exploits → generate → number → of → examples → used → train → svm",
        "sentence": "The method exploits on-line encyclopedias and dictionaries to generate examples used to train an SVM.",
        "sentence_llm_dp_info": "Entity 1 ('on-line encyclopedias and dictionaries') is the object of the preposition 'exploits', depending on 'exploits' in the phrase 'exploits on-line encyclopedias and dictionaries'. Entity 2 ('SVM') is the object of the preposition 'train', depending on 'train' in the phrase 'train an SVM'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and contribute to the overall meaning of the sentence, where Entity 1 provides the resources used to generate examples, and Entity 2 is the model being trained with these examples."
    },
    {
        "raw_sentence": "The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .",
        "ner_pair": [
            [
                "positive and negative definition examples",
                "Material"
            ],
            [
                "svm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('positive and negative definition examples') is the object, depending on 'generate' with 'method'. Entity 2 ('svm') is the object, depending on 'train' with 'examples'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'train'.",
        "sdp_path_text": "examples → used → train → svm",
        "sentence": "Positive and negative definition examples are used to train an SVM.",
        "sentence_llm_dp_info": "Entity 1 ('positive and negative definition examples') is the subject, depending on 'used' with the verb 'are used'. Entity 2 ('SVM') is the object of the preposition 'an', depending on 'train' in the phrase 'to train an SVM'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the preposition 'to train'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject complement, depending on the verb 'is' with 'viable'. Entity 2 ('it') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but 'it' refers back to 'the proposed method', indicating a coreference relationship rather than a syntactic dependency.",
        "sdp_path_text": "method → is → outperforms → it",
        "sentence": "The proposed method outperforms it.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('it') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is the subject performing the action on 'it'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "alternative",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject complement, depending on the verb 'is' in the clause 'the proposed method is viable'. Entity 2 ('alternative') is the object of the preposition 'of', depending on 'of' in the phrase 'the alternative of training the system on questions and news articles from trec'. There is no direct dependency between Entity 1 and Entity 2, but they are part of different clauses that are coordinated in the sentence.",
        "sdp_path_text": "method → is → outperforms → alternative",
        "sentence": "The method outperforms the alternative.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('alternative') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, as 'method' outperforms 'alternative'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "system",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'is' in the clause 'the proposed method is viable'. Entity 2 ('system') is the object of the preposition 'on', depending on 'training' in the phrase 'training the system on questions and news articles from trec'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same broader context describing the effectiveness and application of the method.",
        "sdp_path_text": "method → is → outperforms → alternative → of → training → system",
        "sentence": "The proposed method outperforms the alternative of training the system.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('system') is the object of the preposition 'the', part of the phrase 'the system', which is the object of the verb 'training'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'outperforms' and the prepositional phrase 'of training the system'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "news articles",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject complement, depending on the verb 'is' in the clause 'the proposed method is viable'. Entity 2 ('news articles') is part of the object of the preposition 'on', depending on 'on' in the phrase 'on questions and news articles from trec'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence.",
        "sdp_path_text": "method → is → outperforms → alternative → of → training → on → questions → articles",
        "sentence": "The method outperforms training on questions and news articles.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('news articles') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'method' is compared against 'training on questions and news articles'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "trec",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'is' in the clause 'the proposed method is viable'. It also depends on 'outperforms' as the subject in the clause 'it outperforms the alternative of training the system on questions and news articles from trec'. Entity 2 ('trec') is the object of the preposition 'from', depending on 'articles'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clauses describing the performance and viability of the method relative to an alternative involving data from trec.",
        "sdp_path_text": "method → is → outperforms → alternative → of → training → on → questions → from → trec",
        "sentence": "The proposed method outperforms training on questions from TREC.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('TREC') is the object of the preposition 'from', depending on 'from' in the phrase 'from TREC'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'outperforms' and the prepositional phrase 'from TREC'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on 'is' in the clause 'the proposed method is viable'. Entity 2 ('it') is a pronoun, referring back to 'method' and serving as the subject for the verbs 'outperforms' and 'helps'. There is a direct dependency between Entity 1 and Entity 2, as 'it' refers back to 'method' and carries forward its role in subsequent clauses.",
        "sdp_path_text": "method → is → outperforms → it",
        "sentence": "The proposed method outperforms it.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('it') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is performing the action (outperforming) on 'it'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "search engine",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject complement, depending on the verb 'is' with 'viable'. It also serves as the subject of the clause introduced by 'that it outperforms'. Entity 2 ('search engine') is part of the object of the preposition 'for', which is part of the larger clause 'it helps the search engine handle definition questions significantly better'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps' in the clause describing the effect of the method on the search engine's performance.",
        "sdp_path_text": "method → is → outperforms → helps → handle → engine",
        "sentence": "The proposed method helps the search engine handle questions better.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'helps'. Entity 2 ('search engine') is the object, depending on 'helps' with 'method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' directly influences 'search engine' through the verb 'helps'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "alternative",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms'. Entity 2 ('alternative') is the object, depending on the preposition 'of', which itself depends on 'training'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the clause where 'it' (the proposed method) outperforms 'the alternative of training the system on questions and news articles from trec'.",
        "sdp_path_text": "it → outperforms → alternative",
        "sentence": "It outperforms the alternative.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms'. Entity 2 ('alternative') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, as 'it' outperforms 'the alternative'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "system",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on 'outperforms' and 'helps'. Entity 2 ('system') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context where 'it' refers back to the 'proposed method', which is described as being trained on the 'system'.",
        "sdp_path_text": "it → outperforms → alternative → of → training → system",
        "sentence": "It outperforms the alternative of training the system.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms'. Entity 2 ('system') is the object, depending on the preposition 'of' in the phrase 'of training the system'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "news articles",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on 'outperforms' as the main verb of the clause. Entity 2 ('news articles') is the object of the preposition 'from', depending on 'from' in the phrase 'from trec'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "it → outperforms → alternative → of → training → on → questions → articles",
        "sentence": "It outperforms the alternative of training on questions and news articles.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms'. Entity 2 ('news articles') is part of the object of the preposition 'on', depending on 'on' in the phrase 'on questions and news articles'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "trec",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on 'outperforms' as the main verb. Entity 2 ('trec') is the object, depending on 'outperforms' with 'it'. There is a direct dependency between Entity 1 and Entity 2, where 'it' (the proposed method) is performing the action of 'outperforming' 'trec' (questions and news articles from trec).",
        "sdp_path_text": "it → outperforms → alternative → of → training → on → questions → from → trec",
        "sentence": "It outperforms the alternative of training on questions from TREC.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms'. Entity 2 ('TREC') is the object of the preposition 'from', depending on 'from' in the phrase 'from TREC'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'outperforms' and the prepositional phrase 'from TREC'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "search engine",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms' and also part of the clause 'that it helps'. Entity 2 ('search engine') is the object of the preposition 'for', depending on 'handle' in the phrase 'handle definition questions for the search engine'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps' where 'it' (the proposed method) helps the 'search engine'.",
        "sdp_path_text": "it → outperforms → helps → handle → engine",
        "sentence": "It helps the search engine handle questions better.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'helps'. Entity 2 ('search engine') is the object of the preposition 'the', depending on 'helps' in the phrase 'helps the search engine'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "alternative",
                "Generic"
            ],
            [
                "system",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('alternative') is the object of the preposition 'of', depending on 'outperforms'. Entity 2 ('system') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "alternative → of → training → system",
        "sentence": "The alternative of training the system is discussed.",
        "sentence_llm_dp_info": "Entity 1 ('alternative') is the subject, depending on the verb 'discussed'. Entity 2 ('system') is the object of the preposition 'of', depending on 'training' in the phrase 'training the system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'training'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "alternative",
                "Generic"
            ],
            [
                "news articles",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('alternative') is the subject complement, depending on 'of' in the phrase 'the alternative of'. Entity 2 ('news articles') is the object of the preposition 'from', depending on 'from' in the phrase 'from trec'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing an alternative method involving 'training the system on questions and news articles from trec'.",
        "sdp_path_text": "alternative → of → training → on → questions → articles",
        "sentence": "The alternative involves training on questions and news articles.",
        "sentence_llm_dp_info": "Entity 1 ('alternative') is the subject, depending on the verb 'involves'. Entity 2 ('news articles') is the object, depending on the preposition 'on' in the phrase 'on questions and news articles'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "alternative",
                "Generic"
            ],
            [
                "trec",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('alternative') is the subject of the clause, depending on 'outperforms' as the verb. Entity 2 ('trec') is the object of the preposition 'from', depending on 'from' in the phrase 'from trec'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'outperforms' and the prepositional phrase 'from trec'.",
        "sdp_path_text": "alternative → of → training → on → questions → from → trec",
        "sentence": "The alternative involves training on questions from TREC.",
        "sentence_llm_dp_info": "Entity 1 ('alternative') is the subject, depending on the verb 'involves'. Entity 2 ('trec') is the object of the preposition 'from', depending on 'from' in the phrase 'from TREC'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' and the prepositional phrase 'from TREC'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "alternative",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on 'outperforms' as the main verb in the clause 'it outperforms the alternative of training the system on questions and news articles from trec'. Entity 2 ('alternative') is the object, depending on 'outperforms' with 'it'. There is a direct dependency between Entity 1 and Entity 2, as 'it' (the subject) outperforms 'alternative' (the object).",
        "sdp_path_text": "it → outperforms → alternative",
        "sentence": "It outperforms the alternative.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms'. Entity 2 ('alternative') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, as 'it' outperforms 'the alternative'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "alternative",
                "Generic"
            ],
            [
                "search engine",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('alternative') is the subject of the clause 'the alternative of training the system on questions and news articles from trec', depending on the verb 'outperforms'. Entity 2 ('search engine') is the object of the verb 'helps', depending on 'helps' in the clause 'it helps the search engine handle definition questions significantly better'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "alternative → outperforms → helps → handle → engine",
        "sentence": "The alternative outperforms and helps the search engine handle questions better.",
        "sentence_llm_dp_info": "Entity 1 ('alternative') is the subject, depending on the verbs 'outperforms' and 'helps'. Entity 2 ('search engine') is the object, depending on 'helps' with 'the alternative'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "news articles",
                "Material"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news articles') is part of the object complement, depending on the preposition 'from' which itself depends on the verb 'training'. Entity 2 ('system') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on questions and news articles from trec'.",
        "sdp_path_text": "articles → questions → on → training → system",
        "sentence": "News articles are used for training the system.",
        "sentence_llm_dp_info": "Entity 1 ('news articles') is the subject, depending on the verb 'used'. Entity 2 ('system') is the object, depending on 'training' in the phrase 'training the system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the prepositional phrase 'for training the system'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "trec",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the preposition 'on', depending on 'training' which is part of the phrase 'training the system'. Entity 2 ('trec') is the object of the preposition 'from', depending on 'articles'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the source material for training the system.",
        "sdp_path_text": "system → training → on → questions → from → trec",
        "sentence": "The system is trained on questions from TREC.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'trained'. Entity 2 ('TREC') is the object of the preposition 'from', depending on 'from' in the phrase 'from TREC'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on questions from TREC'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the preposition 'on', depending on 'training' in the phrase 'training the system'. Entity 2 ('it') is the subject, depending on the verb 'outperforms' and refers back to 'the proposed method'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where 'it' (referring to 'the proposed method') affects how the 'system' performs.",
        "sdp_path_text": "system → training → of → alternative → outperforms → it",
        "sentence": "The system outperforms alternatives when trained.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'outperforms'. Entity 2 ('it') does not appear in the sentence provided. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence.\"\n\nNote: Since \"it\" is not mentioned in the sentence, it cannot be analyzed for dependencies within this context. If \"it\" was intended to refer to \"the system,\" it would typically appear in a subsequent sentence or clause where \"it\" could then depend on \"the system\" from the previous mention."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "search engine",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the preposition 'on', depending on 'training' which is part of the clause 'training the system on questions and news articles from trec'. Entity 2 ('search engine') is the object of the verb 'helps', depending on 'helps' in the clause 'it helps the search engine handle definition questions significantly better'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence and relate to the effectiveness of the proposed method.",
        "sdp_path_text": "system → training → of → alternative → outperforms → helps → handle → engine",
        "sentence": "The system helps the search engine handle questions better.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'helps'. Entity 2 ('search engine') is the object, depending on the verb 'helps'. There is a direct dependency between Entity 1 and Entity 2, as 'system' directly helps 'search engine'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "news articles",
                "Material"
            ],
            [
                "trec",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news articles') is the object of the preposition 'from', depending on 'from' in the phrase 'from trec'. Entity 2 ('trec') is the source, depending on 'from' in the same phrase 'from trec'. There is a direct dependency between Entity 1 and Entity 2, as 'news articles' is specified as coming from 'trec'.",
        "sdp_path_text": "articles → questions → from → trec",
        "sentence": "News articles from TREC help the search engine handle definition questions better.",
        "sentence_llm_dp_info": "Entity 1 ('news articles') is the subject, depending on the verb 'help'. Entity 2 ('trec') is the source or origin, depending on the preposition 'from' in the phrase 'from TREC'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "news articles",
                "Material"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news articles') is the object, depending on 'from' which is part of the prepositional phrase 'from trec'. Entity 2 ('it') is the subject, depending on 'outperforms' as the main verb in its clause. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where 'it' (the subject) is compared against the 'alternative of training the system on questions and news articles from trec'.",
        "sdp_path_text": "articles → questions → on → training → of → alternative → outperforms → it",
        "sentence": "It outperforms the alternative of training on news articles and questions.",
        "sentence_llm_dp_info": "Entity 1 ('news articles') is the object of the preposition 'on', depending on 'training'. Entity 2 ('it') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'outperforms' and the prepositional phrase 'on news articles'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "news articles",
                "Material"
            ],
            [
                "search engine",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news articles') is part of the object of the preposition 'from', depending on 'from' in the phrase 'from trec'. Entity 2 ('search engine') is the object of the verb 'helps', depending on 'helps' in the clause 'it helps the search engine handle definition questions significantly better'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "articles → questions → on → training → of → alternative → outperforms → helps → handle → engine",
        "sentence": "News articles help the search engine handle questions better.",
        "sentence_llm_dp_info": "Entity 1 ('news articles') is the subject, depending on the verb 'help'. Entity 2 ('search engine') is the object, depending on 'help' with 'news articles'. There is a direct dependency between Entity 1 and Entity 2, as 'search engine' is directly affected by the action performed by 'news articles'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "trec",
                "Material"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('trec') is the object of the preposition 'from', depending on 'articles'. Entity 2 ('it') is the subject, depending on 'outperforms' with 'the alternative of training the system on questions and news articles from trec'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the comparison where 'it' (referring to the proposed method) outperforms the alternative involving 'trec'.",
        "sdp_path_text": "trec → from → questions → on → training → of → alternative → outperforms → it",
        "sentence": "It outperforms the alternative of training on questions from trec.",
        "sentence_llm_dp_info": "Entity 1 ('trec') is the object of the preposition 'from', depending on 'questions'. Entity 2 ('it') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'it' outperforms an alternative that includes 'questions from trec'."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "trec",
                "Material"
            ],
            [
                "search engine",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('trec') is the object of the preposition 'from', depending on 'articles'. Entity 2 ('search engine') is the object of the preposition 'for', depending on 'handle'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing different aspects of the proposed method's performance and impact.",
        "sdp_path_text": "trec → from → questions → on → training → of → alternative → outperforms → helps → handle → engine",
        "sentence": "The method outperforms training on questions from TREC and helps the search engine handle definition questions better.",
        "sentence_llm_dp_info": "Entity 1 ('trec') is the object of the preposition 'from', depending on 'questions'. Entity 2 ('search engine') is the object of the verb 'helps', depending on 'helps' in the clause 'helps the search engine handle definition questions better'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We show experimentally that the proposed method is viable , that it outperforms the alternative of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "search engine",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'outperforms' and also on 'helps'. Entity 2 ('search engine') is the object, depending on 'helps' in the clause 'helps the search engine handle definition questions significantly better'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps'.",
        "sdp_path_text": "it → outperforms → helps → handle → engine",
        "sentence": "It helps the search engine handle questions better.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'helps'. Entity 2 ('search engine') is the object, depending on 'helps' with 'it'. There is a direct dependency between Entity 1 and Entity 2, where 'it' (Entity 1) is the agent performing the action that affects 'search engine' (Entity 2)."
    },
    {
        "raw_sentence": "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective .",
        "ner_pair": [
            [
                "statistical learning perspective",
                "Method"
            ],
            [
                "classical decision-theoretic problem of weighted expert voting",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('statistical learning perspective') is the object of the preposition 'from', depending on the preposition 'from' in the phrase 'from a statistical learning perspective'. Entity 2 ('classical decision-theoretic problem of weighted expert voting') is the object of the preposition 'of', depending on 'problem' in the noun phrase 'the classical decision-theoretic problem of weighted expert voting'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where the main verb is 'revisit'.",
        "sdp_path_text": "perspective → from → revisit → problem",
        "sentence": "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective.",
        "sentence_llm_dp_info": "Entity 1 ('statistical learning perspective') is the complement of the preposition 'from', depending on 'revisit'. Entity 2 ('classical decision-theoretic problem of weighted expert voting') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'the classical decision-theoretic problem of weighted expert voting' is being revisited 'from a statistical learning perspective'."
    },
    {
        "raw_sentence": "In the case of known expert competence levels , we give sharp error estimates for the optimal rule .",
        "ner_pair": [
            [
                "expert competence levels",
                "OtherScientificTerm"
            ],
            [
                "sharp error estimates",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('expert competence levels') is the object of the preposition 'of', depending on 'case'. Entity 2 ('sharp error estimates') is the direct object, depending on the verb 'give'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the context of 'expert competence levels' influences the action of giving 'sharp error estimates'.",
        "sdp_path_text": "levels → of → case → In → give → estimates",
        "sentence": "Expert competence levels give sharp error estimates.",
        "sentence_llm_dp_info": "Entity 1 ('expert competence levels') is the subject, depending on the verb 'give'. Entity 2 ('sharp error estimates') is the object, depending on the verb 'give'. There is a direct dependency between Entity 1 and Entity 2, as 'expert competence levels' is the agent that provides the 'sharp error estimates'."
    },
    {
        "raw_sentence": "In the case of known expert competence levels , we give sharp error estimates for the optimal rule .",
        "ner_pair": [
            [
                "expert competence levels",
                "OtherScientificTerm"
            ],
            [
                "optimal rule",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('expert competence levels') is the object of the preposition 'of', depending on 'case'. Entity 2 ('optimal rule') is the object, depending on 'estimates' in the phrase 'error estimates for the optimal rule'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the context provided by the sentence structure.",
        "sdp_path_text": "levels → of → case → In → give → estimates → for → rule",
        "sentence": "Expert competence levels give estimates for the optimal rule.",
        "sentence_llm_dp_info": "Entity 1 ('expert competence levels') is the subject, depending on the verb 'give'. Entity 2 ('optimal rule') is the object of the preposition 'for', depending on 'estimates'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'give' and the preposition 'for'."
    },
    {
        "raw_sentence": "In the case of known expert competence levels , we give sharp error estimates for the optimal rule .",
        "ner_pair": [
            [
                "sharp error estimates",
                "Method"
            ],
            [
                "optimal rule",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sharp error estimates') is the direct object, depending on the verb 'give'. Entity 2 ('optimal rule') is the object of the preposition 'for', depending on 'for' in the phrase 'for the optimal rule'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'give' and the preposition 'for'.",
        "sdp_path_text": "estimates → for → rule",
        "sentence": "We give sharp error estimates for the optimal rule.",
        "sentence_llm_dp_info": "Entity 1 ('sharp error estimates') is the direct object, depending on the verb 'give'. Entity 2 ('optimal rule') is the object of the preposition 'for', depending on 'for' in the phrase 'for the optimal rule'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'give' and the preposition 'for'."
    },
    {
        "raw_sentence": "We analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph .",
        "ner_pair": [
            [
                "reweighted version of the Kikuchi approximation",
                "Method"
            ],
            [
                "log partition function of a product distribution",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted version of the Kikuchi approximation') is the object of the verb 'analyze', depending on 'We'. Entity 2 ('log partition function of a product distribution') is the object of the preposition 'for', depending on 'estimating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose of the analysis.",
        "sdp_path_text": "version → of → approximation → for → estimating → function",
        "sentence": "A reweighted version of the Kikuchi approximation is used for estimating the log partition function of a product distribution.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted version of the Kikuchi approximation') is the subject, depending on the verb 'is used'. Entity 2 ('log partition function of a product distribution') is the object, depending on the verb 'estimating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'for estimating'."
    },
    {
        "raw_sentence": "We analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph .",
        "ner_pair": [
            [
                "reweighted version of the Kikuchi approximation",
                "Method"
            ],
            [
                "region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted version of the Kikuchi approximation') is the object of the verb 'analyze', depending on 'analyze' with 'We'. Entity 2 ('region graph') is the object of the preposition 'over', depending on 'defined' in the phrase 'defined over a region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where the reweighted version of the Kikuchi approximation is used for estimating the log partition function of a product distribution defined over a region graph.",
        "sdp_path_text": "version → of → approximation → for → estimating → function → of → distribution → defined → over → graph",
        "sentence": "The reweighted version of the Kikuchi approximation estimates the log partition function of a distribution defined over a region graph.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted version of the Kikuchi approximation') is the subject, depending on the verb 'estimates'. Entity 2 ('region graph') is the object of the preposition 'over', depending on 'defined'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'defined over a region graph'."
    },
    {
        "raw_sentence": "We analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph .",
        "ner_pair": [
            [
                "Kikuchi approximation",
                "Method"
            ],
            [
                "log partition function of a product distribution",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'version'. Entity 2 ('log partition function of a product distribution') is the object of the preposition 'for', depending on 'estimating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure being analyzed, connected through the verb 'analyze' and the purpose 'for estimating'.",
        "sdp_path_text": "approximation → for → estimating → function",
        "sentence": "The Kikuchi approximation is used for estimating the log partition function of a product distribution.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi approximation') is the subject, depending on the verb 'is used'. Entity 2 ('log partition function of a product distribution') is the object of the preposition 'for', depending on 'estimating' in the phrase 'for estimating the log partition function of a product distribution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for estimating'."
    },
    {
        "raw_sentence": "We analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph .",
        "ner_pair": [
            [
                "Kikuchi approximation",
                "Method"
            ],
            [
                "region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'version'. Entity 2 ('region graph') is the object of the preposition 'over', depending on 'defined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence.",
        "sdp_path_text": "approximation → for → estimating → function → of → distribution → defined → over → graph",
        "sentence": "The Kikuchi approximation is used for estimating the function of a distribution defined over a region graph.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi approximation') is the subject, depending on the verb 'is used'. Entity 2 ('region graph') is the object of the preposition 'over', depending on 'defined' in the phrase 'defined over a region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'over a region graph' which modifies 'distribution'."
    },
    {
        "raw_sentence": "We analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph .",
        "ner_pair": [
            [
                "log partition function of a product distribution",
                "Task"
            ],
            [
                "region graph",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('log partition function of a product distribution') is the object of the preposition 'for', depending on 'estimating'. Entity 2 ('region graph') is the object of the preposition 'over', depending on 'defined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is being estimated and how it is defined.",
        "sdp_path_text": "function → of → distribution → defined → over → graph",
        "sentence": "The log partition function of a product distribution is defined over a region graph.",
        "sentence_llm_dp_info": "Entity 1 ('log partition function of a product distribution') is the subject, depending on the verb 'is defined'. Entity 2 ('region graph') is the object of the preposition 'over', depending on 'over' in the phrase 'over a region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'over'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('reweighted objective function') is the object, depending on 'concavity'. There is a direct dependency between Entity 1 and Entity 2, as 'reweighted objective function' is the object of which the 'concavity' is being described.",
        "sdp_path_text": "concavity → of → function",
        "sentence": "We establish conditions for the concavity of the reweighted objective function.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('reweighted objective function') is the object, depending on the preposition 'of' with 'function'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrases 'for the concavity' and 'of the reweighted objective function' which both modify 'conditions'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('weight assignments') is the object of the preposition 'of', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the conditions described in the sentence.",
        "sdp_path_text": "concavity → in → terms → of → assignments",
        "sentence": "We establish conditions for the concavity of the objective function in terms of weight assignments.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('weight assignments') is the object of the preposition 'of', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different parts of the sentence."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi expansion') is the object of the preposition 'of', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses within the sentence, connected through the context provided by the main clause about establishing conditions and showing results.",
        "sdp_path_text": "concavity → in → terms → of → assignments → in → expansion",
        "sentence": "We establish conditions for the concavity of the reweighted objective function in terms of weight assignments in the Kikuchi expansion.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi expansion') is the object of the preposition 'in', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the conditions and terms related to the establishment of these conditions."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('reweighted version of the sum product algorithm') is the subject, depending on 'show' with 'We'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "concavity → for → conditions → establish → show → produce → version",
        "sentence": "We show that the concavity of the reweighted objective function is established by the reweighted version of the sum product algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the subject complement, depending on the verb 'is established'. Entity 2 ('reweighted version of the sum product algorithm') is the subject of the clause, depending on the verb 'established'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the agent that establishes the property described by Entity 1."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence discussing conditions and algorithms related to the Kikuchi expansion and approximation.",
        "sdp_path_text": "concavity → for → conditions → establish → show → produce → version → applied → to → graph",
        "sentence": "We establish conditions for the concavity of the reweighted objective function and show that its application to the Kikuchi region graph produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure described in the sentence."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "global optima",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is part of the object complement, depending on 'conditions' with the preposition 'for' in the phrase 'for the concavity of our reweighted objective function'. Entity 2 ('global optima') is the object of the verb 'produce', depending on 'produce' in the clause 'will produce global optima of the Kikuchi approximation'. There is no direct dependency between Entity 1 and Entity 2; however, both are related to the broader context of the Kikuchi approximation and the conditions under which certain properties hold.",
        "sdp_path_text": "concavity → for → conditions → establish → show → produce → optima",
        "sentence": "We establish conditions for concavity that lead to producing global optima.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('global optima') is the object of the verb 'producing', depending on 'that'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'that lead to producing global optima'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context involving the conditions and the optimization process described in the sentence.",
        "sdp_path_text": "concavity → for → conditions → establish → show → produce → optima → of → approximation",
        "sentence": "We establish conditions for the concavity of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'concavity'. There is a direct dependency between Entity 1 and Entity 2, as 'Kikuchi approximation' modifies 'concavity' through the preposition 'of'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('algorithm') is part of a compound noun, depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2; they are related through the context of the sentence, where the conditions for the concavity of the objective function and the application of the algorithm to achieve global optima are discussed.",
        "sdp_path_text": "concavity → for → conditions → establish → show → produce → version → of → algorithm",
        "sentence": "We show that conditions for the concavity of the objective function can produce results from the algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is part of the noun phrase 'the concavity of the objective function', where it depends on 'of' as the head of the prepositional phrase modifying 'function'. Entity 2 ('algorithm') is the object of the preposition 'from', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the sentence structure involving the verb 'produce' and the preposition 'from'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'concavity'. Entity 2 ('weight assignments') is the object of the preposition 'in', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2; both are part of the clause describing the conditions for the concavity of the reweighted objective function.",
        "sdp_path_text": "function → of → concavity → in → terms → of → assignments",
        "sentence": "The concavity of the reweighted objective function depends on the weight assignments.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the subject of the noun phrase, depending on 'depends' as the main verb. Entity 2 ('weight assignments') is the object of the preposition 'on', depending on 'depends'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'depends' and the preposition 'on'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'concavity'. Entity 2 ('Kikuchi expansion') is the object of the preposition 'in', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing conditions related to the concavity and weight assignments.",
        "sdp_path_text": "function → of → concavity → in → terms → of → assignments → in → expansion",
        "sentence": "We establish conditions for the concavity of the reweighted objective function in terms of assignments in the Kikuchi expansion.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object, depending on the preposition 'of' which is part of the prepositional phrase 'of the reweighted objective function'. Entity 2 ('Kikuchi expansion') is the object of the preposition 'in', depending on 'in' in the phrase 'in the Kikuchi expansion'. There is no direct dependency between Entity 1 and Entity 2; both are part of different prepositional phrases that modify different parts of the sentence."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'conditions' in the phrase 'conditions for the concavity of our reweighted objective function'. Entity 2 ('reweighted version of the sum product algorithm') is the subject of the clause, depending on 'show' in the main clause 'and show that a reweighted version of the sum product algorithm...'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same discourse about conditions and algorithms related to the Kikuchi expansion and approximation.",
        "sdp_path_text": "function → of → concavity → for → conditions → establish → show → produce → version",
        "sentence": "We establish conditions for the concavity of the reweighted objective function and show that a reweighted version of the sum product algorithm produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('reweighted version of the sum product algorithm') is the subject complement, depending on 'produces' with 'global optima'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of reweighting within the sentence."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the Kikuchi expansion and the sum product algorithm applied to it.",
        "sdp_path_text": "function → of → concavity → for → conditions → establish → show → produce → version → applied → to → graph",
        "sentence": "We show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph produces global optima of the reweighted objective function.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'optima'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the outcome of applying the sum product algorithm."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "global optima",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('global optima') is the object of the verb 'produce', depending on 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same discourse, where the conditions for the concavity of the 'reweighted objective function' relate to the production of 'global optima' by the algorithm.",
        "sdp_path_text": "function → of → concavity → for → conditions → establish → show → produce → optima",
        "sentence": "We show that the reweighted objective function can produce global optima.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the subject complement, depending on 'can produce'. Entity 2 ('global optima') is the object, depending on 'can produce' with 'reweighted objective function'. There is a direct dependency between Entity 1 and Entity 2, as 'reweighted objective function' produces 'global optima'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2; however, both are related to the context of the 'Kikuchi expansion' and the 'sum product algorithm' described in the sentence.",
        "sdp_path_text": "function → of → concavity → for → conditions → establish → show → produce → optima → of → approximation",
        "sentence": "We establish conditions for the concavity of the reweighted objective function and show that it produces optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where the first is related to the conditions established and the second is the result of the process described."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted objective function",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('algorithm') is the subject, depending on 'applied' with 'sum product'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same context regarding the conditions and the application of the algorithm to achieve global optima of the Kikuchi approximation.",
        "sdp_path_text": "function → of → concavity → for → conditions → establish → show → produce → version → of → algorithm",
        "sentence": "We establish conditions for the concavity of the reweighted objective function and show that the reweighted algorithm produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted objective function') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('algorithm') is the subject, depending on the verb 'produces' with 'global optima'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence context, where the conditions for the concavity of the reweighted objective function and the performance of the reweighted algorithm are discussed."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('Kikuchi expansion') is the object of the preposition 'in', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the conditions for the concavity of the reweighted objective function.",
        "sdp_path_text": "assignments → in → expansion",
        "sentence": "Weight assignments in the Kikuchi expansion establish sufficient conditions for the concavity of the reweighted objective function.",
        "sentence_llm_dp_info": "Entity 1 ('weight assignments') is the subject, depending on the verb 'establish'. Entity 2 ('Kikuchi expansion') is the object of the preposition 'in', depending on 'in' in the phrase 'in the Kikuchi expansion'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the Kikuchi expansion'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('reweighted version of the sum product algorithm') is the subject, depending on 'show' and 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the conditions and the application of the algorithm described in the sentence.",
        "sdp_path_text": "assignments → of → terms → in → concavity → for → conditions → establish → show → produce → version",
        "sentence": "Weight assignments in the Kikuchi expansion help produce a reweighted version of the sum product algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('weight assignments') is the subject, depending on 'help' as the verb. Entity 2 ('reweighted version of the sum product algorithm') is the object, depending on 'produce' as the verb. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'help' which indicates that Entity 1 assists in the production of Entity 2."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing conditions and algorithms related to the Kikuchi expansion and approximation.",
        "sdp_path_text": "assignments → of → terms → in → concavity → for → conditions → establish → show → produce → version → applied → to → graph",
        "sentence": "Weight assignments in the Kikuchi expansion help produce global optima when the sum product algorithm is applied to the Kikuchi region graph.",
        "sentence_llm_dp_info": "Entity 1 ('weight assignments') is the subject, depending on the verb 'help' in the clause 'help produce global optima'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where 'weight assignments' contribute to producing 'global optima' which is relevant when the 'sum product algorithm' is applied to the 'Kikuchi region graph'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            [
                "global optima",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('global optima') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence, connected through the logical flow of the statement about conditions and outcomes.",
        "sdp_path_text": "assignments → of → terms → in → concavity → for → conditions → establish → show → produce → optima",
        "sentence": "Weight assignments help produce global optima in the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('weight assignments') is the subject, depending on the verb 'help'. Entity 2 ('global optima') is the object, depending on the verb 'produce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'help' and 'produce' which describe the relationship where Entity 1 assists in the creation of Entity 2."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the conditions and outcomes described in the sentence.",
        "sdp_path_text": "assignments → of → terms → in → concavity → for → conditions → establish → show → produce → optima → of → approximation",
        "sentence": "Weight assignments in the Kikuchi expansion help produce global optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('weight assignments') is the subject, depending on 'help' as the verb. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'help' and the noun phrase 'global optima of the Kikuchi approximation'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "weight assignments",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('algorithm') is the subject of the clause 'the algorithm converges', and it also depends on 'applied' as part of the passive construction 'applied to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the broader context of the sentence, where 'weight assignments' contribute to the conditions under which the 'algorithm' can converge and produce global optima.",
        "sdp_path_text": "assignments → of → terms → in → concavity → for → conditions → establish → show → produce → version → of → algorithm",
        "sentence": "We establish conditions for the concavity of the objective function in terms of weight assignments, which the algorithm uses to produce global optima.",
        "sentence_llm_dp_info": "Entity 1 ('weight assignments') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('algorithm') is the subject, depending on 'uses' in the relative clause 'which the algorithm uses'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the conditions and the process described."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'of', depending on 'terms'. Entity 2 ('reweighted version of the sum product algorithm') is the subject, depending on 'applied' in the clause 'applied to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same context related to the Kikuchi approximation and the conditions for its concavity and optimization.",
        "sdp_path_text": "expansion → in → assignments → of → terms → in → concavity → for → conditions → establish → show → produce → version",
        "sentence": "We show that a reweighted version of the sum product algorithm produces global optima of the Kikuchi expansion.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object, depending on 'of' which is part of the prepositional phrase 'of the Kikuchi expansion', modifying 'global optima'. Entity 2 ('reweighted version of the sum product algorithm') is the subject complement, depending on 'produces' which is the main verb of the clause. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'produces' and the object 'global optima'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'of', depending on 'conditions'. It also serves as the subject of the clause 'weight assignments in the Kikuchi expansion'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context describing the application of the reweighted sum product algorithm.",
        "sdp_path_text": "expansion → in → assignments → of → terms → in → concavity → for → conditions → establish → show → produce → version → applied → to → graph",
        "sentence": "We establish conditions for the concavity of the Kikuchi expansion and show that the reweighted sum product algorithm applied to the Kikuchi region graph produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of the Kikuchi framework within the sentence."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            [
                "global optima",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('global optima') is the object of the preposition 'of', depending on 'optima' in the phrase 'global optima of the Kikuchi approximation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context related to the Kikuchi approximation and the conditions under which the algorithm produces optimal results.",
        "sdp_path_text": "expansion → in → assignments → of → terms → in → concavity → for → conditions → establish → show → produce → optima",
        "sentence": "We show that the reweighted sum product algorithm applied to the Kikuchi expansion produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('global optima') is the object, depending on 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' which indicates the result of applying the algorithm to the Kikuchi expansion."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'of', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of the Kikuchi framework within the sentence.",
        "sdp_path_text": "expansion → in → assignments → of → terms → in → concavity → for → conditions → establish → show → produce → optima → of → approximation",
        "sentence": "We establish conditions for the concavity of the Kikuchi expansion and show that the reweighted sum product algorithm produces optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of the Kikuchi method, with Entity 1 being discussed in terms of its concavity and Entity 2 in terms of the optima produced by an algorithm."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi expansion",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'of', depending on 'conditions'. It also appears in the phrase 'in terms of weight assignments in the Kikuchi expansion', where it is the object of the preposition 'in'. Entity 2 ('algorithm') is part of the compound noun 'sum product algorithm', which is the object of the preposition 'to', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the broader context of the sentence discussing conditions and algorithms in the Kikuchi framework.",
        "sdp_path_text": "expansion → in → assignments → of → terms → in → concavity → for → conditions → establish → show → produce → version → of → algorithm",
        "sentence": "We show that a reweighted version of the algorithm applied to the Kikuchi expansion produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi expansion') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('algorithm') is part of a noun phrase, depending on 'version' with the prepositional phrase 'of the algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' where 'algorithm' is modified by 'reweighted version' and 'Kikuchi expansion' is the object of its application."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted version of the sum product algorithm') is the subject, depending on 'applied' which indicates the action performed on or with the algorithm. Entity 2 ('Kikuchi region graph') is the object, depending on 'applied' with 'to', indicating the target of the application. There is a direct dependency between Entity 1 and Entity 2, as the algorithm is applied to the graph.",
        "sdp_path_text": "version → applied → to → graph",
        "sentence": "A reweighted version of the sum product algorithm is applied to the Kikuchi region graph.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted version of the sum product algorithm') is the subject, depending on the verb 'applied'. Entity 2 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'to' in the phrase 'to the Kikuchi region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' and the preposition 'to'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            [
                "global optima",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted version of the sum product algorithm') is the subject, depending on 'applied' which indicates the action performed on the Kikuchi region graph. Entity 2 ('global optima') is the object, depending on 'produce' which indicates the result produced by the application of Entity 1. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the producer of Entity 2 through the process described.",
        "sdp_path_text": "version → produce → optima",
        "sentence": "A reweighted version of the sum product algorithm produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted version of the sum product algorithm') is the subject, depending on the verb 'produces'. Entity 2 ('global optima') is the direct object, depending on the verb 'produces'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the producer of Entity 2."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "reweighted version of the sum product algorithm",
                "Method"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('reweighted version of the sum product algorithm') is the subject, depending on 'applied' with 'will produce'. Entity 2 ('Kikuchi approximation') is the object, depending on 'optima' with 'global'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produce', indicating that the application of Entity 1 can result in the optimization of Entity 2.",
        "sdp_path_text": "version → produce → optima → of → approximation",
        "sentence": "A reweighted version of the sum product algorithm produces global optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('reweighted version of the sum product algorithm') is the subject, depending on the verb 'produces'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the noun 'optima'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            [
                "global optima",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. Entity 2 ('global optima') is the object of the preposition 'of', depending on 'produce' in the phrase 'produce global optima of the Kikuchi approximation'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verb 'produce' and the noun 'approximation'.",
        "sdp_path_text": "graph → to → applied → version → produce → optima",
        "sentence": "A reweighted version of the sum product algorithm applied to the Kikuchi region graph produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('global optima') is the object, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' which indicates that the application to Entity 1 results in Entity 2."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima' in the phrase 'global optima of the Kikuchi approximation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the application of the algorithm and its outcome.",
        "sdp_path_text": "graph → to → applied → version → produce → optima → of → approximation",
        "sentence": "A reweighted version of the sum product algorithm applied to the Kikuchi region graph produces global optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the Kikuchi region graph'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima' in the phrase 'global optima of the Kikuchi approximation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the process described in the sentence."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi region graph",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied' which is part of the verb phrase 'applied to'. Entity 2 ('algorithm') is the subject of the clause 'whenever the algorithm converges', depending on the verb 'converges'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger clause describing the application of a reweighted version of the algorithm to the Kikuchi region graph.",
        "sdp_path_text": "graph → to → applied → version → of → algorithm",
        "sentence": "A reweighted version of the algorithm is applied to the Kikuchi region graph.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi region graph') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('algorithm') is the subject, depending on 'is' in the phrase 'is applied'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "global optima",
                "OtherScientificTerm"
            ],
            [
                "Kikuchi approximation",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('global optima') is the object of the verb 'produce', depending on 'produce' which is part of the clause 'will produce global optima'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'of' in the phrase 'of the Kikuchi approximation'. There is a direct dependency between Entity 1 and Entity 2, as 'global optima' is produced 'of the Kikuchi approximation'.",
        "sdp_path_text": "optima → of → approximation",
        "sentence": "The algorithm produces global optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('global optima') is the object, depending on the verb 'produces' with 'The algorithm'. Entity 2 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'of' in the phrase 'of the Kikuchi approximation'. There is a direct dependency between Entity 1 and Entity 2, as 'Kikuchi approximation' specifies what the 'global optima' are of."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "global optima",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('global optima') is the object of the preposition 'of', depending on 'produce' which is part of the clause describing what the 'reweighted version of the sum product algorithm' does when it converges. Entity 2 ('algorithm') is the subject, depending on 'converges' in the clause 'whenever the algorithm converges'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the actions described in the sentence where the 'algorithm' (when converging) produces 'global optima'.",
        "sdp_path_text": "optima → produce → version → of → algorithm",
        "sentence": "A reweighted version of the algorithm produces global optima.",
        "sentence_llm_dp_info": "Entity 1 ('global optima') is the object, depending on the verb 'produces'. Entity 2 ('algorithm') is part of a noun phrase, depending on the preposition 'of' in the phrase 'of the algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces'."
    },
    {
        "raw_sentence": "We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .",
        "ner_pair": [
            [
                "Kikuchi approximation",
                "Method"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. Entity 2 ('algorithm') is the subject, depending on 'converges'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence, where the 'algorithm' is said to produce 'global optima of the Kikuchi approximation' when it converges.",
        "sdp_path_text": "approximation → of → optima → produce → version → of → algorithm",
        "sentence": "A reweighted version of the algorithm produces global optima of the Kikuchi approximation.",
        "sentence_llm_dp_info": "Entity 1 ('Kikuchi approximation') is the object of the preposition 'of', depending on 'optima'. Entity 2 ('algorithm') is the subject, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'optima' and the verb 'produces'."
    },
    {
        "raw_sentence": "When the region graph has two layers , corresponding to a Bethe approximation , we show that our sufficient conditions for concavity are also necessary .",
        "ner_pair": [
            [
                "region graph",
                "OtherScientificTerm"
            ],
            [
                "Bethe approximation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('region graph') is the subject, depending on the verb 'has' with 'two layers'. Entity 2 ('Bethe approximation') is the complement, depending on the preposition 'to' which modifies 'corresponding'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'corresponding to a Bethe approximation'.",
        "sdp_path_text": "graph → has → corresponding → to → approximation",
        "sentence": "The region graph corresponds to a Bethe approximation.",
        "sentence_llm_dp_info": "Entity 1 ('region graph') is the subject, depending on the verb 'corresponds'. Entity 2 ('Bethe approximation') is the complement, depending on the verb 'corresponds'. There is a direct dependency between Entity 1 and Entity 2, as 'region graph' corresponds to 'Bethe approximation'."
    },
    {
        "raw_sentence": "When the region graph has two layers , corresponding to a Bethe approximation , we show that our sufficient conditions for concavity are also necessary .",
        "ner_pair": [
            [
                "region graph",
                "OtherScientificTerm"
            ],
            [
                "concavity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('region graph') is the subject of the clause, depending on the verb 'has' with 'two layers'. Entity 2 ('concavity') is the object, depending on 'conditions' with 'for concavity'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the logical flow of the sentence where the structure of the 'region graph' influences the 'conditions for concavity'.",
        "sdp_path_text": "graph → has → show → are → conditions → for → concavity",
        "sentence": "When the region graph has conditions for concavity, we show they are necessary.",
        "sentence_llm_dp_info": "Entity 1 ('region graph') is the subject, depending on the verb 'has'. Entity 2 ('concavity') is the object, depending on 'for' in the phrase 'for concavity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates that the conditions for concavity are related to the region graph."
    },
    {
        "raw_sentence": "When the region graph has two layers , corresponding to a Bethe approximation , we show that our sufficient conditions for concavity are also necessary .",
        "ner_pair": [
            [
                "Bethe approximation",
                "Method"
            ],
            [
                "concavity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Bethe approximation') is the object of the preposition 'to', depending on 'corresponding'. Entity 2 ('concavity') is the object of the preposition 'for', depending on 'conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the conditions under which the sufficiency and necessity are established.",
        "sdp_path_text": "approximation → to → corresponding → has → show → are → conditions → for → concavity",
        "sentence": "We show that conditions for concavity are met when the region graph corresponds to a Bethe approximation.",
        "sentence_llm_dp_info": "Entity 1 ('Bethe approximation') is the object of the preposition 'to', depending on 'corresponds'. Entity 2 ('concavity') is part of the noun phrase 'conditions for concavity', where it serves as the complement of the preposition 'for', depending on 'conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause structure involving 'conditions for concavity' and the verb 'met'."
    },
    {
        "raw_sentence": "Finally , we provide an explicit characterization of the polytope of concavity in terms of the cycle structure of the region graph .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "cycle structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is part of the compound noun 'polytope of concavity', where it is the complement of the preposition 'of', depending on 'polytope'. Entity 2 ('cycle structure') is the object of the preposition 'of', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through the prepositional phrases they are part of.",
        "sdp_path_text": "concavity → of → polytope → of → characterization → in → terms → of → structure",
        "sentence": "The polytope of concavity is characterized in terms of the cycle structure.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is part of a noun phrase, where it is modified by 'polytope of', depending on 'is characterized'. Entity 2 ('cycle structure') is the object of the preposition 'of', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the clause 'in terms of the cycle structure' which describes how the polytope of concavity is characterized."
    },
    {
        "raw_sentence": "Finally , we provide an explicit characterization of the polytope of concavity in terms of the cycle structure of the region graph .",
        "ner_pair": [
            [
                "concavity",
                "OtherScientificTerm"
            ],
            [
                "region graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concavity') is part of the noun phrase 'polytope of concavity', which is the object of the preposition 'of', depending on 'characterization'. Entity 2 ('region graph') is the object of the preposition 'of', depending on 'structure'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence, connected through the prepositional phrases 'of the polytope of concavity' and 'of the region graph'.",
        "sdp_path_text": "concavity → of → polytope → of → characterization → in → terms → of → structure → of → graph",
        "sentence": "The polytope of concavity is characterized in terms of the structure of the region graph.",
        "sentence_llm_dp_info": "Entity 1 ('concavity') is part of a noun phrase, depending on 'polytope' as a modifier. Entity 2 ('region graph') is the object of the preposition 'of', depending on 'structure'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'concavity' modifies 'polytope' and 'region graph' is described as part of the 'structure' that characterizes the 'polytope of concavity'."
    },
    {
        "raw_sentence": "Finally , we provide an explicit characterization of the polytope of concavity in terms of the cycle structure of the region graph .",
        "ner_pair": [
            [
                "cycle structure",
                "OtherScientificTerm"
            ],
            [
                "region graph",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cycle structure') is part of a prepositional phrase, depending on 'of' with 'terms'. Entity 2 ('region graph') is the object of the preposition 'of', depending on 'of' in the phrase 'of the region graph'. There is a direct dependency between Entity 1 and Entity 2, as 'region graph' modifies 'cycle structure' through the preposition 'of'.",
        "sdp_path_text": "structure → of → graph",
        "sentence": "The cycle structure is characterized in terms of the region graph.",
        "sentence_llm_dp_info": "Entity 1 ('cycle structure') is the subject, depending on the verb 'characterized'. Entity 2 ('region graph') is the object of the preposition 'of', depending on 'in terms of' in the phrase 'in terms of the region graph'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in terms of'."
    },
    {
        "raw_sentence": "We apply a decision tree based approach to pronoun resolution in spoken dialogue .",
        "ner_pair": [
            [
                "decision tree based approach",
                "Method"
            ],
            [
                "pronoun resolution",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decision tree based approach') is the object of the verb 'apply', depending on 'apply' with 'We'. Entity 2 ('pronoun resolution') is the object of the preposition 'to', depending on 'to' in the phrase 'to pronoun resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.",
        "sdp_path_text": "approach → apply → to → resolution",
        "sentence": "We apply a decision tree based approach to pronoun resolution.",
        "sentence_llm_dp_info": "Entity 1 ('decision tree based approach') is the object of the verb 'apply', depending on 'We'. Entity 2 ('pronoun resolution') is the object of the preposition 'to', depending on 'to' in the phrase 'to pronoun resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "We apply a decision tree based approach to pronoun resolution in spoken dialogue .",
        "ner_pair": [
            [
                "decision tree based approach",
                "Method"
            ],
            [
                "spoken dialogue",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decision tree based approach') is the object of the verb 'apply', depending on 'apply' with 'We'. Entity 2 ('spoken dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the application of an approach to a specific context.",
        "sdp_path_text": "approach → apply → in → dialogue",
        "sentence": "We apply a decision tree based approach in spoken dialogue.",
        "sentence_llm_dp_info": "Entity 1 ('decision tree based approach') is the object of the verb 'apply', depending on 'apply' with 'We'. Entity 2 ('spoken dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the approach is applied in the context of spoken dialogue."
    },
    {
        "raw_sentence": "We apply a decision tree based approach to pronoun resolution in spoken dialogue .",
        "ner_pair": [
            [
                "pronoun resolution",
                "Task"
            ],
            [
                "spoken dialogue",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('pronoun resolution') is the object of the preposition 'to', depending on 'to' in the phrase 'to pronoun resolution'. Entity 2 ('spoken dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify the main clause involving the application of the decision tree based approach.",
        "sdp_path_text": "resolution → to → apply → in → dialogue",
        "sentence": "We apply a method for pronoun resolution in spoken dialogue.",
        "sentence_llm_dp_info": "Entity 1 ('pronoun resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for pronoun resolution'. Entity 2 ('spoken dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying the noun 'method'."
    },
    {
        "raw_sentence": "Our system deals with pronouns with NP - and non-NP-antecedents .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "pronouns",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'deals'. Entity 2 ('pronouns') is the object, depending on 'with' in the phrase 'with pronouns'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.",
        "sdp_path_text": "system → deals → with → pronouns",
        "sentence": "Our system deals with pronouns.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the object of the verb 'deals', depending on 'deals' in the phrase 'deals with'. Entity 2 ('pronouns') is also an object, depending on the preposition 'with' in the phrase 'with pronouns'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrase 'deals with pronouns'."
    },
    {
        "raw_sentence": "Our system deals with pronouns with NP - and non-NP-antecedents .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "NP - and non-NP-antecedents",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'deals'. Entity 2 ('NP - and non-NP-antecedents') is the object of the preposition 'with', depending on 'with' in the phrase 'with NP - and non-NP-antecedents'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.",
        "sdp_path_text": "system → deals → with → pronouns → with → antecedents",
        "sentence": "The system deals with pronouns having NP and non-NP antecedents.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'deals'. Entity 2 ('NP and non-NP antecedents') is the object of the preposition 'with', depending on 'with' in the phrase 'with pronouns having NP and non-NP antecedents'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'."
    },
    {
        "raw_sentence": "Our system deals with pronouns with NP - and non-NP-antecedents .",
        "ner_pair": [
            [
                "NP - and non-NP-antecedents",
                "OtherScientificTerm"
            ],
            [
                "pronouns",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('NP - and non-NP-antecedents') is the object of the preposition 'with', depending on 'pronouns'. Entity 2 ('pronouns') is the object of the verb 'deals', depending on 'deals' in the phrase 'deals with pronouns'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.",
        "sdp_path_text": "antecedents → with → pronouns",
        "sentence": "The system handles pronouns with NP and non-NP antecedents.",
        "sentence_llm_dp_info": "Entity 1 ('NP and non-NP antecedents') is the object of the preposition 'with', depending on 'with' in the phrase 'with NP and non-NP antecedents'. Entity 2 ('pronouns') is the object, depending on 'handles' with 'the system'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'the system' is the subject and 'handles' is the main verb."
    },
    {
        "raw_sentence": "We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "pronoun resolution",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the object of the verb 'present', depending on 'present' with 'We'. Entity 2 ('pronoun resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for pronoun resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "features → designed → for → resolution",
        "sentence": "Features are designed for pronoun resolution.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'designed'. Entity 2 ('pronoun resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for pronoun resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "spoken dialogue",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the object of the verb 'present', depending on 'present' in the clause 'We present a set of features'. Entity 2 ('spoken dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context where 'features' are designed for use in 'spoken dialogue'.",
        "sdp_path_text": "features → designed → for → resolution → in → dialogue",
        "sentence": "Features are designed for pronoun resolution in spoken dialogue.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are designed'. Entity 2 ('spoken dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features .",
        "ner_pair": [
            [
                "pronoun resolution",
                "Task"
            ],
            [
                "spoken dialogue",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('pronoun resolution') is the object of the preposition 'for', depending on 'features'. Entity 2 ('spoken dialogue') is part of a compound noun, depending on 'and' which connects it with another noun phrase. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context in which the features are designed to be used.",
        "sdp_path_text": "resolution → in → dialogue",
        "sentence": "Features are designed for pronoun resolution in spoken dialogue.",
        "sentence_llm_dp_info": "Entity 1 ('pronoun resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for pronoun resolution'. Entity 2 ('spoken dialogue') is also the object of the preposition 'in', depending on 'in' in the phrase 'in spoken dialogue'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the context and purpose of the features being designed."
    },
    {
        "raw_sentence": "We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "pronoun resolution",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the object of the verb 'present', depending on 'present' with 'We'. Entity 2 ('pronoun resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for pronoun resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "features → designed → for → resolution",
        "sentence": "Features are designed for pronoun resolution.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'designed'. Entity 2 ('pronoun resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for pronoun resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features .",
        "ner_pair": [
            [
                "spoken dialogue",
                "Task"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spoken dialogue') is part of a prepositional phrase, depending on 'for' in the phrase 'for pronoun resolution in spoken dialogue'. Entity 2 ('features') is the object of the verb 'present', depending on 'present' in the clause 'We present a set of features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that modifies the purpose or context of the 'features'.",
        "sdp_path_text": "dialogue → in → resolution → for → designed → features",
        "sentence": "Features are designed for pronoun resolution in spoken dialogue.",
        "sentence_llm_dp_info": "Entity 1 ('spoken dialogue') is the object of the preposition 'in', depending on 'resolution'. Entity 2 ('features') is the subject, depending on the verb 'are designed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'for pronoun resolution in spoken dialogue'."
    },
    {
        "raw_sentence": "We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron 's -LRB- 2002 -RRB- manually tuned system .",
        "ner_pair": [
            [
                "Switchboard dialogues",
                "Material"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Switchboard dialogues') is the object of the preposition 'on', depending on 'evaluate'. Entity 2 ('system') is the subject of the clause 'it compares well to Byron's (2002) manually tuned system', depending on the verb 'compares'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same evaluative context where the 'system' is evaluated on the 'Switchboard dialogues'.",
        "sdp_path_text": "dialogues → on → system",
        "sentence": "The system is evaluated on Switchboard dialogues.",
        "sentence_llm_dp_info": "Entity 1 ('Switchboard dialogues') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('system') is the subject, depending on the verb 'is evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation process described by the verb 'is evaluated'."
    },
    {
        "raw_sentence": "We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron 's -LRB- 2002 -RRB- manually tuned system .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the preposition 'on', depending on 'evaluate' with 'We'. Entity 2 ('it') is the subject, depending on 'compares' in the clause 'it compares well to Byron's (2002) manually tuned system'. There is a direct dependency between Entity 1 and Entity 2, as 'it' refers back to 'system'.",
        "sdp_path_text": "system → on → dialogues → Switchboard",
        "sentence": "The system evaluates well on Switchboard dialogues.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'evaluates'. Entity 2 ('it') does not appear in the sentence, so there is no dependency for Entity 2 within this sentence. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the given sentence."
    },
    {
        "raw_sentence": "We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron 's -LRB- 2002 -RRB- manually tuned system .",
        "ner_pair": [
            [
                "Switchboard dialogues",
                "Material"
            ],
            [
                "Byron 's -LRB- 2002 -RRB- manually tuned system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Switchboard dialogues') is the object of the preposition 'on', depending on 'evaluate' with 'We'. Entity 2 ('Byron's (2002) manually tuned system') is the object of the preposition 'to', depending on 'compares' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the evaluation and comparison of the system.",
        "sdp_path_text": "dialogues → on → system → evaluate → show → compares → to → system",
        "sentence": "The system evaluated on Switchboard dialogues compares well to Byron's (2002) manually tuned system.",
        "sentence_llm_dp_info": "Entity 1 ('Switchboard dialogues') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('Byron's (2002) manually tuned system') is the object of the preposition 'to', depending on 'compares'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparative structure in the sentence."
    },
    {
        "raw_sentence": "We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron 's -LRB- 2002 -RRB- manually tuned system .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "Byron 's -LRB- 2002 -RRB- manually tuned system",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'compares' in the clause 'it compares well to Byron's -LRB- 2002 -RRB- manually tuned system'. Entity 2 ('Byron's -LRB- 2002 -RRB- manually tuned system') is the object, depending on the verb 'compares' in the same clause. There is a direct dependency between Entity 1 and Entity 2, as 'it' is compared to 'Byron's -LRB- 2002 -RRB- manually tuned system'.",
        "sdp_path_text": "Switchboard → dialogues → on → system → evaluate → show → compares → to → system",
        "sentence": "It compares well to Byron's (2002) manually tuned system.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'compares'. Entity 2 ('Byron's -LRB- 2002 -RRB- manually tuned system') is the object of the preposition 'to', depending on 'to' in the phrase 'to Byron's -LRB- 2002 -RRB- manually tuned system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "classifier",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the direct object, depending on the verb 'present' with 'We'. Entity 2 ('classifier') is the object of the preposition 'for', depending on 'building' in the phrase 'for building an efficient and robust classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the verb 'building'.",
        "sdp_path_text": "approach → for → building → classifier",
        "sentence": "We present a new approach for building a classifier.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the object, depending on the verb 'present'. Entity 2 ('classifier') is the object of the preposition 'for', depending on 'for' in the phrase 'for building a classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the verb 'building'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "class problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'present' with 'We'. Entity 2 ('class problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the two class problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "approach → for → building → classifier → for → problem",
        "sentence": "We present a new approach for building a classifier for the class problem.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the object, depending on the verb 'present' with 'We'. Entity 2 ('class problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the class problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "image",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject complement, depending on the verb 'present' with 'We'. Entity 2 ('image') is the object of the preposition 'in', depending on 'appear' in the phrase 'that may appear in the image'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the purpose of the approach.",
        "sdp_path_text": "approach → for → building → classifier → localizes → objects → appear → in → image",
        "sentence": "The approach builds a classifier that localizes objects appearing in the image.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'builds'. Entity 2 ('image') is the object of the preposition 'in', depending on 'appearing'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause 'that localizes objects appearing in the image'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "orien-tations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject complement, depending on the verb 'present'. Entity 2 ('orien-tations') is the object of the preposition 'under', depending on 'appear'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "approach → for → building → classifier → localizes → objects → appear → under → orien",
        "sentence": "The approach builds a classifier that localizes objects appearing under different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'builds'. Entity 2 ('orientations') is part of a noun phrase, depending on 'different' as its modifier and 'under' as its preposition. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'builds' and the relative clause 'that localizes objects appearing under different orientations'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "classifier",
                "Method"
            ],
            [
                "class problem",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifier') is the object of the preposition 'for', depending on 'building' in the phrase 'for building an efficient and robust classifier'. Entity 2 ('class problem') is the object of the preposition 'for', depending on 'problem' in the phrase 'for the two class problem'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the purpose of the approach presented.",
        "sdp_path_text": "classifier → for → problem",
        "sentence": "We present a new approach for building a classifier for the class problem.",
        "sentence_llm_dp_info": "Entity 1 ('classifier') is the object of the preposition 'for', depending on 'building'. Entity 2 ('class problem') is the object of the preposition 'for', depending on 'classifier'. There is a direct dependency between Entity 1 and Entity 2, as 'class problem' specifies the type or purpose of the 'classifier'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "classifier",
                "Method"
            ],
            [
                "image",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifier') is the object of the preposition 'for', depending on 'building' in the phrase 'building an efficient and robust classifier'. Entity 2 ('image') is the object of the preposition 'in', depending on 'appear' in the phrase 'that may appear in the image'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the purpose of the classifier being to localize objects in images.",
        "sdp_path_text": "classifier → localizes → objects → appear → in → image",
        "sentence": "The classifier localizes objects that appear in the image.",
        "sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on the verb 'localizes'. Entity 2 ('image') is the object of the preposition 'in', depending on 'appear'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'localizes' and the clause 'that appear in the image'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "classifier",
                "Method"
            ],
            [
                "orien-tations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifier') is the object of the preposition 'for', depending on 'approach'. Entity 2 ('orien-tations') is the object of the preposition 'under', depending on 'appear'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the purpose and conditions of the classifier's application.",
        "sdp_path_text": "classifier → localizes → objects → appear → under → orien",
        "sentence": "The classifier localizes objects that appear under different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on the verb 'localizes'. Entity 2 ('orientations') is the object of the preposition 'under', depending on 'appear' in the clause 'that appear under different orientations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'that appear under different orientations'."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "class problem",
                "Task"
            ],
            [
                "image",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('class problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the two class problem'. Entity 2 ('image') is the object of the preposition 'in', depending on 'in' in the phrase 'in the image'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the classifier's purpose.",
        "sdp_path_text": "problem → for → classifier → localizes → objects → appear → in → image",
        "sentence": "The class problem involves a classifier that localizes objects appearing in the image.",
        "sentence_llm_dp_info": "Entity 1 ('class problem') is the subject, depending on the verb 'involves'. Entity 2 ('image') is the object of the preposition 'in', depending on 'appearing' in the phrase 'appearing in the image'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing what the class problem involves."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "class problem",
                "Task"
            ],
            [
                "orien-tations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('class problem') is the object of the preposition 'for', depending on 'classifier'. Entity 2 ('orien-tations') is the object of the preposition 'under', depending on 'appear'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "problem → for → classifier → localizes → objects → appear → under → orien",
        "sentence": "The class problem involves a classifier that localizes objects appearing under different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('class problem') is the subject, depending on the verb 'involves'. Entity 2 ('orientations') is the object of the preposition 'under', depending on 'appearing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing what the class problem involves."
    },
    {
        "raw_sentence": "We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations .",
        "ner_pair": [
            [
                "image",
                "Material"
            ],
            [
                "orien-tations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('image') is the object of the preposition 'in', depending on 'appear'. Entity 2 ('orien-tations') is the object of the preposition 'under', depending on 'appear'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the conditions under which objects may appear.",
        "sdp_path_text": "image → in → appear → under → orien",
        "sentence": "Objects in the image may appear under different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('image') is the object of the preposition 'in', depending on 'in' in the phrase 'in the image'. Entity 2 ('orientations') is the object of the preposition 'under', depending on 'under' in the phrase 'under different orientations'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the possible appearances of objects."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the object of the relative clause 'that address this problem', depending on the verb 'address'. Entity 2 ('classifiers') is the object of the preposition 'using', depending on 'using' in the phrase 'using multiple classifiers'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the clause 'that address this problem using multiple classifiers'.",
        "sdp_path_text": "problem → address → using → classifiers",
        "sentence": "The problem is addressed using classifiers.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the subject, depending on the verb 'addressed'. Entity 2 ('classifiers') is the object of the preposition 'using', depending on 'using' in the phrase 'using classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'addressed' and the preposition 'using'."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "approach",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the object of the relative clause 'that address this problem', depending on the verb 'address'. Entity 2 ('approach') is the object, depending on the verb 'propose' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the discussion of addressing the problem with a specific approach.",
        "sdp_path_text": "problem → address → works → to → contrast → In → propose → approach",
        "sentence": "We propose an approach to address the problem.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the object, depending on 'address' with 'the problem'. Entity 2 ('approach') is the object, depending on 'propose' with 'an approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'address' which indicates the purpose of the approach."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "estimation stage",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the object of the relative clause, depending on 'address' with 'works'. Entity 2 ('estimation stage') is part of a coordination, depending on 'and' with 'classification stage'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "problem → address → works → to → contrast → In → propose → approach → with → stage",
        "sentence": "We propose an approach with an estimation stage to address the problem.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the object, depending on 'address' with 'to address the problem'. Entity 2 ('estimation stage') is part of a prepositional phrase, depending on 'with' in 'with an estimation stage'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the structure that describes the approach being proposed."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "classification stage",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('problem') is the object of the relative clause 'that address this problem', depending on 'address' with 'works'. Entity 2 ('classification stage') is part of the compound object, depending on 'and' in the phrase 'an estimation stage and a classification stage'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the broader context of the sentence where the problem is being addressed by the proposed approach which includes the classification stage.",
        "sdp_path_text": "problem → address → works → to → contrast → In → propose → approach → with → stage → stage",
        "sentence": "We propose an approach to address the problem with a classification stage.",
        "sentence_llm_dp_info": "Entity 1 ('problem') is the object of the preposition 'the', depending on 'address' in the phrase 'to address the problem'. Entity 2 ('classification stage') is the object of the preposition 'with', depending on 'with' in the phrase 'with a classification stage'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifiers') is the object of the preposition 'using', depending on the clause 'that address this problem using multiple classifiers'. Entity 2 ('approach') is the object, depending on the verb 'propose' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different methods or strategies being discussed in the sentence.",
        "sdp_path_text": "classifiers → using → address → works → to → contrast → In → propose → approach",
        "sentence": "We propose an approach in contrast to works using classifiers.",
        "sentence_llm_dp_info": "Entity 1 ('classifiers') is the object of the preposition 'using', depending on 'works'. Entity 2 ('approach') is the object, depending on 'propose' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the contrasting clause 'in contrast to works using classifiers'."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "estimation stage",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifiers') is the object of the preposition 'using', depending on the verb 'address'. Entity 2 ('estimation stage') is the object of the preposition 'with', part of the phrase 'with an estimation stage', depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "classifiers → using → address → works → to → contrast → In → propose → approach → with → stage",
        "sentence": "We propose an approach with an estimation stage, contrasting works that use multiple classifiers.",
        "sentence_llm_dp_info": "Entity 1 ('classifiers') is the object of the preposition 'use', depending on the relative clause 'that use multiple classifiers'. Entity 2 ('estimation stage') is the object of the preposition 'with', depending on 'approach' in the phrase 'an approach with an estimation stage'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "classification stage",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifiers') is the object of the preposition 'using', depending on 'address' in the clause 'that address this problem using multiple classifiers'. Entity 2 ('classification stage') is part of a compound noun, depending on 'approach' in the phrase 'two-step approach with an estimation stage and a classification stage'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses and are not directly connected in the sentence structure.",
        "sdp_path_text": "classifiers → using → address → works → to → contrast → In → propose → approach → with → stage → stage",
        "sentence": "We propose an approach with a classification stage, contrasting works using classifiers.",
        "sentence_llm_dp_info": "Entity 1 ('classifiers') is the object of the preposition 'using', depending on 'works'. Entity 2 ('classification stage') is part of the noun phrase, depending on 'approach' with the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different parts of the sentence structure."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "estimation stage",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimation stage') is the object, depending on the conjunction 'and' which links it to 'classification stage', both being part of the list of stages within the 'approach'. Entity 2 ('approach') is the object, depending on the verb 'propose' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'estimation stage' is a component of the 'approach'.",
        "sdp_path_text": "stage → with → approach",
        "sentence": "The approach includes an estimation stage.",
        "sentence_llm_dp_info": "Entity 1 ('estimation stage') is the object, depending on the verb 'includes'. Entity 2 ('approach') is the subject, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, as 'estimation stage' is directly included in 'approach'."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "classification stage",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classification stage') is part of a coordination, depending on the conjunction 'and' with 'estimation stage'. Entity 2 ('approach') is the object, depending on the verb 'propose' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'classification stage' is described as a component of the 'approach'.",
        "sdp_path_text": "stage → stage → with → approach",
        "sentence": "The approach includes a classification stage.",
        "sentence_llm_dp_info": "Entity 1 ('classification stage') is the object, depending on 'includes' with 'approach'. Entity 2 ('approach') is the subject, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, where 'classification stage' is included in the 'approach'."
    },
    {
        "raw_sentence": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step approach with an estimation stage and a classification stage .",
        "ner_pair": [
            [
                "estimation stage",
                "Method"
            ],
            [
                "classification stage",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimation stage') is part of the compound noun, depending on the conjunction 'and' with 'classification stage'. Entity 2 ('classification stage') is also part of the compound noun, depending on the conjunction 'and' with 'estimation stage'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same list or sequence.",
        "sdp_path_text": "stage → stage",
        "sentence": "We propose an approach with an estimation stage and a classification stage.",
        "sentence_llm_dp_info": "Entity 1 ('estimation stage') is part of a coordination, depending on the conjunction 'and' with 'classification stage'. Entity 2 ('classification stage') is also part of a coordination, depending on the conjunction 'and' with 'estimation stage'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same prepositional phrase 'with an estimation stage and a classification stage'."
    },
    {
        "raw_sentence": "The estimator yields an initial set of potential object poses that are then validated by the classifier .",
        "ner_pair": [
            [
                "estimator",
                "Method"
            ],
            [
                "object poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimator') is the subject, depending on the verb 'yields'. Entity 2 ('object poses') is the object of the preposition 'of', depending on 'set'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'yields' and the prepositional phrase 'of potential object poses'.",
        "sdp_path_text": "estimator → yields → set → of → poses",
        "sentence": "The estimator yields potential object poses.",
        "sentence_llm_dp_info": "Entity 1 ('estimator') is the subject, depending on the verb 'yields'. Entity 2 ('object poses') is the object, depending on the verb 'yields'. There is a direct dependency between Entity 1 and Entity 2, where 'estimator' is the agent that produces 'object poses'."
    },
    {
        "raw_sentence": "The estimator yields an initial set of potential object poses that are then validated by the classifier .",
        "ner_pair": [
            [
                "estimator",
                "Method"
            ],
            [
                "classifier",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimator') is the subject, depending on the verb 'yields'. Entity 2 ('classifier') is the subject of the relative clause, depending on 'validated' with 'that are then validated by the classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described in the sentence where the output of Entity 1 ('estimator') is used as input for the action performed by Entity 2 ('classifier').",
        "sdp_path_text": "estimator → yields → set → validated → by → classifier",
        "sentence": "The estimator yields a set of potential object poses validated by the classifier.",
        "sentence_llm_dp_info": "Entity 1 ('estimator') is the subject, depending on the verb 'yields'. Entity 2 ('classifier') is the subject of the participle 'validated', which modifies 'set of potential object poses'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the validation process described by the participle 'validated'."
    },
    {
        "raw_sentence": "The estimator yields an initial set of potential object poses that are then validated by the classifier .",
        "ner_pair": [
            [
                "classifier",
                "Method"
            ],
            [
                "object poses",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on 'validated' with 'that'. Entity 2 ('object poses') is the object of the preposition 'of', depending on 'set' in the phrase 'set of potential object poses'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the validation process described in the sentence.",
        "sdp_path_text": "classifier → by → validated → set → of → poses",
        "sentence": "The classifier validates the set of object poses.",
        "sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on the verb 'validates'. Entity 2 ('object poses') is the object, depending on the verb 'validates' through the prepositional phrase 'the set of'. There is a direct dependency between Entity 1 and Entity 2, as 'classifier' is performing the action of validating 'object poses'."
    },
    {
        "raw_sentence": "This methodology allows reducing the time complexity of the algorithm while classification results remain high .",
        "ner_pair": [
            [
                "time complexity",
                "Metric"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('time complexity') is the object of the preposition 'of', depending on 'reducing'. Entity 2 ('algorithm') is the object of the preposition 'of', depending on 'the'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'of the algorithm'.",
        "sdp_path_text": "complexity → of → algorithm",
        "sentence": "The methodology reduces the time complexity of the algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('time complexity') is the object of the preposition 'of', depending on 'algorithm'. Entity 2 ('algorithm') is the head noun, depending on 'of' in the phrase 'of the algorithm'. There is a direct dependency between Entity 1 and Entity 2, as 'time complexity' is part of the prepositional phrase that modifies 'algorithm'."
    },
    {
        "raw_sentence": "This methodology allows reducing the time complexity of the algorithm while classification results remain high .",
        "ner_pair": [
            [
                "time complexity",
                "Metric"
            ],
            [
                "classification",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('time complexity') is the object of the preposition 'of', depending on 'algorithm'. Entity 2 ('classification') is part of the compound noun 'classification results', which is the subject of the clause 'results remain high'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to different aspects of the algorithm's performance described in the sentence.",
        "sdp_path_text": "complexity → reducing → remain → results → classification",
        "sentence": "Reducing time complexity allows classification results to remain high.",
        "sentence_llm_dp_info": "Entity 1 ('time complexity') is the object of the verb 'Reducing', which is the subject of the sentence. Entity 2 ('classification') is part of a compound noun, 'classification results', acting as the subject complement of the verb 'allows'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the logical structure of the sentence where reducing Entity 1 (time complexity) influences the ability to maintain high levels of Entity 2 (classification results)."
    },
    {
        "raw_sentence": "This methodology allows reducing the time complexity of the algorithm while classification results remain high .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "classification",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the object of the preposition 'of', depending on 'complexity'. Entity 2 ('classification') is the subject, depending on 'remain' with 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the overall context of the sentence.",
        "sdp_path_text": "algorithm → of → complexity → reducing → remain → results → classification",
        "sentence": "The algorithm's complexity is reduced while maintaining high classification results.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is part of the possessive noun phrase 'algorithm's complexity', where it modifies 'complexity'. Entity 2 ('classification') is part of the noun phrase 'high classification results', where it is modified by 'high' and 'results'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the sentence describing the effect of reducing the algorithm's complexity on the classification results."
    },
    {
        "raw_sentence": "The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .",
        "ner_pair": [
            [
                "boosted combination of Random Ferns",
                "Method"
            ],
            [
                "classifier",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('boosted combination of Random Ferns') is the complement of the preposition 'on', depending on 'based' with 'classifier'. Entity 2 ('classifier') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 modifies Entity 2, indicating what the classifier is based on.",
        "sdp_path_text": "combination → on → based → classifier",
        "sentence": "The classifier is based on a boosted combination of Random Ferns.",
        "sentence_llm_dp_info": "Entity 1 ('boosted combination of Random Ferns') is the complement, depending on the preposition 'on', which modifies 'based'. Entity 2 ('classifier') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 specifies what the classifier is based on."
    },
    {
        "raw_sentence": "The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .",
        "ner_pair": [
            [
                "classifier",
                "Method"
            ],
            [
                "local histograms of oriented gradients -LRB- HOGs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on 'is' as its verb. Entity 2 ('local histograms of oriented gradients -LRB- HOGs -RRB-') is part of a noun phrase, functioning as the object of the preposition 'of', which modifies 'Random Ferns'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun phrase 'a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB-', where Entity 2 specifies the type of data used by the classifier described by Entity 1.",
        "sdp_path_text": "classifier → based → on → combination → over → histograms",
        "sentence": "The classifier is based on a combination over local histograms of oriented gradients (HOGs).",
        "sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on the verb 'is based'. Entity 2 ('local histograms of oriented gradients (HOGs)') is the object of the preposition 'over', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on a combination over'."
    },
    {
        "raw_sentence": "The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .",
        "ner_pair": [
            [
                "classifier",
                "Method"
            ],
            [
                "pre-processing step",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on 'is' as the main verb, and is modified by 'we use in both stages'. Entity 2 ('pre-processing step') is the object, depending on 'compute' with 'which we compute'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the computation process that affects the classifier's operation.",
        "sdp_path_text": "classifier → based → on → combination → compute → during → step",
        "sentence": "The classifier is based on a combination computed during the pre-processing step.",
        "sentence_llm_dp_info": "Entity 1 ('classifier') is the subject, depending on the verb 'is based'. Entity 2 ('pre-processing step') is the object of the preposition 'during', depending on 'during' in the phrase 'during the pre-processing step'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'during the pre-processing step'."
    },
    {
        "raw_sentence": "The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .",
        "ner_pair": [
            [
                "local histograms of oriented gradients -LRB- HOGs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "boosted combination of Random Ferns",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('local histograms of oriented gradients -LRB- HOGs -RRB-') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('boosted combination of Random Ferns') is the complement of 'based on', depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of' and the phrase 'based on'.",
        "sdp_path_text": "histograms → over → combination",
        "sentence": "The classifier uses a boosted combination of Random Ferns over local histograms of oriented gradients (HOGs).",
        "sentence_llm_dp_info": "Entity 1 ('local histograms of oriented gradients (HOGs)') is the object of the preposition 'of', depending on 'Random Ferns'. Entity 2 ('boosted combination of Random Ferns') is the object, depending on 'uses' with 'classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure where Entity 1 modifies Entity 2."
    },
    {
        "raw_sentence": "The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .",
        "ner_pair": [
            [
                "boosted combination of Random Ferns",
                "Method"
            ],
            [
                "pre-processing step",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('boosted combination of Random Ferns') is the object of the preposition 'on', depending on 'based' in the phrase 'is based on'. Entity 2 ('pre-processing step') is the object of the relative clause, depending on 'compute' in the phrase 'which we compute during a pre-processing step'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the classifier's basis and the computational process.",
        "sdp_path_text": "combination → compute → during → step",
        "sentence": "The boosted combination of Random Ferns is computed during the pre-processing step.",
        "sentence_llm_dp_info": "Entity 1 ('boosted combination of Random Ferns') is the subject, depending on the verb 'is computed'. Entity 2 ('pre-processing step') is the temporal modifier, depending on 'during' which modifies the verb 'is computed'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the temporal context provided by 'during'."
    },
    {
        "raw_sentence": "The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .",
        "ner_pair": [
            [
                "pre-processing step",
                "Method"
            ],
            [
                "local histograms of oriented gradients -LRB- HOGs -RRB-",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('pre-processing step') is the object of the relative clause, depending on 'compute' with 'which'. Entity 2 ('local histograms of oriented gradients -LRB- HOGs -RRB-') is the object of the preposition 'of', depending on 'combination' in the phrase 'combination of Random Ferns over local histograms of oriented gradients'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same complex structure describing the components and processes involved in the classifier.",
        "sdp_path_text": "step → during → compute → combination → over → histograms",
        "sentence": "The pre-processing step computes local histograms of oriented gradients (HOGs).",
        "sentence_llm_dp_info": "Entity 1 ('pre-processing step') is the subject, depending on the verb 'computes'. Entity 2 ('local histograms of oriented gradients (HOGs)') is the object, depending on the verb 'computes'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 performs the action of computing Entity 2."
    },
    {
        "raw_sentence": "Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time .",
        "ner_pair": [
            [
                "supervised learning",
                "Method"
            ],
            [
                "gradient space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('supervised learning') is part of a coordination, depending on 'use' which is part of the subject of the sentence. Entity 2 ('gradient space') is the object of the preposition 'on', depending on 'working'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the subject that contribute to making the approach robust.",
        "sdp_path_text": "learning → of → use → working → on → space",
        "sentence": "The use of supervised learning and working on the gradient space makes the approach robust and efficient.",
        "sentence_llm_dp_info": "Entity 1 ('supervised learning') is part of a prepositional phrase, depending on 'use' with 'of'. Entity 2 ('gradient space') is the object of the preposition 'on', depending on 'working'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that modifies 'approach'."
    },
    {
        "raw_sentence": "Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time .",
        "ner_pair": [
            [
                "supervised learning",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('supervised learning') is part of a coordination, depending on 'use' which is part of the subject of the sentence. Entity 2 ('approach') is the object of the possessive pronoun 'our', and it is the subject complement of the verb 'makes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where both contribute to the robustness and efficiency of the 'approach'.",
        "sdp_path_text": "learning → of → use → makes → robust → approach",
        "sentence": "The use of supervised learning makes the approach robust.",
        "sentence_llm_dp_info": "Entity 1 ('supervised learning') is the object of the preposition 'of', depending on 'use'. Entity 2 ('approach') is the subject, depending on the verb 'makes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'use' and the verb 'makes'."
    },
    {
        "raw_sentence": "Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time .",
        "ner_pair": [
            [
                "gradient space",
                "OtherScientificTerm"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('gradient space') is the object of the preposition 'on', depending on 'working'. Entity 2 ('approach') is the subject, depending on 'makes' with 'Both the use of supervised learning and working on the gradient space'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'makes' and the prepositional phrase 'on the gradient space'.",
        "sdp_path_text": "space → on → working → use → makes → robust → approach",
        "sentence": "Working on the gradient space makes the approach robust.",
        "sentence_llm_dp_info": "Entity 1 ('gradient space') is the object of the preposition 'on', depending on 'working'. Entity 2 ('approach') is the subject, depending on the adjective 'robust'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'makes' which indicates the effect of working in the gradient space on the robustness of the approach."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "motorbikes under planar rotations",
                "Material"
            ],
            [
                "database",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is part of the object complement, depending on 'made' within the clause 'a new database made of motorbikes under planar rotations'. Entity 2 ('database') is the object of the preposition 'on', depending on 'testing' in the phrase 'on standard databases and on a new database'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the structure of the sentence where Entity 1 describes the content of Entity 2.",
        "sdp_path_text": "motorbikes → of → made → database → on → on → databases",
        "sentence": "We show these properties by testing on a database made of motorbikes under planar rotations.",
        "sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is the object of the preposition 'of', depending on 'database'. Entity 2 ('database') is the object of the preposition 'on', depending on 'testing'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 modifies Entity 2, specifying what the database is made of."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "conditions",
                "Generic"
            ],
            [
                "database",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('conditions') is the object, depending on the preposition 'with', which modifies the verb phrase 'show these properties'. Entity 2 ('database') is the object of the preposition 'on', depending on 'testing'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the methods used to show the properties.",
        "sdp_path_text": "conditions → with → on → on → databases",
        "sentence": "We test conditions on databases.",
        "sentence_llm_dp_info": "Entity 1 ('conditions') is the object, depending on the verb 'test' with 'We'. Entity 2 ('database') is the object of the preposition 'on', depending on 'on' in the phrase 'on databases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'test' and the preposition 'on'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "database",
                "Generic"
            ],
            [
                "cluttered backgrounds",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('database') is part of the object complement, depending on the preposition 'on' in the phrase 'on a new database'. Entity 2 ('cluttered backgrounds') is part of the object complement, depending on the preposition 'such as' in the phrase 'such as cluttered backgrounds'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that describe different aspects of the testing conditions.",
        "sdp_path_text": "databases → on → on → with → conditions → as → backgrounds",
        "sentence": "The database includes conditions such as cluttered backgrounds.",
        "sentence_llm_dp_info": "Entity 1 ('database') is the subject, depending on the verb 'includes'. Entity 2 ('cluttered backgrounds') is the object of the preposition 'such as', depending on 'conditions'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun 'conditions' and the preposition 'such as'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "database",
                "Generic"
            ],
            [
                "changing illumination conditions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('database') is the object of the preposition 'on', depending on 'testing'. Entity 2 ('changing illumination conditions') is part of a list of conditions, depending on 'with' in the phrase 'with challenging conditions'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of the testing and conditions described in the sentence.",
        "sdp_path_text": "databases → on → on → with → conditions → as → backgrounds → conditions",
        "sentence": "The database includes conditions such as changing illumination conditions.",
        "sentence_llm_dp_info": "Entity 1 ('database') is the subject, depending on the verb 'includes'. Entity 2 ('changing illumination conditions') is the object, depending on the preposition 'such as', which itself depends on 'conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the prepositional phrase 'such as'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "database",
                "Generic"
            ],
            [
                "partial occlusions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('database') is part of a compound noun, depending on 'made' as its modifier. It also depends on 'on' in the prepositional phrase 'on a new database'. Entity 2 ('partial occlusions') is the object of the preposition 'with', depending on 'with' in the phrase 'with challenging conditions such as...partial occlusions'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of the sentence describing the conditions and objects of the testing.",
        "sdp_path_text": "databases → on → on → with → conditions → as → backgrounds → conditions → occlusions",
        "sentence": "The database includes conditions such as partial occlusions.",
        "sentence_llm_dp_info": "Entity 1 ('database') is the subject, depending on the verb 'includes'. Entity 2 ('partial occlusions') is the object, depending on 'conditions' with the preposition 'such as'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'includes' and the prepositional phrase 'such as'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "motorbikes under planar rotations",
                "Material"
            ],
            [
                "conditions",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is the object of the preposition 'of', depending on 'database'. Entity 2 ('conditions') is the object of the preposition 'such as', depending on 'with'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, where 'motorbikes under planar rotations' is an element of the database used for testing, and 'conditions' refers to the various challenging scenarios in which the tests were conducted.",
        "sdp_path_text": "motorbikes → of → made → database → on → with → conditions",
        "sentence": "Motorbikes under planar rotations are tested under challenging conditions.",
        "sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is the subject, depending on the verb 'tested'. Entity 2 ('conditions') is the object of the preposition 'under', depending on 'tested' in the phrase 'under challenging conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the testing process."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "motorbikes under planar rotations",
                "Material"
            ],
            [
                "cluttered backgrounds",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is part of the object of the preposition 'on', depending on 'on' in the phrase 'on a new database made of motorbikes under planar rotations'. Entity 2 ('cluttered backgrounds') is part of the object of the preposition 'such as', depending on 'conditions' in the phrase 'challenging conditions such as cluttered backgrounds'. There is no direct dependency between Entity 1 and Entity 2; both are parts of different clauses describing the conditions under which the testing was performed.",
        "sdp_path_text": "motorbikes → of → made → database → on → with → conditions → as → backgrounds",
        "sentence": "Motorbikes under planar rotations are tested on a database with cluttered backgrounds.",
        "sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is the subject, depending on the verb 'tested'. Entity 2 ('cluttered backgrounds') is the object of the preposition 'with', depending on 'with' in the phrase 'with cluttered backgrounds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "motorbikes under planar rotations",
                "Material"
            ],
            [
                "changing illumination conditions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is part of the object of the preposition 'on', depending on 'testing'. Entity 2 ('changing illumination conditions') is part of the object of the preposition 'such as', depending on 'conditions'. There is no direct dependency between Entity 1 and Entity 2; both are part of the broader context describing the conditions and objects of the testing.",
        "sdp_path_text": "motorbikes → of → made → database → on → with → conditions → as → backgrounds → conditions",
        "sentence": "Motorbikes under planar rotations were tested on a database with changing illumination conditions.",
        "sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is the subject, depending on the verb 'tested'. Entity 2 ('changing illumination conditions') is the object of the preposition 'with', depending on 'with' in the phrase 'with changing illumination conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the testing environment described by the sentence."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "motorbikes under planar rotations",
                "Material"
            ],
            [
                "partial occlusions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is part of the object complement, depending on the preposition 'of' with 'database'. Entity 2 ('partial occlusions') is part of the object complement, depending on the conjunction 'and' with 'challenging conditions'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger object complement describing the conditions under which the testing was performed.",
        "sdp_path_text": "motorbikes → of → made → database → on → with → conditions → as → backgrounds → conditions → occlusions",
        "sentence": "The database includes motorbikes under planar rotations tested with conditions such as partial occlusions.",
        "sentence_llm_dp_info": "Entity 1 ('motorbikes under planar rotations') is the subject, depending on the verb 'includes' with 'The database'. Entity 2 ('partial occlusions') is part of a list of conditions, depending on the preposition 'such as' within the phrase 'conditions such as partial occlusions'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "cluttered backgrounds",
                "OtherScientificTerm"
            ],
            [
                "conditions",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cluttered backgrounds') is the object of the preposition 'such as', depending on 'conditions'. Entity 2 ('conditions') is the object, depending on the preposition 'with' which modifies the verb 'show'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional structure 'such as' which lists examples of 'challenging conditions'.",
        "sdp_path_text": "backgrounds → as → conditions",
        "sentence": "Cluttered backgrounds are among the challenging conditions.",
        "sentence_llm_dp_info": "Entity 1 ('cluttered backgrounds') is the subject, depending on the verb 'are'. Entity 2 ('conditions') is the noun complement, depending on 'among' in the phrase 'among the challenging conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'among the challenging conditions'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "partial occlusions",
                "OtherScientificTerm"
            ],
            [
                "conditions",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('partial occlusions') is the conjunct, depending on 'and' with 'changing illumination conditions'. Entity 2 ('conditions') is the object of the preposition 'such as', depending on 'with' in the phrase 'with challenging conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of conditions described in the sentence.",
        "sdp_path_text": "occlusions → conditions → backgrounds → as → conditions",
        "sentence": "Partial occlusions are among the challenging conditions.",
        "sentence_llm_dp_info": "Entity 1 ('partial occlusions') is the subject, depending on the verb 'are'. Entity 2 ('conditions') is the noun complement, depending on the verb 'are' in the phrase 'are among the conditions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'among the conditions'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "cluttered backgrounds",
                "OtherScientificTerm"
            ],
            [
                "changing illumination conditions",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cluttered backgrounds') is part of a list of conditions, depending on 'with' which modifies 'challenging conditions'. Entity 2 ('changing illumination conditions') is also part of the same list of conditions, depending on 'and' which connects it to 'cluttered backgrounds'. There is no direct dependency between Entity 1 and Entity 2; they are both elements in a series of conditions listed after 'such as'.",
        "sdp_path_text": "backgrounds → conditions",
        "sentence": "We test under challenging conditions such as cluttered backgrounds and changing illumination conditions.",
        "sentence_llm_dp_info": "Entity 1 ('cluttered backgrounds') is part of a coordinate structure, depending on 'such' in the phrase 'such as cluttered backgrounds'. Entity 2 ('changing illumination conditions') is also part of a coordinate structure, depending on 'and' in the phrase 'and changing illumination conditions'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements listed after 'such as'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "cluttered backgrounds",
                "OtherScientificTerm"
            ],
            [
                "partial occlusions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cluttered backgrounds') is part of a list of conditions, depending on the conjunction 'and' with 'changing illumination conditions'. Entity 2 ('partial occlusions') is also part of the same list of conditions, depending on the conjunction 'and' with 'cluttered backgrounds'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a series of challenging conditions listed in the sentence.",
        "sdp_path_text": "backgrounds → conditions → occlusions",
        "sentence": "Challenging conditions include cluttered backgrounds and partial occlusions.",
        "sentence_llm_dp_info": "Entity 1 ('cluttered backgrounds') is the subject, depending on the conjunction 'and' with Entity 2. Entity 2 ('partial occlusions') is also a subject, depending on the conjunction 'and' with Entity 1. There is no direct dependency between Entity 1 and Entity 2; they are coordinated subjects of the verb 'include'."
    },
    {
        "raw_sentence": "We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations , and with challenging conditions such as cluttered backgrounds , changing illumination conditions and partial occlusions .",
        "ner_pair": [
            [
                "changing illumination conditions",
                "OtherScientificTerm"
            ],
            [
                "partial occlusions",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('changing illumination conditions') is part of a coordination, depending on 'and' with 'partial occlusions'. Entity 2 ('partial occlusions') is also part of the same coordination, depending on 'and' with 'changing illumination conditions'. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated elements in the list of challenging conditions.",
        "sdp_path_text": "conditions → occlusions",
        "sentence": "The properties are tested under changing illumination conditions and partial occlusions.",
        "sentence_llm_dp_info": "Entity 1 ('changing illumination conditions') is part of a prepositional phrase, depending on 'under' which modifies 'tested'. Entity 2 ('partial occlusions') is coordinated with 'changing illumination conditions' through the conjunction 'and', both serving as the object of the preposition 'under'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same prepositional phrase."
    },
    {
        "raw_sentence": "A very simple improved duration model has reduced the error rate by about 10 % in both triphone and semiphone systems .",
        "ner_pair": [
            [
                "duration model",
                "Method"
            ],
            [
                "error rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('duration model') is the subject, depending on the verb 'has reduced'. Entity 2 ('error rate') is the object, depending on the verb 'has reduced'. There is a direct dependency between Entity 1 and Entity 2, as 'duration model' is the agent that has caused the reduction in 'error rate'.",
        "sdp_path_text": "model → reduced → rate",
        "sentence": "The duration model has reduced the error rate.",
        "sentence_llm_dp_info": "Entity 1 ('duration model') is the subject, depending on the verb 'has reduced'. Entity 2 ('error rate') is the object, depending on the verb 'has reduced'. There is a direct dependency between Entity 1 and Entity 2, as 'duration model' is the agent that has performed the action (reduced) on 'error rate'."
    },
    {
        "raw_sentence": "A very simple improved duration model has reduced the error rate by about 10 % in both triphone and semiphone systems .",
        "ner_pair": [
            [
                "duration model",
                "Method"
            ],
            [
                "triphone and semiphone systems",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('duration model') is the subject, depending on 'has reduced' as the verb. Entity 2 ('triphone and semiphone systems') is the object of the preposition 'in', depending on 'in' in the phrase 'in both triphone and semiphone systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has reduced' and the preposition 'in'.",
        "sdp_path_text": "model → reduced → in → systems",
        "sentence": "The duration model has reduced the error rate in triphone and semiphone systems.",
        "sentence_llm_dp_info": "Entity 1 ('duration model') is the subject, depending on the verb 'has reduced'. Entity 2 ('triphone and semiphone systems') is the object of the preposition 'in', depending on 'in' in the phrase 'in triphone and semiphone systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has reduced' and the preposition 'in'."
    },
    {
        "raw_sentence": "A very simple improved duration model has reduced the error rate by about 10 % in both triphone and semiphone systems .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "triphone and semiphone systems",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('error rate') is the object of the verb 'reduced', depending on the verb 'reduced' in the clause 'has reduced the error rate'. Entity 2 ('triphone and semiphone systems') is the object of the preposition 'in', depending on the preposition 'in' in the phrase 'in both triphone and semiphone systems'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the reduction of the error rate is described in the context of these systems.",
        "sdp_path_text": "rate → reduced → in → systems",
        "sentence": "The error rate has been reduced in triphone and semiphone systems.",
        "sentence_llm_dp_info": "Entity 1 ('error rate') is the subject, depending on the verb 'reduced'. Entity 2 ('triphone and semiphone systems') is the object of the preposition 'in', depending on 'in' in the phrase 'in triphone and semiphone systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "A new training strategy has been tested which , by itself , did not provide useful improvements but suggests that improvements can be obtained by a related rapid adaptation technique .",
        "ner_pair": [
            [
                "rapid adaptation technique",
                "Method"
            ],
            [
                "training strategy",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rapid adaptation technique') is the object of the preposition 'by', depending on 'obtained'. Entity 2 ('training strategy') is the subject, depending on 'tested' with 'has been tested'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence, where the effectiveness of Entity 2 is discussed in relation to the potential of Entity 1.",
        "sdp_path_text": "technique → by → obtained → suggests → provide → strategy",
        "sentence": "A new training strategy suggests that improvements can be obtained by a rapid adaptation technique.",
        "sentence_llm_dp_info": "Entity 1 ('rapid adaptation technique') is the object of the preposition 'by', depending on 'by' in the phrase 'by a rapid adaptation technique'. Entity 2 ('training strategy') is the subject, depending on the verb 'suggests'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'by'."
    },
    {
        "raw_sentence": "Finally , the recognizer has been modified to use bigram back-off language models .",
        "ner_pair": [
            [
                "bigram back-off language models",
                "Method"
            ],
            [
                "recognizer",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('bigram back-off language models') is the object, depending on the verb 'use'. Entity 2 ('recognizer') is the subject, depending on the verb 'has been modified'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' where Entity 1 is what the recognizer uses after being modified.",
        "sdp_path_text": "models → use → modified → recognizer",
        "sentence": "The recognizer has been modified to use bigram back-off language models.",
        "sentence_llm_dp_info": "Entity 1 ('bigram back-off language models') is the object, depending on the verb 'use'. Entity 2 ('recognizer') is the subject, depending on the verb 'has been modified'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' in the clause 'to use bigram back-off language models'."
    },
    {
        "raw_sentence": "The system was then transferred from the RM task to the ATIS CSR task and a limited number of development tests performed .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "RM task",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'was transferred'. Entity 2 ('RM task') is the object of the preposition 'from', depending on 'transferred' in the phrase 'transferred from the RM task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.",
        "sdp_path_text": "system → transferred → from → task",
        "sentence": "The system was transferred from the RM task.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the passive verb 'was transferred'. Entity 2 ('RM task') is the object of the preposition 'from', depending on 'from' in the phrase 'from the RM task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'."
    },
    {
        "raw_sentence": "The system was then transferred from the RM task to the ATIS CSR task and a limited number of development tests performed .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "ATIS CSR task",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'transferred'. Entity 2 ('ATIS CSR task') is the object of the preposition 'to', depending on 'to' in the phrase 'to the ATIS CSR task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' indicating the direction or destination of the transfer.",
        "sdp_path_text": "system → transferred → to → task",
        "sentence": "The system was transferred to the ATIS CSR task.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the passive verb 'was transferred'. Entity 2 ('ATIS CSR task') is the object of the preposition 'to', depending on 'to' in the phrase 'to the ATIS CSR task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' and the passive construction 'was transferred'."
    },
    {
        "raw_sentence": "The system was then transferred from the RM task to the ATIS CSR task and a limited number of development tests performed .",
        "ner_pair": [
            [
                "RM task",
                "Task"
            ],
            [
                "ATIS CSR task",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('RM task') is the object of the preposition 'from', depending on 'transferred'. Entity 2 ('ATIS CSR task') is the object of the preposition 'to', also depending on 'transferred'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'transferred'.",
        "sdp_path_text": "task → from → transferred → to → task",
        "sentence": "The system was transferred from the RM task to the ATIS CSR task.",
        "sentence_llm_dp_info": "Entity 1 ('RM task') is the object of the preposition 'from', depending on 'transferred'. Entity 2 ('ATIS CSR task') is the object of the preposition 'to', also depending on 'transferred'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the same transfer action described by the verb 'transferred'."
    },
    {
        "raw_sentence": "A new approach for Interactive Machine Translation where the author interacts during the creation or the modification of the document is proposed .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "Interactive Machine Translation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'proposed'. Entity 2 ('Interactive Machine Translation') is the object of the preposition 'for', depending on 'for' in the phrase 'for Interactive Machine Translation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "approach → for → Translation",
        "sentence": "A new approach for Interactive Machine Translation is proposed.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'proposed'. Entity 2 ('Interactive Machine Translation') is the object of the preposition 'for', depending on 'for' in the phrase 'for Interactive Machine Translation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This paper presents a new interactive disambiguation scheme based on the paraphrasing of a parser 's multiple output .",
        "ner_pair": [
            [
                "paraphrasing",
                "Method"
            ],
            [
                "interactive disambiguation scheme",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('paraphrasing') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the paraphrasing'. Entity 2 ('interactive disambiguation scheme') is the direct object, depending on the verb 'presents' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on the paraphrasing'.",
        "sdp_path_text": "paraphrasing → on → based → scheme",
        "sentence": "The paraphrasing is the basis for the interactive disambiguation scheme.",
        "sentence_llm_dp_info": "Entity 1 ('paraphrasing') is the subject, depending on the copula 'is'. Entity 2 ('interactive disambiguation scheme') is the complement, depending on the preposition 'for', which is part of the prepositional phrase 'for the interactive disambiguation scheme'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the copula 'is' and the prepositional phrase 'for the...scheme'."
    },
    {
        "raw_sentence": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "statistical machine translation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject complement, depending on the verb 'describe' with 'We'. Entity 2 ('statistical machine translation') is the object of the preposition 'to', depending on 'to' in the phrase 'to statistical machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' which indicates the purpose or target of the approach.",
        "sdp_path_text": "approach → to → translation",
        "sentence": "A novel approach to statistical machine translation is described.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'described'. Entity 2 ('statistical machine translation') is the object of the preposition 'to', depending on 'to' in the phrase 'to statistical machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .",
        "ner_pair": [
            [
                "syntactic information",
                "OtherScientificTerm"
            ],
            [
                "approach",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('syntactic information') is the object of the preposition 'in', depending on 'source language'. Entity 2 ('approach') is the subject, depending on the verb 'describe' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the components of the novel approach.",
        "sdp_path_text": "information → combines → approach",
        "sentence": "The approach combines syntactic information.",
        "sentence_llm_dp_info": "Entity 1 ('syntactic information') is the object, depending on the verb 'combines' with 'approach'. Entity 2 ('approach') is the subject, depending on the verb 'combines'. There is a direct dependency between Entity 1 and Entity 2, as 'syntactic information' is directly combined by the 'approach'."
    },
    {
        "raw_sentence": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .",
        "ner_pair": [
            [
                "phrasal translation",
                "Task"
            ],
            [
                "approach",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phrasal translation') is the object of the preposition 'in', depending on 'advances'. Entity 2 ('approach') is the subject, depending on 'describe' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the approach that combines syntactic information and advances in phrasal translation.",
        "sdp_path_text": "translation → in → advances → with → combines → approach",
        "sentence": "The approach combines recent advances in phrasal translation.",
        "sentence_llm_dp_info": "Entity 1 ('phrasal translation') is the object of the preposition 'in', depending on 'advances'. Entity 2 ('approach') is the subject, depending on the verb 'combines'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combines' and the prepositional phrase 'in phrasal translation'."
    },
    {
        "raw_sentence": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .",
        "ner_pair": [
            [
                "statistical machine translation",
                "Task"
            ],
            [
                "syntactic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('statistical machine translation') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('syntactic information') is the object, depending on 'combines' with 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the 'approach' described in the sentence.",
        "sdp_path_text": "translation → to → approach → combines → information",
        "sentence": "Statistical machine translation combines syntactic information.",
        "sentence_llm_dp_info": "Entity 1 ('statistical machine translation') is the subject, depending on the verb 'combines'. Entity 2 ('syntactic information') is the object, depending on 'combines' with 'statistical machine translation'. There is a direct dependency between Entity 1 and Entity 2, as 'syntactic information' is directly combined by 'statistical machine translation'."
    },
    {
        "raw_sentence": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .",
        "ner_pair": [
            [
                "statistical machine translation",
                "Task"
            ],
            [
                "phrasal translation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('statistical machine translation') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('phrasal translation') is the object of the preposition 'in', depending on 'advances'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the structure describing the novel approach.",
        "sdp_path_text": "translation → to → approach → combines → with → advances → in → translation",
        "sentence": "Statistical machine translation combines with advances in phrasal translation.",
        "sentence_llm_dp_info": "Entity 1 ('statistical machine translation') is the subject, depending on the verb 'combines'. Entity 2 ('phrasal translation') is the object of the preposition 'in', part of the phrase 'advances in phrasal translation', which is the complement of 'combines'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combines' and the prepositional phrase 'in phrasal translation'."
    },
    {
        "raw_sentence": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .",
        "ner_pair": [
            [
                "syntactic information",
                "OtherScientificTerm"
            ],
            [
                "phrasal translation",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('syntactic information') is the object of the preposition 'in', depending on 'source language'. Entity 2 ('phrasal translation') is the object of the preposition 'in', depending on 'advances'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the components combined in the novel approach.",
        "sdp_path_text": "information → combines → with → advances → in → translation",
        "sentence": "Syntactic information is combined with advances in phrasal translation.",
        "sentence_llm_dp_info": "Entity 1 ('syntactic information') is the subject, depending on the verb 'combined'. Entity 2 ('phrasal translation') is the object of the preposition 'in', depending on 'advances'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'syntactic information' is combined with 'advances in phrasal translation'."
    },
    {
        "raw_sentence": "This method requires a source-language dependency parser , target language word segmentation and an unsupervised word alignment component .",
        "ner_pair": [
            [
                "source-language dependency parser",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('source-language dependency parser') is the object of the preposition 'a', depending on 'requires' with 'method'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires'.",
        "sdp_path_text": "parser → requires → method",
        "sentence": "The method requires a source-language dependency parser.",
        "sentence_llm_dp_info": "Entity 1 ('source-language dependency parser') is the object, depending on 'requires' with 'method'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is required by Entity 2."
    },
    {
        "raw_sentence": "This method requires a source-language dependency parser , target language word segmentation and an unsupervised word alignment component .",
        "ner_pair": [
            [
                "target language word segmentation",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('target language word segmentation') is the object of the preposition 'and', which is part of a list of items required by the 'method'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where Entity 1 is one of the requirements listed for Entity 2.",
        "sdp_path_text": "segmentation → parser → requires → method",
        "sentence": "The method requires target language word segmentation.",
        "sentence_llm_dp_info": "Entity 1 ('target language word segmentation') is the object, depending on the verb 'requires'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is a direct dependency between Entity 1 and Entity 2, as 'method' requires 'target language word segmentation'."
    },
    {
        "raw_sentence": "This method requires a source-language dependency parser , target language word segmentation and an unsupervised word alignment component .",
        "ner_pair": [
            [
                "unsupervised word alignment component",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised word alignment component') is the object, depending on the preposition 'and', which connects it to the list of items required by the 'method'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where Entity 1 is part of the list of requirements for Entity 2.",
        "sdp_path_text": "component → segmentation → parser → requires → method",
        "sentence": "The method requires an unsupervised word alignment component.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised word alignment component') is the object, depending on 'requires' with 'method'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is required by Entity 2."
    },
    {
        "raw_sentence": "This method requires a source-language dependency parser , target language word segmentation and an unsupervised word alignment component .",
        "ner_pair": [
            [
                "source-language dependency parser",
                "Method"
            ],
            [
                "target language word segmentation",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('source-language dependency parser') is the object of the preposition 'a', depending on 'requires' in the phrase 'requires a source-language dependency parser'. Entity 2 ('target language word segmentation') is also the object of the preposition 'and', depending on 'requires' in the phrase 'requires ... and an unsupervised word alignment component'. There is no direct dependency between Entity 1 and Entity 2; both are objects required by the verb 'requires'.",
        "sdp_path_text": "parser → segmentation",
        "sentence": "This method requires a source-language dependency parser and target language word segmentation.",
        "sentence_llm_dp_info": "Entity 1 ('source-language dependency parser') is the object of the preposition 'a', depending on 'requires' in the phrase 'requires a source-language dependency parser'. Entity 2 ('target language word segmentation') is also the object of the preposition 'a', depending on 'requires' in the phrase 'requires ... and target language word segmentation'. There is no direct dependency between Entity 1 and Entity 2, but both are required by the same verb 'requires'."
    },
    {
        "raw_sentence": "This method requires a source-language dependency parser , target language word segmentation and an unsupervised word alignment component .",
        "ner_pair": [
            [
                "source-language dependency parser",
                "Method"
            ],
            [
                "unsupervised word alignment component",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('source-language dependency parser') is the object of the preposition 'a', depending on 'requires' in the phrase 'requires a source-language dependency parser'. Entity 2 ('unsupervised word alignment component') is also the object of the preposition 'an', depending on 'and' in the phrase 'and an unsupervised word alignment component'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of items required by the method.",
        "sdp_path_text": "parser → segmentation → component",
        "sentence": "This method requires a source-language dependency parser and an unsupervised word alignment component.",
        "sentence_llm_dp_info": "Entity 1 ('source-language dependency parser') is the object of the preposition 'a', depending on 'requires' in the phrase 'requires a source-language dependency parser'. Entity 2 ('unsupervised word alignment component') is also the object of the preposition 'an', depending on 'requires' in the phrase 'requires an unsupervised word alignment component'. There is no direct dependency between Entity 1 and Entity 2, but both are required by the verb 'requires'."
    },
    {
        "raw_sentence": "This method requires a source-language dependency parser , target language word segmentation and an unsupervised word alignment component .",
        "ner_pair": [
            [
                "target language word segmentation",
                "Method"
            ],
            [
                "unsupervised word alignment component",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('target language word segmentation') is part of a list, depending on the conjunction 'and', which connects it to 'source-language dependency parser'. Entity 2 ('unsupervised word alignment component') is also part of a list, depending on the conjunction 'and', which connects it to 'target language word segmentation'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a list connected by the conjunction 'and'.",
        "sdp_path_text": "segmentation → component",
        "sentence": "Target language word segmentation and unsupervised word alignment component are required.",
        "sentence_llm_dp_info": "Entity 1 ('target language word segmentation') is part of the conjunction, depending on 'and' which connects it with 'unsupervised word alignment component'. Entity 2 ('unsupervised word alignment component') is also part of the conjunction, depending on 'and' which connects it with 'target language word segmentation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree-based ordering model .",
        "ner_pair": [
            [
                "parallel corpus",
                "Material"
            ],
            [
                "source dependency parse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parallel corpus') is the object, depending on the verb 'align' with 'We'. Entity 2 ('source dependency parse') is the subject, depending on the verb 'project' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but both are related through the actions performed by the subject 'We'.",
        "sdp_path_text": "corpus → align → project → parse",
        "sentence": "We align a parallel corpus and project the source dependency parse.",
        "sentence_llm_dp_info": "Entity 1 ('parallel corpus') is the object of the verb 'align', depending on 'align' with 'We'. Entity 2 ('source dependency parse') is the object of the verb 'project', depending on 'project' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of different verbs in the same clause."
    },
    {
        "raw_sentence": "We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree-based ordering model .",
        "ner_pair": [
            [
                "parallel corpus",
                "Material"
            ],
            [
                "dependency treelet translation pairs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parallel corpus') is the object of the verb 'align', depending on 'align' in the phrase 'We align a parallel corpus'. Entity 2 ('dependency treelet translation pairs') is the object of the verb 'extract', depending on 'extract' in the phrase 'extract dependency treelet translation pairs'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "corpus → align → project → extract → pairs",
        "sentence": "We align a parallel corpus, project dependencies, and extract dependency treelet translation pairs.",
        "sentence_llm_dp_info": "Entity 1 ('parallel corpus') is the object of the verb 'align', depending on 'align' with 'We'. Entity 2 ('dependency treelet translation pairs') is the object of the verb 'extract', depending on 'extract' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of actions performed by the subject 'We'."
    },
    {
        "raw_sentence": "We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree-based ordering model .",
        "ner_pair": [
            [
                "parallel corpus",
                "Material"
            ],
            [
                "tree-based ordering model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parallel corpus') is the object, depending on 'align' with 'We'. Entity 2 ('tree-based ordering model') is the object, depending on 'train' with 'and'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "corpus → align → project → extract → train → model",
        "sentence": "We align a parallel corpus and train a tree-based ordering model.",
        "sentence_llm_dp_info": "Entity 1 ('parallel corpus') is the object of the verb 'align', depending on 'align' with 'We'. Entity 2 ('tree-based ordering model') is the object of the verb 'train', depending on 'train' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different verbs in the sentence."
    },
    {
        "raw_sentence": "We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree-based ordering model .",
        "ner_pair": [
            [
                "source dependency parse",
                "OtherScientificTerm"
            ],
            [
                "dependency treelet translation pairs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('source dependency parse') is the object of the verb 'project', depending on 'project' with the phrase 'project the source dependency parse'. Entity 2 ('dependency treelet translation pairs') is the object of the verb 'extract', depending on 'extract' with the phrase 'extract dependency treelet translation pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a sequence of actions described in the sentence.",
        "sdp_path_text": "parse → project → extract → pairs",
        "sentence": "We project the source dependency parse to extract dependency treelet translation pairs.",
        "sentence_llm_dp_info": "Entity 1 ('source dependency parse') is the object of the verb 'project', depending on 'project'. Entity 2 ('dependency treelet translation pairs') is the object of the verb 'extract', depending on 'extract'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described in the sentence."
    },
    {
        "raw_sentence": "We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree-based ordering model .",
        "ner_pair": [
            [
                "source dependency parse",
                "OtherScientificTerm"
            ],
            [
                "tree-based ordering model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('source dependency parse') is the object of the verb 'project', depending on 'project' with 'the source dependency parse'. Entity 2 ('tree-based ordering model') is the object of the verb 'train', depending on 'train' with 'a tree-based ordering model'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a sequence of actions described in the sentence.",
        "sdp_path_text": "parse → project → extract → train → model",
        "sentence": "We project the source dependency parse, extract translation pairs, and train a tree-based ordering model.",
        "sentence_llm_dp_info": "Entity 1 ('source dependency parse') is the object of the verb 'project', depending on 'project' in the clause 'We project the source dependency parse'. Entity 2 ('tree-based ordering model') is the object of the verb 'train', depending on 'train' in the clause 'and train a tree-based ordering model'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree-based ordering model .",
        "ner_pair": [
            [
                "dependency treelet translation pairs",
                "OtherScientificTerm"
            ],
            [
                "tree-based ordering model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dependency treelet translation pairs') is the object, depending on 'extract' with 'we'. Entity 2 ('tree-based ordering model') is the object, depending on 'train' with 'we'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "pairs → extract → train → model",
        "sentence": "We extract dependency treelet translation pairs and train a tree-based ordering model.",
        "sentence_llm_dp_info": "Entity 1 ('dependency treelet translation pairs') is the object of the verb 'extract', depending on 'extract' with 'We'. Entity 2 ('tree-based ordering model') is the object of the verb 'train', depending on 'train' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different verbs in the sentence."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "decoder",
                "Method"
            ],
            [
                "tree-based models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on the verb 'describe' in the clause 'We describe an efficient decoder'. Entity 2 ('tree-based models') is part of the object of the preposition 'using', depending on 'using' in the phrase 'using these tree-based models'. There is no direct dependency between Entity 1 and Entity 2; both are parts of different clauses within the same sentence.",
        "sdp_path_text": "decoder → describe → show → provides → using → models",
        "sentence": "We describe a decoder that shows the use of tree-based models provides benefits.",
        "sentence_llm_dp_info": "Entity 1 ('decoder') is the subject, depending on the verb 'describe' with 'We'. Entity 2 ('tree-based models') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the use of Entity 2 (tree-based models) is described as providing benefits within the context of Entity 1 (decoder)."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "decoder",
                "Method"
            ],
            [
                "SMT models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on 'We'. Entity 2 ('SMT models') is part of a compound noun phrase, depending on 'models' in the phrase 'conventional SMT models'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of describing an approach that combines different models for improved performance.",
        "sdp_path_text": "decoder → describe → show → provides → using → in → combination → with → models",
        "sentence": "We describe a decoder that provides a promising approach when used in combination with SMT models.",
        "sentence_llm_dp_info": "Entity 1 ('decoder') is the subject of the clause, depending on the verb 'provides'. Entity 2 ('SMT models') is the object of the preposition 'with', depending on 'with' in the phrase 'in combination with SMT models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in combination with'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "decoder",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on 'We'. Entity 2 ('approach') is the subject complement, depending on the verb 'provides' which is part of the clause 'provides a promising approach'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.",
        "sdp_path_text": "decoder → describe → show → provides → approach",
        "sentence": "We describe a decoder that provides a promising approach.",
        "sentence_llm_dp_info": "Entity 1 ('decoder') is the subject complement, depending on the verb 'describe' with 'We'. Entity 2 ('approach') is the object of the preposition 'to', depending on 'promising' in the phrase 'promising approach'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'decoder' is described as providing 'a promising approach'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "decoder",
                "Method"
            ],
            [
                "phrasal SMT",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on 'We'. Entity 2 ('phrasal SMT') is part of the compound noun 'power of phrasal SMT', which is the object of the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; they are both part of different clauses within the same sentence, connected through the context of the described approach.",
        "sdp_path_text": "decoder → describe → show → provides → approach → incorporates → power → of → SMT",
        "sentence": "We describe a decoder that incorporates the power of phrasal SMT.",
        "sentence_llm_dp_info": "Entity 1 ('decoder') is the subject complement, depending on 'describe' with 'We'. Entity 2 ('phrasal SMT') is the object of the preposition 'of', depending on 'power'. There is a direct dependency between Entity 1 and Entity 2, as 'phrasal SMT' is part of the content that the 'decoder' incorporates, linked through the verb 'incorporates'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "decoder",
                "Method"
            ],
            [
                "linguistic generality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on the pronoun 'We'. Entity 2 ('linguistic generality') is part of the noun phrase 'the linguistic generality available in a parser', which is the object of the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger clause describing different aspects of the approach being discussed.",
        "sdp_path_text": "decoder → describe → show → provides → approach → incorporates → with → generality",
        "sentence": "We describe a decoder that incorporates linguistic generality.",
        "sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on 'We'. Entity 2 ('linguistic generality') is the object of the verb 'incorporates', depending on 'decoder'. There is a direct dependency between Entity 1 and Entity 2, as 'linguistic generality' is incorporated into the 'decoder'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "decoder",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoder') is the object of the verb 'describe', depending on the pronoun 'We'. Entity 2 ('parser') is the object of the preposition 'in', depending on the noun 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing components of an approach in the sentence.",
        "sdp_path_text": "decoder → describe → show → provides → approach → incorporates → with → generality → available → in → parser",
        "sentence": "We describe a decoder that incorporates the generality available in a parser.",
        "sentence_llm_dp_info": "Entity 1 ('decoder') is the subject, depending on the verb 'describe' with 'We'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available' in the phrase 'available in a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporates' and the prepositional phrase 'available in a parser'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "tree-based models",
                "Method"
            ],
            [
                "SMT models",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tree-based models') is part of the object of the preposition 'with', depending on 'using'. Entity 2 ('SMT models') is also part of the object of the preposition 'with', depending on 'conventional'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'with conventional SMT models' and 'these tree-based models'.",
        "sdp_path_text": "models → using → in → combination → with → models",
        "sentence": "Tree-based models used in combination with SMT models provide a promising approach.",
        "sentence_llm_dp_info": "Entity 1 ('tree-based models') is the subject, depending on the verb 'provide'. Entity 2 ('SMT models') is part of the prepositional phrase 'in combination with SMT models', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' within the phrase 'in combination with'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "tree-based models",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tree-based models') is the object of the preposition 'using', depending on 'show'. Entity 2 ('approach') is the subject complement, depending on the verb 'provides'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause structure where 'tree-based models' are part of what 'provides a promising approach'.",
        "sdp_path_text": "models → using → provides → approach",
        "sentence": "Using tree-based models provides a promising approach.",
        "sentence_llm_dp_info": "Entity 1 ('tree-based models') is the object of the preposition 'Using', depending on 'Using'. Entity 2 ('approach') is the subject complement, depending on 'provides' with 'provides a promising approach'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'tree-based models' are described as providing the 'approach'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "tree-based models",
                "Method"
            ],
            [
                "phrasal SMT",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tree-based models') is the object of the preposition 'using', depending on 'show'. Entity 2 ('phrasal SMT') is the object of the preposition 'with', depending on 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the promising approach.",
        "sdp_path_text": "models → using → provides → approach → incorporates → power → of → SMT",
        "sentence": "Using tree-based models provides an approach that incorporates the power of phrasal SMT.",
        "sentence_llm_dp_info": "Entity 1 ('tree-based models') is the subject, depending on the verb 'provides'. Entity 2 ('phrasal SMT') is the object of the preposition 'of', depending on 'power'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'approach' and the prepositional phrase 'of phrasal SMT'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "tree-based models",
                "Method"
            ],
            [
                "linguistic generality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tree-based models') is the object of the preposition 'using', depending on 'show'. Entity 2 ('linguistic generality') is the object of the preposition 'with', depending on 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the approach that incorporates various elements.",
        "sdp_path_text": "models → using → provides → approach → incorporates → with → generality",
        "sentence": "Using tree-based models provides an approach that incorporates linguistic generality.",
        "sentence_llm_dp_info": "Entity 1 ('tree-based models') is the object of the verb 'Using', depending on 'provides' with the subject role. Entity 2 ('linguistic generality') is the object of the verb 'incorporates', depending on 'that' which introduces the clause describing the approach. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the clause introduced by 'that'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "tree-based models",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tree-based models') is part of the object of the preposition 'with', depending on 'combination'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the complex structure describing the approach that incorporates different elements.",
        "sdp_path_text": "models → using → provides → approach → incorporates → with → generality → available → in → parser",
        "sentence": "Using tree-based models provides an approach that incorporates the generality available in a parser.",
        "sentence_llm_dp_info": "Entity 1 ('tree-based models') is the subject, depending on the verb 'provides'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available' in the phrase 'available in a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' and the prepositional phrase 'available in a parser'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "SMT models",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SMT models') is part of the object of the preposition 'with', depending on 'with' in the phrase 'with conventional SMT models'. Entity 2 ('approach') is the subject complement, depending on 'provides' with 'that'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' and the conjunction 'with'.",
        "sdp_path_text": "models → with → combination → in → using → provides → approach",
        "sentence": "Using SMT models in combination provides a promising approach.",
        "sentence_llm_dp_info": "Entity 1 ('SMT models') is the object of the preposition 'using', depending on 'using' in the phrase 'Using SMT models'. Entity 2 ('approach') is the subject complement, depending on 'provides' with 'a promising approach'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' which indicates that the use of SMT models contributes to providing a promising approach."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "SMT models",
                "Method"
            ],
            [
                "phrasal SMT",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SMT models') is part of the object of the preposition 'with', depending on 'with' in the phrase 'with conventional SMT models'. Entity 2 ('phrasal SMT') is the object of the preposition 'of', depending on 'power' in the phrase 'the power of phrasal SMT'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the overall structure describing the approach that incorporates different types of SMT models.",
        "sdp_path_text": "models → with → combination → in → using → provides → approach → incorporates → power → of → SMT",
        "sentence": "Combining SMT models with tree-based models provides an approach that incorporates the power of phrasal SMT.",
        "sentence_llm_dp_info": "Entity 1 ('SMT models') is part of the compound subject, depending on 'Combining' with 'with tree-based models'. Entity 2 ('phrasal SMT') is the object of the preposition 'of', depending on 'power'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'approach' and 'power' within the sentence."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "SMT models",
                "Method"
            ],
            [
                "linguistic generality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SMT models') is the object of the preposition 'with', depending on 'combination'. Entity 2 ('linguistic generality') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the approach that incorporates different elements.",
        "sdp_path_text": "models → with → combination → in → using → provides → approach → incorporates → with → generality",
        "sentence": "Using SMT models in combination with tree-based models provides an approach that incorporates linguistic generality.",
        "sentence_llm_dp_info": "Entity 1 ('SMT models') is part of the compound subject, depending on the verb 'provides' through the prepositional phrase 'in combination with tree-based models'. Entity 2 ('linguistic generality') is the object of the relative clause, depending on 'incorporates' in the phrase 'that incorporates linguistic generality'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the relative clause that describes the approach."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "SMT models",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SMT models') is part of the object complement, depending on 'with' in the phrase 'with conventional SMT models'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available' in the phrase 'available in a parser'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the description of the 'promising approach' mentioned in the sentence.",
        "sdp_path_text": "models → with → combination → in → using → provides → approach → incorporates → with → generality → available → in → parser",
        "sentence": "Combining SMT models with a parser provides an approach that incorporates linguistic generality.",
        "sentence_llm_dp_info": "Entity 1 ('SMT models') is part of the compound subject, depending on 'Combining' as a conjunct. Entity 2 ('parser') is also part of the compound subject, depending on 'Combining' as a conjunct. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same compound subject in the sentence."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "phrasal SMT",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject complement, depending on the verb 'provides'. Entity 2 ('phrasal SMT') is part of the compound object, depending on 'power' in the noun phrase 'the power of phrasal SMT'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun phrase that describes the content of the 'approach'.",
        "sdp_path_text": "approach → incorporates → power → of → SMT",
        "sentence": "The approach incorporates the power of phrasal SMT.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'incorporates'. Entity 2 ('phrasal SMT') is the object, depending on 'of' in the prepositional phrase 'of phrasal SMT'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the preposition 'of'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "linguistic generality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject complement, depending on 'provides' with 'that'. Entity 2 ('linguistic generality') is the object of the preposition 'of', depending on 'available' in the phrase 'available in a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'approach' is described as incorporating the 'power of phrasal SMT with the linguistic generality available in a parser'.",
        "sdp_path_text": "approach → incorporates → with → generality",
        "sentence": "The approach incorporates linguistic generality.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'incorporates'. Entity 2 ('linguistic generality') is the object, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, as 'linguistic generality' is directly incorporated by 'the approach'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject complement, depending on the verb 'provides'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available' in the phrase 'available in a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the prepositional phrase 'available in a parser'.",
        "sdp_path_text": "approach → incorporates → with → generality → available → in → parser",
        "sentence": "The approach incorporates the generality available in a parser.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'incorporates'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the prepositional phrase 'in a parser'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "phrasal SMT",
                "Method"
            ],
            [
                "linguistic generality",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phrasal SMT') is part of a compound noun, depending on 'power' with the preposition 'of'. Entity 2 ('linguistic generality') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the components of the promising approach.",
        "sdp_path_text": "SMT → of → power → incorporates → with → generality",
        "sentence": "Phrasal SMT incorporates linguistic generality.",
        "sentence_llm_dp_info": "Entity 1 ('phrasal SMT') is the subject, depending on the verb 'incorporates'. Entity 2 ('linguistic generality') is the object, depending on 'incorporates' with 'phrasal SMT'. There is a direct dependency between Entity 1 and Entity 2, as 'phrasal SMT' incorporates 'linguistic generality'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "phrasal SMT",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phrasal SMT') is part of a compound noun, depending on 'incorporates' as a direct object within the clause 'incorporates the power of phrasal SMT'. Entity 2 ('parser') is also part of a compound noun, depending on 'available' as a prepositional complement in the phrase 'available in a parser'. There is no direct dependency between Entity 1 and Entity 2; both are related to different aspects of the described approach.",
        "sdp_path_text": "SMT → of → power → incorporates → with → generality → available → in → parser",
        "sentence": "Phrasal SMT incorporates its power with the linguistic generality available in a parser.",
        "sentence_llm_dp_info": "Entity 1 ('phrasal SMT') is the subject, depending on the verb 'incorporates'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporates' and the prepositional phrase 'in a parser'."
    },
    {
        "raw_sentence": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser .",
        "ner_pair": [
            [
                "linguistic generality",
                "OtherScientificTerm"
            ],
            [
                "parser",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linguistic generality') is the object, depending on the preposition 'in' within the phrase 'available in a parser'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'in' in the phrase 'in a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.",
        "sdp_path_text": "generality → available → in → parser",
        "sentence": "Linguistic generality is available in a parser.",
        "sentence_llm_dp_info": "Entity 1 ('linguistic generality') is the subject, depending on the verb 'is'. Entity 2 ('parser') is the object of the preposition 'in', depending on 'in' in the phrase 'in a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in a parser'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "visual cues",
                "OtherScientificTerm"
            ],
            [
                "Video",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('visual cues') is the object of the preposition 'such as', depending on 'cues' in the phrase 'rich visual cues'. Entity 2 ('Video') is the subject, depending on the verb 'provides'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'such as motion and appearance' which describes the 'rich visual cues' provided by 'Video'.",
        "sdp_path_text": "cues → provides → Video",
        "sentence": "Video provides visual cues.",
        "sentence_llm_dp_info": "Entity 1 ('visual cues') is the object, depending on the verb 'provides'. Entity 2 ('Video') is the subject, depending on the verb 'provides'. There is a direct dependency between Entity 1 and Entity 2, as 'Video' provides 'visual cues'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "Video",
                "Material"
            ],
            [
                "motion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Video') is the subject, depending on the verb 'provides'. Entity 2 ('motion') is part of a list of examples, depending on the conjunction 'such as' which is linked to 'cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'cues' and the prepositional phrase 'such as motion and appearance'.",
        "sdp_path_text": "Video → provides → cues → as → motion",
        "sentence": "Video provides visual cues such as motion.",
        "sentence_llm_dp_info": "Entity 1 ('Video') is the subject, depending on the verb 'provides'. Entity 2 ('motion') is part of a list of objects, depending on the preposition 'such as' which itself depends on 'cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'cues' and the preposition 'such as'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "Video",
                "Material"
            ],
            [
                "appearance",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Video') is the subject, depending on the verb 'provides'. Entity 2 ('appearance') is part of a coordinated noun phrase, depending on the conjunction 'and' within the list of visual cues provided by 'Video'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'appearance' is listed as one of the visual cues that 'Video' provides.",
        "sdp_path_text": "Video → provides → cues → as → motion → appearance",
        "sentence": "Video provides visual cues such as motion and appearance.",
        "sentence_llm_dp_info": "Entity 1 ('Video') is the subject, depending on the verb 'provides'. Entity 2 ('appearance') is part of the object, depending on the conjunction 'and' within the phrase 'such as motion and appearance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the prepositional phrase 'such as'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "Video",
                "Material"
            ],
            [
                "long-range temporal interactions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Video') is the subject, depending on the verb 'provides'. Entity 2 ('long-range temporal interactions') is the object of the preposition 'among', depending on 'among' in the phrase 'among objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'Video' provides various elements including 'long-range temporal interactions'.",
        "sdp_path_text": "Video → provides → cues → interactions",
        "sentence": "Video provides long-range temporal interactions.",
        "sentence_llm_dp_info": "Entity 1 ('Video') is the subject, depending on the verb 'provides'. Entity 2 ('long-range temporal interactions') is the direct object, depending on 'provides' with 'Video'. There is a direct dependency between Entity 1 and Entity 2, where 'Video' provides 'long-range temporal interactions'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "motion",
                "OtherScientificTerm"
            ],
            [
                "visual cues",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motion') is part of a list, depending on the conjunction 'and' with 'appearance', both being examples of 'visual cues'. Entity 2 ('visual cues') is the object of the preposition 'such as', depending on 'provides' in the phrase 'provides... visual cues'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'motion' is an example of 'visual cues'.",
        "sdp_path_text": "motion → as → cues",
        "sentence": "Motion is a type of visual cue.",
        "sentence_llm_dp_info": "Entity 1 ('motion') is the subject, depending on the copula 'is'. Entity 2 ('visual cues') is the predicate nominative, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as they are linked through the copula 'is'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "appearance",
                "OtherScientificTerm"
            ],
            [
                "visual cues",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('appearance') is part of a coordination, depending on 'and' with 'motion'. Entity 2 ('visual cues') is the object of the preposition 'such as', depending on 'cues' in the phrase 'such as motion and appearance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'such as' and the conjunction 'and'.",
        "sdp_path_text": "appearance → motion → as → cues",
        "sentence": "Appearance and motion are visual cues.",
        "sentence_llm_dp_info": "Entity 1 ('appearance') is the subject, depending on the verb 'are'. Entity 2 ('visual cues') is the predicate nominal, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as both are part of the same copular construction linked by the verb 'are'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "visual cues",
                "OtherScientificTerm"
            ],
            [
                "long-range temporal interactions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('visual cues') is part of a list, depending on 'provides' with 'Video'. Entity 2 ('long-range temporal interactions') is the subject complement, depending on 'but also' which links it to the previous clause. There is no direct dependency between Entity 1 and Entity 2, but they are both related to what 'Video provides'.",
        "sdp_path_text": "cues → interactions",
        "sentence": "Visual cues and long-range temporal interactions are provided by video.",
        "sentence_llm_dp_info": "Entity 1 ('visual cues') is part of a conjunction, depending on the coordinating conjunction 'and' with 'long-range temporal interactions'. Entity 2 ('long-range temporal interactions') is also part of the same conjunction, depending on 'and' with 'visual cues'. Both Entity 1 and Entity 2 are objects of the verb 'provided' in the clause 'are provided by video'. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated subjects in the sentence."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "motion",
                "OtherScientificTerm"
            ],
            [
                "appearance",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motion') is a conjunct, depending on 'cues' with the conjunction 'and'. Entity 2 ('appearance') is another conjunct, also depending on 'cues' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a coordination structure headed by 'cues'.",
        "sdp_path_text": "motion → appearance",
        "sentence": "Video provides visual cues such as motion and appearance.",
        "sentence_llm_dp_info": "Entity 1 ('motion') is part of a coordination, depending on 'and' with 'appearance'. Entity 2 ('appearance') is also part of a coordination, depending on 'and' with 'motion'. Both Entity 1 and Entity 2 are objects of the preposition 'such as', which depends on 'cues'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and' and the prepositional phrase 'such as'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "motion",
                "OtherScientificTerm"
            ],
            [
                "long-range temporal interactions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motion') is part of a conjunction, depending on 'cues' through the conjunction 'and'. Entity 2 ('long-range temporal interactions') is the subject complement, depending on 'provides' through the preposition 'among'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of things provided by video.",
        "sdp_path_text": "motion → as → cues → interactions",
        "sentence": "Motion serves as a cue for long-range temporal interactions.",
        "sentence_llm_dp_info": "Entity 1 ('motion') is the subject, depending on the verb 'serves'. Entity 2 ('long-range temporal interactions') is the object of the preposition 'for', depending on 'for' in the phrase 'for long-range temporal interactions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'as a cue for'."
    },
    {
        "raw_sentence": "Video provides not only rich visual cues such as motion and appearance , but also much less explored long-range temporal interactions among objects .",
        "ner_pair": [
            [
                "appearance",
                "OtherScientificTerm"
            ],
            [
                "long-range temporal interactions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('appearance') is part of a list, depending on the conjunction 'and' with 'motion'. Entity 2 ('long-range temporal interactions') is the subject complement, depending on 'provides' with 'Video'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the information provided by 'Video'.",
        "sdp_path_text": "appearance → motion → as → cues → interactions",
        "sentence": "Appearance and motion provide cues for long-range temporal interactions.",
        "sentence_llm_dp_info": "Entity 1 ('appearance') is the subject, depending on the verb 'provide'. Entity 2 ('long-range temporal interactions') is the object, depending on 'cues' with the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provide' and the preposition 'for'."
    },
    {
        "raw_sentence": "We aim to capture such interactions and to construct a powerful intermediate-level video representation for subsequent recognition .",
        "ner_pair": [
            [
                "interactions",
                "Generic"
            ],
            [
                "intermediate-level video representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('interactions') is the object of the verb 'capture', depending on 'aim' through the infinitive 'to capture'. Entity 2 ('intermediate-level video representation') is the object of the verb 'construct', depending on 'aim' through the infinitive 'to construct'. There is no direct dependency between Entity 1 and Entity 2; both are goals of the aims expressed in the sentence.",
        "sdp_path_text": "interactions → capture → construct → representation",
        "sentence": "We aim to capture interactions and construct an intermediate-level video representation.",
        "sentence_llm_dp_info": "Entity 1 ('interactions') is the object of the verb 'capture', depending on 'aim' through the verb 'capture'. Entity 2 ('intermediate-level video representation') is the object of the verb 'construct', depending on 'aim' through the verb 'construct'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause's intent expressed by 'aim'."
    },
    {
        "raw_sentence": "We aim to capture such interactions and to construct a powerful intermediate-level video representation for subsequent recognition .",
        "ner_pair": [
            [
                "interactions",
                "Generic"
            ],
            [
                "recognition",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('interactions') is the object of the verb 'capture', depending on 'aim'. Entity 2 ('recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for subsequent recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, connected through the main verb 'aim' and the conjunction 'and'.",
        "sdp_path_text": "interactions → capture → construct → for → recognition",
        "sentence": "We aim to capture interactions for subsequent recognition.",
        "sentence_llm_dp_info": "Entity 1 ('interactions') is the object of the verb 'capture', depending on 'aim' through the verb 'capture'. Entity 2 ('recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for subsequent recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' and the preposition 'for'."
    },
    {
        "raw_sentence": "We aim to capture such interactions and to construct a powerful intermediate-level video representation for subsequent recognition .",
        "ner_pair": [
            [
                "intermediate-level video representation",
                "Method"
            ],
            [
                "recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('intermediate-level video representation') is the object, depending on 'construct' with 'to construct'. Entity 2 ('recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for subsequent recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose expressed by 'for'.",
        "sdp_path_text": "representation → construct → for → recognition",
        "sentence": "We construct an intermediate-level video representation for recognition.",
        "sentence_llm_dp_info": "Entity 1 ('intermediate-level video representation') is the object, depending on the verb 'construct'. Entity 2 ('recognition') is the purpose or goal, depending on the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the construction of the representation aimed at facilitating recognition."
    },
    {
        "raw_sentence": "Motivated by this goal , we seek to obtain spatio-temporal over-segmentation of a video into regions that respect object boundaries and , at the same time , associate object pix-els over many video frames .",
        "ner_pair": [
            [
                "spatio-temporal over-segmentation",
                "OtherScientificTerm"
            ],
            [
                "object boundaries",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatio-temporal over-segmentation') is the object of the verb 'obtain', depending on 'seek'. Entity 2 ('object boundaries') is the object of the relative clause 'that respect object boundaries', depending on 'respect'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'respect' within the relative clause.",
        "sdp_path_text": "over → obtain → segmentation → into → regions → respect → boundaries",
        "sentence": "We seek to obtain spatio-temporal over-segmentation into regions that respect object boundaries.",
        "sentence_llm_dp_info": "Entity 1 ('spatio-temporal over-segmentation') is the object, depending on the verb 'obtain'. Entity 2 ('object boundaries') is the object of the relative clause, depending on 'respect' within the clause 'that respect object boundaries'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'respect' in the relative clause."
    },
    {
        "raw_sentence": "First , we develop an efficient spatio-temporal video segmentation algorithm , which naturally incorporates long-range motion cues from the past and future frames in the form of clusters of point tracks with coherent motion .",
        "ner_pair": [
            [
                "long-range motion cues",
                "OtherScientificTerm"
            ],
            [
                "spatio-temporal video segmentation algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('long-range motion cues') is the object of the preposition 'from', depending on 'incorporates' with 'algorithm'. Entity 2 ('spatio-temporal video segmentation algorithm') is the object, depending on 'develop' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates'.",
        "sdp_path_text": "cues → incorporates → algorithm",
        "sentence": "The algorithm incorporates long-range motion cues.",
        "sentence_llm_dp_info": "Entity 1 ('long-range motion cues') is the object, depending on 'incorporates' with 'algorithm'. Entity 2 ('spatio-temporal video segmentation algorithm') is not present in the sentence provided. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 does not appear in the sentence."
    },
    {
        "raw_sentence": "First , we develop an efficient spatio-temporal video segmentation algorithm , which naturally incorporates long-range motion cues from the past and future frames in the form of clusters of point tracks with coherent motion .",
        "ner_pair": [
            [
                "spatio-temporal video segmentation algorithm",
                "Method"
            ],
            [
                "clusters of point tracks",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatio-temporal video segmentation algorithm') is the object, depending on the verb 'develop'. Entity 2 ('clusters of point tracks') is the object of the preposition 'of', depending on 'form' in the phrase 'in the form of clusters of point tracks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that describes a feature of the algorithm.",
        "sdp_path_text": "algorithm → incorporates → cues → in → form → of → clusters",
        "sentence": "The spatio-temporal video segmentation algorithm incorporates clusters of point tracks.",
        "sentence_llm_dp_info": "Entity 1 ('spatio-temporal video segmentation algorithm') is the subject, depending on the verb 'incorporates'. Entity 2 ('clusters of point tracks') is the object, depending on 'incorporates' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly incorporated by Entity 1."
    },
    {
        "raw_sentence": "First , we develop an efficient spatio-temporal video segmentation algorithm , which naturally incorporates long-range motion cues from the past and future frames in the form of clusters of point tracks with coherent motion .",
        "ner_pair": [
            [
                "clusters of point tracks",
                "OtherScientificTerm"
            ],
            [
                "long-range motion cues",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('clusters of point tracks') is the object of the preposition 'of', depending on 'form'. Entity 2 ('long-range motion cues') is the object of the preposition 'from', depending on 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how the algorithm incorporates information.",
        "sdp_path_text": "clusters → of → form → in → cues",
        "sentence": "Clusters of point tracks incorporate long-range motion cues.",
        "sentence_llm_dp_info": "Entity 1 ('clusters of point tracks') is the subject, depending on the verb 'incorporate'. Entity 2 ('long-range motion cues') is the object, depending on 'incorporate' with 'clusters of point tracks'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 incorporates Entity 2."
    },
    {
        "raw_sentence": "Second , we devise a new track clustering cost function that includes occlusion reasoning , in the form of depth ordering constraints , as well as motion similarity along the tracks .",
        "ner_pair": [
            [
                "occlusion reasoning",
                "OtherScientificTerm"
            ],
            [
                "track clustering cost function",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('occlusion reasoning') is the object of the preposition 'includes', depending on 'function'. Entity 2 ('track clustering cost function') is the direct object, depending on the verb 'devises'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure where 'occlusion reasoning' is included within the 'track clustering cost function'.",
        "sdp_path_text": "reasoning → includes → function",
        "sentence": "Occlusion reasoning is included in the track clustering cost function.",
        "sentence_llm_dp_info": "Entity 1 ('occlusion reasoning') is the subject, depending on the verb 'is included'. Entity 2 ('track clustering cost function') is the object of the preposition 'in', depending on 'in' in the phrase 'in the track clustering cost function'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates that Entity 1 is a component or part of Entity 2."
    },
    {
        "raw_sentence": "Second , we devise a new track clustering cost function that includes occlusion reasoning , in the form of depth ordering constraints , as well as motion similarity along the tracks .",
        "ner_pair": [
            [
                "track clustering cost function",
                "Method"
            ],
            [
                "depth ordering constraints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('track clustering cost function') is the direct object, depending on the verb 'devised'. Entity 2 ('depth ordering constraints') is part of the prepositional phrase 'in the form of depth ordering constraints', which modifies the verb 'includes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the prepositional phrase 'in the form of'.",
        "sdp_path_text": "function → includes → reasoning → in → form → of → constraints",
        "sentence": "The track clustering cost function includes depth ordering constraints.",
        "sentence_llm_dp_info": "Entity 1 ('track clustering cost function') is the subject, depending on the verb 'includes'. Entity 2 ('depth ordering constraints') is the object, depending on 'includes' with 'track clustering cost function'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is included in Entity 1."
    },
    {
        "raw_sentence": "Second , we devise a new track clustering cost function that includes occlusion reasoning , in the form of depth ordering constraints , as well as motion similarity along the tracks .",
        "ner_pair": [
            [
                "motion similarity",
                "OtherScientificTerm"
            ],
            [
                "track clustering cost function",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('motion similarity') is part of the list of elements included in the 'track clustering cost function', depending on the conjunction 'as well as'. Entity 2 ('track clustering cost function') is the object of the relative clause, depending on the verb 'includes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'motion similarity' is one of the components included in the 'track clustering cost function'.",
        "sdp_path_text": "similarity → reasoning → includes → function",
        "sentence": "The track clustering cost function includes motion similarity reasoning.",
        "sentence_llm_dp_info": "Entity 1 ('motion similarity') is the object, depending on 'reasoning' with 'includes'. Entity 2 ('track clustering cost function') is the subject, depending on the verb 'includes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' which indicates that the 'track clustering cost function' includes reasoning about 'motion similarity'."
    },
    {
        "raw_sentence": "Second , we devise a new track clustering cost function that includes occlusion reasoning , in the form of depth ordering constraints , as well as motion similarity along the tracks .",
        "ner_pair": [
            [
                "depth ordering constraints",
                "OtherScientificTerm"
            ],
            [
                "occlusion reasoning",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('depth ordering constraints') is the object of the preposition 'of', depending on 'form' in the phrase 'in the form of depth ordering constraints'. Entity 2 ('occlusion reasoning') is the object of the preposition 'includes', depending on 'function' in the phrase 'cost function that includes occlusion reasoning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the components included in the cost function.",
        "sdp_path_text": "constraints → of → form → in → reasoning",
        "sentence": "Depth ordering constraints are included in the form of occlusion reasoning.",
        "sentence_llm_dp_info": "Entity 1 ('depth ordering constraints') is the subject, depending on the verb 'included'. Entity 2 ('occlusion reasoning') is the complement, depending on 'form' in the phrase 'in the form of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the form of'."
    },
    {
        "raw_sentence": "Second , we devise a new track clustering cost function that includes occlusion reasoning , in the form of depth ordering constraints , as well as motion similarity along the tracks .",
        "ner_pair": [
            [
                "occlusion reasoning",
                "OtherScientificTerm"
            ],
            [
                "motion similarity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('occlusion reasoning') is part of a list, included in the object of the preposition 'that' which modifies 'function'. Entity 2 ('motion similarity') is also part of the same list, connected through the conjunction 'as well as'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of a list that is included in the definition of the 'track clustering cost function'.",
        "sdp_path_text": "reasoning → similarity",
        "sentence": "The track clustering cost function includes occlusion reasoning and motion similarity.",
        "sentence_llm_dp_info": "Entity 1 ('occlusion reasoning') is a conjunct, depending on 'includes' with 'cost function'. Entity 2 ('motion similarity') is also a conjunct, depending on 'includes' with 'cost function'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordination structure listed as elements included by the 'cost function'."
    },
    {
        "raw_sentence": "Second , we devise a new track clustering cost function that includes occlusion reasoning , in the form of depth ordering constraints , as well as motion similarity along the tracks .",
        "ner_pair": [
            [
                "depth ordering constraints",
                "OtherScientificTerm"
            ],
            [
                "motion similarity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('depth ordering constraints') is the object of the preposition 'of', depending on 'occlusion reasoning'. Entity 2 ('motion similarity') is the subject complement, depending on 'includes' with 'function'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of elements included in the 'cost function'.",
        "sdp_path_text": "constraints → of → form → in → reasoning → similarity",
        "sentence": "Depth ordering constraints are included in the form of reasoning for motion similarity.",
        "sentence_llm_dp_info": "Entity 1 ('depth ordering constraints') is the subject, depending on 'included' as the main verb. Entity 2 ('motion similarity') is the object of the preposition 'for', depending on 'reasoning'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure where 'depth ordering constraints' are part of the reasoning that is used 'for motion similarity'."
    },
    {
        "raw_sentence": "We evaluate the proposed approach on a challenging set of video sequences of office scenes from feature length movies .",
        "ner_pair": [
            [
                "video sequences of office scenes",
                "Material"
            ],
            [
                "approach",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('video sequences of office scenes') is the object of the preposition 'of', depending on 'set'. Entity 2 ('approach') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same evaluative context where 'approach' is evaluated on 'video sequences of office scenes'.",
        "sdp_path_text": "sequences → of → set → on → evaluate → approach",
        "sentence": "We evaluate the approach on video sequences of office scenes.",
        "sentence_llm_dp_info": "Entity 1 ('video sequences of office scenes') is the object of the preposition 'on', depending on 'evaluate'. Entity 2 ('approach') is the object, depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the evaluation context provided by the verb 'evaluate'."
    },
    {
        "raw_sentence": "We evaluate the proposed approach on a challenging set of video sequences of office scenes from feature length movies .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "movies",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the object of the preposition 'on', depending on 'evaluate' with 'We'. Entity 2 ('movies') is part of a prepositional phrase, depending on 'from' in the phrase 'from feature length movies'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "approach → evaluate → on → set → of → sequences → of → scenes → from → movies",
        "sentence": "We evaluate the approach on video sequences of scenes from movies.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('movies') is part of a prepositional phrase, depending on 'from' in 'scenes from movies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on video sequences of scenes from movies'."
    },
    {
        "raw_sentence": "We evaluate the proposed approach on a challenging set of video sequences of office scenes from feature length movies .",
        "ner_pair": [
            [
                "video sequences of office scenes",
                "Material"
            ],
            [
                "movies",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('video sequences of office scenes') is the object of the preposition 'of', depending on 'set'. Entity 2 ('movies') is the object of the preposition 'from', depending on 'scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional structure describing the source and nature of the video sequences.",
        "sdp_path_text": "sequences → of → scenes → from → movies",
        "sentence": "Video sequences of office scenes are from movies.",
        "sentence_llm_dp_info": "Entity 1 ('video sequences of office scenes') is the subject, depending on the verb 'are'. Entity 2 ('movies') is the noun, depending on 'from' in the prepositional phrase 'from movies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'."
    },
    {
        "raw_sentence": "In this paper , we introduce KAZE features , a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces .",
        "ner_pair": [
            [
                "KAZE features",
                "Method"
            ],
            [
                "multiscale 2D feature detection and description algorithm",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('KAZE features') is the object, depending on the verb 'introduce' with 'we'. Entity 2 ('multiscale 2D feature detection and description algorithm') is the appositive, depending on 'KAZE features' to provide further description. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 serves as an appositive to Entity 1.",
        "sdp_path_text": "features → algorithm",
        "sentence": "KAZE features are a multiscale 2D feature detection and description algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('KAZE features') is the subject, depending on the verb 'are'. Entity 2 ('multiscale 2D feature detection and description algorithm') is the predicate nominative, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 renames or describes Entity 1."
    },
    {
        "raw_sentence": "In this paper , we introduce KAZE features , a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces .",
        "ner_pair": [
            [
                "KAZE features",
                "Method"
            ],
            [
                "nonlinear scale spaces",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('KAZE features') is the object, depending on 'introduce' with 'we'. Entity 2 ('nonlinear scale spaces') is the object of the preposition 'in', depending on 'in' in the phrase 'in nonlinear scale spaces'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the context in which 'KAZE features' are introduced.",
        "sdp_path_text": "features → algorithm → in → spaces",
        "sentence": "KAZE features are an algorithm in nonlinear scale spaces.",
        "sentence_llm_dp_info": "Entity 1 ('KAZE features') is the subject, depending on the verb 'are'. Entity 2 ('nonlinear scale spaces') is the object of the preposition 'in', depending on 'in' in the phrase 'in nonlinear scale spaces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'."
    },
    {
        "raw_sentence": "In this paper , we introduce KAZE features , a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces .",
        "ner_pair": [
            [
                "nonlinear scale spaces",
                "OtherScientificTerm"
            ],
            [
                "multiscale 2D feature detection and description algorithm",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale spaces') is the object of the preposition 'in', depending on the preposition 'in'. Entity 2 ('multiscale 2D feature detection and description algorithm') is the complement of the noun 'features', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the characteristics of the introduced features.",
        "sdp_path_text": "spaces → in → algorithm",
        "sentence": "A novel multiscale 2D feature detection and description algorithm operates in nonlinear scale spaces.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale spaces') is the object of the preposition 'in', depending on 'operates'. Entity 2 ('multiscale 2D feature detection and description algorithm') is the subject, depending on the verb 'operates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates the environment or context in which the algorithm operates."
    },
    {
        "raw_sentence": "However , Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise , reducing localization accuracy and distinctiveness .",
        "ner_pair": [
            [
                "Gaussian blurring",
                "OtherScientificTerm"
            ],
            [
                "boundaries of objects",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Gaussian blurring') is the subject, depending on the verb 'does' in the phrase 'does not respect'. Entity 2 ('boundaries of objects') is the object of the verb 'respect', depending on 'respect' in the phrase 'does not respect the natural boundaries of objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'respect'.",
        "sdp_path_text": "blurring → respect → boundaries",
        "sentence": "Gaussian blurring does not respect the boundaries of objects.",
        "sentence_llm_dp_info": "Entity 1 ('Gaussian blurring') is the subject, depending on the verb 'does not respect'. Entity 2 ('boundaries of objects') is the object, depending on the verb 'does not respect'. There is a direct dependency between Entity 1 and Entity 2, as 'Gaussian blurring' is the subject that performs the action (not respecting) on 'boundaries of objects'."
    },
    {
        "raw_sentence": "However , Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise , reducing localization accuracy and distinctiveness .",
        "ner_pair": [
            [
                "Gaussian blurring",
                "OtherScientificTerm"
            ],
            [
                "localization accuracy and distinctiveness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Gaussian blurring') is the subject, depending on the verb 'does' in the clause 'does not respect'. Entity 2 ('localization accuracy and distinctiveness') is the object, depending on the verb 'reducing'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the causal relationship expressed by the verb 'reducing'.",
        "sdp_path_text": "blurring → respect → smoothes → reducing → accuracy",
        "sentence": "Gaussian blurring reduces localization accuracy and distinctiveness.",
        "sentence_llm_dp_info": "Entity 1 ('Gaussian blurring') is the subject, depending on the verb 'reduces'. Entity 2 ('localization accuracy and distinctiveness') is the object, depending on the verb 'reduces'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the agent performing the action that affects Entity 2."
    },
    {
        "raw_sentence": "However , Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise , reducing localization accuracy and distinctiveness .",
        "ner_pair": [
            [
                "boundaries of objects",
                "OtherScientificTerm"
            ],
            [
                "localization accuracy and distinctiveness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('boundaries of objects') is the object of the preposition 'of', depending on 'respect' with the negation 'not'. Entity 2 ('localization accuracy and distinctiveness') is the object, depending on 'reducing'. There is no direct dependency between Entity 1 and Entity 2, but they are both affected by the actions described in the sentence (not respecting and reducing, respectively).",
        "sdp_path_text": "boundaries → respect → smoothes → reducing → accuracy",
        "sentence": "Gaussian blurring does not respect object boundaries, reducing localization accuracy and distinctiveness.",
        "sentence_llm_dp_info": "Entity 1 ('boundaries of objects') is the object of the preposition 'of', depending on 'respect' in the clause 'does not respect object boundaries'. Entity 2 ('localization accuracy and distinctiveness') is the object of the verb 'reducing', depending on 'reducing' in the clause 'reducing localization accuracy and distinctiveness'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the effects of 'Gaussian blurring' described in the sentence."
    },
    {
        "raw_sentence": "In contrast , we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "2D features",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'in', depending on the preposition 'in' within the phrase 'in a nonlinear scale space'. Entity 2 ('2D features') is the direct object, depending on the verbs 'detect' and 'describe'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where '2D features' are described as being detected and described in the context of 'nonlinear scale space'.",
        "sdp_path_text": "space → in → features",
        "sentence": "2D features are detected and described in a nonlinear scale space.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'in', depending on 'described'. Entity 2 ('2D features') is the subject, depending on the verbs 'are detected' and 'described'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates that the '2D features' are processed within the 'nonlinear scale space'."
    },
    {
        "raw_sentence": "In contrast , we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering .",
        "ner_pair": [
            [
                "nonlinear diffusion filtering",
                "Method"
            ],
            [
                "2D features",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear diffusion filtering') is the object of the preposition 'by', depending on 'by' in the phrase 'by means of nonlinear diffusion filtering'. Entity 2 ('2D features') is the object of the verb 'describe', depending on 'describe' in the clause 'we detect and describe 2D features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the means by which the 2D features are described.",
        "sdp_path_text": "filtering → of → means → by → describe → features",
        "sentence": "Nonlinear diffusion filtering is used to describe 2D features.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear diffusion filtering') is the subject, depending on the verb 'used'. Entity 2 ('2D features') is the object, depending on the verb 'describe'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the purpose of describing 2D features."
    },
    {
        "raw_sentence": "In contrast , we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "nonlinear diffusion filtering",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'in', depending on the preposition 'in' within the phrase 'in a nonlinear scale space'. Entity 2 ('nonlinear diffusion filtering') is the object of the preposition 'by', depending on the preposition 'by' within the phrase 'by means of nonlinear diffusion filtering'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the method used to detect and describe 2D features.",
        "sdp_path_text": "space → in → features → describe → by → means → of → filtering",
        "sentence": "Features in a nonlinear scale space are described by means of nonlinear diffusion filtering.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the subject complement, depending on 'are' which is part of the passive construction 'are described'. Entity 2 ('nonlinear diffusion filtering') is the object of the preposition 'by', depending on 'by' in the phrase 'by means of nonlinear diffusion filtering'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'described' and the prepositional phrase 'by means of'."
    },
    {
        "raw_sentence": "In this way , we can make blurring locally adaptive to the image data , reducing noise but retaining object boundaries , obtaining superior localization accuracy and distinctiviness .",
        "ner_pair": [
            [
                "image data",
                "Material"
            ],
            [
                "object boundaries",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('image data') is the object of the preposition 'to', depending on 'adaptive' in the phrase 'adaptive to the image data'. Entity 2 ('object boundaries') is the object of the verb 'retaining', depending on 'retaining' in the phrase 'retaining object boundaries'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "data → to → adaptive → make → reducing → retaining → boundaries",
        "sentence": "Blurring is made adaptive to image data, retaining object boundaries.",
        "sentence_llm_dp_info": "Entity 1 ('image data') is the object of the preposition 'to', depending on 'adaptive'. Entity 2 ('object boundaries') is the object of the gerund 'retaining'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how 'blurring' is adapted and what it retains."
    },
    {
        "raw_sentence": "In this way , we can make blurring locally adaptive to the image data , reducing noise but retaining object boundaries , obtaining superior localization accuracy and distinctiviness .",
        "ner_pair": [
            [
                "image data",
                "Material"
            ],
            [
                "localization accuracy and distinctiviness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('image data') is the object of the preposition 'to', depending on 'adaptive'. Entity 2 ('localization accuracy and distinctiviness') is the object of the verb 'obtaining'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the outcomes of making blurring locally adaptive.",
        "sdp_path_text": "data → to → adaptive → make → reducing → retaining → obtaining → accuracy",
        "sentence": "Adapting to image data improves localization accuracy and distinctiveness.",
        "sentence_llm_dp_info": "Entity 1 ('image data') is the object of the preposition 'to', depending on 'adapting'. Entity 2 ('localization accuracy and distinctiveness') is the object, depending on 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' which indicates that adapting to Entity 1 (image data) results in an improvement of Entity 2 (localization accuracy and distinctiveness)."
    },
    {
        "raw_sentence": "In this way , we can make blurring locally adaptive to the image data , reducing noise but retaining object boundaries , obtaining superior localization accuracy and distinctiviness .",
        "ner_pair": [
            [
                "object boundaries",
                "OtherScientificTerm"
            ],
            [
                "localization accuracy and distinctiviness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object boundaries') is the object of the verb 'retaining', depending on 'retaining' with 'but'. Entity 2 ('localization accuracy and distinctiviness') is the object of the verb 'obtaining', depending on 'obtaining' with 'and'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "boundaries → retaining → obtaining → accuracy",
        "sentence": "Retaining object boundaries obtains superior localization accuracy and distinctiveness.",
        "sentence_llm_dp_info": "Entity 1 ('object boundaries') is the object of the verb 'Retaining', depending on 'Retaining'. Entity 2 ('localization accuracy and distinctiveness') is the object of the verb 'obtains', depending on 'obtains'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtains' which indicates that retaining object boundaries leads to obtaining superior localization accuracy and distinctiveness."
    },
    {
        "raw_sentence": "The nonlinear scale space is built using efficient Additive Operator Splitting -LRB- AOS -RRB- techniques and variable con-ductance diffusion .",
        "ner_pair": [
            [
                "Additive Operator Splitting -LRB- AOS -RRB- techniques",
                "Method"
            ],
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Additive Operator Splitting -LRB- AOS -RRB- techniques') is the object of the preposition 'using', depending on the verb 'built'. Entity 2 ('nonlinear scale space') is the subject, depending on the verb 'is built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'built' and the preposition 'using'.",
        "sdp_path_text": "techniques → using → built → space",
        "sentence": "The nonlinear scale space is built using AOS techniques.",
        "sentence_llm_dp_info": "Entity 1 ('Additive Operator Splitting (AOS) techniques') is the object, depending on the preposition 'using', which modifies the verb 'built'. Entity 2 ('nonlinear scale space') is the subject, depending on the verb 'is built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'built' and the preposition 'using'."
    },
    {
        "raw_sentence": "The nonlinear scale space is built using efficient Additive Operator Splitting -LRB- AOS -RRB- techniques and variable con-ductance diffusion .",
        "ner_pair": [
            [
                "variable con-ductance diffusion",
                "Method"
            ],
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('variable con-ductance diffusion') is the object, depending on the conjunction 'and' which connects it to 'efficient Additive Operator Splitting (AOS) techniques'. Entity 2 ('nonlinear scale space') is the subject, depending on the verb 'built'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing how the 'nonlinear scale space' is built.",
        "sdp_path_text": "diffusion → techniques → using → built → space",
        "sentence": "The nonlinear scale space is built using variable con-ductance diffusion techniques.",
        "sentence_llm_dp_info": "Entity 1 ('variable con-ductance diffusion') is the subject of the participle 'using', which modifies the verb 'built'. Entity 2 ('nonlinear scale space') is the subject, depending on the verb 'is built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the participle 'using', indicating that Entity 1 is the technique used to build Entity 2."
    },
    {
        "raw_sentence": "The nonlinear scale space is built using efficient Additive Operator Splitting -LRB- AOS -RRB- techniques and variable con-ductance diffusion .",
        "ner_pair": [
            [
                "Additive Operator Splitting -LRB- AOS -RRB- techniques",
                "Method"
            ],
            [
                "variable con-ductance diffusion",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Additive Operator Splitting -LRB- AOS -RRB- techniques') is part of the conjunct, depending on 'and' which connects it to Entity 2. Entity 2 ('variable con-ductance diffusion') is also part of the conjunct, depending on 'and' which connects it to Entity 1. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'.",
        "sdp_path_text": "techniques → diffusion",
        "sentence": "Additive Operator Splitting (AOS) techniques and variable con-ductance diffusion are used to build the nonlinear scale space.",
        "sentence_llm_dp_info": "Entity 1 ('Additive Operator Splitting (AOS) techniques') is the subject, depending on the verb 'used'. Entity 2 ('variable con-ductance diffusion') is a conjunct, coordinated with 'Additive Operator Splitting (AOS) techniques' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the compound subject of the sentence."
    },
    {
        "raw_sentence": "We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces .",
        "ner_pair": [
            [
                "benchmark datasets",
                "Material"
            ],
            [
                "matching application on deformable surfaces",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('benchmark datasets') is the object of the preposition 'on', depending on 'evaluation'. Entity 2 ('matching application on deformable surfaces') is also the object of the preposition 'on', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2; both are independently related to the verb 'present' through the noun 'evaluation'.",
        "sdp_path_text": "datasets → on → evaluation → application",
        "sentence": "We present an evaluation on benchmark datasets and a matching application on deformable surfaces.",
        "sentence_llm_dp_info": "Entity 1 ('benchmark datasets') is the object of the preposition 'on', depending on 'evaluation'. Entity 2 ('matching application on deformable surfaces') is also the object of the preposition 'on', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2; both are objects of different instances of the preposition 'on' within the sentence."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "SURF",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the comparative adjective 'more expensive' which modifies it in the clause 'our features are somewhat more expensive to compute than SURF'. Entity 2 ('SURF') is the object of comparison, depending on the comparative adjective 'more expensive' in the same clause. There is a direct dependency between Entity 1 and Entity 2, established through the comparative structure 'more expensive to compute than'.",
        "sdp_path_text": "features → are → expensive → than → SURF",
        "sentence": "Our features are more expensive to compute than SURF.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are'. Entity 2 ('SURF') is the complement of the preposition 'than', depending on 'than' in the phrase 'than SURF'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the preposition 'than'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are' in the clause 'our features are somewhat more expensive to compute'. Entity 2 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction' in the phrase 'the construction of the nonlinear scale space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'compute' and the prepositional phrase 'due to the construction of the nonlinear scale space'.",
        "sdp_path_text": "features → are → expensive → due → construction → of → space",
        "sentence": "Our features are expensive to compute due to the construction of the nonlinear scale space.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are' in the clause 'Our features are expensive to compute'. Entity 2 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction' in the phrase 'the construction of the nonlinear scale space'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the causal relationship expressed by 'due to'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "SIFT",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on 'are' (verb) in the clause 'our features are somewhat more expensive to compute'. Entity 2 ('SIFT') is the object of the preposition 'to', depending on 'comparable' in the phrase 'comparable to SIFT'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparison made in the sentence.",
        "sdp_path_text": "features → are → expensive → comparable → to → SIFT",
        "sentence": "Our features are expensive but comparable to SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are' and modified by the adjectives 'expensive' and 'comparable'. Entity 2 ('SIFT') is the object of comparison, depending on the preposition 'to' in the phrase 'comparable to SIFT'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure 'comparable to'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "results",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on 'are' in the clause 'our features are somewhat more expensive to compute'. Entity 2 ('results') is the subject, depending on 'reveal' in the clause 'our results reveal a step forward'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same discourse, where 'features' are discussed in terms of their computational cost, and 'results' show the improvement in performance.",
        "sdp_path_text": "features → are → reveal → results",
        "sentence": "Our features reveal results.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'reveal'. Entity 2 ('results') is the object, depending on the verb 'reveal'. There is a direct dependency between Entity 1 and Entity 2, as 'features' directly reveals 'results'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are' in the clause 'our features are somewhat more expensive to compute'. Entity 2 ('detection') is part of the compound object, depending on 'in' in the phrase 'in detection and description'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, particularly the phrase 'a step forward in performance both in detection and description'.",
        "sdp_path_text": "features → are → reveal → step → in → performance → in → detection",
        "sentence": "Our features reveal a step forward in performance for detection.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on 'reveal' as the verb. Entity 2 ('detection') is the object of the preposition 'for', depending on 'for' in the phrase 'for detection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reveal' and the preposition 'for'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "description",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on 'are' as its verb, and is part of the clause describing the cost of computation. Entity 2 ('description') is part of a compound object, depending on 'in' from the prepositional phrase 'in detection and description'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence, which discusses the performance of the features in terms of detection and description.",
        "sdp_path_text": "features → are → reveal → step → in → performance → in → detection → description",
        "sentence": "Our features reveal a step forward in performance in description.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'reveal'. Entity 2 ('description') is the object of the preposition 'in', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in performance in description'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "features",
                "Generic"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are' in the clause 'our features are somewhat more expensive to compute'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against previous state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparative context where the performance of the features is evaluated against the state-of-the-art methods.",
        "sdp_path_text": "features → are → reveal → step → in → performance → in → detection → against → methods",
        "sentence": "Our features reveal a step forward in performance against state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'reveal'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'against'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SURF",
                "Method"
            ],
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'than', depending on 'more expensive' in the comparative clause 'more expensive to compute than SURF'. Entity 2 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction' in the phrase 'construction of the nonlinear scale space'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same comparative context related to computational cost.",
        "sdp_path_text": "SURF → than → expensive → due → construction → of → space",
        "sentence": "Our features are more expensive to compute than SURF due to the construction of the nonlinear scale space.",
        "sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'than', depending on 'expensive'. Entity 2 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparative clause that explains why 'our features are more expensive to compute'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SURF",
                "Method"
            ],
            [
                "SIFT",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'than', depending on 'expensive'. Entity 2 ('SIFT') is the object of the preposition 'to', depending on 'comparable'. There is no direct dependency between Entity 1 and Entity 2, but they are both referenced in the context of comparing computational costs.",
        "sdp_path_text": "SURF → than → expensive → comparable → to → SIFT",
        "sentence": "Our features are more expensive to compute than SURF but comparable to SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('SURF') is the complement of the preposition 'than', depending on 'than' in the phrase 'than SURF'. Entity 2 ('SIFT') is the complement of the preposition 'to', depending on 'comparable' in the phrase 'comparable to SIFT'. There is no direct dependency between Entity 1 and Entity 2, but both are compared to 'our features' in terms of computational cost and comparability."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SURF",
                "Method"
            ],
            [
                "results",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'than', depending on 'expensive' with 'more expensive to compute than SURF'. Entity 2 ('results') is the subject, depending on 'reveal' with 'our results reveal a step forward'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparative context within the sentence.",
        "sdp_path_text": "SURF → than → expensive → are → reveal → results",
        "sentence": "Our results reveal a step forward in performance compared to SURF.",
        "sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'to', depending on 'compared' in the phrase 'compared to SURF'. Entity 2 ('results') is the subject, depending on the verb 'reveal'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'compared to'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SURF",
                "Method"
            ],
            [
                "detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'than', depending on 'expensive' in the phrase 'more expensive to compute than SURF'. Entity 2 ('detection') is part of the compound object of the preposition 'in', depending on 'performance' in the phrase 'performance both in detection and description'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "SURF → than → expensive → are → reveal → step → in → performance → in → detection",
        "sentence": "Our features are more expensive to compute than SURF, but they reveal a step forward in detection performance.",
        "sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the comparative clause, depending on 'than' in the phrase 'than SURF'. Entity 2 ('detection') is part of the compound noun 'detection performance', depending on 'performance' as a modifier. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where 'SURF' is compared to the 'detection performance' of the features being discussed."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SURF",
                "Method"
            ],
            [
                "description",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SURF') is the object of comparison, depending on 'than' with 'expensive'. Entity 2 ('description') is part of the compound object, depending on 'in' with 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the discussion of performance metrics in the sentence.",
        "sdp_path_text": "SURF → than → expensive → are → reveal → step → in → performance → in → detection → description",
        "sentence": "Our results reveal a step forward in performance in description compared to SURF.",
        "sentence_llm_dp_info": "Entity 1 ('SURF') is the object of the preposition 'to', depending on 'to' in the phrase 'compared to SURF'. Entity 2 ('description') is the object of the preposition 'in', depending on 'in' in the phrase 'in description'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the comparative structure introduced by 'compared to'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SURF",
                "Method"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SURF') is the object of comparison, depending on 'than' with 'expensive'. Entity 2 ('state-of-the-art methods') is the object of comparison, depending on 'against' with 'performance'. There is no direct dependency between Entity 1 and Entity 2; both are involved in comparisons but with different aspects of the sentence.",
        "sdp_path_text": "SURF → than → expensive → are → reveal → step → in → performance → in → detection → against → methods",
        "sentence": "Our features are more expensive to compute than SURF, but they reveal a step forward in performance against state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('SURF') is the object of comparison, depending on 'than' in the phrase 'than SURF', which modifies 'expensive'. Entity 2 ('state-of-the-art methods') is the object of preposition 'against', depending on 'against' in the phrase 'against state-of-the-art methods', which modifies 'performance'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "SIFT",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('SIFT') is part of a comparative clause, depending on 'comparable to' with 'text'. There is no direct dependency between Entity 1 and Entity 2; they are mentioned in different contexts within the sentence, with Entity 1 related to the computational cost and Entity 2 used as a point of comparison for overall performance.",
        "sdp_path_text": "space → of → construction → due → expensive → comparable → to → SIFT",
        "sentence": "The construction of the nonlinear scale space is expensive but comparable to SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('SIFT') is the complement of the preposition 'to', depending on 'comparable'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the comparison expressed by 'comparable to'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "results",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('results') is the subject, depending on the verb 'reveal'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where the construction of the nonlinear scale space is mentioned as a factor that affects the computation cost, which is discussed in the context of the results revealing a step forward in performance.",
        "sdp_path_text": "space → of → construction → due → expensive → are → reveal → results",
        "sentence": "The construction of the nonlinear scale space reveals results.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('results') is the direct object, depending on the verb 'reveals'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reveals'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('detection') is part of the prepositional phrase 'in detection', functioning as a complement to the preposition 'in', which itself depends on 'performance'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "space → of → construction → due → expensive → are → reveal → step → in → performance → in → detection",
        "sentence": "The construction of the nonlinear scale space reveals a step forward in detection performance.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('detection') is part of the compound noun 'detection performance', which is the object of the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause through different prepositional phrases."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "description",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('description') is part of a compound noun, depending on 'in' in the phrase 'in detection and description'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "space → of → construction → due → expensive → are → reveal → step → in → performance → in → detection → description",
        "sentence": "The construction of the nonlinear scale space reveals a step forward in performance in description.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('description') is the object of the preposition 'in', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the improvement in performance."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "nonlinear scale space",
                "OtherScientificTerm"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against previous state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence describing different aspects of the comparison made in the research.",
        "sdp_path_text": "space → of → construction → due → expensive → are → reveal → step → in → performance → in → detection → against → methods",
        "sentence": "The construction of the nonlinear scale space reveals a step forward in performance against state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('nonlinear scale space') is the object of the preposition 'of', depending on 'construction'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing a comparison in performance."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SIFT",
                "Method"
            ],
            [
                "results",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SIFT') is the object of the preposition 'to', depending on 'comparable' in the phrase 'comparable to SIFT'. Entity 2 ('results') is the subject, depending on 'reveal' in the clause 'our results reveal a step forward'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "SIFT → to → comparable → expensive → are → reveal → results",
        "sentence": "Our results reveal a step forward in performance comparable to SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('SIFT') is the object of the preposition 'to', depending on 'comparable' in the phrase 'comparable to SIFT'. Entity 2 ('results') is the subject, depending on the verb 'reveal'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure involving 'comparable'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SIFT",
                "Method"
            ],
            [
                "detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SIFT') is the object of the preposition 'to', depending on the comparative phrase 'comparable to'. Entity 2 ('detection') is part of the compound object, depending on the preposition 'in' within the phrase 'in detection and description'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "SIFT → to → comparable → expensive → are → reveal → step → in → performance → in → detection",
        "sentence": "Our results reveal a step forward in performance in detection compared to SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('SIFT') is the object of the preposition 'to', depending on 'compared' in the phrase 'compared to SIFT'. Entity 2 ('detection') is part of the noun phrase 'performance in detection', where it serves as the object of the preposition 'in', depending on 'in' in the phrase 'in detection'. There is no direct dependency between Entity 1 and Entity 2; they are related through the comparative structure of the sentence."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SIFT",
                "Method"
            ],
            [
                "description",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SIFT') is part of a comparison, depending on the preposition 'to' in the phrase 'comparable to SIFT'. Entity 2 ('description') is the second element in a compound object, depending on the preposition 'in' in the phrase 'in detection and description'. There is no direct dependency between Entity 1 and Entity 2; they are both part of different comparative and descriptive clauses within the sentence.",
        "sdp_path_text": "SIFT → to → comparable → expensive → are → reveal → step → in → performance → in → detection → description",
        "sentence": "Our results reveal a step forward in performance in detection and description compared to SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('SIFT') is the object of the preposition 'to', depending on 'compared' in the phrase 'compared to SIFT'. Entity 2 ('description') is part of a coordination, depending on 'and' with 'detection'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "SIFT",
                "Method"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SIFT') is part of a comparison, depending on the preposition 'to' within the comparative clause 'comparable to SIFT'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against' in the phrase 'against previous state-of-the-art methods', which modifies the noun 'performance'. There is no direct dependency between Entity 1 and Entity 2; both are involved in different comparative clauses that relate to the performance of the described results.",
        "sdp_path_text": "SIFT → to → comparable → expensive → are → reveal → step → in → performance → in → detection → against → methods",
        "sentence": "Our results reveal a step forward in performance against state-of-the-art methods, including SIFT.",
        "sentence_llm_dp_info": "Entity 1 ('SIFT') is the object of the preposition 'including', depending on 'including' in the phrase 'including SIFT'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the comparison made by the results."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "detection",
                "Task"
            ],
            [
                "results",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('detection') is part of a coordinated noun phrase, depending on 'performance' with 'in'. Entity 2 ('results') is the subject, depending on 'reveal' with 'our'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the outcomes of the study.",
        "sdp_path_text": "detection → in → performance → in → step → reveal → results",
        "sentence": "Our results reveal a step forward in performance for detection.",
        "sentence_llm_dp_info": "Entity 1 ('detection') is the object of the preposition 'for', depending on 'performance'. Entity 2 ('results') is the subject, depending on the verb 'reveal'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'performance' which is modified by 'detection' and is part of the larger clause that 'results' reveals."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "description",
                "Task"
            ],
            [
                "results",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('description') is part of the compound noun phrase 'detection and description', which is the object of the preposition 'in', depending on 'reveal' with 'results'. Entity 2 ('results') is the subject, depending on 'reveal' with 'a step forward in performance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reveal' and the preposition 'in'.",
        "sdp_path_text": "description → detection → in → performance → in → step → reveal → results",
        "sentence": "Our results reveal a step forward in performance for description and detection.",
        "sentence_llm_dp_info": "Entity 1 ('description') is part of the prepositional phrase 'for description and detection', acting as an object of the preposition 'for', and depends on 'reveal'. Entity 2 ('results') is the direct object of the verb 'reveal', depending on 'reveal'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'reveal' and the prepositional phrase 'for description and detection'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "results",
                "Generic"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('results') is the subject, depending on the verb 'reveal'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against previous state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reveal' and the preposition 'against'.",
        "sdp_path_text": "results → reveal → step → in → performance → in → detection → against → methods",
        "sentence": "Our results reveal improved performance against state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('results') is the subject, depending on the verb 'reveal'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'against'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "detection",
                "Task"
            ],
            [
                "description",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('detection') is part of a coordinated structure, depending on the preposition 'in' with the verb 'reveal'. Entity 2 ('description') is also part of a coordinated structure, depending on the conjunction 'and' with 'detection'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a coordinated list that serves as the object of the preposition 'in'.",
        "sdp_path_text": "detection → description",
        "sentence": "Our results reveal a step forward in performance in both detection and description.",
        "sentence_llm_dp_info": "Entity 1 ('detection') is part of a coordination, depending on 'and' with 'description'. Entity 2 ('description') is also part of the same coordination, depending on 'and' with 'detection'. There is no direct dependency between Entity 1 and Entity 2; they are coordinated together as objects of the preposition 'in'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "detection",
                "Task"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('detection') is part of a compound noun, depending on the conjunction 'and' with 'description'. It is also part of the prepositional phrase 'in detection and description', which modifies the verb 'reveal'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against previous state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'reveal' and the preposition 'against'.",
        "sdp_path_text": "detection → against → methods",
        "sentence": "Our results show a step forward in detection against state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('detection') is the object of the preposition 'in', depending on 'show' with 'results'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, connected through the verb 'show'."
    },
    {
        "raw_sentence": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods .",
        "ner_pair": [
            [
                "description",
                "Task"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('description') is part of a compound noun, depending on 'performance' with the conjunction 'and'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against previous state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of comparison in the sentence.",
        "sdp_path_text": "description → detection → against → methods",
        "sentence": "Our results show a step forward in description and detection against state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('description') is part of the compound object, depending on 'show' with 'results'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'against', depending on 'against' in the phrase 'against state-of-the-art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger object that is being shown by the results."
    },
    {
        "raw_sentence": "Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest .",
        "ner_pair": [
            [
                "lengthy Semantic Web documents",
                "Material"
            ],
            [
                "Creating summaries",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lengthy Semantic Web documents') is the object of the preposition 'on', depending on 'Creating summaries'. Entity 2 ('Creating summaries') is the subject, depending on the verb 'has been'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on lengthy Semantic Web documents'.",
        "sdp_path_text": "documents → on → summaries → Creating",
        "sentence": "Creating summaries on lengthy Semantic Web documents has been of interest.",
        "sentence_llm_dp_info": "Entity 1 ('lengthy Semantic Web documents') is the object, depending on the preposition 'on', which modifies 'Creating summaries'. Entity 2 ('Creating summaries') is the subject, depending on the verb 'has been'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'."
    },
    {
        "raw_sentence": "Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest .",
        "ner_pair": [
            [
                "Creating summaries",
                "Task"
            ],
            [
                "identification of the corresponding entity",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Creating summaries') is the subject, depending on the verb 'has been'. Entity 2 ('identification of the corresponding entity') is the object of the preposition 'for', depending on 'for' in the phrase 'for quick identification of the corresponding entity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'for'.",
        "sdp_path_text": "Creating → for → identification",
        "sentence": "Creating summaries is for the identification of the corresponding entity.",
        "sentence_llm_dp_info": "Entity 1 ('Creating summaries') is the subject, depending on the verb 'is'. Entity 2 ('identification of the corresponding entity') is the complement, depending on the preposition 'for', which itself depends on 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest .",
        "ner_pair": [
            [
                "lengthy Semantic Web documents",
                "Material"
            ],
            [
                "identification of the corresponding entity",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lengthy Semantic Web documents') is the object of the preposition 'on', depending on 'Creating summaries'. Entity 2 ('identification of the corresponding entity') is the object of the preposition 'for', depending on 'Creating summaries'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the action of creating summaries.",
        "sdp_path_text": "documents → on → summaries → Creating → for → identification",
        "sentence": "Creating summaries on lengthy Semantic Web documents facilitates quick identification of the corresponding entity.",
        "sentence_llm_dp_info": "Entity 1 ('lengthy Semantic Web documents') is the object of the preposition 'on', depending on 'Creating'. Entity 2 ('identification of the corresponding entity') is the object of the verb 'facilitates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'facilitates' which indicates that creating summaries on Entity 1 facilitates Entity 2."
    },
    {
        "raw_sentence": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , uniqueness , and popularity .",
        "ner_pair": [
            [
                "diversity",
                "OtherScientificTerm"
            ],
            [
                "diversified -LRB- faceted -RRB- summaries",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('diversity') is one of the objects listed, depending on the verb 'combining' which is part of the clause 'by combining three dimensions'. Entity 2 ('diversified -LRB- faceted -RRB- summaries') is the object of the preposition 'of', depending on 'importance'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where 'diversity' is one of the dimensions used to create 'diversified -LRB- faceted -RRB- summaries'.",
        "sdp_path_text": "diversity → dimensions → combining → by → highlight → importance → of → summaries",
        "sentence": "Diversity is a dimension that highlights the importance of diversified summaries.",
        "sentence_llm_dp_info": "Entity 1 ('diversity') is the subject, depending on the verb 'is'. Entity 2 ('diversified summaries') is the object of the preposition 'of', depending on 'importance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'highlights the importance of'."
    },
    {
        "raw_sentence": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , uniqueness , and popularity .",
        "ner_pair": [
            [
                "uniqueness",
                "OtherScientificTerm"
            ],
            [
                "diversified -LRB- faceted -RRB- summaries",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('uniqueness') is an element in a list, depending on 'dimensions' as one of the dimensions being combined. Entity 2 ('diversified -LRB- faceted -RRB- summaries') is the object of the preposition 'of', depending on 'importance'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the dimensions that contribute to the importance of diversified (faceted) summaries.",
        "sdp_path_text": "uniqueness → diversity → dimensions → combining → by → highlight → importance → of → summaries",
        "sentence": "Uniqueness is highlighted as an important dimension for diversified summaries.",
        "sentence_llm_dp_info": "Entity 1 ('uniqueness') is the subject, depending on the verb 'highlighted'. Entity 2 ('diversified summaries') is the object of the preposition 'for', depending on 'dimension'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the noun 'dimension'."
    },
    {
        "raw_sentence": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , uniqueness , and popularity .",
        "ner_pair": [
            [
                "popularity",
                "OtherScientificTerm"
            ],
            [
                "diversified -LRB- faceted -RRB- summaries",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('popularity') is part of a list, depending on the conjunction 'and', which links it to 'diversity' and 'uniqueness'. Entity 2 ('diversified -LRB- faceted -RRB- summaries') is the object of the preposition 'of', depending on 'importance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the dimensions that contribute to the importance of the summaries.",
        "sdp_path_text": "popularity → uniqueness → diversity → dimensions → combining → by → highlight → importance → of → summaries",
        "sentence": "Popularity is one of the dimensions considered in creating diversified (faceted) summaries.",
        "sentence_llm_dp_info": "Entity 1 ('popularity') is the subject, depending on the verb 'is'. It is also part of the prepositional phrase 'of the dimensions', where it serves as the object of the preposition 'of'. Entity 2 ('diversified (faceted) summaries') is the object of the preposition 'in', indicating what the dimensions (including popularity) are considered for. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase that connects the dimensions to the purpose of their consideration."
    },
    {
        "raw_sentence": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , uniqueness , and popularity .",
        "ner_pair": [
            [
                "diversity",
                "OtherScientificTerm"
            ],
            [
                "uniqueness",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('diversity') is one of the objects listed, depending on the verb 'combining' which is part of the phrase 'combining three dimensions'. Entity 2 ('uniqueness') is another object listed, also depending on the verb 'combining' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are listed as part of the dimensions being combined.",
        "sdp_path_text": "diversity → uniqueness",
        "sentence": "Diversity and uniqueness are combined in the summaries.",
        "sentence_llm_dp_info": "Entity 1 ('diversity') is part of a coordination, depending on 'and' with 'uniqueness'. Entity 2 ('uniqueness') is also part of the same coordination, depending on 'and' with 'diversity'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated together in the subject position of the sentence."
    },
    {
        "raw_sentence": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , uniqueness , and popularity .",
        "ner_pair": [
            [
                "diversity",
                "OtherScientificTerm"
            ],
            [
                "popularity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('diversity') is one of the objects listed, depending on the conjunction 'and' which connects it with 'uniqueness' and 'popularity'. Entity 2 ('popularity') is also an object listed, depending on the conjunction 'and' which connects it with 'diversity' and 'uniqueness'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a list connected through the conjunction 'and'.",
        "sdp_path_text": "diversity → uniqueness → popularity",
        "sentence": "Diversity, uniqueness, and popularity are combined to create diversified summaries.",
        "sentence_llm_dp_info": "Entity 1 ('diversity') is part of a conjunction, depending on 'are' with the verb 'combined'. Entity 2 ('popularity') is also part of the same conjunction, depending on 'are' with the verb 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of the conjunction linked by the verb 'are'."
    },
    {
        "raw_sentence": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , uniqueness , and popularity .",
        "ner_pair": [
            [
                "uniqueness",
                "OtherScientificTerm"
            ],
            [
                "popularity",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('uniqueness') is one of the objects listed, depending on the conjunction 'and', which connects it with 'diversity' and 'popularity'. Entity 2 ('popularity') is another object listed, also depending on the conjunction 'and', connecting it with 'diversity' and 'uniqueness'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list connected by the conjunction 'and'.",
        "sdp_path_text": "uniqueness → popularity",
        "sentence": "Uniqueness and popularity are combined dimensions of diversified summaries.",
        "sentence_llm_dp_info": "Entity 1 ('uniqueness') is a conjunct, depending on 'and' with 'popularity'. Entity 2 ('popularity') is also a conjunct, depending on 'and' with 'uniqueness'. There is a direct dependency between Entity 1 and Entity 2, as they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "Our novel diversity-aware entity summarization approach mimics human conceptual clustering techniques to group facts , and picks representative facts from each group to form concise -LRB- i.e. , short -RRB- and comprehensive -LRB- i.e. , improved coverage through diversity -RRB- summaries .",
        "ner_pair": [
            [
                "human conceptual clustering techniques",
                "Method"
            ],
            [
                "diversity-aware entity summarization approach",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('human conceptual clustering techniques') is the object of the preposition 'to', depending on 'mimics' in the phrase 'mimics human conceptual clustering techniques'. Entity 2 ('diversity-aware entity summarization approach') is the subject, depending on 'mimics' as the verb. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'mimics' where Entity 2 performs the action of mimicking Entity 1.",
        "sdp_path_text": "techniques → mimics → approach",
        "sentence": "The diversity-aware entity summarization approach mimics human conceptual clustering techniques.",
        "sentence_llm_dp_info": "Entity 1 ('human conceptual clustering techniques') is the object of the preposition 'mimics', depending on 'mimics' in the phrase 'mimics human conceptual clustering techniques'. Entity 2 ('diversity-aware entity summarization approach') is the subject, depending on the verb 'mimics'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the agent performing the action (mimicking) on Entity 1."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "state-of-the-art techniques",
                "Generic"
            ],
            [
                "approach",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluate' with 'We'. Entity 2 ('approach') is the object, depending on 'evaluate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the action of evaluating.",
        "sdp_path_text": "techniques → against → evaluate → approach",
        "sentence": "We evaluate our approach against state-of-the-art techniques.",
        "sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluate'. Entity 2 ('approach') is the object, depending on 'evaluate' with 'our'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the evaluation process described by the verb 'evaluate'."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('quality') is part of the compound object, depending on 'improves' with 'our work'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' which indicates the effect of evaluating the approach on the quality.",
        "sdp_path_text": "approach → evaluate → show → improves → quality",
        "sentence": "Our approach is evaluated to show it improves quality.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'evaluated'. Entity 2 ('quality') is the object, depending on 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' which indicates the effect of the evaluation of the approach on the quality."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "efficiency",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('efficiency') is part of the compound object of the verb 'improves', depending on 'and' which connects it with 'quality'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where 'approach' is evaluated and found to improve 'efficiency' (among other things).",
        "sdp_path_text": "approach → evaluate → show → improves → quality → efficiency",
        "sentence": "Our approach evaluates to show improvements in efficiency.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'evaluates'. Entity 2 ('efficiency') is the object of the preposition 'in', depending on 'show'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'shows' and the preposition 'in'."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "entity summarization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('entity summarization') is the object of the preposition 'of', depending on 'quality and the efficiency of'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the improvement of the quality and efficiency of Entity 2 is attributed to the evaluation of Entity 1.",
        "sdp_path_text": "approach → evaluate → show → improves → quality → of → summarization",
        "sentence": "Our approach is evaluated to show it improves the quality of entity summarization.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'evaluated'. Entity 2 ('entity summarization') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improves' and the preposition 'of'."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "state-of-the-art techniques",
                "Generic"
            ],
            [
                "quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluate' with 'We'. Entity 2 ('quality') is part of a coordinated noun phrase, depending on 'improves' with 'our work'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "techniques → against → evaluate → show → improves → quality",
        "sentence": "Evaluating against state-of-the-art techniques shows improvement in quality.",
        "sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'Evaluating'. Entity 2 ('quality') is the object of the preposition 'in', depending on 'shows improvement'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the evaluation and its outcome."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "state-of-the-art techniques",
                "Generic"
            ],
            [
                "efficiency",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluate'. Entity 2 ('efficiency') is part of a coordination, depending on 'and' in the phrase 'the quality and the efficiency'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "techniques → against → evaluate → show → improves → quality → efficiency",
        "sentence": "Our approach evaluates against state-of-the-art techniques and shows improvements in efficiency.",
        "sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluates' with 'approach'. Entity 2 ('efficiency') is the object of the preposition 'in', depending on 'shows' with 'approach'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the action described by 'approach'."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "state-of-the-art techniques",
                "Generic"
            ],
            [
                "entity summarization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluate' with 'We'. Entity 2 ('entity summarization') is the object of the preposition 'of', depending on 'quality and the efficiency'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same evaluative context within the sentence.",
        "sdp_path_text": "techniques → against → evaluate → show → improves → quality → of → summarization",
        "sentence": "We evaluate our approach against state-of-the-art techniques and show it improves the quality of entity summarization.",
        "sentence_llm_dp_info": "Entity 1 ('state-of-the-art techniques') is the object of the preposition 'against', depending on 'evaluate' with 'We'. Entity 2 ('entity summarization') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the evaluation and improvement described in the sentence."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "quality",
                "Metric"
            ],
            [
                "efficiency",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('quality') is the object, depending on 'improves' with 'work'. Entity 2 ('efficiency') is also the object, depending on 'improves' with 'work'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'improves'.",
        "sdp_path_text": "quality → efficiency",
        "sentence": "Our work improves both quality and efficiency.",
        "sentence_llm_dp_info": "Entity 1 ('quality') is the object, depending on the conjunction 'and' which connects it with 'efficiency'. Entity 2 ('efficiency') is also an object, depending on the conjunction 'and' which connects it with 'quality'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "quality",
                "Metric"
            ],
            [
                "entity summarization",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('quality') is part of a compound object, depending on 'improves' with 'our work'. Entity 2 ('entity summarization') is the object of the preposition 'of', depending on 'of' in the phrase 'of entity summarization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' and the preposition 'of'.",
        "sdp_path_text": "quality → of → summarization",
        "sentence": "Our work improves the quality of entity summarization.",
        "sentence_llm_dp_info": "Entity 1 ('quality') is the object of the preposition 'of', depending on 'improves'. Entity 2 ('entity summarization') is also the object of the preposition 'of', depending on 'quality'. There is a direct dependency between Entity 1 and Entity 2, as 'entity summarization' modifies 'quality' through the preposition 'of'."
    },
    {
        "raw_sentence": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization .",
        "ner_pair": [
            [
                "efficiency",
                "Metric"
            ],
            [
                "entity summarization",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('efficiency') is part of a conjunction, depending on 'and' which connects it to 'quality'. Both 'quality' and 'efficiency' are objects of the preposition 'of', depending on 'of' in the phrase 'of entity summarization'. Entity 2 ('entity summarization') is the object of the preposition 'of', depending on 'of' in the same phrase. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.",
        "sdp_path_text": "efficiency → quality → of → summarization",
        "sentence": "Our work improves the efficiency of entity summarization.",
        "sentence_llm_dp_info": "Entity 1 ('efficiency') is the object of the preposition 'of', depending on 'improves'. Entity 2 ('entity summarization') is also the object of the preposition 'of', depending on 'efficiency'. There is a direct dependency between Entity 1 and Entity 2, where 'entity summarization' modifies 'efficiency'."
    },
    {
        "raw_sentence": "We present a framework for the fast computation of lexical affinity models .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "fast computation of lexical affinity models",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('framework') is the direct object, depending on the verb 'present' with 'We'. Entity 2 ('fast computation of lexical affinity models') is the object of the preposition 'for', depending on 'for' in the phrase 'for the fast computation of lexical affinity models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "framework → for → computation",
        "sentence": "We present a framework for the fast computation of lexical affinity models.",
        "sentence_llm_dp_info": "Entity 1 ('framework') is the direct object, depending on the verb 'present' with 'We'. Entity 2 ('fast computation of lexical affinity models') is the object of the preposition 'for', depending on 'for' in the phrase 'for the fast computation of lexical affinity models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "framework",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is part of the object complement, depending on 'composed' with 'is'. Entity 2 ('framework') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is composed of'.",
        "sdp_path_text": "algorithm → of → composed → framework",
        "sentence": "The framework is composed of a novel algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the object of the preposition 'of', depending on 'composed'. Entity 2 ('framework') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is composed of'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "co-occurrence distribution",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('framework') is the subject, depending on the verb 'is composed of'. Entity 2 ('co-occurrence distribution') is the object of the preposition 'between', depending on 'compute' which is part of the infinitive clause 'to efficiently compute'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'compute' and the preposition 'between'.",
        "sdp_path_text": "framework → composed → of → algorithm → compute → distribution",
        "sentence": "The framework is composed of an algorithm to compute the co-occurrence distribution.",
        "sentence_llm_dp_info": "Entity 1 ('framework') is the subject, depending on the verb 'is composed of'. Entity 2 ('co-occurrence distribution') is the object, depending on 'compute' within the prepositional phrase 'to compute the co-occurrence distribution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'composed' and the prepositional phrase 'to compute'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "independence model",
                "Method"
            ],
            [
                "framework",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independence model') is the third item in a list, depending on 'composed of' with 'framework'. Entity 2 ('framework') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'framework' is described as being composed of multiple components, one of which is the 'independence model'.",
        "sdp_path_text": "model → algorithm → of → composed → framework",
        "sentence": "The framework is composed of an independence model.",
        "sentence_llm_dp_info": "Entity 1 ('independence model') is the object, depending on the verb 'composed' with 'is composed of'. Entity 2 ('framework') is the subject, depending on the verb 'is composed of'. There is a direct dependency between Entity 1 and Entity 2, as 'independence model' is directly part of what the 'framework' is composed of."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "parametric affinity model",
                "Method"
            ],
            [
                "framework",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parametric affinity model') is the last item in a list, depending on the conjunction 'and' which connects it to the rest of the components of the framework. Entity 2 ('framework') is the subject, depending on the verb 'is composed of' which introduces the components. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where Entity 1 is listed as one of the components that Entity 2 is composed of.",
        "sdp_path_text": "model → model → algorithm → of → composed → framework",
        "sentence": "The framework is composed of a parametric affinity model.",
        "sentence_llm_dp_info": "Entity 1 ('parametric affinity model') is the object, depending on the preposition 'of', which modifies 'composed'. Entity 2 ('framework') is the subject, depending on the verb 'is' in the phrase 'is composed'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is part of what Entity 2 is composed of."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "co-occurrence distribution",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is the object of the preposition 'of', depending on 'composed' in the phrase 'composed of a novel algorithm'. Entity 2 ('co-occurrence distribution') is the object of the infinitive 'to compute', depending on 'compute' in the phrase 'to efficiently compute the co-occurrence distribution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to compute'.",
        "sdp_path_text": "algorithm → compute → distribution",
        "sentence": "The algorithm computes the co-occurrence distribution.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is the subject, depending on the verb 'computes'. Entity 2 ('co-occurrence distribution') is the object, depending on the verb 'computes'. There is a direct dependency between Entity 1 and Entity 2, as 'algorithm' directly governs 'co-occurrence distribution' through the verb 'computes'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "independence model",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is part of the list item, depending on 'composed' with 'is'. Entity 2 ('independence model') is also part of the list item, depending on 'and' which connects it to the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of what the framework is composed of.",
        "sdp_path_text": "algorithm → model",
        "sentence": "The framework includes an algorithm and an independence model.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is part of a conjunction, depending on 'includes' with 'framework'. Entity 2 ('independence model') is also part of the same conjunction, depending on 'includes' with 'framework'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the list included by the framework."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "parametric affinity model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('algorithm') is part of the list of components, depending on the verb 'composed' with 'is'. Entity 2 ('parametric affinity model') is also part of the list of components, depending on the conjunction 'and' which links it to the other components. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of components that the framework is composed of.",
        "sdp_path_text": "algorithm → model → model",
        "sentence": "The framework includes a novel algorithm and a parametric affinity model.",
        "sentence_llm_dp_info": "Entity 1 ('algorithm') is part of a conjunction, depending on 'includes' with 'framework'. Entity 2 ('parametric affinity model') is also part of the same conjunction, depending on 'includes' with 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects included by the 'framework'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "co-occurrence distribution",
                "OtherScientificTerm"
            ],
            [
                "independence model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('co-occurrence distribution') is the object of the verb 'compute', depending on 'compute' with 'algorithm'. Entity 2 ('independence model') is one of the items in a list, depending on 'composed' with 'framework'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "distribution → compute → algorithm → model",
        "sentence": "The framework computes the co-occurrence distribution using an algorithm and an independence model.",
        "sentence_llm_dp_info": "Entity 1 ('co-occurrence distribution') is the object, depending on the verb 'computes' with 'framework'. Entity 2 ('independence model') is part of a compound object, depending on the conjunction 'and' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'computes'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "co-occurrence distribution",
                "OtherScientificTerm"
            ],
            [
                "parametric affinity model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('co-occurrence distribution') is the object of the verb 'compute', depending on 'compute' in the clause 'to efficiently compute the co-occurrence distribution'. Entity 2 ('parametric affinity model') is part of a list of items, depending on 'and' which connects it to the other components of what the framework is composed of. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure described by the sentence.",
        "sdp_path_text": "distribution → compute → algorithm → model → model",
        "sentence": "The framework computes the co-occurrence distribution using a novel algorithm and includes a parametric affinity model.",
        "sentence_llm_dp_info": "Entity 1 ('co-occurrence distribution') is the object of the verb 'computes', depending on 'framework'. Entity 2 ('parametric affinity model') is the object of the verb 'includes', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the 'framework'."
    },
    {
        "raw_sentence": "The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , and a parametric affinity model .",
        "ner_pair": [
            [
                "independence model",
                "Method"
            ],
            [
                "parametric affinity model",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independence model') is a conjunct, depending on 'and' which connects it to 'parametric affinity model'. Entity 2 ('parametric affinity model') is also a conjunct, depending on 'and' which connects it back to 'independence model'. Both are part of the list of components that the framework is composed of, where 'composed' is the main verb. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.",
        "sdp_path_text": "model → model",
        "sentence": "The framework includes an independence model and a parametric affinity model.",
        "sentence_llm_dp_info": "Entity 1 ('independence model') is the object of the conjunction 'and', depending on 'includes' with 'The framework'. Entity 2 ('parametric affinity model') is also the object of the conjunction 'and', depending on 'includes' with 'The framework'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' under the same governing verb 'includes'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "similarity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on 'focus' with 'we'. Entity 2 ('similarity') is part of the object of the preposition 'to', depending on 'compute' in the clause 'use arbitrary windows to compute similarity between words'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause that describes the methods used by the models.",
        "sdp_path_text": "models → use → compute → similarity",
        "sentence": "Models use to compute similarity.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'use'. Entity 2 ('similarity') is the object, depending on 'compute' with 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'use' and 'compute'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "lexical affinity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'with', depending on 'comparison' in the phrase 'In comparison with previous models'. Entity 2 ('lexical affinity') is the object of the preposition 'to', depending on 'use' in the clause 'or use lexical affinity to create sequential models'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger comparative structure describing different approaches used in previous models.",
        "sdp_path_text": "models → use → use → affinity",
        "sentence": "Models use lexical affinity.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on the verb 'use'. Entity 2 ('lexical affinity') is the object, depending on the verb 'use'. There is a direct dependency between Entity 1 and Entity 2, as 'models' uses 'lexical affinity'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "co-occurrence patterns",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'on', depending on 'focus' with 'we'. Entity 2 ('co-occurrence patterns') is the object of the preposition 'of', depending on 'capture' with 'intended'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'models' is focused on capturing 'co-occurrence patterns'.",
        "sdp_path_text": "models → with → comparison → In → focus → on → models → intended → capture → patterns",
        "sentence": "We focus on models intended to capture co-occurrence patterns.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'on', depending on 'focus' with 'We'. Entity 2 ('co-occurrence patterns') is the object of the preposition 'to', depending on 'intended'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'intended' and the preposition 'to'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "similarity",
                "OtherScientificTerm"
            ],
            [
                "lexical affinity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the verb 'compute', depending on 'compute' in the clause 'use arbitrary windows to compute similarity between words'. Entity 2 ('lexical affinity') is the object of the verb 'use', depending on 'use' in the clause 'or use lexical affinity to create sequential models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of methods used by previous models described in the sentence.",
        "sdp_path_text": "similarity → compute → use → use → affinity",
        "sentence": "Models use similarity to compute lexical affinity.",
        "sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the preposition 'use', depending on 'use' in the phrase 'use similarity'. Entity 2 ('lexical affinity') is the object of the verb 'compute', depending on 'compute' in the phrase 'compute lexical affinity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'compute' where 'similarity' is used to compute 'lexical affinity'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "similarity",
                "OtherScientificTerm"
            ],
            [
                "sequential models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the verb 'compute', depending on the verb 'use' in the clause 'which either use arbitrary windows to compute similarity between words'. Entity 2 ('sequential models') is the object of the verb 'create', depending on the verb 'use' in the clause 'or use lexical affinity to create sequential models'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses describing different methods used in previous models.",
        "sdp_path_text": "similarity → compute → use → use → create → models",
        "sentence": "Models use similarity to create sequential models.",
        "sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the preposition 'use', depending on 'use' in the phrase 'use similarity'. Entity 2 ('sequential models') is the object of the verb 'create', depending on 'create' in the phrase 'create sequential models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the verb 'create'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "similarity",
                "OtherScientificTerm"
            ],
            [
                "models",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the verb 'compute', depending on 'compute' in the clause 'which either use arbitrary windows to compute similarity between words'. Entity 2 ('models') is the subject, depending on 'focus' with 'we' in the clause 'in this paper we focus on models'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing different approaches in computational linguistics.",
        "sdp_path_text": "similarity → compute → use → models",
        "sentence": "Models use similarity to compute relationships between words.",
        "sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the preposition 'to', depending on 'use' with 'models'. Entity 2 ('models') is the subject, depending on the verb 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' where 'models' uses 'similarity'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "similarity",
                "OtherScientificTerm"
            ],
            [
                "co-occurrence patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the preposition 'between', depending on 'compute' with 'words'. Entity 2 ('co-occurrence patterns') is the object of the preposition 'to', depending on 'capture' with 'models'. There is no direct dependency between Entity 1 and Entity 2; they are both part of different clauses describing aspects of models used in text analysis.",
        "sdp_path_text": "similarity → compute → use → models → with → comparison → In → focus → on → models → intended → capture → patterns",
        "sentence": "We focus on models intended to capture co-occurrence patterns, in comparison to models that compute similarity.",
        "sentence_llm_dp_info": "Entity 1 ('similarity') is the object of the relative clause, depending on 'compute' with 'models'. Entity 2 ('co-occurrence patterns') is the object, depending on 'capture' with 'intended'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different types of 'models' in the sentence."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "lexical affinity",
                "OtherScientificTerm"
            ],
            [
                "sequential models",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lexical affinity') is part of a clause functioning as an object complement, depending on 'use' with 'or'. Entity 2 ('sequential models') is the object of the verb 'create', depending on 'create' with 'lexical affinity'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of different clauses within the same sentence, connected through the conjunction 'or'.",
        "sdp_path_text": "affinity → use → create → models",
        "sentence": "Lexical affinity is used to create sequential models.",
        "sentence_llm_dp_info": "Entity 1 ('lexical affinity') is the subject, depending on the verb 'used'. Entity 2 ('sequential models') is the object, depending on the verb 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'used' and 'create'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "lexical affinity",
                "OtherScientificTerm"
            ],
            [
                "models",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lexical affinity') is part of a clause, functioning as the object of the verb 'use', depending on 'use' in the phrase 'or use lexical affinity'. Entity 2 ('models') is the object of the preposition 'on', depending on 'focus' in the phrase 'focus on models'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.",
        "sdp_path_text": "affinity → use → use → models",
        "sentence": "Lexical affinity is used to create models.",
        "sentence_llm_dp_info": "Entity 1 ('lexical affinity') is the subject, depending on the verb 'is used'. Entity 2 ('models') is the object, depending on the verb 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'is used' and 'create' which describe the process involving both entities."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "lexical affinity",
                "OtherScientificTerm"
            ],
            [
                "co-occurrence patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lexical affinity') is part of a clause modifying 'models', depending on 'use' with 'which'. Entity 2 ('co-occurrence patterns') is the object of the verb 'capture', depending on 'intended' in the phrase 'intended to capture'. There is no direct dependency between Entity 1 and Entity 2; both are related to different aspects of 'models' being discussed in the sentence.",
        "sdp_path_text": "affinity → use → use → models → with → comparison → In → focus → on → models → intended → capture → patterns",
        "sentence": "Lexical affinity is used to create models intended to capture co-occurrence patterns.",
        "sentence_llm_dp_info": "Entity 1 ('lexical affinity') is the subject, depending on the verb 'is used'. Entity 2 ('co-occurrence patterns') is the object, depending on the verb 'capture' within the clause 'intended to capture co-occurrence patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of using 'lexical affinity' to 'capture' 'co-occurrence patterns'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "sequential models",
                "Method"
            ],
            [
                "co-occurrence patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sequential models') is the object of the preposition 'create', depending on the verb 'use' within the relative clause 'which...use lexical affinity to create sequential models'. Entity 2 ('co-occurrence patterns') is the object of the verb 'capture', depending on the verb 'intended' within the clause 'models intended to capture the co-occurrence patterns'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses that describe different types of models.",
        "sdp_path_text": "models → create → use → use → models → with → comparison → In → focus → on → models → intended → capture → patterns",
        "sentence": "Sequential models are used to create models intended to capture co-occurrence patterns.",
        "sentence_llm_dp_info": "Entity 1 ('sequential models') is the subject, depending on the verb 'used'. Entity 2 ('co-occurrence patterns') is the object of the clause, depending on 'capture' with 'intended to capture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' and the purpose clause 'intended to capture co-occurrence patterns'."
    },
    {
        "raw_sentence": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .",
        "ner_pair": [
            [
                "models",
                "Generic"
            ],
            [
                "co-occurrence patterns",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('models') is the subject, depending on 'focus' with 'we'. Entity 2 ('co-occurrence patterns') is the object, depending on 'capture' with 'intended'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' and the prepositional phrase 'intended to capture the co-occurrence patterns'.",
        "sdp_path_text": "models → with → comparison → In → focus → on → models → intended → capture → patterns",
        "sentence": "We focus on models intended to capture co-occurrence patterns.",
        "sentence_llm_dp_info": "Entity 1 ('models') is the object of the preposition 'on', depending on 'focus' with 'We'. Entity 2 ('co-occurrence patterns') is the object of the infinitive 'to capture', depending on 'capture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' which describes the purpose of the models."
    },
    {
        "raw_sentence": "We apply it in combination with a terabyte corpus to answer natural language tests , achieving encouraging results .",
        "ner_pair": [
            [
                "terabyte corpus",
                "Material"
            ],
            [
                "it",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('terabyte corpus') is the object of the preposition 'with', depending on 'apply'. Entity 2 ('it') is the object, depending on 'apply' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'apply'.",
        "sdp_path_text": "corpus → with → combination → in → apply → it",
        "sentence": "We apply it in combination with a terabyte corpus.",
        "sentence_llm_dp_info": "Entity 1 ('terabyte corpus') is the object of the preposition 'with', depending on 'with' in the phrase 'with a terabyte corpus'. Entity 2 ('it') is the object, depending on 'apply' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'it' is applied in combination with the 'terabyte corpus'."
    },
    {
        "raw_sentence": "We apply it in combination with a terabyte corpus to answer natural language tests , achieving encouraging results .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "natural language tests",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the object, depending on the verb 'apply'. Entity 2 ('natural language tests') is the object of the preposition 'to', depending on 'to' in the phrase 'to answer natural language tests'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' is applied to answer 'natural language tests'.",
        "sdp_path_text": "it → apply → answer → tests",
        "sentence": "We apply it to answer natural language tests.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the object of the verb 'apply', depending on 'apply' in the phrase 'apply it'. Entity 2 ('natural language tests') is the object of the preposition 'to', depending on 'to' in the phrase 'to answer natural language tests'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'it' is applied to the purpose of answering 'natural language tests'."
    },
    {
        "raw_sentence": "We apply it in combination with a terabyte corpus to answer natural language tests , achieving encouraging results .",
        "ner_pair": [
            [
                "terabyte corpus",
                "Material"
            ],
            [
                "natural language tests",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('terabyte corpus') is the object of the preposition 'with', depending on 'apply'. Entity 2 ('natural language tests') is the object of the infinitive 'to answer', depending on 'answer'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose and method of applying the technique.",
        "sdp_path_text": "corpus → with → combination → in → apply → answer → tests",
        "sentence": "We apply a terabyte corpus to answer natural language tests.",
        "sentence_llm_dp_info": "Entity 1 ('terabyte corpus') is the object of the preposition 'to', depending on 'apply'. Entity 2 ('natural language tests') is the object of the infinitive 'to answer', depending on 'answer'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing what is being applied and what it aims to answer."
    },
    {
        "raw_sentence": "This paper introduces a system for categorizing unknown words .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "categorizing unknown words",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object, depending on 'introduces' with 'This paper'. Entity 2 ('categorizing unknown words') is the complement of the preposition 'for', depending on 'for' in the phrase 'for categorizing unknown words'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "system → for → categorizing",
        "sentence": "This paper introduces a system for categorizing unknown words.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the object, depending on 'introduces' with 'This paper'. Entity 2 ('categorizing unknown words') is the complement of the preposition 'for', depending on 'for' in the phrase 'for categorizing unknown words'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words .",
        "ner_pair": [
            [
                "multi-component architecture",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-component architecture') is the object of the preposition 'on', depending on 'based'. Entity 2 ('system') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is part of the prepositional phrase that modifies Entity 2, indicating what the system is based on.",
        "sdp_path_text": "architecture → on → based → system",
        "sentence": "The system is based on a multi-component architecture.",
        "sentence_llm_dp_info": "Entity 1 ('multi-component architecture') is the object of the preposition 'on', depending on 'based'. Entity 2 ('system') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' and the verb 'based'."
    },
    {
        "raw_sentence": "The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "component",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is' and modified by the prepositional phrase 'based on a multi-component architecture'. Entity 2 ('component') is the subject of the relative clause 'where each component is responsible', depending on the verb 'is' within this clause. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase and the relative clause that describes the structure of the system.",
        "sdp_path_text": "system → based → on → architecture → component",
        "sentence": "The system is based on an architecture with components.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is'. Entity 2 ('component') is part of the object, depending on 'with' in the phrase 'with components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which describes the relationship between the system's architecture and its components."
    },
    {
        "raw_sentence": "The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "unknown words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is' with 'based'. Entity 2 ('unknown words') is the object of the preposition 'for', depending on 'identifying' in the phrase 'responsible for identifying'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure describing the system's architecture and the components' responsibilities.",
        "sdp_path_text": "system → based → on → architecture → is → responsible → for → identifying → class → of → words",
        "sentence": "The system is based on an architecture responsible for identifying unknown words.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is'. Entity 2 ('unknown words') is the object, depending on the verb 'identifying'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for identifying unknown words' which modifies 'architecture'."
    },
    {
        "raw_sentence": "The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words .",
        "ner_pair": [
            [
                "multi-component architecture",
                "Method"
            ],
            [
                "unknown words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-component architecture') is the object of the preposition 'on', depending on 'based' in the phrase 'based on a multi-component architecture'. Entity 2 ('unknown words') is the object of the preposition 'for', depending on 'responsible' in the phrase 'responsible for identifying one class of unknown words'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "architecture → is → responsible → for → identifying → class → of → words",
        "sentence": "The multi-component architecture is responsible for identifying classes of unknown words.",
        "sentence_llm_dp_info": "Entity 1 ('multi-component architecture') is the subject, depending on the verb 'is'. Entity 2 ('unknown words') is the object of the preposition 'of', depending on 'classes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'responsible' and the prepositional phrase 'for identifying classes of unknown words'."
    },
    {
        "raw_sentence": "The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words .",
        "ner_pair": [
            [
                "component",
                "Generic"
            ],
            [
                "unknown words",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('component') is the subject, depending on the verb 'is' in the clause 'each component is responsible'. Entity 2 ('unknown words') is the object, depending on the verb 'identifying' in the phrase 'for identifying one class of unknown words'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'identifying' which describes the responsibility of the component.",
        "sdp_path_text": "component → architecture → is → responsible → for → identifying → class → of → words",
        "sentence": "Each component is responsible for identifying classes of unknown words.",
        "sentence_llm_dp_info": "Entity 1 ('component') is the subject, depending on the verb 'is'. Entity 2 ('unknown words') is the object of the preposition 'for', depending on 'identifying' in the phrase 'identifying classes of unknown words'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'responsible' and the prepositional phrase 'for identifying classes of unknown words'."
    },
    {
        "raw_sentence": "The focus of this paper is the components that identify names and spelling errors .",
        "ner_pair": [
            [
                "components",
                "Generic"
            ],
            [
                "names",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('components') is the subject complement, depending on 'is' with 'focus'. Entity 2 ('names') is the object of the relative clause, depending on 'identify' with 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'identify'.",
        "sdp_path_text": "components → identify → names",
        "sentence": "The components identify names.",
        "sentence_llm_dp_info": "Entity 1 ('components') is the subject, depending on the verb 'identify'. Entity 2 ('names') is the object, depending on 'identify' with 'components'. There is a direct dependency between Entity 1 and Entity 2, where 'components' identifies 'names'."
    },
    {
        "raw_sentence": "The focus of this paper is the components that identify names and spelling errors .",
        "ner_pair": [
            [
                "components",
                "Generic"
            ],
            [
                "spelling errors",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('components') is the subject, depending on 'is' as the main verb of the sentence. Entity 2 ('spelling errors') is part of a noun phrase, depending on 'that' which introduces the relative clause modifying 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause introduced by 'that'.",
        "sdp_path_text": "components → identify → names → errors",
        "sentence": "Components identify spelling errors.",
        "sentence_llm_dp_info": "Entity 1 ('components') is the subject, depending on the verb 'identify'. Entity 2 ('spelling errors') is the object, depending on 'identify' with 'components'. There is a direct dependency between Entity 1 and Entity 2, as 'components' identifies 'spelling errors'."
    },
    {
        "raw_sentence": "The focus of this paper is the components that identify names and spelling errors .",
        "ner_pair": [
            [
                "names",
                "OtherScientificTerm"
            ],
            [
                "spelling errors",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('names') is the object, depending on 'identify' with 'components'. Entity 2 ('spelling errors') is also the object, depending on 'identify' with 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'identify'.",
        "sdp_path_text": "names → errors",
        "sentence": "The components identify names and spelling errors.",
        "sentence_llm_dp_info": "Entity 1 ('names') is the object, depending on 'identify' with 'components'. Entity 2 ('spelling errors') is also the object, depending on 'identify' with 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'identify'."
    },
    {
        "raw_sentence": "Each component uses a decision tree architecture to combine multiple types of evidence about the unknown word .",
        "ner_pair": [
            [
                "decision tree architecture",
                "Method"
            ],
            [
                "component",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decision tree architecture') is the object, depending on 'uses' with 'component'. Entity 2 ('component') is the subject, depending on 'uses' with 'decision tree architecture'. There is a direct dependency between Entity 1 and Entity 2, as 'component' uses 'decision tree architecture'.",
        "sdp_path_text": "architecture → uses → component",
        "sentence": "Components use a decision tree architecture.",
        "sentence_llm_dp_info": "Entity 1 ('decision tree architecture') is the object, depending on the verb 'use' with 'Components'. Entity 2 ('component') is the subject, depending on the verb 'use'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 uses Entity 1."
    },
    {
        "raw_sentence": "Each component uses a decision tree architecture to combine multiple types of evidence about the unknown word .",
        "ner_pair": [
            [
                "component",
                "Generic"
            ],
            [
                "unknown word",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('component') is the subject, depending on the verb 'uses'. Entity 2 ('unknown word') is the object, depending on the preposition 'about' in the phrase 'about the unknown word'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the prepositional phrase 'about the unknown word'.",
        "sdp_path_text": "component → uses → combine → types → of → evidence → about → word",
        "sentence": "Each component uses evidence to combine information about the unknown word.",
        "sentence_llm_dp_info": "Entity 1 ('component') is the subject, depending on the verb 'uses'. Entity 2 ('unknown word') is the object of the preposition 'about', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the prepositional phrase 'about the unknown word'."
    },
    {
        "raw_sentence": "Each component uses a decision tree architecture to combine multiple types of evidence about the unknown word .",
        "ner_pair": [
            [
                "decision tree architecture",
                "Method"
            ],
            [
                "unknown word",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decision tree architecture') is the object of the verb 'uses', depending on 'component'. Entity 2 ('unknown word') is the object of the preposition 'about', depending on 'evidence'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combine' which combines 'evidence' (related to 'unknown word') using the 'decision tree architecture'.",
        "sdp_path_text": "architecture → uses → combine → types → of → evidence → about → word",
        "sentence": "Decision tree architecture is used to combine evidence about the unknown word.",
        "sentence_llm_dp_info": "Entity 1 ('decision tree architecture') is the subject, depending on the verb 'used'. Entity 2 ('unknown word') is the object of the preposition 'about', depending on 'combine'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the prepositional phrase 'about the unknown word'."
    },
    {
        "raw_sentence": "The system is evaluated using data from live closed captions - a genre replete with a wide variety of unknown words .",
        "ner_pair": [
            [
                "live closed captions",
                "Material"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('live closed captions') is the source of the data, depending on the preposition 'from' with 'data'. Entity 2 ('system') is the subject, depending on the verb 'is evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'using data from live closed captions'.",
        "sdp_path_text": "captions → from → data → using → evaluated → system",
        "sentence": "The system is evaluated using data from live closed captions.",
        "sentence_llm_dp_info": "Entity 1 ('live closed captions') is the source of the data, depending on 'from' in the prepositional phrase 'from live closed captions'. Entity 2 ('system') is the subject, depending on the verb 'is evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating the source of the data used for evaluating the system."
    },
    {
        "raw_sentence": "The system is evaluated using data from live closed captions - a genre replete with a wide variety of unknown words .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "unknown words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is evaluated'. Entity 2 ('unknown words') is part of the noun phrase, depending on 'variety' in the phrase 'variety of unknown words'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the evaluation process described in the sentence.",
        "sdp_path_text": "system → evaluated → using → data → from → captions → genre → replete → with → variety → of → words",
        "sentence": "The system is evaluated using data from captions replete with unknown words.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'evaluated'. Entity 2 ('unknown words') is the object, depending on the preposition 'with' within the phrase 'replete with unknown words'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from captions replete with unknown words'."
    },
    {
        "raw_sentence": "The system is evaluated using data from live closed captions - a genre replete with a wide variety of unknown words .",
        "ner_pair": [
            [
                "live closed captions",
                "Material"
            ],
            [
                "unknown words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('live closed captions') is the object of the preposition 'from', depending on 'using' in the phrase 'using data from live closed captions'. Entity 2 ('unknown words') is part of the complement of the noun 'variety', depending on 'variety' in the phrase 'a wide variety of unknown words'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the evaluation of the system.",
        "sdp_path_text": "captions → genre → replete → with → variety → of → words",
        "sentence": "Live closed captions are a genre replete with a variety of unknown words.",
        "sentence_llm_dp_info": "Entity 1 ('live closed captions') is the subject, depending on the verb 'are'. Entity 2 ('unknown words') is the object of the preposition 'with', depending on 'replete'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'replete with a variety of unknown words'."
    },
    {
        "raw_sentence": "At MIT Lincoln Laboratory , we have been developing a Korean-to-English machine translation system CCLINC -LRB- Common Coalition Language System at Lincoln Laboratory -RRB- .",
        "ner_pair": [
            [
                "CCLINC -LRB- Common Coalition Language System at Lincoln Laboratory -RRB-",
                "Method"
            ],
            [
                "Korean-to-English machine translation system",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCLINC -LRB- Common Coalition Language System at Lincoln Laboratory -RRB-') is the appositive, depending on 'system' with a clarification role. Entity 2 ('Korean-to-English machine translation system') is the object, depending on the verb 'developing'. There is no direct dependency between Entity 1 and Entity 2, but they are closely related as Entity 1 provides additional information about Entity 2.",
        "sdp_path_text": "at → developing → English",
        "sentence": "CCLINC is being developed for a Korean-to-English machine translation system.",
        "sentence_llm_dp_info": "Entity 1 ('CCLINC') is the subject, depending on the verb 'being developed'. Entity 2 ('Korean-to-English machine translation system') is the object of the preposition 'for', depending on 'for' in the phrase 'for a Korean-to-English machine translation system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "core modules",
                "Generic"
            ],
            [
                "CCLINC Korean-to-English translation system",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('core modules') is the object of the preposition 'of', depending on 'consists' with 'system'. Entity 2 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'consists' where 'core modules' are part of the 'CCLINC Korean-to-English translation system'.",
        "sdp_path_text": "modules → of → consists → system",
        "sentence": "The CCLINC Korean-to-English translation system consists of core modules.",
        "sentence_llm_dp_info": "Entity 1 ('core modules') is the object, depending on the verb 'consists'. Entity 2 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. There is a direct dependency between Entity 1 and Entity 2, as 'core modules' is the object that the 'CCLINC Korean-to-English translation system' consists of."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "CCLINC Korean-to-English translation system",
                "Method"
            ],
            [
                "language understanding and generation modules",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. Entity 2 ('language understanding and generation modules') is the object, depending on 'consists' with 'CCLINC Korean-to-English translation system'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is part of what Entity 1 consists of.",
        "sdp_path_text": "system → consists → of → modules → understanding",
        "sentence": "The CCLINC Korean-to-English translation system consists of language understanding and generation modules.",
        "sentence_llm_dp_info": "Entity 1 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. Entity 2 ('language understanding and generation modules') is the object, depending on 'consists' with 'CCLINC Korean-to-English translation system'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the direct object of the verb 'consists' which is linked to Entity 1."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "CCLINC Korean-to-English translation system",
                "Method"
            ],
            [
                "language neutral meaning representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. Entity 2 ('language neutral meaning representation') is the object of the preposition 'by', depending on 'mediated' in the phrase 'mediated by a language neutral meaning representation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'consists' and the prepositional phrase 'mediated by'.",
        "sdp_path_text": "system → consists → of → modules → understanding → mediated → by → representation",
        "sentence": "The CCLINC Korean-to-English translation system consists of modules mediated by a language neutral meaning representation.",
        "sentence_llm_dp_info": "Entity 1 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. Entity 2 ('language neutral meaning representation') is the object of the preposition 'by', depending on 'mediated' in the phrase 'mediated by a language neutral meaning representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'consists' and the prepositional phrase 'mediated by'."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "CCLINC Korean-to-English translation system",
                "Method"
            ],
            [
                "semantic frame",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. Entity 2 ('semantic frame') is the object of the preposition 'called', depending on 'called' in the phrase 'called a semantic frame'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'called' and the verb 'consists'.",
        "sdp_path_text": "system → consists → of → modules → understanding → mediated → by → representation → called → frame",
        "sentence": "The CCLINC Korean-to-English translation system consists of modules mediated by a semantic frame.",
        "sentence_llm_dp_info": "Entity 1 ('CCLINC Korean-to-English translation system') is the subject, depending on the verb 'consists'. Entity 2 ('semantic frame') is the object of the preposition 'by', depending on 'mediated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'consists' and the prepositional phrase 'mediated by a semantic frame'."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "core modules",
                "Generic"
            ],
            [
                "language understanding and generation modules",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('core modules') is the object of the preposition 'of', depending on 'consists' with 'system'. Entity 2 ('language understanding and generation modules') is the subject, depending on 'mediated' with 'by'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of components within the system, where Entity 2 specifies what the Entity 1 are.",
        "sdp_path_text": "modules → understanding",
        "sentence": "The core modules consist of language understanding and generation modules.",
        "sentence_llm_dp_info": "Entity 1 ('core modules') is the subject, depending on the verb 'consist'. Entity 2 ('language understanding and generation modules') is the object, depending on the verb 'consist' with 'core modules'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 specifies what Entity 1 consists of."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "core modules",
                "Generic"
            ],
            [
                "language neutral meaning representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('core modules') is the object of the preposition 'of', depending on 'consists' in the phrase 'consists of two core modules'. Entity 2 ('language neutral meaning representation') is the subject complement, depending on 'called' in the phrase 'called a language neutral meaning representation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the components of the CCLINC Korean-to-English translation system.",
        "sdp_path_text": "modules → understanding → mediated → by → representation",
        "sentence": "The core modules are mediated by a language neutral meaning representation.",
        "sentence_llm_dp_info": "Entity 1 ('core modules') is the subject, depending on the passive verb 'are mediated'. Entity 2 ('language neutral meaning representation') is the object of the preposition 'by', depending on 'by' in the phrase 'by a language neutral meaning representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by'."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "core modules",
                "Generic"
            ],
            [
                "semantic frame",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('core modules') is the object, depending on 'consists' with 'system'. Entity 2 ('semantic frame') is the object of the preposition 'called', depending on 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'mediated by a language neutral meaning representation called a semantic frame'.",
        "sdp_path_text": "modules → understanding → mediated → by → representation → called → frame",
        "sentence": "The core modules are mediated by a semantic frame.",
        "sentence_llm_dp_info": "Entity 1 ('core modules') is the subject, depending on the verb 'are mediated'. Entity 2 ('semantic frame') is the object, depending on the preposition 'by' in the phrase 'by a semantic frame'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are mediated' and the preposition 'by'."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "language neutral meaning representation",
                "Method"
            ],
            [
                "language understanding and generation modules",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language neutral meaning representation') is the object of the preposition 'by', depending on 'mediated'. Entity 2 ('language understanding and generation modules') is the object of the preposition 'of', depending on 'consists'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing components of the 'CCLINC Korean-to-English translation system'.",
        "sdp_path_text": "representation → by → mediated → understanding",
        "sentence": "A language neutral meaning representation mediates language understanding and generation modules.",
        "sentence_llm_dp_info": "Entity 1 ('language neutral meaning representation') is the subject, depending on the verb 'mediates'. Entity 2 ('language understanding and generation modules') is the object, depending on the verb 'mediates'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is mediating Entity 2."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "language understanding and generation modules",
                "Method"
            ],
            [
                "semantic frame",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language understanding and generation modules') is the subject, depending on the verb 'consists'. Entity 2 ('semantic frame') is the object of the preposition 'by', depending on 'mediated' in the phrase 'mediated by a language neutral meaning representation called a semantic frame'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'by' and the verb 'mediated'.",
        "sdp_path_text": "understanding → mediated → by → representation → called → frame",
        "sentence": "Language understanding and generation modules are mediated by a semantic frame.",
        "sentence_llm_dp_info": "Entity 1 ('language understanding and generation modules') is the subject, depending on the verb 'are mediated'. Entity 2 ('semantic frame') is the object, depending on 'by' in the phrase 'by a semantic frame'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'mediated' and the preposition 'by'."
    },
    {
        "raw_sentence": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame .",
        "ner_pair": [
            [
                "semantic frame",
                "OtherScientificTerm"
            ],
            [
                "language neutral meaning representation",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('semantic frame') is the appositive, depending on the noun 'representation' with the preposition 'called'. Entity 2 ('language neutral meaning representation') is the object of the preposition 'by', depending on 'mediated'. There is a direct dependency between Entity 1 and Entity 2, as 'semantic frame' is used to specify or rename 'language neutral meaning representation'.",
        "sdp_path_text": "frame → called → representation",
        "sentence": "A semantic frame is a language neutral meaning representation.",
        "sentence_llm_dp_info": "Entity 1 ('semantic frame') is the subject, depending on the copula 'is'. Entity 2 ('language neutral meaning representation') is the predicate nominative, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as they are linked by the copula 'is'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "parsing of Korean",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the possessive noun, depending on 'features' with 'of' in the phrase 'features of the system'. Entity 2 ('parsing of Korean') is part of a list, depending on 'include' with 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'parsing of Korean' is one of the features included in the 'system'.",
        "sdp_path_text": "system → of → features → include → -LRB- → parsing",
        "sentence": "The system includes robust parsing of Korean.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'includes'. Entity 2 ('parsing of Korean') is the object, depending on 'includes' with 'system'. There is a direct dependency between Entity 1 and Entity 2, as 'parsing of Korean' is directly included by the 'system'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "Korean",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the noun being described, depending on 'features' with the preposition 'of' in the phrase 'features of the system'. Entity 2 ('Korean') is the object of the preposition 'of', depending on 'parsing' in the phrase 'parsing of Korean'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain 'system -> features -> parsing -> Korean'.",
        "sdp_path_text": "system → of → features → include → -LRB- → parsing → of → Korean",
        "sentence": "The system includes robust parsing of Korean.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'includes'. Entity 2 ('Korean') is the object of the preposition 'of', depending on 'parsing' in the phrase 'parsing of Korean'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'includes' and the noun 'parsing'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "verb final language",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the preposition 'of', depending on 'features'. Entity 2 ('verb final language') is part of the appositive clause describing 'Korean', depending on 'parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the description of the system's features.",
        "sdp_path_text": "system → of → features → include → -LRB- → parsing → language",
        "sentence": "The system includes robust parsing of a verb final language.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'includes'. Entity 2 ('verb final language') is the object of the preposition 'of', depending on 'parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the prepositional phrase 'of a verb final language'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "overt case markers",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the preposition 'of', depending on 'features'. Entity 2 ('overt case markers') is part of a list describing characteristics of the language (Korean), depending on the verb 'parsing'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure that describes the features of the system and the characteristics of the language being parsed.",
        "sdp_path_text": "system → of → features → include → -LRB- → parsing → language → with → markers",
        "sentence": "The system includes parsing of a language with overt case markers.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'includes'. Entity 2 ('overt case markers') is the object of the preposition 'with', depending on 'with' in the phrase 'with overt case markers'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "parsing of Korean",
                "Task"
            ],
            [
                "verb final language",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parsing of Korean') is the object of the verb 'include', depending on the preposition 'of' with 'features'. Entity 2 ('verb final language') is an appositive, depending on 'Korean' with the preposition 'a'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the description of the system's features.",
        "sdp_path_text": "parsing → language",
        "sentence": "Parsing of Korean involves a verb final language.",
        "sentence_llm_dp_info": "Entity 1 ('parsing of Korean') is the subject, depending on the verb 'involves'. Entity 2 ('verb final language') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly involved with Entity 1 through the verb 'involves'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "parsing of Korean",
                "Task"
            ],
            [
                "overt case markers",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parsing of Korean') is part of a list item, depending on the verb 'include' from 'The key features of the system include'. Entity 2 ('overt case markers') is an element within the description of Korean, depending on the conjunction 'and' which connects it with other characteristics of Korean. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger descriptive clause about the robust and efficient parsing capabilities of the system.",
        "sdp_path_text": "parsing → language → with → markers",
        "sentence": "Parsing of Korean involves handling languages with overt case markers.",
        "sentence_llm_dp_info": "Entity 1 ('parsing of Korean') is the subject, depending on the verb 'involves'. Entity 2 ('overt case markers') is the object of the preposition 'with', depending on 'handling'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' and the prepositional phrase 'with overt case markers'."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "Korean",
                "Material"
            ],
            [
                "verb final language",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Korean') is the object, depending on 'parsing' with the preposition 'of'. Entity 2 ('verb final language') is the complement of the preposition 'with', describing a characteristic of 'Korean'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase that describes properties of 'Korean'.",
        "sdp_path_text": "Korean → of → parsing → language",
        "sentence": "Korean is a verb final language with robust efficient parsing.",
        "sentence_llm_dp_info": "Entity 1 ('Korean') is the subject, depending on the verb 'is'. Entity 2 ('verb final language') is the predicate nominal, depending on 'is' as its head. There is a direct dependency between Entity 1 and Entity 2, as 'verb final language' describes what 'Korean' is."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "Korean",
                "Material"
            ],
            [
                "overt case markers",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Korean') is the object of the preposition 'of', depending on 'parsing'. Entity 2 ('overt case markers') is part of a list of attributes, depending on 'language' within the descriptive clause. There is no direct dependency between Entity 1 and Entity 2; both are elements within the larger description of the characteristics of the Korean language.",
        "sdp_path_text": "Korean → of → parsing → language → with → markers",
        "sentence": "Korean parsing involves handling a language with overt case markers.",
        "sentence_llm_dp_info": "Entity 1 ('Korean') is the modifier, depending on 'parsing' as an adjective. Entity 2 ('overt case markers') is the object, depending on 'handling' with the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Korean parsing' is the subject and 'handling a language with overt case markers' is part of the predicate."
    },
    {
        "raw_sentence": "The key features of the system include : -LRB- i -RRB- Robust efficient parsing of Korean -LRB- a verb final language with overt case markers , relatively free word order , and frequent omissions of arguments -RRB- .",
        "ner_pair": [
            [
                "overt case markers",
                "OtherScientificTerm"
            ],
            [
                "verb final language",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('overt case markers') is part of a list of characteristics, depending on the conjunction 'and' within the description of Korean. Entity 2 ('verb final language') is a noun phrase, depending on the preposition 'of' within the appositive phrase describing Korean. There is no direct dependency between Entity 1 and Entity 2; both are elements in the list of characteristics that describe the nature of the Korean language.",
        "sdp_path_text": "markers → with → language",
        "sentence": "Overt case markers are features of a verb final language.",
        "sentence_llm_dp_info": "Entity 1 ('overt case markers') is the subject, depending on the verb 'are'. Entity 2 ('verb final language') is the complement, depending on the preposition 'of' in the phrase 'features of a verb final language'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are' and the prepositional phrase 'features of'."
    },
    {
        "raw_sentence": "-LRB- ii -RRB- High quality translation via word sense disambiguation and accurate word order generation of the target language .",
        "ner_pair": [
            [
                "word sense disambiguation",
                "Method"
            ],
            [
                "translation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word sense disambiguation') is part of the prepositional phrase 'via word sense disambiguation', functioning as a means or method, depending on the preposition 'via'. Entity 2 ('translation') is the subject complement, depending on the adjective 'High quality' and the verb 'is' (implied). There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'via', indicating that 'word sense disambiguation' is a method used to achieve 'high quality translation'.",
        "sdp_path_text": "disambiguation → via → translation",
        "sentence": "High quality translation is achieved via word sense disambiguation.",
        "sentence_llm_dp_info": "Entity 1 ('word sense disambiguation') is the means, depending on the preposition 'via', which modifies the verb 'achieved'. Entity 2 ('translation') is the subject, depending on the verb 'is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'via' that indicates the method by which the action (achievement) of Entity 2 occurs."
    },
    {
        "raw_sentence": "-LRB- ii -RRB- High quality translation via word sense disambiguation and accurate word order generation of the target language .",
        "ner_pair": [
            [
                "word order generation",
                "Task"
            ],
            [
                "translation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word order generation') is part of a compound noun, depending on 'accurate' as its modifier. Entity 2 ('translation') is the object of the preposition 'via', depending on 'via' in the phrase 'via word sense disambiguation and accurate word order generation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described in the sentence that leads to 'High quality translation'.",
        "sdp_path_text": "generation → translation",
        "sentence": "High quality translation involves accurate word order generation.",
        "sentence_llm_dp_info": "Entity 1 ('word order generation') is the object, depending on 'involves' with 'translation'. Entity 2 ('translation') is the subject, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as 'word order generation' is directly involved in the process of 'translation'."
    },
    {
        "raw_sentence": "-LRB- ii -RRB- High quality translation via word sense disambiguation and accurate word order generation of the target language .",
        "ner_pair": [
            [
                "word sense disambiguation",
                "Method"
            ],
            [
                "word order generation",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word sense disambiguation') is part of the coordination, depending on 'and' which connects it to 'word order generation'. Entity 2 ('word order generation') is also part of the coordination, depending on 'and' which connects it back to 'word sense disambiguation'. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated elements in the list of methods contributing to 'High quality translation'.",
        "sdp_path_text": "disambiguation → via → translation → generation",
        "sentence": "High quality translation is achieved via word sense disambiguation and word order generation.",
        "sentence_llm_dp_info": "Entity 1 ('word sense disambiguation') is part of a compound object, depending on the preposition 'via' which connects it to the verb 'achieved'. Entity 2 ('word order generation') is also part of a compound object, depending on the same preposition 'via'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'via'."
    },
    {
        "raw_sentence": "Having been trained on Korean newspaper articles on missiles and chemical biological warfare , the system produces the translation output sufficient for content understanding of the original document .",
        "ner_pair": [
            [
                "missiles and chemical biological warfare",
                "Material"
            ],
            [
                "Korean newspaper articles",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('missiles and chemical biological warfare') is the object of the preposition 'on', depending on 'articles'. Entity 2 ('Korean newspaper articles') is the object of the preposition 'on', depending on 'trained'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase describing what the system has been trained on.",
        "sdp_path_text": "missiles → on → articles",
        "sentence": "The system trained on Korean newspaper articles about missiles and chemical biological warfare produces sufficient translation output.",
        "sentence_llm_dp_info": "Entity 1 ('missiles and chemical biological warfare') is the object of the preposition 'about', depending on 'articles'. Entity 2 ('Korean newspaper articles') is the object of the preposition 'on', depending on 'trained'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrases 'on Korean newspaper articles' and 'about missiles and chemical biological warfare'."
    },
    {
        "raw_sentence": "Having been trained on Korean newspaper articles on missiles and chemical biological warfare , the system produces the translation output sufficient for content understanding of the original document .",
        "ner_pair": [
            [
                "Korean newspaper articles",
                "Material"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Korean newspaper articles') is the object of the preposition 'on', depending on the verb 'trained'. Entity 2 ('system') is the subject, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'trained' where Entity 1 serves as the object of the training process that Entity 2 undergoes.",
        "sdp_path_text": "articles → on → trained → produces → system",
        "sentence": "The system, trained on Korean newspaper articles, produces translation output.",
        "sentence_llm_dp_info": "Entity 1 ('Korean newspaper articles') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('system') is the subject, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'trained on Korean newspaper articles'."
    },
    {
        "raw_sentence": "Having been trained on Korean newspaper articles on missiles and chemical biological warfare , the system produces the translation output sufficient for content understanding of the original document .",
        "ner_pair": [
            [
                "missiles and chemical biological warfare",
                "Material"
            ],
            [
                "system",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('missiles and chemical biological warfare') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('system') is the subject, depending on 'produces' with 'the translation output'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the training context of the system.",
        "sdp_path_text": "missiles → on → articles → on → trained → produces → system",
        "sentence": "The system, trained on articles about missiles and chemical biological warfare, produces sufficient translation output.",
        "sentence_llm_dp_info": "Entity 1 ('missiles and chemical biological warfare') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('system') is the subject, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'trained on articles about missiles and chemical biological warfare'."
    },
    {
        "raw_sentence": "The JAVELIN system integrates a flexible , planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text .",
        "ner_pair": [
            [
                "planning-based architecture",
                "Method"
            ],
            [
                "JAVELIN system",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('planning-based architecture') is the object of the preposition 'with', depending on 'integrates' with 'JAVELIN system'. Entity 2 ('JAVELIN system') is the subject, depending on the verb 'integrates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'integrates'.",
        "sdp_path_text": "architecture → integrates → system",
        "sentence": "The JAVELIN system integrates a planning-based architecture.",
        "sentence_llm_dp_info": "Entity 1 ('planning-based architecture') is the object, depending on the verb 'integrates'. Entity 2 ('JAVELIN system') is the subject, depending on the verb 'integrates'. There is a direct dependency between Entity 1 and Entity 2, as 'JAVELIN system' integrates 'planning-based architecture'."
    },
    {
        "raw_sentence": "The JAVELIN system integrates a flexible , planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text .",
        "ner_pair": [
            [
                "language processing modules",
                "Method"
            ],
            [
                "JAVELIN system",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language processing modules') is the object of the preposition 'with', depending on 'integrates' in the clause 'integrates a flexible, planning-based architecture with a variety of language processing modules'. Entity 2 ('JAVELIN system') is the subject, depending on 'integrates' with 'the JAVELIN system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'integrates'.",
        "sdp_path_text": "modules → of → variety → with → integrates → system",
        "sentence": "The JAVELIN system integrates a variety of language processing modules.",
        "sentence_llm_dp_info": "Entity 1 ('language processing modules') is the object, depending on the verb 'integrates'. Entity 2 ('JAVELIN system') is the subject, also depending on the verb 'integrates'. There is a direct dependency between Entity 1 and Entity 2, as 'JAVELIN system' integrates 'language processing modules'."
    },
    {
        "raw_sentence": "The JAVELIN system integrates a flexible , planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text .",
        "ner_pair": [
            [
                "JAVELIN system",
                "Method"
            ],
            [
                "open-domain question answering capability",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('JAVELIN system') is the subject, depending on the verb 'integrates'. Entity 2 ('open-domain question answering capability') is the object, depending on 'provide' with 'to provide'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the purpose clause 'to provide an open-domain question answering capability on free text'.",
        "sdp_path_text": "system → integrates → provide → capability",
        "sentence": "The JAVELIN system provides an open-domain question answering capability.",
        "sentence_llm_dp_info": "Entity 1 ('JAVELIN system') is the subject, depending on the verb 'provides'. Entity 2 ('open-domain question answering capability') is the direct object, depending on 'provides' with 'JAVELIN system'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 provides Entity 2."
    },
    {
        "raw_sentence": "The JAVELIN system integrates a flexible , planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text .",
        "ner_pair": [
            [
                "language processing modules",
                "Method"
            ],
            [
                "planning-based architecture",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language processing modules') is the object of the preposition 'with', depending on 'integrates' in the clause 'integrates a flexible, planning-based architecture with a variety of language processing modules'. Entity 2 ('planning-based architecture') is the direct object, depending on 'integrates' in the same clause. There is no direct dependency between Entity 1 and Entity 2; both are dependent on the verb 'integrates'.",
        "sdp_path_text": "modules → of → variety → with → integrates → architecture",
        "sentence": "The JAVELIN system integrates language processing modules with a planning-based architecture.",
        "sentence_llm_dp_info": "Entity 1 ('language processing modules') is the object, depending on the verb 'integrates' with 'The JAVELIN system'. Entity 2 ('planning-based architecture') is the object of the preposition 'with', depending on 'with' in the phrase 'with a planning-based architecture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'integrates' and the preposition 'with'."
    },
    {
        "raw_sentence": "The JAVELIN system integrates a flexible , planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text .",
        "ner_pair": [
            [
                "planning-based architecture",
                "Method"
            ],
            [
                "open-domain question answering capability",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('planning-based architecture') is part of the object complement, depending on 'integrates' with 'JAVELIN system'. Entity 2 ('open-domain question answering capability') is the object, depending on 'provide' with 'modules'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence.",
        "sdp_path_text": "architecture → integrates → provide → capability",
        "sentence": "A planning-based architecture integrates to provide open-domain question answering capability.",
        "sentence_llm_dp_info": "Entity 1 ('planning-based architecture') is the subject, depending on the verb 'integrates'. Entity 2 ('open-domain question answering capability') is the object, depending on the verb 'provide'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'integrates' and 'provide'."
    },
    {
        "raw_sentence": "The JAVELIN system integrates a flexible , planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text .",
        "ner_pair": [
            [
                "language processing modules",
                "Method"
            ],
            [
                "open-domain question answering capability",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language processing modules') is the object of the preposition 'with', depending on 'integrates' in the phrase 'integrates... with a variety of language processing modules'. Entity 2 ('open-domain question answering capability') is the object of the verb 'provide', depending on 'provide' in the phrase 'to provide an open-domain question answering capability'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of what the JAVELIN system integrates and provides.",
        "sdp_path_text": "modules → of → variety → with → integrates → provide → capability",
        "sentence": "Language processing modules integrate to provide open-domain question answering capability.",
        "sentence_llm_dp_info": "Entity 1 ('language processing modules') is the subject, depending on the verb 'integrate'. Entity 2 ('open-domain question answering capability') is the object of the preposition 'to', depending on 'provide' in the phrase 'to provide open-domain question answering capability'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provide' and the preposition 'to'."
    },
    {
        "raw_sentence": "The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "question answering",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the possessor, depending on the noun 'operation' with 'of'. It also appears as the agent in the passive construction 'created by the system'. Entity 2 ('question answering') is part of the compound noun 'question answering session', depending on 'session'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence, particularly through the phrase 'during each question answering session' which describes an event involving the system.",
        "sdp_path_text": "system → of → operation → explained → through → browsing → repository → of → objects → created → during → session → answering",
        "sentence": "The system's operation is explained through browsing the repository of objects created during question answering sessions.",
        "sentence_llm_dp_info": "Entity 1 ('system') is part of the possessive noun phrase 'The system's operation', where it modifies 'operation'. Entity 2 ('question answering') is part of the noun phrase 'question answering sessions', where it modifies 'sessions'. There is no direct dependency between Entity 1 and Entity 2; both are involved in different parts of the sentence structure, with 'system' being part of the subject and 'question answering' being part of the object complement."
    },
    {
        "raw_sentence": "The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "question answering",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the possessor, depending on the noun 'operation' with 'of' in the phrase 'operation of the system'. It also appears as the subject of the clause 'created by the system'. Entity 2 ('question answering') is part of the compound noun 'question answering session', depending on 'session' with 'question answering'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the same clause where the 'system' creates data objects during 'question answering sessions'.",
        "sdp_path_text": "system → of → operation → explained → through → browsing → repository → of → objects → created → during → session → answering",
        "sentence": "The system's operation is explained through browsing the repository of objects created during question answering sessions.",
        "sentence_llm_dp_info": "Entity 1 ('system') is part of the possessive noun phrase 'The system's operation', where it modifies 'operation' as a determiner. Entity 2 ('question answering') is part of the noun phrase 'question answering sessions', where it modifies 'sessions' as an attributive. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence, specifically through the explanation of the system's operation involving sessions related to question answering."
    },
    {
        "raw_sentence": "We present the first application of the head-driven statistical parsing model of Collins -LRB- 1999 -RRB- as a simultaneous language model and parser for large-vocabulary speech recognition .",
        "ner_pair": [
            [
                "head-driven statistical parsing model",
                "Method"
            ],
            [
                "simultaneous language model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('head-driven statistical parsing model') is the object of the preposition 'of', depending on 'model'. Entity 2 ('simultaneous language model') is the complement of the preposition 'as', depending on 'as'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through different prepositional phrases.",
        "sdp_path_text": "model → of → application → present → as → model",
        "sentence": "We present the head-driven statistical parsing model as a simultaneous language model.",
        "sentence_llm_dp_info": "Entity 1 ('head-driven statistical parsing model') is the subject complement, depending on the verb 'present'. Entity 2 ('simultaneous language model') is also a subject complement, depending on the verb 'as' in the phrase 'as a simultaneous language model'. There is no direct dependency between Entity 1 and Entity 2, but they are both complements of the verb 'present' and are linked through the preposition 'as'."
    },
    {
        "raw_sentence": "We present the first application of the head-driven statistical parsing model of Collins -LRB- 1999 -RRB- as a simultaneous language model and parser for large-vocabulary speech recognition .",
        "ner_pair": [
            [
                "head-driven statistical parsing model",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('head-driven statistical parsing model') is the object of the preposition 'of', depending on 'model'. Entity 2 ('parser') is the object of the preposition 'as', depending on 'as' in the phrase 'as a simultaneous language model and parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'present'.",
        "sdp_path_text": "model → of → application → present → as → model → parser",
        "sentence": "We present the head-driven statistical parsing model as a parser.",
        "sentence_llm_dp_info": "Entity 1 ('head-driven statistical parsing model') is the complement, depending on the verb 'present'. Entity 2 ('parser') is the object of the preposition 'as', depending on 'as' in the phrase 'as a parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'."
    },
    {
        "raw_sentence": "We present the first application of the head-driven statistical parsing model of Collins -LRB- 1999 -RRB- as a simultaneous language model and parser for large-vocabulary speech recognition .",
        "ner_pair": [
            [
                "head-driven statistical parsing model",
                "Method"
            ],
            [
                "large-vocabulary speech recognition",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('head-driven statistical parsing model') is the object of the preposition 'of', depending on 'model'. It is part of the larger noun phrase 'the head-driven statistical parsing model of Collins (1999)', which is the object of the verb 'present'. Entity 2 ('large-vocabulary speech recognition') is the object of the preposition 'for', depending on 'parser'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a complex sentence structure where the model (Entity 1) is used as a parser for recognition (Entity 2).",
        "sdp_path_text": "model → of → application → present → as → model → for → recognition",
        "sentence": "We present the head-driven statistical parsing model as a model for large-vocabulary speech recognition.",
        "sentence_llm_dp_info": "Entity 1 ('head-driven statistical parsing model') is the subject complement, depending on the verb 'present'. Entity 2 ('large-vocabulary speech recognition') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'present' and the preposition 'for'."
    },
    {
        "raw_sentence": "We present the first application of the head-driven statistical parsing model of Collins -LRB- 1999 -RRB- as a simultaneous language model and parser for large-vocabulary speech recognition .",
        "ner_pair": [
            [
                "simultaneous language model",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('simultaneous language model') is the object of the preposition 'as', depending on 'as' in the phrase 'as a simultaneous language model'. Entity 2 ('parser') is also the object of the preposition 'as', depending on 'as' in the phrase 'as a parser'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'as', indicating that the model serves both roles.",
        "sdp_path_text": "model → parser",
        "sentence": "The head-driven statistical parsing model serves as a simultaneous language model and parser.",
        "sentence_llm_dp_info": "Entity 1 ('simultaneous language model') is part of the predicate, depending on the verb 'serves' with the preposition 'as'. Entity 2 ('parser') is also part of the predicate, depending on the same verb 'serves' with the preposition 'as'. There is no direct dependency between Entity 1 and Entity 2, but they are both governed by the verb 'serves' and the preposition 'as'."
    },
    {
        "raw_sentence": "We present the first application of the head-driven statistical parsing model of Collins -LRB- 1999 -RRB- as a simultaneous language model and parser for large-vocabulary speech recognition .",
        "ner_pair": [
            [
                "simultaneous language model",
                "Method"
            ],
            [
                "large-vocabulary speech recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('simultaneous language model') is part of the compound noun phrase, acting as the object complement, depending on 'as' in the phrase 'as a simultaneous language model'. Entity 2 ('large-vocabulary speech recognition') is also part of a compound noun phrase, acting as the object of the preposition 'for', depending on 'for' in the phrase 'for large-vocabulary speech recognition'. There is no direct dependency between Entity 1 and Entity 2; both are connected through their roles in the sentence structure, specifically through the prepositions 'as' and 'for'.",
        "sdp_path_text": "model → for → recognition",
        "sentence": "The simultaneous language model is applied for large-vocabulary speech recognition.",
        "sentence_llm_dp_info": "Entity 1 ('simultaneous language model') is the subject, depending on the verb 'applied'. Entity 2 ('large-vocabulary speech recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for large-vocabulary speech recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present the first application of the head-driven statistical parsing model of Collins -LRB- 1999 -RRB- as a simultaneous language model and parser for large-vocabulary speech recognition .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "large-vocabulary speech recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parser') is part of a compound noun, depending on 'model' with the conjunction 'and'. Entity 2 ('large-vocabulary speech recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for large-vocabulary speech recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'as a simultaneous language model and parser for large-vocabulary speech recognition'.",
        "sdp_path_text": "parser → model → for → recognition",
        "sentence": "The parser serves as a model for large-vocabulary speech recognition.",
        "sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'serves'. Entity 2 ('large-vocabulary speech recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for large-vocabulary speech recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The model is adapted to an online left to right chart-parser for word lattices , integrating acoustic , n-gram , and parser probabilities .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "online left to right chart-parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'adapted'. Entity 2 ('online left to right chart-parser') is the object of the preposition 'to', depending on 'to' in the phrase 'to an online left to right chart-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.",
        "sdp_path_text": "model → adapted → to → chart",
        "sentence": "The model is adapted to an online left to right chart-parser.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'adapted'. Entity 2 ('online left to right chart-parser') is the object of the preposition 'to', depending on 'to' in the phrase 'to an online left to right chart-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "The model is adapted to an online left to right chart-parser for word lattices , integrating acoustic , n-gram , and parser probabilities .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "word lattices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'adapted'. Entity 2 ('word lattices') is the object of the preposition 'for', depending on 'chart-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for word lattices'.",
        "sdp_path_text": "model → adapted → to → parser → for → lattices",
        "sentence": "The model is adapted to a parser for word lattices.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'adapted'. Entity 2 ('word lattices') is the object of the preposition 'for', depending on 'for' in the phrase 'for word lattices'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The model is adapted to an online left to right chart-parser for word lattices , integrating acoustic , n-gram , and parser probabilities .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "acoustic , n-gram , and parser probabilities",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'adapted'. Entity 2 ('acoustic, n-gram, and parser probabilities') is the object, depending on the verb 'integrating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'integrating' which indicates that the model integrates these probabilities.",
        "sdp_path_text": "model → adapted → integrating → probabilities",
        "sentence": "The model is adapted to integrate acoustic, n-gram, and parser probabilities.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'adapted'. Entity 2 ('acoustic, n-gram, and parser probabilities') is the object of the preposition 'to integrate', depending on 'integrate' in the phrase 'to integrate acoustic, n-gram, and parser probabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'adapted' and the preposition 'to integrate'."
    },
    {
        "raw_sentence": "The model is adapted to an online left to right chart-parser for word lattices , integrating acoustic , n-gram , and parser probabilities .",
        "ner_pair": [
            [
                "online left to right chart-parser",
                "Method"
            ],
            [
                "word lattices",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('online left to right chart-parser') is the object of the preposition 'to', depending on 'adapted'. Entity 2 ('word lattices') is the object of the preposition 'for', depending on 'chart-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the model's adaptation is described.",
        "sdp_path_text": "chart → to → parser → for → lattices",
        "sentence": "The online left to right chart-parser is adapted for word lattices.",
        "sentence_llm_dp_info": "Entity 1 ('online left to right chart-parser') is the subject, depending on the verb 'adapted'. Entity 2 ('word lattices') is the object of the preposition 'for', depending on 'for' in the phrase 'for word lattices'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The model is adapted to an online left to right chart-parser for word lattices , integrating acoustic , n-gram , and parser probabilities .",
        "ner_pair": [
            [
                "acoustic , n-gram , and parser probabilities",
                "OtherScientificTerm"
            ],
            [
                "online left to right chart-parser",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('acoustic, n-gram, and parser probabilities') is the object, depending on the verb 'integrating' with 'chart-parser'. Entity 2 ('online left to right chart-parser') is the object of the preposition 'to', depending on 'adapted' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'integrating' and the preposition 'to'.",
        "sdp_path_text": "probabilities → integrating → adapted → to → chart",
        "sentence": "The model integrates acoustic, n-gram, and parser probabilities into an online left to right chart-parser.",
        "sentence_llm_dp_info": "Entity 1 ('acoustic, n-gram, and parser probabilities') is the object of the verb 'integrates', depending on 'model'. Entity 2 ('online left to right chart-parser') is the object of the preposition 'into', depending on 'integrates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'integrates' and the preposition 'into'."
    },
    {
        "raw_sentence": "The model is adapted to an online left to right chart-parser for word lattices , integrating acoustic , n-gram , and parser probabilities .",
        "ner_pair": [
            [
                "word lattices",
                "OtherScientificTerm"
            ],
            [
                "acoustic , n-gram , and parser probabilities",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word lattices') is the object of the preposition 'for', depending on 'chart-parser'. Entity 2 ('acoustic, n-gram, and parser probabilities') is the object of the verb 'integrating', depending on 'integrating'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the adaptation of the model.",
        "sdp_path_text": "lattices → for → parser → to → adapted → integrating → probabilities",
        "sentence": "The model adapted for word lattices integrates acoustic, n-gram, and parser probabilities.",
        "sentence_llm_dp_info": "Entity 1 ('word lattices') is the object of the preposition 'for', depending on 'adapted'. Entity 2 ('acoustic, n-gram, and parser probabilities') is the object, depending on 'integrates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'word lattices' being an adaptation target and 'acoustic, n-gram, and parser probabilities' being what is integrated by the model."
    },
    {
        "raw_sentence": "The parser uses structural and lexical dependencies not considered by n-gram models , conditioning recognition on more linguistically-grounded relationships .",
        "ner_pair": [
            [
                "structural and lexical dependencies",
                "OtherScientificTerm"
            ],
            [
                "parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('structural and lexical dependencies') is the object, depending on the verb 'uses' with 'parser'. Entity 2 ('parser') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is the agent performing the action of using Entity 1.",
        "sdp_path_text": "dependencies → uses → parser",
        "sentence": "The parser uses structural and lexical dependencies.",
        "sentence_llm_dp_info": "Entity 1 ('structural and lexical dependencies') is the object, depending on the verb 'uses' with 'parser'. Entity 2 ('parser') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the object that Entity 2 (the subject) uses."
    },
    {
        "raw_sentence": "The parser uses structural and lexical dependencies not considered by n-gram models , conditioning recognition on more linguistically-grounded relationships .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "n-gram models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'uses'. Entity 2 ('n-gram models') is the object of the preposition 'by', depending on 'considered' in the phrase 'not considered by n-gram models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'considered' and the preposition 'by'.",
        "sdp_path_text": "parser → uses → dependencies → considered → by → models",
        "sentence": "The parser uses dependencies not considered by n-gram models.",
        "sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'uses'. Entity 2 ('n-gram models') is the object of the preposition 'by', depending on 'considered'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'considered' and the preposition 'by'."
    },
    {
        "raw_sentence": "The parser uses structural and lexical dependencies not considered by n-gram models , conditioning recognition on more linguistically-grounded relationships .",
        "ner_pair": [
            [
                "structural and lexical dependencies",
                "OtherScientificTerm"
            ],
            [
                "n-gram models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('structural and lexical dependencies') is the object of the verb 'uses', depending on 'parser'. Entity 2 ('n-gram models') is the object of the preposition 'by', depending on 'considered'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the parser does and does not consider.",
        "sdp_path_text": "dependencies → considered → by → models",
        "sentence": "Structural and lexical dependencies are not considered by n-gram models.",
        "sentence_llm_dp_info": "Entity 1 ('structural and lexical dependencies') is the subject, depending on the verb 'are' which indicates the state of not being considered. Entity 2 ('n-gram models') is the subject of the passive clause, depending on the verb 'considered' with the preposition 'by'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'considered' and the preposition 'by'."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "Wall Street Journal treebank",
                "Material"
            ],
            [
                "lattice corpora",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the first object of the preposition 'on', depending on 'Experiments'. Entity 2 ('lattice corpora') is the second object of the preposition 'on', also depending on 'Experiments'. There is no direct dependency between Entity 1 and Entity 2; both are listed as objects of the same preposition 'on'.",
        "sdp_path_text": "treebank → corpora",
        "sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show competitive word error rates.",
        "sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('lattice corpora') is coordinated with 'Wall Street Journal treebank' through the conjunction 'and', both being objects of the preposition 'on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through coordination."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "Wall Street Journal treebank",
                "Material"
            ],
            [
                "word error rates",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('word error rates') is the subject, depending on 'show' with 'Experiments'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Experiments' is the main subject.",
        "sdp_path_text": "treebank → on → Experiments → show → rates",
        "sentence": "Experiments on the Wall Street Journal treebank show word error rates.",
        "sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('word error rates') is the direct object, depending on 'show' with 'Experiments'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause involving 'Experiments' and 'show'."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "Wall Street Journal treebank",
                "Material"
            ],
            [
                "n-gram language model",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('n-gram language model') is the object of the preposition 'with', depending on 'competitive'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the outcomes of the experiments.",
        "sdp_path_text": "treebank → on → Experiments → show → rates → competitive → with → model",
        "sentence": "Experiments on the Wall Street Journal treebank show word error rates competitive with the n-gram language model.",
        "sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('n-gram language model') is the object of the preposition 'with', depending on 'competitive'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "Wall Street Journal treebank",
                "Material"
            ],
            [
                "structural information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('structural information') is the object, depending on 'extracting'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the outcomes of the experiments.",
        "sdp_path_text": "treebank → on → Experiments → show → extracting → information",
        "sentence": "Experiments on the Wall Street Journal treebank show extracting structural information.",
        "sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('structural information') is the object of the verb 'showing', depending on 'show'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "Wall Street Journal treebank",
                "Material"
            ],
            [
                "speech understanding",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "treebank → on → Experiments → show → extracting → information → useful → for → understanding",
        "sentence": "Experiments on the Wall Street Journal treebank show information useful for speech understanding.",
        "sentence_llm_dp_info": "Entity 1 ('Wall Street Journal treebank') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the context and outcome of the experiments."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "lattice corpora",
                "Material"
            ],
            [
                "word error rates",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lattice corpora') is part of the compound noun phrase, depending on 'on' with 'Experiments on the Wall Street Journal treebank and lattice corpora'. Entity 2 ('word error rates') is the subject of the clause, depending on 'show' with 'Experiments'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the experimental context provided by the sentence.",
        "sdp_path_text": "corpora → treebank → on → Experiments → show → rates",
        "sentence": "Experiments on lattice corpora show competitive word error rates.",
        "sentence_llm_dp_info": "Entity 1 ('lattice corpora') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('word error rates') is the object of the verb 'show', depending on 'show' in the clause 'show competitive word error rates'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'lattice corpora' is the context in which the 'word error rates' are evaluated."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "lattice corpora",
                "Material"
            ],
            [
                "n-gram language model",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lattice corpora') is part of the compound noun phrase, depending on 'on' as part of the prepositional phrase 'on the Wall Street Journal treebank and lattice corpora'. Entity 2 ('n-gram language model') is the object of the preposition 'with', depending on 'with' in the phrase 'with the standard n-gram language model'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause describing the results of the experiments.",
        "sdp_path_text": "corpora → treebank → on → Experiments → show → rates → competitive → with → model",
        "sentence": "Experiments on lattice corpora show word error rates competitive with the n-gram language model.",
        "sentence_llm_dp_info": "Entity 1 ('lattice corpora') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('n-gram language model') is the object of the preposition 'with', depending on 'competitive'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the results of the experiments."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "lattice corpora",
                "Material"
            ],
            [
                "structural information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lattice corpora') is part of the compound noun phrase, depending on 'on' with 'Experiments'. Entity 2 ('structural information') is the object, depending on 'extracting' which is part of the verb phrase describing what the experiments achieve. There is no direct dependency between Entity 1 and Entity 2, but both are related to the outcomes of the experiments described in the sentence.",
        "sdp_path_text": "corpora → treebank → on → Experiments → show → extracting → information",
        "sentence": "Experiments on lattice corpora show extracting structural information.",
        "sentence_llm_dp_info": "Entity 1 ('lattice corpora') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('structural information') is the object of the verb 'show', depending on 'showing'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Experiments' are conducted on 'lattice corpora' that 'show' the extraction of 'structural information'."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "lattice corpora",
                "Material"
            ],
            [
                "speech understanding",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lattice corpora') is part of the compound object of the preposition 'on', depending on 'on' in the phrase 'on the Wall Street Journal treebank and lattice corpora'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'useful' in the phrase 'useful for speech understanding'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "corpora → treebank → on → Experiments → show → extracting → information → useful → for → understanding",
        "sentence": "Experiments on lattice corpora show information useful for speech understanding.",
        "sentence_llm_dp_info": "Entity 1 ('lattice corpora') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure that describes what the experiments show."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "word error rates",
                "Metric"
            ],
            [
                "n-gram language model",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word error rates') is the subject, depending on the verb 'show'. Entity 2 ('n-gram language model') is the object of the preposition 'with', depending on 'with' in the phrase 'with the standard n-gram language model'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in the context of the sentence.",
        "sdp_path_text": "rates → competitive → with → model",
        "sentence": "Word error rates are competitive with the n-gram language model.",
        "sentence_llm_dp_info": "Entity 1 ('word error rates') is the subject, depending on the verb 'are'. Entity 2 ('n-gram language model') is the object of the preposition 'with', depending on 'with' in the phrase 'with the n-gram language model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure indicated by 'competitive with'."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "word error rates",
                "Metric"
            ],
            [
                "structural information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word error rates') is the subject, depending on the verb 'show'. Entity 2 ('structural information') is the object of the preposition 'for', depending on 'useful' in the phrase 'useful for speech understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence's main clause and related through the conjunction 'while' which indicates a contrast or additional information.",
        "sdp_path_text": "rates → show → extracting → information",
        "sentence": "Word error rates show the extraction of structural information.",
        "sentence_llm_dp_info": "Entity 1 ('word error rates') is the subject, depending on the verb 'show'. Entity 2 ('structural information') is the object, depending on the verb 'extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'show', which indicates that 'word error rates' demonstrate the 'extraction of structural information'."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "word error rates",
                "Metric"
            ],
            [
                "speech understanding",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word error rates') is the subject, depending on the verb 'show'. Entity 2 ('speech understanding') is part of a prepositional phrase, depending on 'useful' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the outcomes of the experiments.",
        "sdp_path_text": "rates → show → extracting → information → useful → for → understanding",
        "sentence": "Word error rates show information useful for speech understanding.",
        "sentence_llm_dp_info": "Entity 1 ('word error rates') is the subject, depending on the verb 'show'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'for' in the phrase 'for speech understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "n-gram language model",
                "Method"
            ],
            [
                "structural information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('n-gram language model') is the object of the preposition 'with', depending on 'competitive'. Entity 2 ('structural information') is the object of the verb 'extracting', depending on 'extracting'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "model → with → competitive → rates → show → extracting → information",
        "sentence": "Experiments show competitive word error rates with the n-gram language model while extracting structural information.",
        "sentence_llm_dp_info": "Entity 1 ('n-gram language model') is the object of the preposition 'with', depending on 'show' in the clause 'show competitive word error rates with the n-gram language model'. Entity 2 ('structural information') is the object of the verb 'extracting', depending on 'while' in the phrase 'while extracting structural information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing different aspects of the experiments."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "n-gram language model",
                "Method"
            ],
            [
                "speech understanding",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('n-gram language model') is the object of the preposition 'with', depending on 'competitive'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the outcomes of the experiments.",
        "sdp_path_text": "model → with → competitive → rates → show → extracting → information → useful → for → understanding",
        "sentence": "Experiments show competitive word error rates with the n-gram language model while extracting information useful for speech understanding.",
        "sentence_llm_dp_info": "Entity 1 ('n-gram language model') is the object of the preposition 'with', depending on 'with' in the phrase 'with the n-gram language model'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'for' in the phrase 'useful for speech understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence, where the 'n-gram language model' is compared in terms of performance, and 'speech understanding' is mentioned as a domain where the extracted information is useful."
    },
    {
        "raw_sentence": "Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .",
        "ner_pair": [
            [
                "structural information",
                "OtherScientificTerm"
            ],
            [
                "speech understanding",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('structural information') is the object of the verb 'extracting', depending on 'extracting' in the phrase 'while extracting additional structural information'. Entity 2 ('speech understanding') is the object of the adjective 'useful', depending on 'useful' in the phrase 'useful for speech understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the modifier 'useful' which describes the utility of Entity 1 for Entity 2.",
        "sdp_path_text": "information → useful → for → understanding",
        "sentence": "Structural information useful for speech understanding is extracted.",
        "sentence_llm_dp_info": "Entity 1 ('structural information') is the subject, depending on the verb 'extracted'. Entity 2 ('speech understanding') is the object of the preposition 'for', depending on 'useful' in the phrase 'useful for speech understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the adjective 'useful' and the preposition 'for'."
    },
    {
        "raw_sentence": "Image composition -LRB- or mosaicing -RRB- has attracted a growing attention in recent years as one of the main elements in video analysis and representation .",
        "ner_pair": [
            [
                "Image composition -LRB- or mosaicing -RRB-",
                "Task"
            ],
            [
                "video analysis and representation",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Image composition -LRB- or mosaicing -RRB-') is the subject, depending on the verb 'attracted'. Entity 2 ('video analysis and representation') is the object of the preposition 'in', depending on 'in' in the phrase 'in video analysis and representation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.",
        "sdp_path_text": "composition → attracted → as → one → of → elements → in → analysis",
        "sentence": "Image composition has attracted attention as an element in video analysis and representation.",
        "sentence_llm_dp_info": "Entity 1 ('Image composition -LRB- or mosaicing -RRB-') is the subject, depending on the verb 'attracted'. Entity 2 ('video analysis and representation') is the object of the preposition 'in', depending on 'in' in the phrase 'in video analysis and representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that describes the context in which Entity 1 has attracted attention."
    },
    {
        "raw_sentence": "In this paper we deal with the problem of global alignment and super-resolution .",
        "ner_pair": [
            [
                "global alignment",
                "Task"
            ],
            [
                "super-resolution",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('global alignment') is part of the compound object of the preposition 'with', depending on 'problem'. Entity 2 ('super-resolution') is also part of the compound object of the preposition 'with', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are both directly connected to 'problem' through the preposition 'with'.",
        "sdp_path_text": "alignment → super",
        "sentence": "The paper deals with the problem of global alignment and super-resolution.",
        "sentence_llm_dp_info": "Entity 1 ('global alignment') is part of the compound object, depending on 'with' in the phrase 'with the problem of global alignment'. Entity 2 ('super-resolution') is also part of the compound object, depending on 'and' which connects it to 'global alignment'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same compound object in the sentence."
    },
    {
        "raw_sentence": "We also propose to evaluate the quality of the resulting mosaic by measuring the amount of blurring .",
        "ner_pair": [
            [
                "amount of blurring",
                "Metric"
            ],
            [
                "mosaic",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('amount of blurring') is the object, depending on 'measuring' with 'by measuring the amount of blurring'. Entity 2 ('mosaic') is the object of the preposition 'of', depending on 'resulting' in the phrase 'the resulting mosaic'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the evaluation process.",
        "sdp_path_text": "amount → measuring → by → evaluate → quality → of → mosaic",
        "sentence": "The amount of blurring is measured to evaluate the quality of the mosaic.",
        "sentence_llm_dp_info": "Entity 1 ('amount of blurring') is the subject, depending on the verb 'is measured'. Entity 2 ('mosaic') is the object of the preposition 'of', depending on 'quality' in the phrase 'the quality of the mosaic'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'measured' and the purpose clause 'to evaluate the quality of the mosaic'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "graph-based technique",
                "Method"
            ],
            [
                "Global registration",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graph-based technique') is part of the means, depending on the verb 'combining' which is used to describe how 'Global registration' is achieved. Entity 2 ('Global registration') is the subject, depending on the verb 'is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described by the verb 'combining'.",
        "sdp_path_text": "technique → combining → by → achieved → registration",
        "sentence": "Global registration is achieved by combining a graph-based technique.",
        "sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the object, depending on the verb 'combining'. Entity 2 ('Global registration') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combining' which describes how Entity 2 is achieved."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "Global registration",
                "Task"
            ],
            [
                "topological structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Global registration') is the subject, depending on the verb 'is achieved'. Entity 2 ('topological structure') is part of a relative clause modifying 'technique', depending on 'exploits' with 'that'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the description of the technique used to achieve the goal of global registration.",
        "sdp_path_text": "registration → achieved → by → combining → technique → exploits → structure",
        "sentence": "Global registration is achieved by combining a technique that exploits the topological structure.",
        "sentence_llm_dp_info": "Entity 1 ('Global registration') is the subject, depending on the verb 'achieved'. Entity 2 ('topological structure') is the object of the relative clause, depending on 'exploits' in the phrase 'that exploits the topological structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the prepositional phrase 'by combining a technique'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "Global registration",
                "Task"
            ],
            [
                "spatial overlap",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Global registration') is the subject, depending on the verb 'is achieved'. Entity 2 ('spatial overlap') is part of a relative clause, modifying 'structure', and is the object of the preposition 'by' in the phrase 'induced by the spatial overlap'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence of relationships involving 'combining', 'graph-based technique', 'topological structure', and 'induced by'.",
        "sdp_path_text": "registration → achieved → by → combining → technique → exploits → structure → of → sequence → induced → by → overlap",
        "sentence": "Global registration is achieved by combining a technique that exploits the structure of the sequence induced by spatial overlap.",
        "sentence_llm_dp_info": "Entity 1 ('Global registration') is the subject, depending on the verb 'achieved'. Entity 2 ('spatial overlap') is part of a prepositional phrase, depending on 'induced' with 'by'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the prepositional phrase describing how the achievement is accomplished."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "bundle adjustment",
                "Method"
            ],
            [
                "Global registration",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('bundle adjustment') is the object of the preposition 'with', depending on 'combining'. Entity 2 ('Global registration') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Global registration' is achieved through the combination that includes 'bundle adjustment'.",
        "sdp_path_text": "adjustment → with → combining → by → achieved → registration",
        "sentence": "Global registration is achieved by combining techniques with bundle adjustment.",
        "sentence_llm_dp_info": "Entity 1 ('bundle adjustment') is the object of the preposition 'with', depending on 'combining'. Entity 2 ('Global registration') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'achieved' and the prepositional phrase 'with bundle adjustment'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "Global registration",
                "Task"
            ],
            [
                "homographies",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Global registration') is the subject, depending on the verb 'achieved'. Entity 2 ('homographies') is the object, depending on 'uses' with 'bundle adjustment'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described in the sentence where 'Global registration' is achieved using techniques that include the use of 'homographies'.",
        "sdp_path_text": "registration → achieved → by → combining → with → adjustment → uses → homographies",
        "sentence": "Global registration is achieved by combining techniques with an adjustment that uses homographies.",
        "sentence_llm_dp_info": "Entity 1 ('Global registration') is the subject, depending on the verb 'achieved'. Entity 2 ('homographies') is the object, depending on 'uses' within the clause 'that uses homographies'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'uses' and the clause 'that uses homographies'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "graph-based technique",
                "Method"
            ],
            [
                "topological structure",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the object of the preposition 'by', depending on 'combining'. Entity 2 ('topological structure') is the object of the relative clause 'that exploits the topological structure', depending on 'exploits'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'exploits' within the relative clause modifying 'graph-based technique'.",
        "sdp_path_text": "technique → exploits → structure",
        "sentence": "A graph-based technique exploits the topological structure.",
        "sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the subject, depending on the verb 'exploits'. Entity 2 ('topological structure') is the object, depending on 'exploits' with 'graph-based technique'. There is a direct dependency between Entity 1 and Entity 2, as 'topological structure' is directly exploited by the 'graph-based technique'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "graph-based technique",
                "Method"
            ],
            [
                "spatial overlap",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the object of the preposition 'by', depending on 'combining' in the phrase 'combining a graph-based technique'. Entity 2 ('spatial overlap') is the object of the preposition 'by', depending on 'induced' in the phrase 'induced by the spatial overlap'. There is no direct dependency between Entity 1 and Entity 2, but both are part of a larger clause describing how global registration is achieved.",
        "sdp_path_text": "technique → exploits → structure → of → sequence → induced → by → overlap",
        "sentence": "The graph-based technique exploits the structure of the sequence induced by the spatial overlap.",
        "sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the subject, depending on the verb 'exploits'. Entity 2 ('spatial overlap') is the object, depending on the preposition 'by' in the phrase 'by the spatial overlap'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploits' and the prepositional phrase 'by the spatial overlap'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "graph-based technique",
                "Method"
            ],
            [
                "bundle adjustment",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graph-based technique') is part of the means, depending on 'combining' with 'achieved'. Entity 2 ('bundle adjustment') is also part of the means, depending on 'combining' with 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of the method used to achieve 'Global registration'.",
        "sdp_path_text": "technique → combining → with → adjustment",
        "sentence": "Global registration combines a graph-based technique with bundle adjustment.",
        "sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the object of the preposition 'with', depending on 'combines' in the phrase 'combines with'. Entity 2 ('bundle adjustment') is also the object of the preposition 'with', depending on 'combines' in the same phrase. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'with' in the context of the verb 'combines'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "graph-based technique",
                "Method"
            ],
            [
                "homographies",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graph-based technique') is part of the compound object of the verb 'combining', depending on 'combining' with the conjunction 'with'. Entity 2 ('homographies') is the object of the relative clause, depending on 'uses' in the phrase 'which uses only the homographies'. There is no direct dependency between Entity 1 and Entity 2; both are connected through their roles in the overall structure of the sentence, where 'graph-based technique' is one component being combined, and 'homographies' are used in another component (bundle adjustment).",
        "sdp_path_text": "technique → combining → with → adjustment → uses → homographies",
        "sentence": "A graph-based technique is combined with an adjustment that uses homographies.",
        "sentence_llm_dp_info": "Entity 1 ('graph-based technique') is the subject, depending on the verb 'combined'. Entity 2 ('homographies') is the object of the relative clause, depending on 'uses' within the phrase 'that uses homographies'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'combined' and the relative clause 'that uses homographies'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "topological structure",
                "OtherScientificTerm"
            ],
            [
                "spatial overlap",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('topological structure') is the object of the relative clause, depending on 'exploits' with 'that exploits the topological structure'. Entity 2 ('spatial overlap') is the object of the preposition 'by', depending on 'induced' in the phrase 'induced by the spatial overlap'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same relative clause describing what is exploited by the graph-based technique.",
        "sdp_path_text": "structure → of → sequence → induced → by → overlap",
        "sentence": "The topological structure of the sequence is induced by the spatial overlap.",
        "sentence_llm_dp_info": "Entity 1 ('topological structure') is the subject, depending on the passive verb 'is induced'. Entity 2 ('spatial overlap') is the agent of the passive construction, depending on 'by' in the phrase 'by the spatial overlap'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive verb 'is induced' and the preposition 'by'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "topological structure",
                "OtherScientificTerm"
            ],
            [
                "bundle adjustment",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('topological structure') is the object of the relative clause 'that exploits the topological structure of the sequence induced by the spatial overlap', depending on 'exploits'. Entity 2 ('bundle adjustment') is the object of the preposition 'with', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described in the sentence.",
        "sdp_path_text": "structure → exploits → technique → combining → with → adjustment",
        "sentence": "The topological structure is exploited in a technique combined with bundle adjustment.",
        "sentence_llm_dp_info": "Entity 1 ('topological structure') is the subject, depending on the verb 'exploited'. Entity 2 ('bundle adjustment') is part of a prepositional phrase, depending on 'combined' in the phrase 'combined with bundle adjustment'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploited' and the prepositional phrase 'combined with'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "topological structure",
                "OtherScientificTerm"
            ],
            [
                "homographies",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('topological structure') is the object of the relative clause 'that exploits the topological structure of the sequence induced by the spatial overlap', depending on 'exploits'. Entity 2 ('homographies') is the object of the relative clause 'which uses only the homographies computed in the previous steps', depending on 'uses'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses within the same sentence.",
        "sdp_path_text": "structure → exploits → technique → combining → with → adjustment → uses → homographies",
        "sentence": "The topological structure is exploited by a technique combined with an adjustment that uses homographies.",
        "sentence_llm_dp_info": "Entity 1 ('topological structure') is the subject, depending on the verb 'exploited'. Entity 2 ('homographies') is the object, depending on the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions described in the sentence, where the exploitation of the 'topological structure' involves a technique that uses 'homographies'."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "spatial overlap",
                "OtherScientificTerm"
            ],
            [
                "bundle adjustment",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial overlap') is part of a relative clause modifying 'sequence', depending on 'induced' with 'by the spatial overlap'. Entity 2 ('bundle adjustment') is the object of the preposition 'with', depending on 'combining' in the phrase 'with a bundle adjustment'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described in the sentence.",
        "sdp_path_text": "overlap → by → induced → sequence → of → structure → exploits → technique → combining → with → adjustment",
        "sentence": "Global registration combines a technique that exploits the spatial overlap with bundle adjustment.",
        "sentence_llm_dp_info": "Entity 1 ('spatial overlap') is the object of the verb 'exploits', depending on 'technique'. Entity 2 ('bundle adjustment') is the object of the verb 'combines', depending on 'registration'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described by the sentence."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "spatial overlap",
                "OtherScientificTerm"
            ],
            [
                "homographies",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatial overlap') is part of a relative clause modifying 'sequence', where it serves as the subject complement of 'induced'. Entity 2 ('homographies') is the object of the verb 'uses', depending on 'bundle adjustment'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the broader context of the sentence, describing different aspects of the method used for global registration.",
        "sdp_path_text": "overlap → by → induced → sequence → of → structure → exploits → technique → combining → with → adjustment → uses → homographies",
        "sentence": "A graph-based technique that exploits the spatial overlap is combined with an adjustment that uses homographies.",
        "sentence_llm_dp_info": "Entity 1 ('spatial overlap') is the object of the relative clause, depending on 'exploits' with 'technique'. Entity 2 ('homographies') is the object of the relative clause, depending on 'uses' with 'adjustment'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence's structure, contributing to the description of the techniques being combined."
    },
    {
        "raw_sentence": "Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps .",
        "ner_pair": [
            [
                "homographies",
                "OtherScientificTerm"
            ],
            [
                "bundle adjustment",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('homographies') is the object of the relative clause, depending on 'computed' with 'in the previous steps'. Entity 2 ('bundle adjustment') is the object of the preposition 'with', depending on 'combining' in the phrase 'with a bundle adjustment'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described in the sentence.",
        "sdp_path_text": "homographies → uses → adjustment",
        "sentence": "Bundle adjustment uses homographies.",
        "sentence_llm_dp_info": "Entity 1 ('homographies') is the object, depending on the verb 'uses'. Entity 2 ('bundle adjustment') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'bundle adjustment' uses 'homographies'."
    },
    {
        "raw_sentence": "Experimental comparison with other techniques shows the effectiveness of our approach .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "techniques",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the object of the preposition 'of', depending on 'shows' in the phrase 'shows the effectiveness of our approach'. Entity 2 ('techniques') is the object of the preposition 'with', depending on 'comparison' in the phrase 'comparison with other techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the experimental comparison and its outcome.",
        "sdp_path_text": "approach → of → effectiveness → shows → comparison → with → techniques",
        "sentence": "Comparison with techniques shows the effectiveness of our approach.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the object of the preposition 'of', depending on 'effectiveness'. Entity 2 ('techniques') is the object of the preposition 'with', depending on 'Comparison'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "The main of this project is computer-assisted acquisition and morpho-syntactic description of verb-noun collocations in Polish .",
        "ner_pair": [
            [
                "Polish",
                "Material"
            ],
            [
                "computer-assisted acquisition and morpho-syntactic description of verb-noun collocations",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Polish') is the object of the preposition 'of', depending on 'collocations'. Entity 2 ('computer-assisted acquisition and morpho-syntactic description of verb-noun collocations') is the complement of the verb 'is', depending on 'main'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where Entity 2 describes the main goal, which involves Entity 1 as part of its scope.",
        "sdp_path_text": "Polish → in → collocations → of → description → acquisition",
        "sentence": "Polish involves computer-assisted acquisition and morpho-syntactic description of verb-noun collocations.",
        "sentence_llm_dp_info": "Entity 1 ('Polish') is the subject, depending on the verb 'involves'. Entity 2 ('computer-assisted acquisition and morpho-syntactic description of verb-noun collocations') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly involved or affected by the action described by the verb 'involves' from Entity 1."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "dictionary-based acquisition of collocation lexicon",
                "Task"
            ],
            [
                "phases",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is part of a list, depending on the verb 'are' which follows the colon, indicating items that belong to 'phases'. Entity 2 ('phases') is the object of the relative clause 'which are', depending on the verb 'obtained'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually linked as Entity 1 is one of the items listed under Entity 2.",
        "sdp_path_text": "acquisition → are → phases",
        "sentence": "Dictionary-based acquisition of collocation lexicon is one of the phases.",
        "sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is the subject, depending on the verb 'is'. Entity 2 ('phases') is part of the noun phrase 'one of the phases', which is the predicate nominative, depending on 'one'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the copular verb 'is' and the prepositional phrase 'one of the phases'."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "feasibility study",
                "Task"
            ],
            [
                "phases",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('feasibility study') is part of the object list, depending on 'phases' through the conjunction 'and'. Entity 2 ('phases') is the object of the relative clause, depending on 'which' in the phrase 'which are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the list structure of the object described after 'which are'.",
        "sdp_path_text": "study → acquisition → are → phases",
        "sentence": "Feasibility study is one of the phases of the project.",
        "sentence_llm_dp_info": "Entity 1 ('feasibility study') is the subject, depending on the verb 'is'. Entity 2 ('phases') is part of the noun phrase that serves as the complement of the preposition 'of', depending on 'of' in the phrase 'of the project'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional structure indicating that the 'feasibility study' is a phase within the larger context of 'the project'."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "phases",
                "Generic"
            ],
            [
                "corpus-based lexicon enlargement phase",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phases') is the object of the preposition 'in', depending on 'obtained'. Entity 2 ('corpus-based lexicon enlargement phase') is part of a list, depending on 'which' that introduces the list of phases. There is no direct dependency between Entity 1 and Entity 2; however, Entity 2 is one of the items listed under Entity 1.",
        "sdp_path_text": "phases → are → acquisition → study → for → phase",
        "sentence": "Phases include a study for the corpus-based lexicon enlargement phase.",
        "sentence_llm_dp_info": "Entity 1 ('phases') is the subject, depending on the verb 'include'. Entity 2 ('corpus-based lexicon enlargement phase') is the object of the preposition 'for', depending on 'study'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for the corpus-based lexicon enlargement phase'."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "corpus-based lexicon enlargement and collocation description",
                "Task"
            ],
            [
                "phases",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus-based lexicon enlargement and collocation description') is part of the list, depending on the verb 'are' which connects it to 'phases'. Entity 2 ('phases') is the subject complement, depending on the verb 'are' in the clause 'which are: ...'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are' and the structure of the list.",
        "sdp_path_text": "enlargement → acquisition → are → phases",
        "sentence": "Corpus-based lexicon enlargement and collocation description are phases of the project.",
        "sentence_llm_dp_info": "Entity 1 ('corpus-based lexicon enlargement and collocation description') is the subject, depending on the verb 'are'. Entity 2 ('phases') is the predicate nominative, depending on the verb 'are' and linked to Entity 1. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 describes what Entity 1 is."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "dictionary-based acquisition of collocation lexicon",
                "Task"
            ],
            [
                "feasibility study",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is the object of the preposition 'which', depending on 'phases'. Entity 2 ('feasibility study') is also an object of the preposition 'which', depending on 'phases'. There is no direct dependency between Entity 1 and Entity 2; both are listed as part of the same list of items described by the preposition 'which'.",
        "sdp_path_text": "acquisition → study",
        "sentence": "Dictionary-based acquisition of collocation lexicon involves a feasibility study.",
        "sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is the subject, depending on the verb 'involves'. Entity 2 ('feasibility study') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 involves Entity 2."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "dictionary-based acquisition of collocation lexicon",
                "Task"
            ],
            [
                "corpus-based lexicon enlargement phase",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is part of a list of items, depending on 'which' in the phrase 'which are'. Entity 2 ('corpus-based lexicon enlargement phase') is also part of the same list, depending on 'which' in the phrase 'which are'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list described by 'which are'.",
        "sdp_path_text": "acquisition → study → for → phase",
        "sentence": "Dictionary-based acquisition of collocation lexicon includes a feasibility study for corpus-based lexicon enlargement phase.",
        "sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is the subject, depending on the verb 'includes'. Entity 2 ('corpus-based lexicon enlargement phase') is the object, depending on 'includes' with 'dictionary-based acquisition of collocation lexicon'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is included as part of the process described by Entity 1."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "dictionary-based acquisition of collocation lexicon",
                "Task"
            ],
            [
                "corpus-based lexicon enlargement and collocation description",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is a list item, depending on the conjunction 'and' that connects it to other items in the list, which is part of the object of the preposition 'which'. Entity 2 ('corpus-based lexicon enlargement and collocation description') is also a list item, depending on the conjunction 'and' that connects it to other items in the list, which is part of the object of the preposition 'which'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger list described by the sentence.",
        "sdp_path_text": "acquisition → enlargement",
        "sentence": "Dictionary-based acquisition of collocation lexicon and corpus-based lexicon enlargement and collocation description are connected through the process of acquisition leading to enlargement.",
        "sentence_llm_dp_info": "Entity 1 ('dictionary-based acquisition of collocation lexicon') is part of the subject, depending on the verb 'are' and modified by the prepositional phrase 'through the process of acquisition'. Entity 2 ('corpus-based lexicon enlargement and collocation description') is also part of the subject, depending on the verb 'are' and is coordinated with Entity 1. There is no direct dependency between Entity 1 and Entity 2, but they are both parts of a larger coordinated subject that describes what is connected through the process of acquisition."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "feasibility study",
                "Task"
            ],
            [
                "corpus-based lexicon enlargement phase",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('feasibility study') is part of the list item, depending on the conjunction 'and' with 'dictionary-based acquisition of collocation lexicon'. Entity 2 ('corpus-based lexicon enlargement phase') is also part of the list item, depending on the conjunction 'and' with 'feasibility study'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list connected by the conjunction 'and'.",
        "sdp_path_text": "study → for → phase",
        "sentence": "Feasibility study for corpus-based lexicon enlargement phase.",
        "sentence_llm_dp_info": "Entity 1 ('feasibility study') is the subject, depending on the preposition 'for'. Entity 2 ('corpus-based lexicon enlargement phase') is the object of the preposition 'for', depending on 'for' in the phrase 'for corpus-based lexicon enlargement phase'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "corpus-based lexicon enlargement and collocation description",
                "Task"
            ],
            [
                "feasibility study",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus-based lexicon enlargement and collocation description') is part of the list, depending on 'which' with 'phases'. Entity 2 ('feasibility study') is also part of the list, depending on 'which' with 'phases'. There is no direct dependency between Entity 1 and Entity 2; both are listed items under the same parent node 'phases'.",
        "sdp_path_text": "enlargement → acquisition → study",
        "sentence": "A feasibility study was conducted for corpus-based lexicon enlargement and collocation description.",
        "sentence_llm_dp_info": "Entity 1 ('corpus-based lexicon enlargement and collocation description') is the object of the preposition 'for', depending on 'for' in the phrase 'for corpus-based lexicon enlargement and collocation description'. Entity 2 ('feasibility study') is the subject, depending on the passive verb 'was conducted'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We present methodology and resources obtained in three main project phases which are : dictionary-based acquisition of collocation lexicon , feasibility study for corpus-based lexicon enlargement phase , corpus-based lexicon enlargement and collocation description .",
        "ner_pair": [
            [
                "corpus-based lexicon enlargement phase",
                "Task"
            ],
            [
                "corpus-based lexicon enlargement and collocation description",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus-based lexicon enlargement phase') is part of a list, depending on the conjunction 'and' that connects it with 'dictionary-based acquisition of collocation lexicon' and 'feasibility study for corpus-based lexicon enlargement phase'. Entity 2 ('corpus-based lexicon enlargement and collocation description') is also part of the same list, directly connected through the conjunction 'and' to 'corpus-based lexicon enlargement phase'. There is a direct dependency between Entity 1 and Entity 2, as they are both elements in a list connected by the conjunction 'and'.",
        "sdp_path_text": "phase → for → study → acquisition → enlargement",
        "sentence": "The corpus-based lexicon enlargement phase includes corpus-based lexicon enlargement and collocation description.",
        "sentence_llm_dp_info": "Entity 1 ('corpus-based lexicon enlargement phase') is the subject, depending on the verb 'includes'. Entity 2 ('corpus-based lexicon enlargement and collocation description') is the object, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is included in or part of Entity 1."
    },
    {
        "raw_sentence": "The presented here corpus-based approach permitted us to triple the size the verb-noun collocation dictionary for Polish .",
        "ner_pair": [
            [
                "corpus-based approach",
                "Method"
            ],
            [
                "verb-noun collocation dictionary",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus-based approach') is the subject, depending on the verb 'permitted'. Entity 2 ('verb-noun collocation dictionary') is the object of the verb 'triple', depending on 'size'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by the verb 'permitted' and the action of tripling the size of the dictionary.",
        "sdp_path_text": "approach → permitted → triple → size → dictionary",
        "sentence": "The corpus-based approach permitted tripling the size of the verb-noun collocation dictionary.",
        "sentence_llm_dp_info": "Entity 1 ('corpus-based approach') is the subject, depending on the verb 'permitted'. Entity 2 ('verb-noun collocation dictionary') is the object, depending on the verb 'tripling'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'permitted' which affects the process of 'tripling the size of' Entity 2."
    },
    {
        "raw_sentence": "The presented here corpus-based approach permitted us to triple the size the verb-noun collocation dictionary for Polish .",
        "ner_pair": [
            [
                "corpus-based approach",
                "Method"
            ],
            [
                "Polish",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus-based approach') is the subject, depending on the verb 'permitted'. Entity 2 ('Polish') is the object of the preposition 'for', depending on 'for' in the phrase 'for Polish'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'permitted' and the prepositional phrase 'for Polish'.",
        "sdp_path_text": "approach → permitted → triple → size → dictionary → for → Polish",
        "sentence": "The corpus-based approach permitted tripling the size of the verb-noun collocation dictionary for Polish.",
        "sentence_llm_dp_info": "Entity 1 ('corpus-based approach') is the subject, depending on the verb 'permitted'. Entity 2 ('Polish') is the object of the preposition 'for', depending on 'for' in the phrase 'for Polish'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'permitted' and the prepositional phrase 'for Polish'."
    },
    {
        "raw_sentence": "The presented here corpus-based approach permitted us to triple the size the verb-noun collocation dictionary for Polish .",
        "ner_pair": [
            [
                "Polish",
                "Material"
            ],
            [
                "verb-noun collocation dictionary",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Polish') is the object of the preposition 'for', depending on 'dictionary'. Entity 2 ('verb-noun collocation dictionary') is the object, depending on the verb 'triple'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for Polish'.",
        "sdp_path_text": "Polish → for → dictionary",
        "sentence": "The approach permitted tripling the size of the verb-noun collocation dictionary for Polish.",
        "sentence_llm_dp_info": "Entity 1 ('Polish') is the object of the preposition 'for', depending on 'for' in the phrase 'for Polish'. Entity 2 ('verb-noun collocation dictionary') is the object, depending on 'tripling' with 'the size of the verb-noun collocation dictionary'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for Polish'."
    },
    {
        "raw_sentence": "Along with the increasing requirements , the hash-tag recommendation task for microblogs has been receiving considerable attention in recent years .",
        "ner_pair": [
            [
                "hash-tag recommendation task",
                "Task"
            ],
            [
                "microblogs",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('hash-tag recommendation task') is the subject, depending on the verb 'has been receiving'. Entity 2 ('microblogs') is the object of the preposition 'for', depending on 'for' in the phrase 'for microblogs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "task → for → microblogs",
        "sentence": "The hash-tag recommendation task is for microblogs.",
        "sentence_llm_dp_info": "Entity 1 ('hash-tag recommendation task') is the subject, depending on the copula 'is'. Entity 2 ('microblogs') is the object of the preposition 'for', depending on 'for' in the phrase 'for microblogs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Motivated by the successful use of convolutional neural networks -LRB- CNNs -RRB- for many natural language processing tasks , in this paper , we adopt CNNs to perform the hashtag recommendation problem .",
        "ner_pair": [
            [
                "convolutional neural networks -LRB- CNNs -RRB-",
                "Method"
            ],
            [
                "natural language processing tasks",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('convolutional neural networks -LRB- CNNs -RRB-') is the object of the preposition 'of', depending on 'use'. Entity 2 ('natural language processing tasks') is the object of the preposition 'for', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase describing the context of the successful use mentioned in the sentence.",
        "sdp_path_text": "networks → of → use → for → tasks",
        "sentence": "Convolutional neural networks are used for natural language processing tasks.",
        "sentence_llm_dp_info": "Entity 1 ('convolutional neural networks -LRB- CNNs -RRB-') is the subject, depending on the verb 'are used'. Entity 2 ('natural language processing tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for natural language processing tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Motivated by the successful use of convolutional neural networks -LRB- CNNs -RRB- for many natural language processing tasks , in this paper , we adopt CNNs to perform the hashtag recommendation problem .",
        "ner_pair": [
            [
                "convolutional neural networks -LRB- CNNs -RRB-",
                "Method"
            ],
            [
                "hashtag recommendation problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('convolutional neural networks -LRB- CNNs -RRB-') is the object of the preposition 'of', depending on 'use'. Entity 2 ('hashtag recommendation problem') is the object of the infinitive 'to perform', depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the larger context where CNNs are adopted to address the hashtag recommendation problem.",
        "sdp_path_text": "networks → of → use → by → Motivated → adopt → perform → problem",
        "sentence": "CNNs are adopted to perform the hashtag recommendation problem.",
        "sentence_llm_dp_info": "Entity 1 ('convolutional neural networks (CNNs)') is the subject, depending on the verb 'adopted'. Entity 2 ('hashtag recommendation problem') is the object of the verb 'perform', depending on 'perform' in the phrase 'to perform the hashtag recommendation problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'adopted' and 'perform'."
    },
    {
        "raw_sentence": "Motivated by the successful use of convolutional neural networks -LRB- CNNs -RRB- for many natural language processing tasks , in this paper , we adopt CNNs to perform the hashtag recommendation problem .",
        "ner_pair": [
            [
                "natural language processing tasks",
                "Task"
            ],
            [
                "CNNs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('natural language processing tasks') is the object of the preposition 'for', depending on 'use'. Entity 2 ('CNNs') is the object of the preposition 'of', part of the compound noun 'convolutional neural networks (CNNs)', and also serves as the subject complement to the verb 'adopt'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where CNNs are used for the tasks mentioned.",
        "sdp_path_text": "tasks → for → use → of → networks → CNNs",
        "sentence": "CNNs are used for natural language processing tasks.",
        "sentence_llm_dp_info": "Entity 1 ('natural language processing tasks') is the object, depending on 'used' with 'CNNs'. Entity 2 ('CNNs') is the subject, depending on the verb 'are used'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the object of the verb 'used' that Entity 2 (CNNs) performs."
    },
    {
        "raw_sentence": "Motivated by the successful use of convolutional neural networks -LRB- CNNs -RRB- for many natural language processing tasks , in this paper , we adopt CNNs to perform the hashtag recommendation problem .",
        "ner_pair": [
            [
                "natural language processing tasks",
                "Task"
            ],
            [
                "hashtag recommendation problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('natural language processing tasks') is the object of the preposition 'for', depending on 'use' within the phrase 'the successful use of...for many natural language processing tasks'. Entity 2 ('hashtag recommendation problem') is the object of the verb 'perform', depending on 'perform' in the clause 'we adopt CNNs to perform the hashtag recommendation problem'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence structure involving the use and application of CNNs.",
        "sdp_path_text": "tasks → for → use → by → Motivated → adopt → perform → problem",
        "sentence": "Motivated by the use of CNNs for natural language processing tasks, we adopt CNNs to perform the hashtag recommendation problem.",
        "sentence_llm_dp_info": "Entity 1 ('natural language processing tasks') is the object of the preposition 'for', depending on 'use'. Entity 2 ('hashtag recommendation problem') is the object of the verb 'perform', depending on 'perform' in the phrase 'to perform the hashtag recommendation problem'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the use and adoption of CNNs in different contexts within the sentence."
    },
    {
        "raw_sentence": "Motivated by the successful use of convolutional neural networks -LRB- CNNs -RRB- for many natural language processing tasks , in this paper , we adopt CNNs to perform the hashtag recommendation problem .",
        "ner_pair": [
            [
                "CNNs",
                "Method"
            ],
            [
                "hashtag recommendation problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('CNNs') is the object of the preposition 'of', depending on 'use' in the phrase 'use of CNNs'. It also appears later in the sentence as the object of the verb 'adopt'. Entity 2 ('hashtag recommendation problem') is the object of the infinitive 'to perform', depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'adopt' which indicates that CNNs are used to perform the hashtag recommendation problem.",
        "sdp_path_text": "CNNs → networks → of → use → by → Motivated → adopt → perform → problem",
        "sentence": "CNNs are adopted to perform the hashtag recommendation problem.",
        "sentence_llm_dp_info": "Entity 1 ('CNNs') is the subject, depending on the verb 'adopted'. Entity 2 ('hashtag recommendation problem') is the object of the verb 'perform', depending on 'perform' in the phrase 'to perform the hashtag recommendation problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'adopted' and 'perform'."
    },
    {
        "raw_sentence": "To incorporate the trigger words whose effectiveness have been experimentally evaluated in several previous works , we propose a novel architecture with an attention mechanism .",
        "ner_pair": [
            [
                "architecture",
                "Generic"
            ],
            [
                "trigger words",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('architecture') is the object, depending on 'propose' with 'we'. Entity 2 ('trigger words') is part of a relative clause, depending on 'incorporate' with 'To incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main action of proposing a novel architecture that incorporates the trigger words.",
        "sdp_path_text": "architecture → propose → incorporate → words",
        "sentence": "We propose a novel architecture to incorporate trigger words.",
        "sentence_llm_dp_info": "Entity 1 ('architecture') is the object of the verb 'propose', depending on 'propose' in the clause 'We propose a novel architecture'. Entity 2 ('trigger words') is the object of the preposition 'to incorporate', depending on 'incorporate' in the phrase 'to incorporate trigger words'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the purpose clause 'to incorporate trigger words' which modifies 'architecture'."
    },
    {
        "raw_sentence": "To incorporate the trigger words whose effectiveness have been experimentally evaluated in several previous works , we propose a novel architecture with an attention mechanism .",
        "ner_pair": [
            [
                "trigger words",
                "OtherScientificTerm"
            ],
            [
                "attention mechanism",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('trigger words') is the object of the relative clause, depending on 'incorporate' with 'To incorporate'. Entity 2 ('attention mechanism') is the object of the preposition 'with', depending on 'architecture'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure describing the proposal of a novel architecture.",
        "sdp_path_text": "words → incorporate → propose → architecture → with → mechanism",
        "sentence": "We propose an architecture with an attention mechanism to incorporate trigger words.",
        "sentence_llm_dp_info": "Entity 1 ('trigger words') is the object, depending on the verb 'incorporate'. Entity 2 ('attention mechanism') is part of a prepositional phrase, depending on 'with' in the phrase 'with an attention mechanism'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate' which is part of the purpose clause 'to incorporate trigger words'."
    },
    {
        "raw_sentence": "To incorporate the trigger words whose effectiveness have been experimentally evaluated in several previous works , we propose a novel architecture with an attention mechanism .",
        "ner_pair": [
            [
                "attention mechanism",
                "OtherScientificTerm"
            ],
            [
                "architecture",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('attention mechanism') is the object of the preposition 'with', depending on 'architecture'. Entity 2 ('architecture') is the direct object, depending on the verb 'propose' with 'we'. There is a direct dependency between Entity 1 and Entity 2, as 'attention mechanism' is part of the 'architecture' described in the sentence.",
        "sdp_path_text": "mechanism → with → architecture",
        "sentence": "We propose a novel architecture with an attention mechanism.",
        "sentence_llm_dp_info": "Entity 1 ('attention mechanism') is the object of the preposition 'with', depending on 'architecture'. Entity 2 ('architecture') is the direct object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The results of experiments on the data collected from a real world microblogging service demonstrated that the proposed model outperforms state-of-the-art methods .",
        "ner_pair": [
            [
                "data",
                "Generic"
            ],
            [
                "model",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data') is the object of the preposition 'from', depending on 'collected'. Entity 2 ('model') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the demonstration of the experiment's results.",
        "sdp_path_text": "data → on → experiments → of → results → demonstrated → outperforms → model",
        "sentence": "Experiments on the data demonstrated that the model outperforms state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('model') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "The results of experiments on the data collected from a real world microblogging service demonstrated that the proposed model outperforms state-of-the-art methods .",
        "ner_pair": [
            [
                "data",
                "Generic"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data') is the object of the preposition 'from', depending on 'collected'. Entity 2 ('state-of-the-art methods') is the object of the verb 'outperforms', depending on 'outperforms' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the outcomes of the experiments.",
        "sdp_path_text": "data → on → experiments → of → results → demonstrated → outperforms → methods",
        "sentence": "Data from experiments demonstrated that the proposed model outperforms state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('data') is the subject, depending on the verb 'demonstrated'. Entity 2 ('state-of-the-art methods') is the object, depending on 'outperforms' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrated' and the comparative clause 'outperforms state-of-the-art methods'."
    },
    {
        "raw_sentence": "The results of experiments on the data collected from a real world microblogging service demonstrated that the proposed model outperforms state-of-the-art methods .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('model') is the subject of the clause, depending on the verb 'outperforms'. Entity 2 ('state-of-the-art methods') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, where 'model' is the subject performing the action (outperforming) on 'state-of-the-art methods'.",
        "sdp_path_text": "model → outperforms → methods",
        "sentence": "The proposed model outperforms state-of-the-art methods.",
        "sentence_llm_dp_info": "Entity 1 ('model') is the subject, depending on the verb 'outperforms'. Entity 2 ('state-of-the-art methods') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, where 'model' outperforms 'state-of-the-art methods'."
    },
    {
        "raw_sentence": "By incorporating trigger words into the consideration , the relative improvement of the proposed method over the state-of-the-art method is around 9.4 % in the F1-score .",
        "ner_pair": [
            [
                "trigger words",
                "OtherScientificTerm"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('trigger words') is the object of the preposition 'incorporating', depending on 'incorporating' in the phrase 'By incorporating trigger words'. Entity 2 ('method') is the object of the preposition 'over', depending on 'over' in the phrase 'over the state-of-the-art method'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the context of the improvement described in the sentence.",
        "sdp_path_text": "words → incorporating → By → is → improvement → of → method",
        "sentence": "Incorporating trigger words improves the method.",
        "sentence_llm_dp_info": "Entity 1 ('trigger words') is the subject, depending on the verb 'incorporating'. Entity 2 ('method') is the object, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'incorporating' and 'improves'."
    },
    {
        "raw_sentence": "By incorporating trigger words into the consideration , the relative improvement of the proposed method over the state-of-the-art method is around 9.4 % in the F1-score .",
        "ner_pair": [
            [
                "trigger words",
                "OtherScientificTerm"
            ],
            [
                "state-of-the-art method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('trigger words') is the object of the preposition 'into', depending on 'incorporating'. Entity 2 ('state-of-the-art method') is the object of the preposition 'over', depending on 'improvement'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the context of the improvement described in the sentence.",
        "sdp_path_text": "words → incorporating → By → is → improvement → over → method",
        "sentence": "Incorporating trigger words improves performance over the state-of-the-art method.",
        "sentence_llm_dp_info": "Entity 1 ('trigger words') is the object of the verb 'Incorporating', which is the subject of the sentence. Entity 2 ('state-of-the-art method') is the object of the preposition 'over', depending on 'over' in the phrase 'over the state-of-the-art method'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'trigger words' contributes to the improvement described, and 'state-of-the-art method' serves as a point of comparison."
    },
    {
        "raw_sentence": "By incorporating trigger words into the consideration , the relative improvement of the proposed method over the state-of-the-art method is around 9.4 % in the F1-score .",
        "ner_pair": [
            [
                "trigger words",
                "OtherScientificTerm"
            ],
            [
                "F1-score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('trigger words') is the object of the preposition 'incorporating', depending on the verb 'incorporating'. Entity 2 ('F1-score') is the object of the preposition 'in', depending on 'is' in the phrase 'is around 9.4% in the F1-score'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the improvement of the proposed method.",
        "sdp_path_text": "words → incorporating → By → is → % → in → score",
        "sentence": "Incorporating trigger words improves the F1-score.",
        "sentence_llm_dp_info": "Entity 1 ('trigger words') is the subject, depending on the verb 'incorporating'. Entity 2 ('F1-score') is the object, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' which indicates that incorporating Entity 1 has an effect on Entity 2."
    },
    {
        "raw_sentence": "By incorporating trigger words into the consideration , the relative improvement of the proposed method over the state-of-the-art method is around 9.4 % in the F1-score .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "F1-score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is part of a comparative construction, depending on 'improvement' with 'the relative improvement of the proposed method over the state-of-the-art method'. Entity 2 ('F1-score') is the object of the preposition 'in', depending on 'is' in the phrase 'is around 9.4% in the F1-score'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the improvement measurement described in the sentence.",
        "sdp_path_text": "method → of → improvement → is → % → in → score",
        "sentence": "The proposed method shows an improvement in the F1-score.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'shows'. Entity 2 ('F1-score') is the object of the preposition 'in', depending on 'improvement'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'improvement' which is the object shown by the method."
    },
    {
        "raw_sentence": "By incorporating trigger words into the consideration , the relative improvement of the proposed method over the state-of-the-art method is around 9.4 % in the F1-score .",
        "ner_pair": [
            [
                "F1-score",
                "Metric"
            ],
            [
                "state-of-the-art method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('F1-score') is the object of the preposition 'in', depending on 'in' in the phrase 'in the F1-score'. Entity 2 ('state-of-the-art method') is the object of the preposition 'over', depending on 'over' in the phrase 'over the state-of-the-art method'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the improvement of the proposed method.",
        "sdp_path_text": "score → in → % → is → improvement → over → method",
        "sentence": "The improvement in F1-score over the state-of-the-art method is 9.4%.",
        "sentence_llm_dp_info": "Entity 1 ('F1-score') is part of a prepositional phrase, depending on 'in' with 'improvement'. Entity 2 ('state-of-the-art method') is the object of the preposition 'over', depending on 'over' in the phrase 'over the state-of-the-art method'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'improvement' through the prepositions 'in' and 'over'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "Expectation-Maximization -LRB- EM -RRB- algorithm",
                "Method"
            ],
            [
                "unsupervised learning method",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Expectation-Maximization -LRB- EM -RRB- algorithm') is the object of the preposition 'using', depending on 'improve'. Entity 2 ('unsupervised learning method') is the object of the verb 'improve', depending on 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'unsupervised learning method' is being improved using the 'Expectation-Maximization -LRB- EM -RRB- algorithm'.",
        "sdp_path_text": "algorithm → using → method",
        "sentence": "The Expectation-Maximization (EM) algorithm is used to improve an unsupervised learning method.",
        "sentence_llm_dp_info": "Entity 1 ('Expectation-Maximization (EM) algorithm') is the subject, depending on the verb 'is used'. Entity 2 ('unsupervised learning method') is the object of the preposition 'to', depending on 'improve' in the phrase 'to improve an unsupervised learning method'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve' and the preposition 'to'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "unsupervised learning method",
                "Method"
            ],
            [
                "text classification problems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object of the verb 'improve', depending on 'improve' with 'we'. Entity 2 ('text classification problems') is the object of the preposition 'for', depending on 'for' in the phrase 'for text classification problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose expressed by the preposition 'for'.",
        "sdp_path_text": "method → improve → for → problems",
        "sentence": "We improve an unsupervised learning method for text classification problems.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object of the preposition 'for', depending on 'improve'. Entity 2 ('text classification problems') is the object of the preposition 'for', also depending on 'improve'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrase 'for text classification problems' that modifies the verb 'improve'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "unsupervised learning method",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object, depending on 'improve' with 'we'. Entity 2 ('it') is the object, depending on 'apply' with 'in order to'. There is no direct dependency between Entity 1 and Entity 2, but they are semantically related as 'it' refers back to the 'unsupervised learning method' being discussed.",
        "sdp_path_text": "method → using → algorithm",
        "sentence": "We improve an unsupervised learning method using the EM algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object of the verb 'improve', depending on 'improve'. Entity 2 ('it') does not appear in the sentence, so there is no dependency for Entity 2. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "unsupervised learning method",
                "Method"
            ],
            [
                "word sense disambiguation -LRB- WSD -RRB- problems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the object, depending on 'improve' with 'we'. Entity 2 ('word sense disambiguation (WSD) problems') is the object, depending on 'apply' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the improvement of Entity 1 is aimed at being applied to Entity 2.",
        "sdp_path_text": "method → improve → order → apply → to → problems",
        "sentence": "The unsupervised learning method is improved to be applied to word sense disambiguation problems.",
        "sentence_llm_dp_info": "Entity 1 ('unsupervised learning method') is the subject, depending on the verb 'is improved'. Entity 2 ('word sense disambiguation -LRB- WSD -RRB- problems') is the object of the preposition 'to', depending on 'applied' in the phrase 'to be applied to word sense disambiguation -LRB- WSD -RRB- problems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' and the preposition 'to'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "Expectation-Maximization -LRB- EM -RRB- algorithm",
                "Method"
            ],
            [
                "text classification problems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Expectation-Maximization -LRB- EM -RRB- algorithm') is the object of the preposition 'using', depending on 'improve'. Entity 2 ('text classification problems') is the object of the preposition 'for', depending on 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the purpose and method of improvement.",
        "sdp_path_text": "algorithm → using → method → improve → for → problems",
        "sentence": "The Expectation-Maximization (EM) algorithm is used to improve methods for text classification problems.",
        "sentence_llm_dp_info": "Entity 1 ('Expectation-Maximization (EM) algorithm') is the subject, depending on the verb 'is used'. Entity 2 ('text classification problems') is the object of the preposition 'for', depending on 'for' in the phrase 'for text classification problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "Expectation-Maximization -LRB- EM -RRB- algorithm",
                "Method"
            ],
            [
                "word sense disambiguation -LRB- WSD -RRB- problems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Expectation-Maximization -LRB- EM -RRB- algorithm') is the object of the preposition 'using', depending on 'improve'. Entity 2 ('word sense disambiguation -LRB- WSD -RRB- problems') is the object of the preposition 'to', depending on 'apply'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger purpose clause that describes the application of the improved method.",
        "sdp_path_text": "algorithm → using → method → improve → order → apply → to → problems",
        "sentence": "The Expectation-Maximization (EM) algorithm is used to improve a method for applying it to word sense disambiguation (WSD) problems.",
        "sentence_llm_dp_info": "Entity 1 ('Expectation-Maximization (EM) algorithm') is the subject, depending on the verb 'is used'. Entity 2 ('word sense disambiguation (WSD) problems') is the object of the preposition 'to', depending on 'applying' in the phrase 'applying it to word sense disambiguation (WSD) problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'applying'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "text classification problems",
                "Task"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('text classification problems') is the object of the preposition 'for', depending on 'proposed'. Entity 2 ('it') is the object of the preposition 'to', depending on 'apply'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the same context involving the application of the method described.",
        "sdp_path_text": "problems → for → improve → method → using → algorithm",
        "sentence": "The method is improved using the algorithm for text classification problems.",
        "sentence_llm_dp_info": "Entity 1 ('text classification problems') is the object of the preposition 'for', depending on 'for' in the phrase 'for text classification problems'. Entity 2 ('it') is the subject, depending on the verb 'is' in the phrase 'it is improved'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' (the method) is improved for the purpose of 'text classification problems'."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "text classification problems",
                "Task"
            ],
            [
                "word sense disambiguation -LRB- WSD -RRB- problems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('text classification problems') is the object of the preposition 'for', depending on 'proposed'. Entity 2 ('word sense disambiguation -LRB- WSD -RRB- problems') is the object of the preposition 'to', depending on 'apply'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the purpose or application context of the method described in the sentence.",
        "sdp_path_text": "problems → for → improve → order → apply → to → problems",
        "sentence": "The method is improved for text classification problems to be applied to word sense disambiguation (WSD) problems.",
        "sentence_llm_dp_info": "Entity 1 ('text classification problems') is the object of the preposition 'for', depending on 'improved'. Entity 2 ('word sense disambiguation (WSD) problems') is the complement of the infinitive 'to be applied', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the improvement and application context of the method."
    },
    {
        "raw_sentence": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation -LRB- WSD -RRB- problems .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "word sense disambiguation -LRB- WSD -RRB- problems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the object, depending on 'apply' with 'in order to apply it'. Entity 2 ('word sense disambiguation -LRB- WSD -RRB- problems') is the object of the preposition 'to', depending on 'to' in the phrase 'to word sense disambiguation -LRB- WSD -RRB- problems'. There is a direct dependency between Entity 1 and Entity 2, as 'it' refers to the method being applied to 'word sense disambiguation -LRB- WSD -RRB- problems'.",
        "sdp_path_text": "algorithm → using → method → improve → order → apply → to → problems",
        "sentence": "The improved method is applied to word sense disambiguation (WSD) problems.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'applied'. Entity 2 ('word sense disambiguation (WSD) problems') is the object of the preposition 'to', depending on 'to' in the phrase 'to word sense disambiguation (WSD) problems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'."
    },
    {
        "raw_sentence": "The improved method stops the EM algorithm at the optimum iteration number .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "EM algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'stops'. Entity 2 ('EM algorithm') is the object, depending on the verb 'stops'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is the agent that performs the action of stopping 'EM algorithm'.",
        "sdp_path_text": "method → stops → algorithm",
        "sentence": "The method stops the EM algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'stops'. Entity 2 ('EM algorithm') is the object, depending on the verb 'stops'. There is a direct dependency between Entity 1 and Entity 2, where 'method' is the agent performing the action on 'EM algorithm'."
    },
    {
        "raw_sentence": "The improved method stops the EM algorithm at the optimum iteration number .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "optimum iteration number",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'stops'. Entity 2 ('optimum iteration number') is the object, depending on the preposition 'at' within the phrase 'at the optimum iteration number'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'stops' and the preposition 'at'.",
        "sdp_path_text": "method → stops → at → number",
        "sentence": "The method stops at the optimum iteration number.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'stops'. Entity 2 ('optimum iteration number') is the object of the preposition 'at', depending on 'at' in the phrase 'at the optimum iteration number'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'at'."
    },
    {
        "raw_sentence": "The improved method stops the EM algorithm at the optimum iteration number .",
        "ner_pair": [
            [
                "EM algorithm",
                "Method"
            ],
            [
                "optimum iteration number",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('EM algorithm') is the object of the preposition 'the', depending on 'stops' with 'method'. Entity 2 ('optimum iteration number') is the object of the preposition 'at', depending on 'stops'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the action described by the verb 'stops'.",
        "sdp_path_text": "algorithm → stops → at → number",
        "sentence": "The EM algorithm stops at the optimum iteration number.",
        "sentence_llm_dp_info": "Entity 1 ('EM algorithm') is the subject, depending on the verb 'stops'. Entity 2 ('optimum iteration number') is the object of the preposition 'at', depending on 'at' in the phrase 'at the optimum iteration number'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'at'."
    },
    {
        "raw_sentence": "In experiments , we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2 .",
        "ner_pair": [
            [
                "noun WSD problems",
                "Task"
            ],
            [
                "Japanese Dictionary Task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noun WSD problems') is the direct object, depending on the verb 'solved'. Entity 2 ('Japanese Dictionary Task') is the object of the preposition 'in', depending on 'in' in the phrase 'in the Japanese Dictionary Task'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with Entity 1 being the object of the action and Entity 2 specifying the context or domain in which the action takes place.",
        "sdp_path_text": "problems → solved → in → Task",
        "sentence": "Noun WSD problems were solved in the Japanese Dictionary Task.",
        "sentence_llm_dp_info": "Entity 1 ('noun WSD problems') is the subject, depending on the verb 'were solved'. Entity 2 ('Japanese Dictionary Task') is the object of the preposition 'in', depending on 'in' in the phrase 'in the Japanese Dictionary Task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence structure."
    },
    {
        "raw_sentence": "In experiments , we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2 .",
        "ner_pair": [
            [
                "noun WSD problems",
                "Task"
            ],
            [
                "SENSEVAL2",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noun WSD problems') is the object, depending on 'solved' with 'we'. Entity 2 ('SENSEVAL2') is the object of the preposition 'in', depending on 'in' in the phrase 'in SENSEVAL2'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the prepositional phrase 'in the Japanese Dictionary Task in SENSEVAL2'.",
        "sdp_path_text": "problems → solved → in → Task → in → SENSEVAL2",
        "sentence": "Noun WSD problems were solved in the SENSEVAL2 task.",
        "sentence_llm_dp_info": "Entity 1 ('noun WSD problems') is the subject, depending on the verb 'were solved'. Entity 2 ('SENSEVAL2') is the object of the preposition 'in', depending on 'in' in the phrase 'in the SENSEVAL2 task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'were solved' and the prepositional phrase 'in the SENSEVAL2 task'."
    },
    {
        "raw_sentence": "In experiments , we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2 .",
        "ner_pair": [
            [
                "Japanese Dictionary Task",
                "Task"
            ],
            [
                "SENSEVAL2",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Japanese Dictionary Task') is the object of the preposition 'in', depending on 'in' within the phrase 'in the Japanese Dictionary Task'. Entity 2 ('SENSEVAL2') is also the object of the preposition 'in', depending on 'in' within the phrase 'in SENSEVAL2'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger prepositional phrase modifying the verb 'solved'.",
        "sdp_path_text": "Task → in → SENSEVAL2",
        "sentence": "The Japanese Dictionary Task was part of SENSEVAL2.",
        "sentence_llm_dp_info": "Entity 1 ('Japanese Dictionary Task') is the subject, depending on the verb 'was'. Entity 2 ('SENSEVAL2') is the object of the preposition 'of', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'was part of'."
    },
    {
        "raw_sentence": "The score of our method is a match for the best public score of this task .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is part of the possessive noun phrase 'our method', depending on the preposition 'of' in 'the score of our method'. Entity 2 ('task') is the object of the preposition 'of' in the phrase 'score of this task', depending on 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'score' through different prepositional phrases.",
        "sdp_path_text": "method → of → score → is → match → for → score → of → task",
        "sentence": "The score of our method matches the best score of this task.",
        "sentence_llm_dp_info": "Entity 1 ('method') is part of a noun phrase, depending on 'score' with the preposition 'of' in the phrase 'of our method'. Entity 2 ('task') is part of another noun phrase, depending on 'score' with the preposition 'of' in the phrase 'of this task'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the word 'score' through the preposition 'of'."
    },
    {
        "raw_sentence": "Furthermore , our methods were confirmed to be effective also for verb WSD problems .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "verb WSD problems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on 'confirmed' with 'were'. Entity 2 ('verb WSD problems') is the object of the preposition 'for', depending on 'for' in the phrase 'for verb WSD problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'confirmed' and the preposition 'for'.",
        "sdp_path_text": "methods → confirmed → be → for → problems",
        "sentence": "Our methods were confirmed to be effective for verb WSD problems.",
        "sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'were confirmed'. Entity 2 ('verb WSD problems') is the object of the preposition 'for', depending on 'for' in the phrase 'for verb WSD problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Dividing sentences in chunks of words is a useful preprocessing step for parsing , information extraction and information retrieval .",
        "ner_pair": [
            [
                "Dividing sentences in chunks of words",
                "Task"
            ],
            [
                "parsing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dividing sentences in chunks of words') is the subject, depending on the verb 'is'. Entity 2 ('parsing') is part of a list, depending on the preposition 'for' which modifies the noun 'step'. There is no direct dependency between Entity 1 and Entity 2; both are related through the noun 'step' and the preposition 'for'.",
        "sdp_path_text": "Dividing → is → step → for → parsing",
        "sentence": "Dividing sentences in chunks of words is a preprocessing step for parsing.",
        "sentence_llm_dp_info": "Entity 1 ('Dividing sentences in chunks of words') is the subject, depending on the verb 'is'. Entity 2 ('parsing') is the object of the preposition 'for', depending on 'for' in the phrase 'for parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Dividing sentences in chunks of words is a useful preprocessing step for parsing , information extraction and information retrieval .",
        "ner_pair": [
            [
                "Dividing sentences in chunks of words",
                "Task"
            ],
            [
                "information extraction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dividing sentences in chunks of words') is the subject, depending on the verb 'is'. Entity 2 ('information extraction') is one of the objects of the preposition 'for', depending on 'for' in the phrase 'for parsing, information extraction and information retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "Dividing → is → step → for → parsing → extraction",
        "sentence": "Dividing sentences in chunks of words is a useful step for information extraction.",
        "sentence_llm_dp_info": "Entity 1 ('Dividing sentences in chunks of words') is the subject, depending on the verb 'is'. Entity 2 ('information extraction') is the object of the preposition 'for', depending on 'for' in the phrase 'for information extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose or benefit of the action described by Entity 1."
    },
    {
        "raw_sentence": "Dividing sentences in chunks of words is a useful preprocessing step for parsing , information extraction and information retrieval .",
        "ner_pair": [
            [
                "Dividing sentences in chunks of words",
                "Task"
            ],
            [
                "information retrieval",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dividing sentences in chunks of words') is the subject, depending on the verb 'is'. Entity 2 ('information retrieval') is one of the objects of the preposition 'for', depending on 'for' in the phrase 'for parsing, information extraction and information retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "Dividing → is → step → for → parsing → extraction → retrieval",
        "sentence": "Dividing sentences in chunks of words is a useful step for information retrieval.",
        "sentence_llm_dp_info": "Entity 1 ('Dividing sentences in chunks of words') is the subject, depending on the verb 'is'. Entity 2 ('information retrieval') is the object of the preposition 'for', depending on 'for' in the phrase 'for information retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates that Entity 1 is a useful step for Entity 2."
    },
    {
        "raw_sentence": "Dividing sentences in chunks of words is a useful preprocessing step for parsing , information extraction and information retrieval .",
        "ner_pair": [
            [
                "parsing",
                "Task"
            ],
            [
                "information extraction",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parsing') is the object of the preposition 'for', depending on 'for' in the phrase 'for parsing'. Entity 2 ('information extraction') is also the object of the preposition 'for', depending on 'for' in the phrase 'for information extraction'. There is no direct dependency between Entity 1 and Entity 2; both are listed as objects of the same preposition 'for'.",
        "sdp_path_text": "parsing → extraction",
        "sentence": "Dividing sentences in chunks is useful for parsing and information extraction.",
        "sentence_llm_dp_info": "Entity 1 ('parsing') is the object of the preposition 'for', depending on 'for' in the phrase 'for parsing'. Entity 2 ('information extraction') is also the object of the preposition 'for', depending on 'for' in the phrase 'for information extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'for'."
    },
    {
        "raw_sentence": "Dividing sentences in chunks of words is a useful preprocessing step for parsing , information extraction and information retrieval .",
        "ner_pair": [
            [
                "parsing",
                "Task"
            ],
            [
                "information retrieval",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parsing') is the object of the preposition 'for', depending on 'step'. Entity 2 ('information retrieval') is also the object of the preposition 'for', depending on 'step'. There is no direct dependency between Entity 1 and Entity 2; both are connected to the noun 'step' through the preposition 'for'.",
        "sdp_path_text": "parsing → extraction → retrieval",
        "sentence": "Dividing sentences into chunks is useful for parsing, information extraction, and information retrieval.",
        "sentence_llm_dp_info": "Entity 1 ('parsing') is the object of the preposition 'for', depending on 'for' in the phrase 'for parsing'. Entity 2 ('information retrieval') is also the object of the preposition 'for', depending on 'for' in the phrase 'for information retrieval'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'for'."
    },
    {
        "raw_sentence": "Dividing sentences in chunks of words is a useful preprocessing step for parsing , information extraction and information retrieval .",
        "ner_pair": [
            [
                "information extraction",
                "Task"
            ],
            [
                "information retrieval",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction') is one of the objects of the preposition 'for', depending on 'for' in the phrase 'for parsing, information extraction and information retrieval'. Entity 2 ('information retrieval') is another object of the same preposition 'for', also depending on 'for' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are coordinated objects of the preposition 'for'.",
        "sdp_path_text": "extraction → retrieval",
        "sentence": "Dividing sentences in chunks is useful for information extraction and information retrieval.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction') is the object of the preposition 'for', depending on 'for' in the phrase 'for information extraction'. Entity 2 ('information retrieval') is also the object of the preposition 'for', depending on 'for' in the phrase 'for information retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'for'."
    },
    {
        "raw_sentence": "-LRB- Ramshaw and Marcus , 1995 -RRB- have introduced a `` convenient '' data representation for chunking by converting it to a tagging task .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "chunking",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'for', depending on 'introduced' with 'have introduced'. Entity 2 ('chunking') is the object of the preposition 'for', depending on 'converting' in the phrase 'converting it to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence through the verbs 'introduced' and 'converting'.",
        "sdp_path_text": "representation → for → chunking",
        "sentence": "A data representation has been introduced for chunking.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the subject, depending on the verb 'introduced'. Entity 2 ('chunking') is the object of the preposition 'for', depending on 'for' in the phrase 'for chunking'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "-LRB- Ramshaw and Marcus , 1995 -RRB- have introduced a `` convenient '' data representation for chunking by converting it to a tagging task .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'for', depending on 'introduced' with 'have introduced'. Entity 2 ('it') is the object, depending on 'converting' with 'converting it to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'converting' which refers back to the 'data representation'.",
        "sdp_path_text": "representation → introduced → by → converting → it",
        "sentence": "A data representation was introduced by converting it to a tagging task.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the subject, depending on the passive verb 'was introduced'. Entity 2 ('it') is the object of the preposition 'by', referring back to 'data representation' and depending on 'converting' in the phrase 'by converting it to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but 'it' refers back to 'data representation' in the context of the sentence."
    },
    {
        "raw_sentence": "-LRB- Ramshaw and Marcus , 1995 -RRB- have introduced a `` convenient '' data representation for chunking by converting it to a tagging task .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "tagging task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'for', depending on 'introduced' with 'have introduced'. Entity 2 ('tagging task') is the object of the preposition 'to', depending on 'converting' in the phrase 'converting it to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'converting'.",
        "sdp_path_text": "representation → introduced → by → converting → to → task",
        "sentence": "A data representation was introduced by converting it to a tagging task.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the subject, depending on the verb 'introduced'. Entity 2 ('tagging task') is the object of the preposition 'to', depending on 'converting' in the phrase 'converting it to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of conversion described in the sentence."
    },
    {
        "raw_sentence": "-LRB- Ramshaw and Marcus , 1995 -RRB- have introduced a `` convenient '' data representation for chunking by converting it to a tagging task .",
        "ner_pair": [
            [
                "chunking",
                "Task"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('chunking') is the object of the preposition 'for', depending on 'representation'. Entity 2 ('it') is the direct object, depending on 'converting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'converting' where 'it' refers back to 'chunking'.",
        "sdp_path_text": "chunking → for → representation → introduced → by → converting → it",
        "sentence": "Chunking is represented by converting it.",
        "sentence_llm_dp_info": "Entity 1 ('chunking') is the subject, depending on the verb 'is represented'. Entity 2 ('it') is the object, depending on the verb 'converting'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate structure where 'chunking' is what is being represented by the action of converting 'it'."
    },
    {
        "raw_sentence": "-LRB- Ramshaw and Marcus , 1995 -RRB- have introduced a `` convenient '' data representation for chunking by converting it to a tagging task .",
        "ner_pair": [
            [
                "chunking",
                "Task"
            ],
            [
                "tagging task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('chunking') is the object of the preposition 'for', depending on 'representation'. Entity 2 ('tagging task') is the complement of the preposition 'to', depending on 'converting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'representing' and 'converting' which describe the transformation process from one to the other.",
        "sdp_path_text": "chunking → for → representation → introduced → by → converting → to → task",
        "sentence": "Chunking is represented by converting it to a tagging task.",
        "sentence_llm_dp_info": "Entity 1 ('chunking') is the subject, depending on the verb 'is represented'. Entity 2 ('tagging task') is the object, depending on the preposition 'to' in the phrase 'to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conversion process described in the sentence."
    },
    {
        "raw_sentence": "-LRB- Ramshaw and Marcus , 1995 -RRB- have introduced a `` convenient '' data representation for chunking by converting it to a tagging task .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "tagging task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the object of the preposition 'by', depending on the verb 'converting'. Entity 2 ('tagging task') is the object, depending on the preposition 'to' in the phrase 'to a tagging task'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'converting' which indicates the transformation from one form (chunking) to another (tagging task).",
        "sdp_path_text": "it → converting → to → task",
        "sentence": "It is converted to a tagging task.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'converted'. Entity 2 ('tagging task') is the object, depending on the preposition 'to' in the phrase 'to a tagging task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'converted'."
    },
    {
        "raw_sentence": "In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks .",
        "ner_pair": [
            [
                "data representations",
                "Method"
            ],
            [
                "recognizing noun phrase chunks",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representations') is the object of the verb 'examine', depending on 'will examine'. Entity 2 ('recognizing noun phrase chunks') is the complement of the preposition 'for', depending on 'for' in the phrase 'for the problem of recognizing noun phrase chunks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what will be examined and the context or purpose of the examination.",
        "sdp_path_text": "representations → for → problem → of → recognizing",
        "sentence": "Data representations are examined for the problem of recognizing noun phrase chunks.",
        "sentence_llm_dp_info": "Entity 1 ('data representations') is the subject, depending on the verb 'examined'. Entity 2 ('recognizing noun phrase chunks') is the complement of the preposition 'for', depending on 'for' in the phrase 'for the problem of recognizing noun phrase chunks'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for' which indicates the purpose or context in which the data representations are examined."
    },
    {
        "raw_sentence": "We will show that the data representation choice has a minor influence on chunking performance .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "chunking",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is part of the noun phrase functioning as the subject complement, depending on 'choice' with the possessive 'the'. Entity 2 ('chunking') is part of the noun phrase functioning as the object of the preposition 'on', depending on 'influence' with the prepositional phrase 'on chunking performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the influence of one on the performance of the other.",
        "sdp_path_text": "representation → choice → has → influence → on → performance → chunking",
        "sentence": "The choice of data representation has an influence on chunking performance.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'of', depending on 'choice'. Entity 2 ('chunking') is part of the compound noun 'chunking performance', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the influence on chunking performance."
    },
    {
        "raw_sentence": "However , equipped with the most suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "memory-based learning chunker",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'with', depending on the verb 'equipped'. Entity 2 ('memory-based learning chunker') is the subject, depending on the verb 'was able to improve'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'data representation' modifies the conditions under which the 'memory-based learning chunker' was able to improve results.",
        "sdp_path_text": "representation → with → equipped → was → chunker",
        "sentence": "The memory-based learning chunker was equipped with the most suitable data representation.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the object, depending on the adjective 'suitable' and the determiner 'the', and it is part of the prepositional phrase 'with the most suitable data representation', which modifies the verb 'equipped'. Entity 2 ('memory-based learning chunker') is the subject, depending on the verb 'was equipped'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' in the phrase 'with the most suitable data representation'."
    },
    {
        "raw_sentence": "However , equipped with the most suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "chunking",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'with', depending on 'equipped'. Entity 2 ('chunking') is part of the compound noun 'chunking results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where 'data representation' contributes to improving 'chunking results'.",
        "sdp_path_text": "representation → with → equipped → was → able → improve → results → chunking",
        "sentence": "Data representation equipped our chunker to improve chunking results.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the subject, depending on the verb 'equipped'. Entity 2 ('chunking') is part of the compound noun 'chunking results', which is the object of the verb 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'equipped' and 'improve'."
    },
    {
        "raw_sentence": "However , equipped with the most suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set .",
        "ner_pair": [
            [
                "data representation",
                "Method"
            ],
            [
                "data set",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data representation') is the object of the preposition 'with', depending on 'equipped'. Entity 2 ('data set') is the object of the preposition 'for', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "representation → with → equipped → was → able → improve → for → set",
        "sentence": "Data representation enabled improvement of results for a data set.",
        "sentence_llm_dp_info": "Entity 1 ('data representation') is the subject, depending on the verb 'enabled'. Entity 2 ('data set') is the object of the preposition 'for', depending on 'for' in the phrase 'for a data set'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "However , equipped with the most suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set .",
        "ner_pair": [
            [
                "memory-based learning chunker",
                "Method"
            ],
            [
                "chunking",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('memory-based learning chunker') is the subject, depending on the verb 'was able to improve'. Entity 2 ('chunking') is part of the compound noun 'chunking results', which is the object of the verb 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the object 'chunking results'.",
        "sdp_path_text": "chunker → was → able → improve → results → chunking",
        "sentence": "The memory-based learning chunker was able to improve chunking results.",
        "sentence_llm_dp_info": "Entity 1 ('memory-based learning chunker') is the subject, depending on the verb 'was able to improve'. Entity 2 ('chunking') is part of the compound noun 'chunking results', which is the object of the verb 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'improve'."
    },
    {
        "raw_sentence": "However , equipped with the most suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set .",
        "ner_pair": [
            [
                "data set",
                "Material"
            ],
            [
                "memory-based learning chunker",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data set') is the object, depending on 'for' in the prepositional phrase 'for a standard data set'. Entity 2 ('memory-based learning chunker') is the subject, depending on the verb 'was able to improve'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the action described by the verb 'improve'.",
        "sdp_path_text": "set → for → improve → able → was → chunker",
        "sentence": "The memory-based learning chunker improved results for the data set.",
        "sentence_llm_dp_info": "Entity 1 ('data set') is the object of the preposition 'for', depending on 'for' in the phrase 'for the data set'. Entity 2 ('memory-based learning chunker') is the subject, depending on the verb 'improved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improved' which indicates that the chunker's action had an effect on the data set."
    },
    {
        "raw_sentence": "However , equipped with the most suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set .",
        "ner_pair": [
            [
                "chunking",
                "Task"
            ],
            [
                "data set",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('chunking') is part of a compound noun, depending on 'results' as a modifier. Entity 2 ('data set') is the object of the preposition 'for', depending on 'for' in the phrase 'for a standard data set'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'results' and the preposition 'for'.",
        "sdp_path_text": "chunking → results → improve → for → set",
        "sentence": "Chunking results were improved for a data set.",
        "sentence_llm_dp_info": "Entity 1 ('chunking') is part of the compound noun 'chunking results', which acts as the subject, depending on the verb 'were improved'. Entity 2 ('data set') is the object of the preposition 'for', depending on 'for' in the phrase 'for a data set'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'were improved' and the preposition 'for'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "FAQ-like questions and answers",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object, depending on the verb 'build' with 'We'. Entity 2 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focus' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as part of the same sentence describing the focus and construction of the system.",
        "sdp_path_text": "system → build → focus → on → questions",
        "sentence": "We build our system focusing on FAQ-like questions and answers.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the object, depending on the verb 'build' with 'We'. Entity 2 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focusing' in the phrase 'focusing on FAQ-like questions and answers'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the system focuses on."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "FAQ-like questions and answers",
                "Material"
            ],
            [
                "noisy-channel architecture",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focus' with 'We'. Entity 2 ('noisy-channel architecture') is the object of the verb 'build', depending on 'build' with 'our system'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context where the system being built is intended to handle the type of content described by Entity 1.",
        "sdp_path_text": "questions → on → focus → build → around → architecture",
        "sentence": "We build our noisy-channel architecture focused on FAQ-like questions and answers.",
        "sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focused'. Entity 2 ('noisy-channel architecture') is the object, depending on the verb 'build'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'focused on FAQ-like questions and answers'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "FAQ-like questions and answers",
                "Material"
            ],
            [
                "language model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focus' in the phrase 'focus on FAQ-like questions and answers'. Entity 2 ('language model') is part of the object complement, depending on 'exploits' in the phrase 'exploits both a language model'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "questions → on → focus → build → around → architecture → exploits → model",
        "sentence": "We focus on FAQ-like questions and answers, building a system that exploits a language model.",
        "sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focus'. Entity 2 ('language model') is the object of the relative clause, depending on 'exploits'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause describing the system's function."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "FAQ-like questions and answers",
                "Material"
            ],
            [
                "transformation model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focus' with 'We'. Entity 2 ('transformation model') is the object of the preposition 'for', depending on 'model' in the phrase 'a transformation model for answer/question terms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context within the sentence, where Entity 1 is the focus area and Entity 2 is a component used in the system built around that focus.",
        "sdp_path_text": "questions → on → focus → build → around → architecture → exploits → model → model",
        "sentence": "We build our system around an architecture that exploits a transformation model for FAQ-like questions and answers.",
        "sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object, depending on the preposition 'for', which is part of the prepositional phrase 'for FAQ-like questions and answers'. Entity 2 ('transformation model') is the object of the relative clause, depending on 'exploits' with 'architecture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the verb 'exploits'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "FAQ-like questions and answers",
                "Material"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the object of the preposition 'on', depending on 'focus'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "questions → on → focus → build → around → architecture → exploits → model → model → trained → on → corpus → of → pairs → collected → from → Web",
        "sentence": "FAQ-like questions and answers are used in a system trained on pairs collected from the Web.",
        "sentence_llm_dp_info": "Entity 1 ('FAQ-like questions and answers') is the subject, depending on the verb 'used'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from the Web'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "noisy-channel architecture",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the object of the preposition 'around', depending on 'build' with 'our system'. Entity 2 ('system') is the object, depending on 'build' with 'we'. There is a direct dependency between Entity 1 and Entity 2, as 'noisy-channel architecture' is the element around which the 'system' is built.",
        "sdp_path_text": "architecture → around → build → system",
        "sentence": "We build our system around a noisy-channel architecture.",
        "sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the object of the preposition 'around', depending on 'build'. Entity 2 ('system') is the object, depending on 'build' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'build'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "language model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the verb 'build', depending on 'build' with 'our'. Entity 2 ('language model') is the object of the preposition 'for', depending on 'for' in the phrase 'for answers'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'system' is built around an architecture that exploits 'language model' among other components.",
        "sdp_path_text": "system → build → around → architecture → exploits → model",
        "sentence": "The system is built around an architecture that exploits a language model.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is built'. Entity 2 ('language model') is the object, depending on the verb 'exploits' within the relative clause 'that exploits a language model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause where 'system' is modified by the clause that includes 'language model'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "transformation model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the verb 'build', depending on the verb 'build' with 'We'. Entity 2 ('transformation model') is the object of the preposition 'for', depending on 'for' in the phrase 'for answer/question terms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the conjunction 'and' and the context provided by the sentence.",
        "sdp_path_text": "system → build → around → architecture → exploits → model → model",
        "sentence": "The system is built around an architecture that exploits a transformation model.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is built'. Entity 2 ('transformation model') is the object, depending on the verb 'exploits'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the architecture that the system is built around, which exploits the transformation model."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the object of the verb 'build', depending on 'build' with 'We'. Entity 2 ('Web') is the object of the verb 'collected', depending on 'collected' in the phrase 'collected from the Web'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of building the system and the data source used for training.",
        "sdp_path_text": "system → build → around → architecture → exploits → model → model → trained → on → corpus → of → pairs → collected → from → Web",
        "sentence": "The system is built around an architecture that exploits models trained on question/answer pairs collected from the Web.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'is' in the phrase 'is built'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected' in the phrase 'collected from the Web'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'built' and the participial phrase 'trained on question/answer pairs collected from the Web'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "noisy-channel architecture",
                "Method"
            ],
            [
                "language model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the object of the verb 'build', depending on 'build' with 'our system'. Entity 2 ('language model') is the object of the preposition 'for', depending on 'for' in the phrase 'for answers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the clause 'which exploits both a language model for answers and a transformation model for answer/question terms'.",
        "sdp_path_text": "architecture → exploits → model",
        "sentence": "The noisy-channel architecture exploits a language model.",
        "sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the subject, depending on the verb 'exploits'. Entity 2 ('language model') is the object, depending on the verb 'exploits'. There is a direct dependency between Entity 1 and Entity 2, as 'noisy-channel architecture' exploits 'language model'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "noisy-channel architecture",
                "Method"
            ],
            [
                "transformation model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the object of the verb 'build', depending on 'build' with 'we'. Entity 2 ('transformation model') is part of the compound object of the preposition 'for', depending on 'for' in the phrase 'for answer/question terms'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the broader context described in the sentence, where the 'noisy-channel architecture' exploits both a 'language model for answers' and a 'transformation model for answer/question terms'.",
        "sdp_path_text": "architecture → exploits → model → model",
        "sentence": "The noisy-channel architecture exploits a transformation model.",
        "sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the subject, depending on the verb 'exploits'. Entity 2 ('transformation model') is the object, depending on the verb 'exploits'. There is a direct dependency between Entity 1 and Entity 2, as 'noisy-channel architecture' is the agent that exploits the 'transformation model'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "noisy-channel architecture",
                "Method"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the object of the verb 'build', depending on 'build' with 'our system'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected' in the phrase 'collected from the Web'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the training data source.",
        "sdp_path_text": "architecture → exploits → model → model → trained → on → corpus → of → pairs → collected → from → Web",
        "sentence": "The noisy-channel architecture exploits models trained on a corpus of question/answer pairs collected from the Web.",
        "sentence_llm_dp_info": "Entity 1 ('noisy-channel architecture') is the subject, depending on the verb 'exploits'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from the Web' which modifies 'pairs'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "language model",
                "Method"
            ],
            [
                "transformation model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language model') is the object of the preposition 'for', depending on 'exploits' in the clause 'which exploits both a language model for answers'. Entity 2 ('transformation model') is also the object of the preposition 'for', depending on 'exploits' in the clause 'and a transformation model for answer/question terms'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same verb 'exploits' but are related through the conjunction 'and'.",
        "sdp_path_text": "model → model",
        "sentence": "The system uses both a language model and a transformation model.",
        "sentence_llm_dp_info": "Entity 1 ('language model') is part of the conjunction, depending on 'uses' with 'system'. Entity 2 ('transformation model') is also part of the conjunction, depending on 'uses' with 'system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' under the same governing verb 'uses'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "language model",
                "Method"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('language model') is part of the object complement, depending on 'exploits' with 'architecture'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where 'Web' is the source of data used to train models that include the 'language model'.",
        "sdp_path_text": "model → model → trained → on → corpus → of → pairs → collected → from → Web",
        "sentence": "The language model is trained on a corpus of question/answer pairs collected from the Web.",
        "sentence_llm_dp_info": "Entity 1 ('language model') is the subject, depending on the verb 'is trained'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the chain of dependencies involving 'trained', 'corpus', and 'collected'."
    },
    {
        "raw_sentence": "We focus on FAQ-like questions and answers , and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .",
        "ner_pair": [
            [
                "transformation model",
                "Method"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('transformation model') is part of the conjunction, depending on 'exploits' with 'architecture'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected' in the phrase 'collected from the Web'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "model → trained → on → corpus → of → pairs → collected → from → Web",
        "sentence": "The transformation model is trained on a corpus of question/answer pairs collected from the Web.",
        "sentence_llm_dp_info": "Entity 1 ('transformation model') is the subject, depending on the verb 'is trained'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'from the Web' which modifies 'pairs'."
    },
    {
        "raw_sentence": "In this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations .",
        "ner_pair": [
            [
                "measures of speech",
                "Metric"
            ],
            [
                "intelligibility prediction",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures of speech') is the object of the verb 'evaluate', depending on 'we'. Entity 2 ('intelligibility prediction') is the object of the preposition 'to', depending on 'with regards to'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same evaluative context within the sentence.",
        "sdp_path_text": "measures → with → regards → to → prediction",
        "sentence": "Measures of speech are evaluated with regards to intelligibility prediction.",
        "sentence_llm_dp_info": "Entity 1 ('measures of speech') is the subject, depending on the verb 'evaluated'. Entity 2 ('intelligibility prediction') is the object of the preposition 'to', but in this case, it is part of the phrase 'with regards to', which modifies the verb 'evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with regards to'."
    },
    {
        "raw_sentence": "In this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations .",
        "ner_pair": [
            [
                "measures of speech",
                "Metric"
            ],
            [
                "synthesized speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures of speech') is the object of the verb 'evaluate', depending on 'we' (the subject). Entity 2 ('synthesized speech') is the object of the preposition 'of', depending on 'intelligibility prediction'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger context of evaluating measures for predicting the intelligibility of synthesized speech.",
        "sdp_path_text": "measures → with → regards → to → prediction → of → speech",
        "sentence": "We evaluate measures of speech with regards to the prediction of synthesized speech.",
        "sentence_llm_dp_info": "Entity 1 ('measures of speech') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('synthesized speech') is the object of the preposition 'of', depending on 'prediction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context related to the evaluation and prediction processes."
    },
    {
        "raw_sentence": "In this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations .",
        "ner_pair": [
            [
                "measures of speech",
                "Metric"
            ],
            [
                "diverse noisy situations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures of speech') is the object of the verb 'evaluate', depending on 'we'. Entity 2 ('diverse noisy situations') is the object of the preposition 'in', depending on 'in' in the phrase 'in diverse noisy situations'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, connected through the context of the evaluation described in the sentence.",
        "sdp_path_text": "measures → with → regards → to → prediction → in → situations",
        "sentence": "Measures of speech are evaluated for prediction in diverse noisy situations.",
        "sentence_llm_dp_info": "Entity 1 ('measures of speech') is the subject, depending on the verb 'are evaluated'. Entity 2 ('diverse noisy situations') is the object of the preposition 'in', depending on 'in' in the phrase 'in diverse noisy situations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation context provided by the verb 'are evaluated'."
    },
    {
        "raw_sentence": "In this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations .",
        "ner_pair": [
            [
                "synthesized speech",
                "Material"
            ],
            [
                "intelligibility prediction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('synthesized speech') is the object of the preposition 'of', depending on 'prediction'. Entity 2 ('intelligibility prediction') is the object, depending on 'with regards to' which connects it to 'measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with regards to intelligibility prediction of synthesized speech'.",
        "sdp_path_text": "speech → of → prediction",
        "sentence": "Synthesized speech is evaluated for intelligibility prediction.",
        "sentence_llm_dp_info": "Entity 1 ('synthesized speech') is the subject, depending on the verb 'is evaluated'. Entity 2 ('intelligibility prediction') is the object of the preposition 'for', depending on 'for' in the phrase 'for intelligibility prediction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation process described by the verb 'is evaluated'."
    },
    {
        "raw_sentence": "In this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations .",
        "ner_pair": [
            [
                "intelligibility prediction",
                "Task"
            ],
            [
                "diverse noisy situations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('intelligibility prediction') is the object of the preposition 'to', depending on 'with regards to'. Entity 2 ('diverse noisy situations') is the object of the preposition 'in', depending on 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify the main clause about evaluating objective measures.",
        "sdp_path_text": "prediction → in → situations",
        "sentence": "Intelligibility prediction is evaluated in diverse noisy situations.",
        "sentence_llm_dp_info": "Entity 1 ('intelligibility prediction') is the subject, depending on the verb 'is evaluated'. Entity 2 ('diverse noisy situations') is the object of the preposition 'in', depending on 'in' in the phrase 'in diverse noisy situations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "In this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations .",
        "ner_pair": [
            [
                "diverse noisy situations",
                "OtherScientificTerm"
            ],
            [
                "synthesized speech",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('diverse noisy situations') is the object of the preposition 'in', depending on 'in' in the phrase 'in diverse noisy situations'. Entity 2 ('synthesized speech') is the object of the preposition 'of', depending on 'of' in the phrase 'of synthesized speech'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context of the sentence where 'synthesized speech' is being evaluated for its intelligibility prediction in 'diverse noisy situations'.",
        "sdp_path_text": "situations → in → prediction → of → speech",
        "sentence": "Diverse noisy situations affect the intelligibility prediction of synthesized speech.",
        "sentence_llm_dp_info": "Entity 1 ('diverse noisy situations') is the subject, depending on the verb 'affect'. Entity 2 ('synthesized speech') is the object of the preposition 'of', depending on 'prediction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'affect' and the noun 'prediction'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Dau measure",
                "Metric"
            ],
            [
                "intel-ligibility measures",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau measure') is an appositive, depending on 'measures' with the preposition 'the'. Entity 2 ('intel-ligibility measures') is the object, depending on 'evaluated' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the appositive relationship where 'Dau measure' specifies one of the 'intel-ligibility measures'.",
        "sdp_path_text": "measure → measures",
        "sentence": "The Dau measure is one of the intelligibility measures evaluated.",
        "sentence_llm_dp_info": "Entity 1 ('Dau measure') is the subject, depending on the verb 'is'. Entity 2 ('intelligibility measures') is the object of the preposition 'of', depending on 'measures evaluated'. There is a direct dependency between Entity 1 and Entity 2, as 'Dau measure' is specified as being one of the 'intelligibility measures'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "glimpse proportion",
                "Metric"
            ],
            [
                "intel-ligibility measures",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is part of the list of items, depending on the conjunction 'and', which connects it to other items in the list. Entity 2 ('intel-ligibility measures') is the object of the verb 'evaluated', depending on 'evaluated' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list of evaluated measures.",
        "sdp_path_text": "proportion → measure → measures",
        "sentence": "The glimpse proportion is an intelligibility measure.",
        "sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is the subject, depending on the verb 'is'. Entity 2 ('intelligibility measure') is the predicate nominative, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'is' links them directly, indicating that 'glimpse proportion' is a type of 'intelligibility measure'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Speech Intelligibility Index -LRB- SII -RRB-",
                "Metric"
            ],
            [
                "intel-ligibility measures",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Speech Intelligibility Index -LRB- SII -RRB-') is the third item in a list, depending on the conjunction 'and' which connects it to the previous items in the list. Entity 2 ('intel-ligibility measures') is the direct object, depending on the verb 'evaluated'. There is no direct dependency between Entity 1 and Entity 2; they are part of the same list, where Entity 1 is one of the specific measures being evaluated under the broader category represented by Entity 2.",
        "sdp_path_text": "Index → proportion → measure → measures",
        "sentence": "The Speech Intelligibility Index is one of the intelligibility measures.",
        "sentence_llm_dp_info": "Entity 1 ('Speech Intelligibility Index') is the subject, depending on the copula 'is'. Entity 2 ('intelligibility measures') is the complement, depending on the noun 'one' in the phrase 'one of the intelligibility measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the copula 'is' and the prepositional structure 'one of'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "intel-ligibility measures",
                "Metric"
            ],
            [
                "quality measure",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('intel-ligibility measures') is the object of the verb 'evaluated', depending on 'We'. Entity 2 ('quality measure') is also an object of the verb 'evaluated', depending on 'We'. There is no direct dependency between Entity 1 and Entity 2; both are listed as separate objects of the same verb 'evaluated'.",
        "sdp_path_text": "measures → measure → measure",
        "sentence": "We evaluated intelligibility measures and a quality measure.",
        "sentence_llm_dp_info": "Entity 1 ('intelligibility measures') is the object, depending on the verb 'evaluated' with 'We'. Entity 2 ('quality measure') is also an object, depending on the conjunction 'and' which links it to 'intelligibility measures'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of the verb 'evaluated' and are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "intel-ligibility measures",
                "Metric"
            ],
            [
                "Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('intel-ligibility measures') is the object of the verb 'evaluated', depending on 'We'. Entity 2 ('Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-') is the appositive, depending on 'measure' in the phrase 'a quality measure'. There is no direct dependency between Entity 1 and Entity 2; they are part of a list of items that were evaluated.",
        "sdp_path_text": "measures → measure → measure → -RRB-",
        "sentence": "We evaluated intelligibility measures including the Perceptual Evaluation of Speech Quality (PESQ).",
        "sentence_llm_dp_info": "Entity 1 ('intelligibility measures') is the object, depending on the verb 'evaluated'. Entity 2 ('Perceptual Evaluation of Speech Quality (PESQ)') is part of the list, depending on the preposition 'including' which modifies 'measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'including'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Dau measure",
                "Metric"
            ],
            [
                "glimpse proportion",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau measure') is the object of the preposition 'the', part of a list of items being evaluated, and it depends on 'evaluated' through the conjunction 'and'. Entity 2 ('glimpse proportion') is also an object of the preposition 'the', part of the same list, and it depends on 'evaluated' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of items being evaluated.",
        "sdp_path_text": "measure → proportion",
        "sentence": "We evaluated the Dau measure and the glimpse proportion.",
        "sentence_llm_dp_info": "Entity 1 ('Dau measure') is the object of the verb 'evaluated', depending on 'evaluated' with 'We'. Entity 2 ('glimpse proportion') is also an object of the verb 'evaluated', coordinated with 'Dau measure' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'evaluated'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Dau measure",
                "Metric"
            ],
            [
                "Speech Intelligibility Index -LRB- SII -RRB-",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau measure') is part of a list of intelligibility measures, depending on the conjunction 'and' that connects it with other items in the list, which is under the verb 'evaluated'. Entity 2 ('Speech Intelligibility Index -LRB- SII -RRB-') is also part of the same list, similarly depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same list being evaluated.",
        "sdp_path_text": "measure → proportion → Index",
        "sentence": "The Dau measure and the Speech Intelligibility Index were evaluated.",
        "sentence_llm_dp_info": "Entity 1 ('Dau measure') is the first conjunct, depending on 'and' with 'Speech Intelligibility Index'. Entity 2 ('Speech Intelligibility Index -LRB- SII -RRB-') is the second conjunct, also depending on 'and' with 'Dau measure'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated by the conjunction 'and'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Dau measure",
                "Metric"
            ],
            [
                "quality measure",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau measure') is part of a list of objects, depending on the verb 'evaluated' with 'We'. Entity 2 ('quality measure') is also an object, depending on 'and' which connects it to the list of measures being evaluated. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of evaluated measures.",
        "sdp_path_text": "measure → measure",
        "sentence": "We evaluated the Dau measure and a quality measure.",
        "sentence_llm_dp_info": "Entity 1 ('Dau measure') is the object of the verb 'evaluated', depending on 'evaluated' in the clause 'We evaluated the Dau measure'. Entity 2 ('quality measure') is also an object, depending on 'and' which connects it to 'Dau measure'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a coordinated structure connected by 'and'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Dau measure",
                "Metric"
            ],
            [
                "Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau measure') is part of the list of objects, depending on the verb 'evaluated' with 'We'. Entity 2 ('Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-') is also part of the list of objects, depending on the verb 'evaluated' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list of evaluated measures.",
        "sdp_path_text": "measure → measure → -RRB-",
        "sentence": "We evaluated the Dau measure and the Perceptual Evaluation of Speech Quality (PESQ).",
        "sentence_llm_dp_info": "Entity 1 ('Dau measure') is part of the object of the verb 'evaluated', coordinated with Entity 2 through the conjunction 'and'. Entity 2 ('Perceptual Evaluation of Speech Quality (PESQ)') is also part of the object of the verb 'evaluated', coordinated with Entity 1 through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a coordinated structure under the verb 'evaluated'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "glimpse proportion",
                "Metric"
            ],
            [
                "Speech Intelligibility Index -LRB- SII -RRB-",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is one of the objects in a list, depending on the conjunction 'and' that connects it with other items in the list. Entity 2 ('Speech Intelligibility Index -LRB- SII -RRB-') is also an object in the same list, similarly depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list of objects being evaluated.",
        "sdp_path_text": "proportion → Index",
        "sentence": "The glimpse proportion and the Speech Intelligibility Index (SII) were evaluated.",
        "sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is a conjunct, depending on 'and' with 'Speech Intelligibility Index (SII)'. Entity 2 ('Speech Intelligibility Index (SII)') is also a conjunct, depending on 'and' with 'glimpse proportion'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and both serve as subjects of the verb 'were evaluated'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "glimpse proportion",
                "Metric"
            ],
            [
                "quality measure",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is part of a list of objects, depending on the verb 'evaluated'. Entity 2 ('quality measure') is also an object in the same list, depending on the conjunction 'and' which connects it to the rest of the list. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list of objects being evaluated.",
        "sdp_path_text": "proportion → measure → measure",
        "sentence": "The glimpse proportion is one of the measures, while the Perceptual Evaluation of Speech Quality (PESQ) is a quality measure.",
        "sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is the subject, depending on the verb 'is' in the clause 'The glimpse proportion is one of the measures'. Entity 2 ('quality measure') is the subject complement, depending on 'is' in the clause 'PESQ is a quality measure'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in separate clauses of the sentence."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "glimpse proportion",
                "Metric"
            ],
            [
                "Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is part of a list of objects, depending on the verb 'evaluated' with 'We'. Entity 2 ('Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-') is also part of the same list of objects, depending on the conjunction 'and' which connects it to the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list being evaluated.",
        "sdp_path_text": "proportion → measure → measure → -RRB-",
        "sentence": "The glimpse proportion and the Perceptual Evaluation of Speech Quality (PESQ) are measures.",
        "sentence_llm_dp_info": "Entity 1 ('glimpse proportion') is a conjunct, depending on 'are' as part of the list of subjects. Entity 2 ('Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-') is also a conjunct, depending on 'are' as part of the same list of subjects. There is no direct dependency between Entity 1 and Entity 2; both are coordinated subjects in the sentence."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Speech Intelligibility Index -LRB- SII -RRB-",
                "Metric"
            ],
            [
                "quality measure",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Speech Intelligibility Index -LRB- SII -RRB-') is part of a coordinated list of objects, depending on the verb 'evaluated'. Entity 2 ('quality measure') is also part of the same coordinated list of objects, depending on the verb 'evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list of objects being evaluated.",
        "sdp_path_text": "Index → proportion → measure → measure",
        "sentence": "The Speech Intelligibility Index (SII) is one of the intelligibility measures, distinct from the quality measure.",
        "sentence_llm_dp_info": "Entity 1 ('Speech Intelligibility Index (SII)') is the subject, depending on the verb 'is'. Entity 2 ('quality measure') is the object of the preposition 'from', depending on 'distinct'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'distinct from'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Speech Intelligibility Index -LRB- SII -RRB-",
                "Metric"
            ],
            [
                "Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Speech Intelligibility Index -LRB- SII -RRB-') is one of the objects in a list, depending on the conjunction 'and' which connects it to other intelligibility measures in the sentence. Entity 2 ('Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-') is also an object in the list, depending on the conjunction 'and' which connects it to the quality measure. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger list of measures being evaluated.",
        "sdp_path_text": "Index → proportion → measure → measure → -RRB-",
        "sentence": "The Speech Intelligibility Index (SII) and the Perceptual Evaluation of Speech Quality (PESQ) were evaluated as measures.",
        "sentence_llm_dp_info": "Entity 1 ('Speech Intelligibility Index (SII)') is a conjunct, depending on the conjunction 'and' with 'Perceptual Evaluation of Speech Quality (PESQ)'. Entity 2 ('Perceptual Evaluation of Speech Quality (PESQ)') is also a conjunct, depending on the same conjunction 'and' with 'Speech Intelligibility Index (SII)'. There is no direct dependency between Entity 1 and Entity 2; they are coordinated together as part of the subject of the sentence, both depending on the verb 'were evaluated'."
    },
    {
        "raw_sentence": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .",
        "ner_pair": [
            [
                "Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-",
                "Metric"
            ],
            [
                "quality measure",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB-') is an appositive, depending on 'measure' with 'quality measure'. Entity 2 ('quality measure') is the object of the preposition 'and', depending on 'evaluated' with 'We'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 specifies or renames Entity 2.",
        "sdp_path_text": "-RRB- → measure",
        "sentence": "Perceptual Evaluation of Speech Quality (PESQ) is a quality measure.",
        "sentence_llm_dp_info": "Entity 1 ('Perceptual Evaluation of Speech Quality (PESQ)') is the subject, depending on the verb 'is'. Entity 2 ('quality measure') is the predicate nominative, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'PESQ' is described as being a 'quality measure'."
    },
    {
        "raw_sentence": "For the generation of synthesized speech we used a state of the art HMM-based speech synthesis system .",
        "ner_pair": [
            [
                "HMM-based speech synthesis system",
                "Method"
            ],
            [
                "generation of synthesized speech",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('HMM-based speech synthesis system') is the object, depending on the verb 'used'. Entity 2 ('generation of synthesized speech') is the object of the preposition 'For', depending on 'For' in the phrase 'For the generation of synthesized speech'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose expressed by the preposition 'For'.",
        "sdp_path_text": "system → used → For → generation",
        "sentence": "A HMM-based speech synthesis system was used for the generation of synthesized speech.",
        "sentence_llm_dp_info": "Entity 1 ('HMM-based speech synthesis system') is the subject, depending on the passive verb 'was used'. Entity 2 ('generation of synthesized speech') is the object of the preposition 'for', depending on 'for' in the phrase 'for the generation of synthesized speech'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The noisy conditions comprised four additive noises .",
        "ner_pair": [
            [
                "additive noises",
                "OtherScientificTerm"
            ],
            [
                "noisy conditions",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('additive noises') is the object, depending on the verb 'comprised'. Entity 2 ('noisy conditions') is the subject, depending on the verb 'comprised'. There is a direct dependency between Entity 1 and Entity 2, where 'additive noises' is the direct object of the verb 'comprised' that has 'noisy conditions' as its subject.",
        "sdp_path_text": "noises → comprised → conditions",
        "sentence": "The noisy conditions comprised additive noises.",
        "sentence_llm_dp_info": "Entity 1 ('additive noises') is the subject complement, depending on the verb 'comprised'. Entity 2 ('noisy conditions') is the subject, depending on the verb 'comprised'. There is a direct dependency between Entity 1 and Entity 2, as 'additive noises' directly complements 'noisy conditions' in the sentence."
    },
    {
        "raw_sentence": "The measures were compared with subjective intelligibility scores obtained in listening tests .",
        "ner_pair": [
            [
                "measures",
                "Generic"
            ],
            [
                "subjective intelligibility scores",
                "Metric"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'compared'. Entity 2 ('subjective intelligibility scores') is the object of the preposition 'with', depending on 'with' in the phrase 'with subjective intelligibility scores'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'compared' and the preposition 'with'.",
        "sdp_path_text": "measures → compared → with → scores",
        "sentence": "The measures were compared with subjective intelligibility scores.",
        "sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'compared'. Entity 2 ('subjective intelligibility scores') is the object of the preposition 'with', depending on 'with' in the phrase 'with subjective intelligibility scores'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "Dau",
                "Metric"
            ],
            [
                "glimpse measures",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau') is part of a coordination, depending on 'and' with 'glimpse measures'. Entity 2 ('glimpse measures') is also part of the same coordination, depending on 'and' with 'Dau'. Both are objects of the preposition 'the', which modifies the noun 'predictors'. There is a direct dependency between Entity 1 and Entity 2 through the coordinating conjunction 'and'.",
        "sdp_path_text": "Dau → measures",
        "sentence": "The Dau and glimpse measures are the best predictors of intelligibility.",
        "sentence_llm_dp_info": "Entity 1 ('Dau') is part of a compound noun, depending on 'measures' with 'and'. Entity 2 ('glimpse measures') is the subject, depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected as parts of a coordinated subject."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "Dau",
                "Metric"
            ],
            [
                "predictors of intelligibility",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau') is part of a conjunction, depending on the coordinating conjunction 'and' with 'glimpse measures'. Entity 2 ('predictors of intelligibility') is the complement of the verb 'be', depending on the verb 'be' in the clause 'to be the best predictors of intelligibility'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause 'to be the best predictors of intelligibility' where 'Dau' (along with 'glimpse measures') is described as being one of the 'best predictors of intelligibility'.",
        "sdp_path_text": "Dau → be → predictors",
        "sentence": "The Dau measure is one of the best predictors of intelligibility.",
        "sentence_llm_dp_info": "Entity 1 ('Dau') is part of the compound noun 'Dau measure', which serves as the subject, depending on the verb 'is'. Entity 2 ('predictors of intelligibility') is the complement, depending on the verb 'is' and further modified by the prepositional phrase 'of intelligibility'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of the larger nominal structure where 'Dau measure' is identified as being among 'the best predictors of intelligibility'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "correlations",
                "Metric"
            ],
            [
                "Dau",
                "Metric"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('correlations') is the subject, depending on the preposition 'of' with 'with'. Entity 2 ('Dau') is part of a compound noun, depending on the conjunction 'and' with 'glimpse measures'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the predicate 'to be the best predictors of intelligibility' and the prepositional phrase 'with correlations of around 0.83 to subjective scores'.",
        "sdp_path_text": "correlations → with → be → Dau",
        "sentence": "Correlations with Dau are around 0.83.",
        "sentence_llm_dp_info": "Entity 1 ('correlations') is the subject, depending on the verb 'are'. Entity 2 ('Dau') is the object of the preposition 'with', depending on 'with' in the phrase 'with Dau'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "Dau",
                "Metric"
            ],
            [
                "subjective scores",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dau') is part of a compound noun, depending on 'measures' with 'and'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'correlations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the predicate that describes their relationship in terms of predictors and correlations.",
        "sdp_path_text": "Dau → be → with → correlations → of → 0.83 → to → scores",
        "sentence": "The Dau measure shows strong correlation with subjective scores.",
        "sentence_llm_dp_info": "Entity 1 ('Dau') is part of the noun phrase 'The Dau measure', which acts as the subject, depending on the verb 'shows'. Entity 2 ('subjective scores') is the object, depending on the verb 'shows' in the phrase 'shows strong correlation with subjective scores'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'shows' and the preposition 'with'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "glimpse measures",
                "Metric"
            ],
            [
                "predictors of intelligibility",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('glimpse measures') is part of a coordination, depending on 'and' with 'Dau'. Entity 2 ('predictors of intelligibility') is the complement of the verb 'be', depending on 'be' in the clause 'to be the best predictors of intelligibility'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger structure where 'glimpse measures' is one of the subjects being described as 'the best predictors of intelligibility'.",
        "sdp_path_text": "measures → Dau → be → predictors",
        "sentence": "Glimpse measures are among the best predictors of intelligibility.",
        "sentence_llm_dp_info": "Entity 1 ('glimpse measures') is the subject, depending on the copula 'are'. Entity 2 ('predictors of intelligibility') is the predicate nominative, depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, as they are linked by the copula 'are' to form the main clause of the sentence."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "correlations",
                "Metric"
            ],
            [
                "glimpse measures",
                "Metric"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('correlations') is the subject, depending on the preposition 'of' with 'around'. Entity 2 ('glimpse measures') is the object of the preposition 'of', depending on 'predictors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'predictors' and the preposition 'of'.",
        "sdp_path_text": "correlations → with → be → Dau → measures",
        "sentence": "Correlations with the glimpse measures are around 0.83.",
        "sentence_llm_dp_info": "Entity 1 ('correlations') is the subject, depending on the verb 'are'. Entity 2 ('glimpse measures') is the object of the preposition 'with', depending on 'with' in the phrase 'with the glimpse measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "glimpse measures",
                "Metric"
            ],
            [
                "subjective scores",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('glimpse measures') is part of a coordination with 'Dau', together forming the subject complement of 'the results', depending on the verb 'show'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'correlations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the correlation.",
        "sdp_path_text": "measures → Dau → be → with → correlations → of → 0.83 → to → scores",
        "sentence": "Glimpse measures have correlations of around 0.83 to subjective scores.",
        "sentence_llm_dp_info": "Entity 1 ('glimpse measures') is the subject, depending on the verb 'have'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'to' in the phrase 'to subjective scores'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase indicating the correlation."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "predictors of intelligibility",
                "Method"
            ],
            [
                "correlations",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('predictors of intelligibility') is the subject complement, depending on the verb 'be' in the clause 'to be the best predictors of intelligibility'. Entity 2 ('correlations') is the subject of the prepositional phrase 'with correlations of around 0.83 to subjective scores', depending on the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same larger clause describing the results.",
        "sdp_path_text": "predictors → be → with → correlations",
        "sentence": "The predictors of intelligibility have correlations of around 0.83.",
        "sentence_llm_dp_info": "Entity 1 ('predictors of intelligibility') is the subject, depending on the verb 'have'. Entity 2 ('correlations') is the object, depending on 'have' with 'predictors of intelligibility'. There is a direct dependency between Entity 1 and Entity 2, as 'correlations' is the direct object of the verb 'have' which is associated with 'predictors of intelligibility'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "predictors of intelligibility",
                "Method"
            ],
            [
                "subjective scores",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('predictors of intelligibility') is the subject complement, depending on the verb 'be' with 'show'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'to' in the phrase 'correlations of around 0.83 to subjective scores'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence structure, where 'predictors of intelligibility' are described as having high correlations to 'subjective scores'.",
        "sdp_path_text": "predictors → be → with → correlations → of → 0.83 → to → scores",
        "sentence": "The predictors of intelligibility have correlations of around 0.83 to subjective scores.",
        "sentence_llm_dp_info": "Entity 1 ('predictors of intelligibility') is the subject, depending on the verb 'have'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'to' in the phrase 'to subjective scores'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "The results show the Dau and the glimpse measures to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .",
        "ner_pair": [
            [
                "correlations",
                "Metric"
            ],
            [
                "subjective scores",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('correlations') is the subject, depending on the verb 'be' with 'to be'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'to' in the phrase 'to subjective scores'. There is a direct dependency between Entity 1 and Entity 2, as 'correlations' is directly related to 'subjective scores' through the preposition 'to'.",
        "sdp_path_text": "correlations → of → 0.83 → to → scores",
        "sentence": "Correlations of 0.83 to subjective scores were found.",
        "sentence_llm_dp_info": "Entity 1 ('correlations') is the subject, depending on the verb 'found'. Entity 2 ('subjective scores') is the object of the preposition 'to', depending on 'to' in the phrase 'to subjective scores'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "measures",
                "Generic"
            ],
            [
                "predictions of intelligibility",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'gave'. Entity 2 ('predictions of intelligibility') is the object, depending on 'less accurate' which modifies it, and is part of the larger noun phrase 'less accurate predictions of intelligibility'. There is a direct dependency between Entity 1 and Entity 2, where 'measures' is the subject that 'gave' the 'less accurate predictions of intelligibility'.",
        "sdp_path_text": "measures → gave → predictions",
        "sentence": "Measures gave predictions of intelligibility.",
        "sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'gave'. Entity 2 ('predictions of intelligibility') is the object, depending on the verb 'gave'. There is a direct dependency between Entity 1 and Entity 2, as 'measures' directly gives 'predictions of intelligibility'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "measures",
                "Generic"
            ],
            [
                "synthetic speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'gave'. Entity 2 ('synthetic speech') is the object of the preposition 'of', depending on 'predictions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'gave less accurate predictions of intelligibility for'.",
        "sdp_path_text": "measures → gave → predictions → for → speech",
        "sentence": "Measures gave less accurate predictions for synthetic speech.",
        "sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'gave'. Entity 2 ('synthetic speech') is the object of the preposition 'for', depending on 'for' in the phrase 'for synthetic speech'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gave' and the preposition 'for'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "measures",
                "Generic"
            ],
            [
                "natural speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'gave'. Entity 2 ('natural speech') is the object of the preposition 'for', depending on 'found'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparative structure where 'measures' are compared against what has been found for 'natural speech'.",
        "sdp_path_text": "measures → gave → predictions → found → for → speech",
        "sentence": "Measures gave less accurate predictions for natural speech.",
        "sentence_llm_dp_info": "Entity 1 ('measures') is the subject, depending on the verb 'gave'. Entity 2 ('natural speech') is the object of the preposition 'for', depending on 'for' in the phrase 'for natural speech'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gave' and the preposition 'for'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "SII measure",
                "Metric"
            ],
            [
                "measures",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('SII measure') is the subject complement, depending on the conjunction 'and' which links it to the main clause, and it modifies the noun 'measure'. Entity 2 ('measures') is the subject, depending on the verb 'gave'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, with Entity 1 being part of an additional detail provided after the semicolon.",
        "sdp_path_text": "measure → gave → measures",
        "sentence": "The SII measure gave less accurate predictions than other measures.",
        "sentence_llm_dp_info": "Entity 1 ('SII measure') is the subject, depending on the verb 'gave'. Entity 2 ('measures') is the object of the preposition 'than', depending on 'than' in the phrase 'than other measures'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the comparative structure involving 'than'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "synthetic speech",
                "Material"
            ],
            [
                "predictions of intelligibility",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('synthetic speech') is the object of the preposition 'of', depending on 'predictions'. Entity 2 ('predictions of intelligibility') is the subject complement, depending on 'gave' with 'measures'. There is a direct dependency between Entity 1 and Entity 2, as 'synthetic speech' modifies 'predictions of intelligibility' through the preposition 'of'.",
        "sdp_path_text": "speech → for → predictions",
        "sentence": "Predictions of intelligibility were less accurate for synthetic speech.",
        "sentence_llm_dp_info": "Entity 1 ('synthetic speech') is the object, depending on 'for' with 'accurate'. Entity 2 ('predictions of intelligibility') is the subject, depending on the verb 'were'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adverbial phrase 'for synthetic speech' which modifies the predicate 'were less accurate'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "predictions of intelligibility",
                "Task"
            ],
            [
                "natural speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('predictions of intelligibility') is the object of the verb 'gave', depending on 'measures'. It also has a prepositional modifier 'of intelligibility' that specifies what the predictions are about. Entity 2 ('natural speech') is the object of the preposition 'for', depending on 'found'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparison clause that contrasts 'synthetic speech' with 'natural speech'.",
        "sdp_path_text": "predictions → found → for → speech",
        "sentence": "Predictions of intelligibility were found for natural speech.",
        "sentence_llm_dp_info": "Entity 1 ('predictions of intelligibility') is the subject, depending on the verb 'were found'. Entity 2 ('natural speech') is the object of the preposition 'for', depending on 'for' in the phrase 'for natural speech'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "predictions of intelligibility",
                "Task"
            ],
            [
                "SII measure",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('predictions of intelligibility') is the object of the verb 'gave', depending on 'measures'. Entity 2 ('SII measure') is the subject complement, depending on the verb 'be' (implied in the phrase 'in particular the SII measure'). There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.",
        "sdp_path_text": "predictions → gave → measure",
        "sentence": "Predictions of intelligibility were less accurate for the SII measure.",
        "sentence_llm_dp_info": "Entity 1 ('predictions of intelligibility') is the subject, depending on the verb 'were'. Entity 2 ('SII measure') is the object of the preposition 'for', depending on 'for' in the phrase 'for the SII measure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "synthetic speech",
                "Material"
            ],
            [
                "natural speech",
                "Material"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('synthetic speech') is the object of the preposition 'of', depending on 'predictions'. Entity 2 ('natural speech') is also the object of the preposition 'for', depending on 'found'. There is no direct dependency between Entity 1 and Entity 2; both are related to the concept of 'predictions' and 'found' respectively, indicating a comparison between the two.",
        "sdp_path_text": "speech → for → predictions → found → for → speech",
        "sentence": "Predictions for synthetic speech were less accurate than those for natural speech.",
        "sentence_llm_dp_info": "Entity 1 ('synthetic speech') is the object of the preposition 'for', depending on 'for' in the phrase 'for synthetic speech'. Entity 2 ('natural speech') is also the object of the preposition 'for', depending on 'for' in the phrase 'for natural speech'. There is no direct dependency between Entity 1 and Entity 2; both are compared through the comparative structure involving 'less accurate than'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "synthetic speech",
                "Material"
            ],
            [
                "SII measure",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('synthetic speech') is the object of the preposition 'of', depending on 'predictions'. Entity 2 ('SII measure') is the subject complement, depending on the verb 'be' (in the form of 'is') in the phrase 'the SII measure is'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing the comparison of prediction accuracy.",
        "sdp_path_text": "speech → for → predictions → gave → measure",
        "sentence": "The SII measure gave less accurate predictions for synthetic speech.",
        "sentence_llm_dp_info": "Entity 1 ('synthetic speech') is the object, depending on the preposition 'for', which modifies 'predictions'. Entity 2 ('SII measure') is the subject, depending on the verb 'gave'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'predictions' and the preposition 'for'."
    },
    {
        "raw_sentence": "All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech ; in particular the SII measure .",
        "ner_pair": [
            [
                "natural speech",
                "Material"
            ],
            [
                "SII measure",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('natural speech') is the object of the preposition 'for', depending on 'found'. Entity 2 ('SII measure') is the subject of the clause, depending on 'the' and modified by 'in particular'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of predictions of intelligibility for different types of speech.",
        "sdp_path_text": "speech → for → found → predictions → gave → measure",
        "sentence": "Predictions for natural speech were more accurate with the SII measure.",
        "sentence_llm_dp_info": "Entity 1 ('natural speech') is the object of the preposition 'for', depending on 'for' in the phrase 'for natural speech'. Entity 2 ('SII measure') is the object of the preposition 'with', depending on 'with' in the phrase 'with the SII measure'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where predictions about Entity 1 are influenced by the use of Entity 2."
    },
    {
        "raw_sentence": "In additional experiments , we processed the synthesized speech by an ideal binary mask before adding noise .",
        "ner_pair": [
            [
                "ideal binary mask",
                "Method"
            ],
            [
                "synthesized speech",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ideal binary mask') is the object of the preposition 'by', depending on 'processed'. Entity 2 ('synthesized speech') is the object, depending on 'processed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'synthesized speech' is being processed 'by an ideal binary mask'.",
        "sdp_path_text": "mask → by → processed → speech",
        "sentence": "The synthesized speech was processed by an ideal binary mask.",
        "sentence_llm_dp_info": "Entity 1 ('ideal binary mask') is the object of the preposition 'by', depending on 'processed'. Entity 2 ('synthesized speech') is the subject, depending on the verb 'was processed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'was processed' where Entity 2 is the subject being acted upon and Entity 1 is the agent performing the action."
    },
    {
        "raw_sentence": "The Glimpse measure gave the most accurate intelligibility predictions in this situation .",
        "ner_pair": [
            [
                "Glimpse measure",
                "Metric"
            ],
            [
                "intelligibility predictions",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Glimpse measure') is the subject, depending on the verb 'gave'. Entity 2 ('intelligibility predictions') is the object, depending on the verb 'gave'. There is a direct dependency between Entity 1 and Entity 2, as 'Glimpse measure' is the subject that performs the action of giving 'intelligibility predictions'.",
        "sdp_path_text": "measure → gave → predictions",
        "sentence": "The Glimpse measure gave accurate intelligibility predictions.",
        "sentence_llm_dp_info": "Entity 1 ('Glimpse measure') is the subject, depending on the verb 'gave'. Entity 2 ('intelligibility predictions') is the object, depending on the verb 'gave'. There is a direct dependency between Entity 1 and Entity 2, as 'Glimpse measure' directly provides 'intelligibility predictions'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "'' graphics for vision '' approach",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('reconstruction') is part of the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where the approach is proposed to address problems involving reconstruction.",
        "sdp_path_text": "approach → proposed → address → problem → of → reconstruction",
        "sentence": "A 'graphics for vision' approach is proposed to address the problem of reconstruction.",
        "sentence_llm_dp_info": "Entity 1 (''graphics for vision'' approach') is the subject, depending on the verb 'proposed'. Entity 2 ('reconstruction') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'to address the problem of reconstruction'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "'' graphics for vision '' approach",
                "Method"
            ],
            [
                "large and imperfect data set",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('large and imperfect data set') is the object of the preposition 'from', depending on 'reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'proposed' and the phrase 'reconstruction from a large and imperfect data set'.",
        "sdp_path_text": "approach → proposed → address → problem → of → reconstruction → from → set",
        "sentence": "A 'graphics for vision' approach is proposed to address the problem of reconstruction from a large and imperfect data set.",
        "sentence_llm_dp_info": "Entity 1 (''graphics for vision'' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('large and imperfect data set') is the object of the preposition 'from', depending on 'from' in the phrase 'from a large and imperfect data set'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "'' graphics for vision '' approach",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('reconstruction') is part of the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose described in the sentence, where the approach aims to address issues related to reconstruction.",
        "sdp_path_text": "approach → proposed → address → problem → of → reconstruction",
        "sentence": "A 'graphics for vision' approach is proposed to address the problem of reconstruction.",
        "sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('reconstruction') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure 'the problem of reconstruction'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "'' graphics for vision '' approach",
                "Method"
            ],
            [
                "tensor voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('tensor voting') is part of a nominal compound, depending on 'ROD-TV' which is an appositive modifier of 'reconstruction on demand'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the proposed approach and the method (ROD-TV) used for reconstruction.",
        "sdp_path_text": "approach → proposed → address → problem → of → reconstruction → reconstruction → by → voting",
        "sentence": "A 'graphics for vision' approach is proposed to address reconstruction problems using tensor voting.",
        "sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('tensor voting') is the object of the preposition 'using', depending on 'using' in the phrase 'using tensor voting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'using'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "'' graphics for vision '' approach",
                "Method"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('graphics for vision' approach) is the subject, depending on the verb 'proposed'. Entity 2 ('ROD-TV') is an appositive, providing additional information about the noun phrase 'reconstruction on demand by tensor voting'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same descriptive context, where Entity 2 further specifies a particular method within the scope of the approach described by Entity 1.",
        "sdp_path_text": "approach → proposed → address → problem → of → reconstruction → reconstruction → ROD",
        "sentence": "'Graphics for vision' approach is proposed to address reconstruction problems, including ROD-TV.",
        "sentence_llm_dp_info": "Entity 1 (''graphics for vision'' approach') is the subject, depending on the verb 'proposed'. Entity 2 ('ROD-TV') is part of the list of objects, depending on the preposition 'including'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'including' which links 'reconstruction problems' to the list that includes 'ROD-TV'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "large and imperfect data set",
                "Material"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object of the preposition 'from', depending on 'reconstruction'. Entity 2 ('reconstruction') is part of the compound noun 'reconstruction from a large and imperfect data set', acting as the head noun, and it also depends on 'address' as the object of the clause 'to address the problem of reconstruction'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 modifies Entity 2, specifying the type of data involved in the reconstruction process.",
        "sdp_path_text": "set → from → reconstruction",
        "sentence": "Reconstruction is addressed from a large and imperfect data set.",
        "sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object, depending on the preposition 'from', which modifies the verb 'addressed'. Entity 2 ('reconstruction') is the subject, depending on the verb 'is addressed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "tensor voting",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tensor voting') is part of a compound noun, depending on 'reconstruction' with the preposition 'by' in the phrase 'reconstruction on demand by tensor voting'. Entity 2 ('reconstruction') is the object of the preposition 'of', depending on 'problem' in the phrase 'the problem of reconstruction'. There is a direct dependency between Entity 1 and Entity 2, as 'tensor voting' modifies 'reconstruction' in the context of the method being described.",
        "sdp_path_text": "voting → by → reconstruction → reconstruction",
        "sentence": "Reconstruction is achieved by tensor voting.",
        "sentence_llm_dp_info": "Entity 1 ('tensor voting') is the instrument, depending on the verb 'achieved'. Entity 2 ('reconstruction') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, where 'tensor voting' is used as the means by which 'reconstruction' is achieved."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "ROD-TV",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the appositive, depending on 'reconstruction' which it renames or specifies further. Entity 2 ('reconstruction') is part of the compound noun 'reconstruction on demand by tensor voting', which is the object of the preposition 'of', depending on 'problem'. There is a direct dependency between Entity 1 and Entity 2, where 'ROD-TV' serves as an appositive to 'reconstruction'.",
        "sdp_path_text": "ROD → reconstruction → reconstruction",
        "sentence": "ROD-TV addresses reconstruction on demand.",
        "sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'addresses'. Entity 2 ('reconstruction') is the object of the preposition 'on', depending on 'on' in the phrase 'on demand'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on demand'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "large and imperfect data set",
                "Material"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object of the preposition 'from', depending on 'problem'. Entity 2 ('reconstruction') is part of a compound noun, depending on 'problem' as part of 'the problem of reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase describing the problem being addressed.",
        "sdp_path_text": "set → from → reconstruction",
        "sentence": "Reconstruction addresses the problem from a large and imperfect data set.",
        "sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object, depending on the preposition 'from' which modifies 'problem'. Entity 2 ('reconstruction') is the subject, depending on 'addresses' as the verb of the sentence. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'addresses' and the prepositional phrase 'from a large and imperfect data set'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "large and imperfect data set",
                "Material"
            ],
            [
                "tensor voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object of the preposition 'from', depending on 'reconstruction'. Entity 2 ('tensor voting') is part of a compound noun, depending on 'ROD-TV' as a modifier. There is no direct dependency between Entity 1 and Entity 2; both are related to the concept of 'reconstruction', with Entity 1 being the source of the problem and Entity 2 being a method used in the solution (ROD-TV).",
        "sdp_path_text": "set → from → reconstruction → reconstruction → by → voting",
        "sentence": "Reconstruction from a large and imperfect data set is addressed by tensor voting.",
        "sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object of the preposition 'from', depending on 'Reconstruction'. Entity 2 ('tensor voting') is the subject complement, depending on 'is addressed by'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the method used to address the reconstruction challenge."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "large and imperfect data set",
                "Material"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object of the preposition 'from', depending on 'reconstruction'. Entity 2 ('ROD-TV') is an appositive, depending on 'voting' and further specifying the method 'reconstruction on demand by tensor voting'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of the methods described for addressing the problem of reconstruction.",
        "sdp_path_text": "set → from → reconstruction → reconstruction → ROD",
        "sentence": "Reconstruction from a large and imperfect data set is addressed by ROD-TV.",
        "sentence_llm_dp_info": "Entity 1 ('large and imperfect data set') is the object of the preposition 'from', depending on 'Reconstruction'. Entity 2 ('ROD-TV') is the subject complement, depending on the verb 'is addressed by'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is being addressed and how it is addressed."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "tensor voting",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tensor voting') is part of a compound noun, depending on 'ROD-TV' as a modifier. Entity 2 ('reconstruction') is the subject, depending on the verb 'address' through the prepositional phrase 'to address the problem of reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, where 'reconstruction on demand by tensor voting' (ROD-TV) is described as a solution.",
        "sdp_path_text": "voting → by → reconstruction → reconstruction",
        "sentence": "Reconstruction on demand uses tensor voting.",
        "sentence_llm_dp_info": "Entity 1 ('tensor voting') is the object, depending on the verb 'uses'. Entity 2 ('reconstruction') is part of the compound subject, depending on 'on' in the phrase 'on demand'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "ROD-TV",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the appositive, depending on the noun 'reconstruction'. Entity 2 ('reconstruction') is the object of the preposition 'of', depending on 'problem'. There is a direct dependency between Entity 1 and Entity 2, where 'ROD-TV' provides a specific name for the type of 'reconstruction' being discussed.",
        "sdp_path_text": "ROD → reconstruction → reconstruction",
        "sentence": "ROD-TV addresses reconstruction.",
        "sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'addresses'. Entity 2 ('reconstruction') is the object, depending on 'addresses' with 'ROD-TV'. There is a direct dependency between Entity 1 and Entity 2, as 'reconstruction' is directly addressed by 'ROD-TV'."
    },
    {
        "raw_sentence": "A '' graphics for vision '' approach is proposed to address the problem of reconstruction from a large and imperfect data set : reconstruction on demand by tensor voting , or ROD-TV .",
        "ner_pair": [
            [
                "tensor voting",
                "Method"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tensor voting') is part of a compound noun, depending on 'reconstruction' with the prepositional phrase 'on demand by tensor voting'. Entity 2 ('ROD-TV') is an abbreviation, depending on 'reconstruction' as an appositive that renames or explains 'reconstruction on demand by tensor voting'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same nominal structure describing the method of reconstruction.",
        "sdp_path_text": "voting → by → reconstruction → ROD",
        "sentence": "Reconstruction on demand by tensor voting, or ROD-TV, is proposed.",
        "sentence_llm_dp_info": "Entity 1 ('tensor voting') is part of a compound noun, depending on the conjunction 'by' in the phrase 'by tensor voting'. Entity 2 ('ROD-TV') is the subject complement, depending on the copula verb 'is' in the phrase 'is proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'ROD-TV' is described as being proposed, and 'tensor voting' is a method used in this proposal."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "efficiency",
                "Metric"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('efficiency') is the object of the verb 'delivers', depending on 'ROD-TV'. Entity 2 ('ROD-TV') is the subject, depending on the verb 'delivers'. There is a direct dependency between Entity 1 and Entity 2, as 'ROD-TV' is delivering 'efficiency'.",
        "sdp_path_text": "efficiency → delivers → ROD",
        "sentence": "ROD-TV delivers good efficiency.",
        "sentence_llm_dp_info": "Entity 1 ('efficiency') is the object, depending on the verb 'delivers'. Entity 2 ('ROD-TV') is the subject, depending on the verb 'delivers'. There is a direct dependency between Entity 1 and Entity 2, as 'ROD-TV' delivers 'efficiency'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "robust-ness",
                "Metric"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust-ness') is part of a conjunction, depending on the conjunction 'and' with 'efficiency'. Entity 2 ('ROD-TV') is the subject, depending on the verb 'delivers'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'ROD-TV' is the subject delivering both 'efficiency' and 'robust-ness'.",
        "sdp_path_text": "robust → efficiency → delivers → ROD",
        "sentence": "ROD-TV delivers robustness and efficiency.",
        "sentence_llm_dp_info": "Entity 1 ('robustness') is the object, depending on the verb 'delivers'. Entity 2 ('ROD-TV') is the subject, depending on the verb 'delivers'. There is a direct dependency between Entity 1 and Entity 2, as 'ROD-TV' delivers 'robustness'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "ROD-TV",
                "Method"
            ],
            [
                "primitive connectivity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'delivers'. Entity 2 ('primitive connectivity') is part of a list of items, depending on the preposition 'to' within the phrase 'adapting to a continuum of primitive connectivity'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase that describes what ROD-TV adapts to.",
        "sdp_path_text": "ROD → delivers → by → adapting → to → continuum → of → connectivity",
        "sentence": "ROD-TV delivers by adapting to a continuum of primitive connectivity.",
        "sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'delivers'. Entity 2 ('primitive connectivity') is the object of the preposition 'of', depending on 'continuum'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'adapting' and the prepositional phrase 'to a continuum of primitive connectivity'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "ROD-TV",
                "Method"
            ],
            [
                "view dependence",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'delivers'. Entity 2 ('view dependence') is part of a list of objects, depending on the preposition 'of' within the phrase 'of primitive connectivity, view dependence, and levels of detail'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase describing what ROD-TV adapts to.",
        "sdp_path_text": "ROD → delivers → by → adapting → to → continuum → of → connectivity → dependence",
        "sentence": "ROD-TV delivers by adapting to a continuum of connectivity and view dependence.",
        "sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'delivers'. Entity 2 ('view dependence') is part of the object complement, depending on 'continuum' within the prepositional phrase 'of connectivity and view dependence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'ROD-TV' is the subject performing the action of delivering, which involves adapting to the 'continuum' that includes 'view dependence'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "ROD-TV",
                "Method"
            ],
            [
                "levels of detail -LRB- LOD -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'delivers'. Entity 2 ('levels of detail -LRB- LOD -RRB-') is part of a list of items, depending on the preposition 'of' within the prepositional phrase 'of primitive connectivity, view dependence, and levels of detail -LRB- LOD -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the verb 'adapting'.",
        "sdp_path_text": "ROD → delivers → by → adapting → to → continuum → -LRB-",
        "sentence": "ROD-TV delivers by adapting to a continuum including levels of detail (LOD).",
        "sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the subject, depending on the verb 'delivers'. Entity 2 ('levels of detail (LOD)') is part of the object complement, depending on the preposition 'including' within the phrase 'including levels of detail (LOD)'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of 'delivering' which involves adapting to a continuum that includes Entity 2."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "robust-ness",
                "Metric"
            ],
            [
                "efficiency",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust-ness') is part of a coordination, depending on 'and' with 'good efficiency'. Entity 2 ('efficiency') is also part of the same coordination, depending on 'and' with 'robust-ness'. Both are objects of the verb 'delivers'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'.",
        "sdp_path_text": "robust → efficiency",
        "sentence": "ROD-TV delivers robustness and efficiency.",
        "sentence_llm_dp_info": "Entity 1 ('robustness') is the object, depending on the verb 'delivers' with 'ROD-TV'. Entity 2 ('efficiency') is also an object, depending on the same verb 'delivers' with 'ROD-TV'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same verb 'delivers'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "efficiency",
                "Metric"
            ],
            [
                "primitive connectivity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('efficiency') is part of the object complement, depending on the verb 'delivers' with 'ROD-TV'. Entity 2 ('primitive connectivity') is part of the prepositional phrase, depending on 'adapting' with 'to'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through different verbs and prepositions.",
        "sdp_path_text": "efficiency → delivers → by → adapting → to → continuum → of → connectivity",
        "sentence": "Efficiency is delivered by adapting to a continuum of primitive connectivity.",
        "sentence_llm_dp_info": "Entity 1 ('efficiency') is the subject, depending on the verb 'delivered'. Entity 2 ('primitive connectivity') is the object of the preposition 'to', depending on 'continuum'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'delivered' and the prepositional phrase 'by adapting to a continuum of primitive connectivity'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "efficiency",
                "Metric"
            ],
            [
                "view dependence",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('efficiency') is part of a compound noun, depending on the adjective 'good' and the conjunction 'and' which links it to 'robust-ness'. Entity 2 ('view dependence') is the object of the preposition 'of', depending on 'continuum'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the list of elements that ROD-TV adapts to, connected through the preposition 'of' and the conjunction 'and'.",
        "sdp_path_text": "efficiency → delivers → by → adapting → to → continuum → of → connectivity → dependence",
        "sentence": "ROD-TV delivers efficiency by adapting to a continuum of view dependence.",
        "sentence_llm_dp_info": "Entity 1 ('efficiency') is the object of the preposition 'by', depending on 'delivers' in the phrase 'delivers efficiency'. Entity 2 ('view dependence') is the object of the preposition 'of', depending on 'continuum' in the phrase 'continuum of view dependence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how ROD-TV operates."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "efficiency",
                "Metric"
            ],
            [
                "levels of detail -LRB- LOD -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('efficiency') is part of a coordinated object, depending on the verb 'delivers' with 'ROD-TV'. Entity 2 ('levels of detail -LRB- LOD -RRB-') is also part of a coordinated object, depending on the conjunction 'and' which connects it with other objects of adaptation. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of items that ROD-TV adapts to.",
        "sdp_path_text": "efficiency → delivers → by → adapting → to → continuum → -LRB-",
        "sentence": "ROD-TV delivers efficiency by adapting to a continuum including levels of detail.",
        "sentence_llm_dp_info": "Entity 1 ('efficiency') is the object of the preposition 'by', depending on the verb 'delivers'. Entity 2 ('levels of detail') is part of the noun phrase 'a continuum including levels of detail', where it is the object of the preposition 'including'. There is no direct dependency between Entity 1 and Entity 2; both are related through the verb 'delivers' and the structure of the sentence that describes how efficiency is achieved."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "robust-ness",
                "Metric"
            ],
            [
                "primitive connectivity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust-ness') is part of a conjunction, depending on 'and' with 'efficiency'. Entity 2 ('primitive connectivity') is the object of the preposition 'of', depending on 'continuum'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "robust → efficiency → delivers → by → adapting → to → continuum → of → connectivity",
        "sentence": "ROD-TV delivers robustness by adapting to a continuum of primitive connectivity.",
        "sentence_llm_dp_info": "Entity 1 ('robustness') is the object of the preposition 'by', depending on 'delivers'. Entity 2 ('primitive connectivity') is the object of the preposition 'to', depending on 'adapting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'delivers' and 'adapting' which form part of the same clause."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "robust-ness",
                "Metric"
            ],
            [
                "view dependence",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust-ness') is part of a conjunction, depending on 'and' with 'efficiency'. Entity 2 ('view dependence') is one of the objects of the preposition 'to', depending on 'adapting'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the characteristics that 'ROD-TV' adapts to.",
        "sdp_path_text": "robust → efficiency → delivers → by → adapting → to → continuum → of → connectivity → dependence",
        "sentence": "ROD-TV delivers robustness by adapting to view dependence.",
        "sentence_llm_dp_info": "Entity 1 ('robustness') is the object, depending on the verb 'delivers' with 'ROD-TV'. Entity 2 ('view dependence') is the object of the preposition 'to', depending on 'adapting' in the phrase 'adapting to view dependence'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'delivers' and the prepositional phrase 'adapting to view dependence'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "robust-ness",
                "Metric"
            ],
            [
                "levels of detail -LRB- LOD -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('robust-ness') is part of a conjunction, depending on the conjunction 'and' with 'good efficiency'. Entity 2 ('levels of detail -LRB- LOD -RRB-') is the last item in a list, depending on the preposition 'of' with 'continuum'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list described by the prepositional phrase 'by adapting to a continuum of...and levels of detail -LRB- LOD -RRB-.'\"",
        "sdp_path_text": "robust → efficiency → delivers → by → adapting → to → continuum → -LRB-",
        "sentence": "ROD-TV delivers robustness by adapting to a continuum of levels of detail.",
        "sentence_llm_dp_info": "Entity 1 ('robustness') is the object, depending on the verb 'delivers' with 'ROD-TV'. Entity 2 ('levels of detail') is the object of the preposition 'of', depending on 'continuum'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how robustness is delivered by adapting to different levels of detail."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "view dependence",
                "OtherScientificTerm"
            ],
            [
                "primitive connectivity",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('view dependence') is part of a list of items, depending on the conjunction 'and' with 'levels of detail'. Entity 2 ('primitive connectivity') is also part of a list of items, depending on the conjunction 'and' with 'view dependence'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a list connected by the conjunction 'and'.",
        "sdp_path_text": "dependence → connectivity",
        "sentence": "ROD-TV adapts to view dependence and primitive connectivity.",
        "sentence_llm_dp_info": "Entity 1 ('view dependence') is the object of the preposition 'to', depending on 'adapts' in the phrase 'adapts to view dependence'. Entity 2 ('primitive connectivity') is also the object of the preposition 'and', depending on 'to' in the phrase 'to view dependence and primitive connectivity'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the compound object of the preposition 'to'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "primitive connectivity",
                "OtherScientificTerm"
            ],
            [
                "levels of detail -LRB- LOD -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('primitive connectivity') is part of a list, depending on the verb 'adapting' through the preposition 'to'. Entity 2 ('levels of detail -LRB- LOD -RRB-') is also part of the same list, depending on the same verb 'adapting' through the same preposition 'to'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a list that the system adapts to.",
        "sdp_path_text": "connectivity → of → continuum → -LRB-",
        "sentence": "ROD-TV adapts to a continuum of primitive connectivity and levels of detail.",
        "sentence_llm_dp_info": "Entity 1 ('primitive connectivity') is part of a prepositional phrase, depending on 'to' with 'continuum'. Entity 2 ('levels of detail -LRB- LOD -RRB-') is also part of a prepositional phrase, depending on 'of' with 'detail'. There is no direct dependency between Entity 1 and Entity 2; both are elements within the prepositional phrases modifying 'continuum'."
    },
    {
        "raw_sentence": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .",
        "ner_pair": [
            [
                "levels of detail -LRB- LOD -RRB-",
                "OtherScientificTerm"
            ],
            [
                "view dependence",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('levels of detail -LRB- LOD -RRB-') is part of a list, depending on the conjunction 'and' with 'continuum of primitive connectivity' and 'view dependence'. Entity 2 ('view dependence') is also part of the same list, depending on the conjunction 'and' with 'continuum of primitive connectivity' and 'levels of detail -LRB- LOD -RRB-'. There is no direct dependency between Entity 1 and Entity 2; they are both elements in a list connected by the conjunction 'and'.",
        "sdp_path_text": "-LRB- → continuum → of → connectivity → dependence",
        "sentence": "Levels of detail adapt to a continuum of connectivity and view dependence.",
        "sentence_llm_dp_info": "Entity 1 ('levels of detail -LRB- LOD -RRB-') is the subject, depending on the verb 'adapt'. Entity 2 ('view dependence') is part of a compound noun phrase, depending on 'continuum' with the preposition 'of' in the phrase 'of connectivity and view dependence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'levels of detail' adapts to a 'continuum' that includes 'view dependence'."
    },
    {
        "raw_sentence": "Locally inferred surface elements are robust to noise and better capture local shapes .",
        "ner_pair": [
            [
                "Locally inferred surface elements",
                "OtherScientificTerm"
            ],
            [
                "noise",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Locally inferred surface elements') is the subject, depending on the verb 'are'. Entity 2 ('noise') is the object of the preposition 'to', depending on 'robust' in the phrase 'robust to noise'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.",
        "sdp_path_text": "elements → are → robust → to → noise",
        "sentence": "Locally inferred surface elements are robust to noise.",
        "sentence_llm_dp_info": "Entity 1 ('Locally inferred surface elements') is the subject, depending on the verb 'are'. Entity 2 ('noise') is the object of the preposition 'to', depending on 'robust'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'robust' and the preposition 'to'."
    },
    {
        "raw_sentence": "Locally inferred surface elements are robust to noise and better capture local shapes .",
        "ner_pair": [
            [
                "Locally inferred surface elements",
                "OtherScientificTerm"
            ],
            [
                "local shapes",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Locally inferred surface elements') is the subject, depending on the verb 'are'. Entity 2 ('local shapes') is the object, depending on 'capture' with 'better capture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' which indicates that Entity 1 has an effect on Entity 2.",
        "sdp_path_text": "elements → are → capture → shapes",
        "sentence": "Locally inferred surface elements capture local shapes.",
        "sentence_llm_dp_info": "Entity 1 ('Locally inferred surface elements') is the subject, depending on the verb 'capture'. Entity 2 ('local shapes') is the object, depending on the verb 'capture'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 captures Entity 2."
    },
    {
        "raw_sentence": "Locally inferred surface elements are robust to noise and better capture local shapes .",
        "ner_pair": [
            [
                "noise",
                "OtherScientificTerm"
            ],
            [
                "local shapes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('noise') is the object of the preposition 'to', depending on 'robust'. Entity 2 ('local shapes') is the object of the verb 'capture', depending on 'better capture'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "noise → to → robust → are → capture → shapes",
        "sentence": "Locally inferred elements are robust to noise and capture local shapes.",
        "sentence_llm_dp_info": "Entity 1 ('noise') is the object of the preposition 'to', depending on 'robust'. Entity 2 ('local shapes') is the object, depending on 'capture'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "By inferring per-vertex normals at sub-voxel precision on the fly , we can achieve interpolative shading .",
        "ner_pair": [
            [
                "sub-voxel precision",
                "Metric"
            ],
            [
                "per-vertex normals",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sub-voxel precision') is the object of the preposition 'at', depending on the verb 'inferring'. Entity 2 ('per-vertex normals') is the direct object, depending on the verb 'inferring'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same verbal phrase 'inferring per-vertex normals at sub-voxel precision'.",
        "sdp_path_text": "precision → at → inferring → normals",
        "sentence": "We can infer per-vertex normals at sub-voxel precision.",
        "sentence_llm_dp_info": "Entity 1 ('sub-voxel precision') is the object of the preposition 'at', depending on the verb 'infer'. Entity 2 ('per-vertex normals') is the direct object, depending on the verb 'infer'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'per-vertex normals' is what is inferred and 'sub-voxel precision' describes the level of precision at which this inference is made."
    },
    {
        "raw_sentence": "By inferring per-vertex normals at sub-voxel precision on the fly , we can achieve interpolative shading .",
        "ner_pair": [
            [
                "per-vertex normals",
                "OtherScientificTerm"
            ],
            [
                "interpolative shading",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('per-vertex normals') is the object of the preposition 'at', depending on 'inferring'. Entity 2 ('interpolative shading') is the object of the verb 'achieve', depending on 'can achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the process of inferring per-vertex normals contributes to achieving interpolative shading.",
        "sdp_path_text": "normals → inferring → By → achieve → shading",
        "sentence": "By inferring per-vertex normals, we can achieve interpolative shading.",
        "sentence_llm_dp_info": "Entity 1 ('per-vertex normals') is the object of the preposition 'By', depending on the verb 'inferring'. Entity 2 ('interpolative shading') is the object, depending on the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the logical flow of the sentence where inferring Entity 1 enables the achievement of Entity 2."
    },
    {
        "raw_sentence": "By inferring per-vertex normals at sub-voxel precision on the fly , we can achieve interpolative shading .",
        "ner_pair": [
            [
                "sub-voxel precision",
                "Metric"
            ],
            [
                "interpolative shading",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sub-voxel precision') is the object of the preposition 'at', depending on 'inferring'. Entity 2 ('interpolative shading') is the object, depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.",
        "sdp_path_text": "precision → at → inferring → By → achieve → shading",
        "sentence": "By inferring at sub-voxel precision, we can achieve interpolative shading.",
        "sentence_llm_dp_info": "Entity 1 ('sub-voxel precision') is the object of the preposition 'at', depending on 'inferring'. Entity 2 ('interpolative shading') is the object of the verb 'achieve', depending on 'can'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the clause describing the effect of inferring at sub-voxel precision."
    },
    {
        "raw_sentence": "By relaxing the mesh connectivity requirement , we extend ROD-TV and propose a simple but effective multiscale feature extraction algorithm .",
        "ner_pair": [
            [
                "mesh connectivity requirement",
                "OtherScientificTerm"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('mesh connectivity requirement') is the object of the preposition 'relaxing', depending on 'By' in the phrase 'By relaxing the mesh connectivity requirement'. Entity 2 ('ROD-TV') is the object of the verb 'extend', depending on 'we'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "requirement → relaxing → By → extend → ROD",
        "sentence": "By relaxing the mesh connectivity requirement, we extend ROD-TV.",
        "sentence_llm_dp_info": "Entity 1 ('mesh connectivity requirement') is the object of the preposition 'by', depending on 'relaxing'. Entity 2 ('ROD-TV') is the object, depending on 'extend' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the actions described in the sentence."
    },
    {
        "raw_sentence": "By relaxing the mesh connectivity requirement , we extend ROD-TV and propose a simple but effective multiscale feature extraction algorithm .",
        "ner_pair": [
            [
                "mesh connectivity requirement",
                "OtherScientificTerm"
            ],
            [
                "multiscale feature extraction algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('mesh connectivity requirement') is the object of the preposition 'relaxing', depending on the verb 'relaxing' in the phrase 'By relaxing the mesh connectivity requirement'. Entity 2 ('multiscale feature extraction algorithm') is the object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the action of relaxing the requirement enables the proposal of the algorithm.",
        "sdp_path_text": "requirement → relaxing → By → extend → propose → algorithm",
        "sentence": "By relaxing the mesh connectivity requirement, we propose a multiscale feature extraction algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('mesh connectivity requirement') is the object of the preposition 'relaxing', depending on 'By' in the phrase 'By relaxing the mesh connectivity requirement'. Entity 2 ('multiscale feature extraction algorithm') is the direct object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing actions taken (relaxing) and the result (proposing an algorithm)."
    },
    {
        "raw_sentence": "By relaxing the mesh connectivity requirement , we extend ROD-TV and propose a simple but effective multiscale feature extraction algorithm .",
        "ner_pair": [
            [
                "ROD-TV",
                "Method"
            ],
            [
                "multiscale feature extraction algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the object of the verb 'extend', depending on 'we'. Entity 2 ('multiscale feature extraction algorithm') is the object of the verb 'propose', depending on 'we'. There is no direct dependency between Entity 1 and Entity 2, but both are influenced by the actions performed by the subject 'we'.",
        "sdp_path_text": "ROD → extend → propose → algorithm",
        "sentence": "We extend ROD-TV to propose a multiscale feature extraction algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('ROD-TV') is the object of the verb 'extend', depending on 'We' as the subject. Entity 2 ('multiscale feature extraction algorithm') is the object of the verb 'propose', depending on 'to propose' in the phrase 'to propose a multiscale feature extraction algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions described in the sentence."
    },
    {
        "raw_sentence": "ROD-TV consists of a hierarchical data structure that encodes different levels of detail .",
        "ner_pair": [
            [
                "hierarchical data structure",
                "Method"
            ],
            [
                "ROD-TV",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('hierarchical data structure') is the object, depending on the verb 'consists' with 'ROD-TV'. Entity 2 ('ROD-TV') is the subject, depending on the verb 'consists'. There is a direct dependency between Entity 1 and Entity 2, where 'hierarchical data structure' is part of what 'ROD-TV' consists of.",
        "sdp_path_text": "structure → of → consists → ROD",
        "sentence": "ROD-TV consists of a hierarchical data structure.",
        "sentence_llm_dp_info": "Entity 1 ('hierarchical data structure') is the complement of the verb 'consists', depending on 'consists' with 'ROD-TV'. Entity 2 ('ROD-TV') is the subject, depending on the verb 'consists'. There is a direct dependency between Entity 1 and Entity 2, as 'ROD-TV' consists of the 'hierarchical data structure'."
    },
    {
        "raw_sentence": "The local reconstruction algorithm is tensor voting .",
        "ner_pair": [
            [
                "tensor voting",
                "Method"
            ],
            [
                "local reconstruction algorithm",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tensor voting') is the predicate nominative, depending on the copula 'is'. Entity 2 ('local reconstruction algorithm') is the subject, also depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'tensor voting' directly identifies what the 'local reconstruction algorithm' is.",
        "sdp_path_text": "voting → is → algorithm",
        "sentence": "Tensor voting is the local reconstruction algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('tensor voting') is the subject, depending on the copula 'is'. Entity 2 ('local reconstruction algorithm') is the complement, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as they are linked by the copula 'is', indicating that 'tensor voting' is identified as being the 'local reconstruction algorithm'."
    },
    {
        "raw_sentence": "It is applied on demand to the visible subset of data at a desired level of detail , by traversing the data hierarchy and collecting tensorial support in a neighborhood .",
        "ner_pair": [
            [
                "traversing the data hierarchy",
                "Method"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('traversing the data hierarchy') is part of a coordination, depending on 'and' with 'collecting tensorial support'. Entity 2 ('It') is the subject, depending on the verb 'is' in the clause 'It is applied'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the main clause and the coordination of actions described in the sentence.",
        "sdp_path_text": "traversing → by → applied → It",
        "sentence": "It is applied by traversing the data hierarchy.",
        "sentence_llm_dp_info": "Entity 1 ('traversing the data hierarchy') is the object of the preposition 'by', depending on 'applied'. Entity 2 ('It') is the subject, depending on the verb 'is applied'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is applied' and the preposition 'by'."
    },
    {
        "raw_sentence": "It is applied on demand to the visible subset of data at a desired level of detail , by traversing the data hierarchy and collecting tensorial support in a neighborhood .",
        "ner_pair": [
            [
                "collecting tensorial support",
                "Method"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('collecting tensorial support') is part of a larger clause, acting as the object of the preposition 'by', depending on 'by' in the phrase 'by traversing the data hierarchy and collecting tensorial support'. Entity 2 ('It') is the subject, depending on the verb 'is' in the main clause 'It is applied'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'It' initiates the action that leads to 'collecting tensorial support'.",
        "sdp_path_text": "collecting → traversing → by → applied → It",
        "sentence": "It is applied by traversing the data hierarchy and collecting tensorial support.",
        "sentence_llm_dp_info": "Entity 1 ('collecting tensorial support') is the object, depending on the verb 'is applied'. Entity 2 ('It') is the subject, depending on the verb 'is applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'It' (Entity 2) undergoes the action described by 'is applied' which includes 'collecting tensorial support' (Entity 1)."
    },
    {
        "raw_sentence": "It is applied on demand to the visible subset of data at a desired level of detail , by traversing the data hierarchy and collecting tensorial support in a neighborhood .",
        "ner_pair": [
            [
                "traversing the data hierarchy",
                "Method"
            ],
            [
                "collecting tensorial support",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('traversing the data hierarchy') is part of a coordination, depending on the conjunction 'and' with 'collecting tensorial support'. Entity 2 ('collecting tensorial support') is also part of a coordination, depending on the conjunction 'and' with 'traversing the data hierarchy'. There is no direct dependency between Entity 1 and Entity 2; they are coordinated elements in the same clause, both depending on the verb 'is applied' through the conjunction 'and'.",
        "sdp_path_text": "traversing → collecting",
        "sentence": "Traversing the data hierarchy involves collecting tensorial support.",
        "sentence_llm_dp_info": "Entity 1 ('traversing the data hierarchy') is the subject, depending on the verb 'involves'. Entity 2 ('collecting tensorial support') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as 'involves' directly connects them."
    },
    {
        "raw_sentence": "Both rhetorical structure and punctuation have been helpful in discourse processing .",
        "ner_pair": [
            [
                "rhetorical structure",
                "OtherScientificTerm"
            ],
            [
                "punctuation",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rhetorical structure') is part of a conjunction, depending on 'and' with 'punctuation'. Entity 2 ('punctuation') is also part of the conjunction, depending on 'and' with 'rhetorical structure'. Both entities are the subjects of the sentence, depending on the verb 'have been'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.",
        "sdp_path_text": "structure → punctuation",
        "sentence": "Rhetorical structure and punctuation have been helpful in discourse processing.",
        "sentence_llm_dp_info": "Entity 1 ('rhetorical structure') is a conjunct, depending on 'and' with 'punctuation'. Entity 2 ('punctuation') is a conjunct, also depending on 'and' with 'rhetorical structure'. Both entities are part of the subject, depending on the verb 'have been'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "Both rhetorical structure and punctuation have been helpful in discourse processing .",
        "ner_pair": [
            [
                "rhetorical structure",
                "OtherScientificTerm"
            ],
            [
                "discourse processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rhetorical structure') is part of a coordination, depending on 'and' with 'punctuation'. Entity 2 ('discourse processing') is the object of the preposition 'in', depending on 'helpful'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'have been helpful in'.",
        "sdp_path_text": "structure → been → in → processing",
        "sentence": "Rhetorical structure has been helpful in discourse processing.",
        "sentence_llm_dp_info": "Entity 1 ('rhetorical structure') is the subject, depending on the verb 'has been'. Entity 2 ('discourse processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in discourse processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in discourse processing' which modifies the predicate 'has been helpful'."
    },
    {
        "raw_sentence": "Both rhetorical structure and punctuation have been helpful in discourse processing .",
        "ner_pair": [
            [
                "punctuation",
                "OtherScientificTerm"
            ],
            [
                "discourse processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('punctuation') is part of a coordination, depending on 'and' with 'rhetorical structure'. Entity 2 ('discourse processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in discourse processing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'have been' and the preposition 'in'.",
        "sdp_path_text": "punctuation → structure → been → in → processing",
        "sentence": "Punctuation has been helpful in discourse processing.",
        "sentence_llm_dp_info": "Entity 1 ('punctuation') is the subject, depending on the verb 'has been'. Entity 2 ('discourse processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in discourse processing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'based'. Entity 2 ('discursive usage of 6 Chinese punctuation marks') is the subject complement, depending on 'reports' with 'this paper'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context described in the sentence, where the paper's reporting is based on the corpus annotation project.",
        "sdp_path_text": "project → on → Based → reports → usage",
        "sentence": "Based on a corpus annotation project, this paper reports the discursive usage of 6 Chinese punctuation marks.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'based'. Entity 2 ('discursive usage of 6 Chinese punctuation marks') is the object of the verb 'reports', depending on 'reports' in the phrase 'reports the discursive usage of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence.",
        "sdp_path_text": "project → on → Based → reports → usage → of → marks",
        "sentence": "Based on a corpus annotation project, this paper reports the usage of Chinese punctuation marks.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('Chinese punctuation marks') is the object, depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence context where the project's results relate to the usage of the marks."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "news commentary texts",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('news commentary texts') is the object of the preposition 'in', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "project → on → Based → reports → usage → in → texts",
        "sentence": "The corpus annotation project reports the usage of punctuation marks in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the subject, depending on the verb 'reports'. Entity 2 ('news commentary texts') is the object, depending on the preposition 'in', which is part of the prepositional phrase 'in news commentary texts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reports' and the prepositional phrase 'in news commentary texts'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Colon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'based'. Entity 2 ('Colon') is part of a list, depending on 'marks' in the phrase 'punctuation marks'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "project → on → Based → reports → usage → Colon",
        "sentence": "The corpus annotation project reports the usage of Colon.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the subject, depending on the verb 'reports'. Entity 2 ('Colon') is the object, depending on the preposition 'of' in the phrase 'of Colon'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reports' and the preposition 'of'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Dash",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('Dash') is one of the items in a list, depending on the verb 'reports'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context described by the sentence.",
        "sdp_path_text": "project → on → Based → reports → usage → Colon → Dash",
        "sentence": "The corpus annotation project reports the usage of Dash in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the subject, depending on the verb 'reports'. Entity 2 ('Dash') is the object of the preposition 'of', depending on 'usage' in the phrase 'the usage of Dash'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reports' and the prepositional phrase 'the usage of Dash'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('Ellipsis') is one of the items in a list, depending on 'marks'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "project → on → Based → reports → usage → Colon → Dash → Ellipsis",
        "sentence": "The corpus annotation project reports the usage of Ellipsis.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the subject, depending on the verb 'reports'. Entity 2 ('Ellipsis') is the object, depending on the preposition 'of' in the phrase 'usage of Ellipsis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reports' and the prepositional phrase 'the usage of Ellipsis'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'based'. Entity 2 ('Exclamation Mark') is one of the items in a list, depending on the preposition 'of' within the phrase 'of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "project → on → Based → reports → usage → Colon → Dash → Ellipsis → Mark",
        "sentence": "The corpus annotation project reports the usage of Exclamation Mark.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the subject, depending on the verb 'reports'. Entity 2 ('Exclamation Mark') is the object, depending on 'usage' in the phrase 'the usage of Exclamation Mark'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reports' and the noun 'usage'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'reports' in the clause 'this paper reports'. Entity 2 ('Question Mark') is part of a list, depending on the preposition 'of' in the phrase 'the discursive usage of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "project → on → Based → reports → usage → Colon → Dash → Ellipsis → Mark → Mark",
        "sentence": "Based on a corpus annotation project, this paper reports the usage of Question Mark in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('Question Mark') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "corpus annotation project",
                "Task"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'on', depending on 'Based'. Entity 2 ('Semicolon') is part of a list, depending on the verb 'reports' through the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "project → on → Based → reports → usage → Colon → Dash → Ellipsis → Mark → Mark → Semicolon",
        "sentence": "This paper reports the usage of Semicolon based on a corpus annotation project.",
        "sentence_llm_dp_info": "Entity 1 ('corpus annotation project') is the object of the preposition 'based', depending on 'based'. Entity 2 ('Semicolon') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure describing what is reported in the paper."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "news commentary texts",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the direct object, depending on 'reports' with 'this paper'. Entity 2 ('news commentary texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in news commentary texts'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where Entity 1 is reported in the context of Entity 2.",
        "sdp_path_text": "usage → in → texts",
        "sentence": "The discursive usage of 6 Chinese punctuation marks is reported in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the subject, depending on the verb 'reported'. Entity 2 ('news commentary texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in news commentary texts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "Colon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the direct object, depending on the verb 'reports' with 'this paper'. Entity 2 ('Colon') is one of the items in a list, depending on the preposition 'of' within the phrase 'of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 2 is part of the list that is described by Entity 1.",
        "sdp_path_text": "usage → Colon",
        "sentence": "The discursive usage of 6 Chinese punctuation marks includes Colon.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the subject, depending on the verb 'includes'. Entity 2 ('Colon') is the object, depending on 'includes' in the phrase 'includes Colon'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly included in Entity 1."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "Dash",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the direct object, depending on 'reports' with 'this paper'. Entity 2 ('Dash') is part of a list, depending on 'punctuation marks' through the preposition 'of' within the list of punctuation marks. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where Entity 2 is an example of the items described by Entity 1.",
        "sdp_path_text": "usage → Colon → Dash",
        "sentence": "The discursive usage of Chinese punctuation marks includes the Dash.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of Chinese punctuation marks') is the subject complement, depending on the verb 'includes'. Entity 2 ('Dash') is the direct object, also depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is included within the scope of Entity 1 through the verb 'includes'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the object of the verb 'reports', depending on 'reports' with 'this paper'. Entity 2 ('Ellipsis') is part of a list, depending on the preposition 'of' within the larger noun phrase '6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where Entity 2 is one of the items listed as part of Entity 1.",
        "sdp_path_text": "usage → Colon → Dash → Ellipsis",
        "sentence": "The discursive usage of Chinese punctuation marks includes Ellipsis.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of Chinese punctuation marks') is the subject, depending on the verb 'includes'. Entity 2 ('Ellipsis') is the direct object, depending on 'includes' in the sentence. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 includes Entity 2."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the subject complement, depending on 'reports' with 'this paper'. Entity 2 ('Exclamation Mark') is part of a list, depending on 'of' within the prepositional phrase 'of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where Entity 2 is one of the items listed as part of Entity 1.",
        "sdp_path_text": "usage → Colon → Dash → Ellipsis → Mark",
        "sentence": "This paper reports the discursive usage of Chinese punctuation marks including the Exclamation Mark.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of Chinese punctuation marks') is the object, depending on the verb 'reports' with 'This paper'. Entity 2 ('Exclamation Mark') is part of the prepositional phrase 'including the Exclamation Mark', which modifies 'Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'including'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the direct object, depending on the verb 'reports' with 'this paper'. Entity 2 ('Question Mark') is part of a list, depending on the conjunction 'and' with 'Semicolon'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the list of punctuation marks described in the sentence.",
        "sdp_path_text": "usage → Colon → Dash → Ellipsis → Mark → Mark",
        "sentence": "The discursive usage of Chinese punctuation marks includes the Question Mark.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of Chinese punctuation marks') is the subject, depending on the verb 'includes'. Entity 2 ('Question Mark') is the object, depending on 'includes' in the phrase 'includes the Question Mark'. There is a direct dependency between Entity 1 and Entity 2, as 'Question Mark' is included within the 'discursive usage of Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "discursive usage of 6 Chinese punctuation marks",
                "Task"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the subject complement, depending on the verb 'reports' with 'this paper'. Entity 2 ('Semicolon') is part of a list, depending on the conjunction 'and' which links it to other items in the list. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause describing the content of the report.",
        "sdp_path_text": "usage → Colon → Dash → Ellipsis → Mark → Mark → Semicolon",
        "sentence": "The discursive usage of 6 Chinese punctuation marks includes Semicolon.",
        "sentence_llm_dp_info": "Entity 1 ('discursive usage of 6 Chinese punctuation marks') is the subject, depending on the verb 'includes'. Entity 2 ('Semicolon') is the direct object, depending on 'includes'. There is a direct dependency between Entity 1 and Entity 2, as 'Semicolon' is included within the 'discursive usage of 6 Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            [
                "news commentary texts",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage' in the phrase 'the discursive usage of 6 Chinese punctuation marks'. Entity 2 ('news commentary texts') is the object of the preposition 'in', depending on 'usage' in the phrase 'the discursive usage ... in news commentary texts'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same noun phrase describing where and what is being reported about the usage.",
        "sdp_path_text": "marks → of → usage → in → texts",
        "sentence": "The discursive usage of Chinese punctuation marks is reported in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage'. Entity 2 ('news commentary texts') is the object of the preposition 'in', depending on 'reported'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Colon",
                "OtherScientificTerm"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Colon') is one of the items in a list, depending on the preposition 'of' with 'Chinese punctuation marks'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage' in the phrase 'the discursive usage of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list and contextually related through the preposition 'of'.",
        "sdp_path_text": "Colon → usage → of → marks",
        "sentence": "Colon is used among Chinese punctuation marks.",
        "sentence_llm_dp_info": "Entity 1 ('Colon') is the subject, depending on the verb 'is used'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'among', depending on 'among' in the phrase 'among Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'among'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Dash",
                "OtherScientificTerm"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dash') is one of the items in a list, depending on the conjunction 'and' which connects it to other punctuation marks. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage' in the phrase 'the discursive usage of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2; they are part of the same list but connected through the prepositional phrase that describes the subject of the report.",
        "sdp_path_text": "Dash → Colon → usage → of → marks",
        "sentence": "Dash is one of the Chinese punctuation marks used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Dash') is the subject, depending on 'is' as part of the copular construction. Entity 2 ('Chinese punctuation marks') is the complement, depending on 'is' as part of the same copular construction. There is a direct dependency between Entity 1 and Entity 2, as 'Dash' is described as being 'one of the Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Ellipsis') is one of the items in a list, depending on the conjunction 'and' with 'Semicolon'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context where 'Ellipsis' is listed as one of the 'Chinese punctuation marks'.",
        "sdp_path_text": "Ellipsis → Dash → Colon → usage → of → marks",
        "sentence": "Ellipsis is among the Chinese punctuation marks used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Ellipsis') is the subject, depending on the verb 'is'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'among', depending on 'among' in the phrase 'among the Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'among the Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Exclamation Mark') is part of a list, depending on the conjunction 'and' which connects it to the other items in the list. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where Entity 1 is an example of Entity 2.",
        "sdp_path_text": "Mark → Ellipsis → Dash → Colon → usage → of → marks",
        "sentence": "Exclamation Mark is one of the Chinese punctuation marks used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Exclamation Mark') is the subject, depending on the verb 'is'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'one' in the phrase 'one of the Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Question Mark') is part of a list, depending on the conjunction 'and'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list and related through the context of the sentence.",
        "sdp_path_text": "Mark → Mark → Ellipsis → Dash → Colon → usage → of → marks",
        "sentence": "Question Mark is one of the Chinese punctuation marks used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Question Mark') is the subject, depending on the verb 'is'. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'one'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Semicolon') is part of a list, depending on the conjunction 'and' which connects it to the other items listed. Entity 2 ('Chinese punctuation marks') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the list structure where 'Semicolon' is one of the 'Chinese punctuation marks' being discussed.",
        "sdp_path_text": "Semicolon → Mark → Mark → Ellipsis → Dash → Colon → usage → of → marks",
        "sentence": "Semicolon is one of the Chinese punctuation marks used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Semicolon') is the subject, depending on the verb 'is'. Entity 2 ('Chinese punctuation marks') is the complement of the preposition 'of', depending on 'one'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure 'one of the Chinese punctuation marks'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "news commentary texts",
                "Material"
            ],
            [
                "Colon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object of the preposition 'of', depending on 'usage'. Entity 2 ('Colon') is part of a list, depending on the conjunction 'and' which connects it with other items in the list. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "texts → in → usage → Colon",
        "sentence": "The discursive usage of Colon is reported in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the preposition 'in', which itself depends on 'reported'. Entity 2 ('Colon') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing where and what is reported."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "news commentary texts",
                "Material"
            ],
            [
                "Dash",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object of the preposition 'of', depending on 'usage'. Entity 2 ('Dash') is part of a list, depending on the conjunction 'and' which connects it with other items in the list. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "texts → in → usage → Colon → Dash",
        "sentence": "Dash is used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the verb 'used'. Entity 2 ('Dash') is the subject, depending on the verb 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "news commentary texts",
                "Material"
            ],
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object of the preposition 'in', depending on 'usage'. Entity 2 ('Ellipsis') is one of the items in a list, depending on the colon that introduces the list. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "texts → in → usage → Colon → Dash → Ellipsis",
        "sentence": "The paper reports the usage of Ellipsis in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the preposition 'in', which is part of the prepositional phrase 'in news commentary texts'. Entity 2 ('Ellipsis') is the object of the preposition 'of', which is part of the noun phrase 'the usage of Ellipsis'. There is no direct dependency between Entity 1 and Entity 2; both are part of prepositional phrases that modify different parts of the sentence."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "news commentary texts",
                "Material"
            ],
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object of the preposition 'in', depending on 'usage'. Entity 2 ('Exclamation Mark') is one of the items in a list, depending on the conjunction 'and' which links it with other punctuation marks. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "texts → in → usage → Colon → Dash → Ellipsis → Mark",
        "sentence": "The paper reports the usage of Exclamation Mark in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the preposition 'in', which modifies 'usage'. Entity 2 ('Exclamation Mark') is the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying 'usage'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "news commentary texts",
                "Material"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the preposition 'in', which is part of the prepositional phrase 'in news commentary texts'. Entity 2 ('Question Mark') is one of the items in a list, depending on the conjunction 'and' within the series of punctuation marks. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context described by the sentence, where the usage of various punctuation marks is reported in news commentary texts.",
        "sdp_path_text": "texts → in → usage → Colon → Dash → Ellipsis → Mark → Mark",
        "sentence": "This paper reports the usage of Question Mark in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in news commentary texts'. Entity 2 ('Question Mark') is the object of the preposition 'of', depending on 'usage' in the phrase 'the usage of Question Mark'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is reported in the paper."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "news commentary texts",
                "Material"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the preposition 'of' which modifies 'usage'. Entity 2 ('Semicolon') is part of a list, depending on the conjunction 'and' that connects it to other items in the list. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "texts → in → usage → Colon → Dash → Ellipsis → Mark → Mark → Semicolon",
        "sentence": "This paper reports the usage of Semicolon in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('news commentary texts') is the object, depending on the preposition 'in', which itself depends on 'usage'. Entity 2 ('Semicolon') is the object, depending on the verb 'usage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'Semicolon' is used within 'news commentary texts'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Colon",
                "OtherScientificTerm"
            ],
            [
                "Dash",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Colon') is one of the items in a list, depending on the preposition 'of' in the phrase 'of 6 Chinese punctuation marks'. Entity 2 ('Dash') is also one of the items in the same list, depending on the conjunction 'and' which connects it to the other items. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of punctuation marks.",
        "sdp_path_text": "Colon → Dash",
        "sentence": "This paper reports the discursive usage of Colon and Dash in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Colon') is the object of the preposition 'of', depending on 'usage'. Entity 2 ('Dash') is coordinated with 'Colon' through the conjunction 'and', also depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated structure that serves as the object of 'of'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Colon",
                "OtherScientificTerm"
            ],
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Colon') is part of a list, depending on the conjunction 'and' with 'Semicolon'. Entity 2 ('Ellipsis') is also part of the same list, depending on the conjunction 'and' with 'Semicolon'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list introduced by the colon after 'punctuation marks'.",
        "sdp_path_text": "Colon → Dash → Ellipsis",
        "sentence": "This paper reports the discursive usage of Colon, Dash, and Ellipsis in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Colon') is part of a coordination, depending on 'of' with 'usage'. Entity 2 ('Ellipsis') is also part of the same coordination, depending on 'and' with 'Colon'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the coordinated list in the prepositional phrase 'of Colon, Dash, and Ellipsis'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Colon",
                "OtherScientificTerm"
            ],
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Colon') is one of the items in a list, depending on the colon (:) with 'punctuation marks'. Entity 2 ('Exclamation Mark') is also an item in the same list, depending on the conjunction 'and' with 'Semicolon'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list introduced by 'punctuation marks'.",
        "sdp_path_text": "Colon → Dash → Ellipsis → Mark",
        "sentence": "This paper reports the discursive usage of punctuation marks including Colon, Dash, Ellipsis, and Exclamation Mark.",
        "sentence_llm_dp_info": "Entity 1 ('Colon') is part of a list, depending on the preposition 'including' which modifies 'punctuation marks'. Entity 2 ('Exclamation Mark') is also part of the same list, depending on the conjunction 'and' which connects it to the other items in the list. There is no direct dependency between Entity 1 and Entity 2; they are both elements of the list introduced by 'including'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Colon",
                "OtherScientificTerm"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Colon') is part of a list, depending on the conjunction 'and' which connects it with other punctuation marks. Entity 2 ('Question Mark') is also part of the same list, depending on the conjunction 'and' which connects it with other punctuation marks. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of punctuation marks.",
        "sdp_path_text": "Colon → Dash → Ellipsis → Mark → Mark",
        "sentence": "This paper reports the discursive usage of Colon, Dash, Ellipsis, and Question Mark in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Colon') is part of a coordinated list, depending on 'of' in the phrase 'of Colon, Dash, Ellipsis, and Question Mark'. Entity 2 ('Question Mark') is also part of a coordinated list, depending on 'and' in the phrase 'and Question Mark'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list, which is the object of the preposition 'of'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Colon",
                "OtherScientificTerm"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Colon') is one of the items in a list, depending on the verb 'reports' through the prepositional phrase 'of 6 Chinese punctuation marks'. Entity 2 ('Semicolon') is also an item in the same list, similarly depending on the verb 'reports' through the same prepositional phrase 'of 6 Chinese punctuation marks'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list.",
        "sdp_path_text": "Colon → Dash → Ellipsis → Mark → Mark → Semicolon",
        "sentence": "This paper reports the discursive usage of punctuation marks including Colon, Dash, Ellipsis, and Semicolon.",
        "sentence_llm_dp_info": "Entity 1 ('Colon') is part of a list, depending on the preposition 'including' which modifies 'punctuation marks'. Entity 2 ('Semicolon') is also part of the same list, depending on the preposition 'including' which modifies 'punctuation marks'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list introduced by 'including'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Dash",
                "OtherScientificTerm"
            ],
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dash') is part of a list, depending on the conjunction 'and' which links it with other items in the series. Entity 2 ('Ellipsis') is also part of a list, depending on the conjunction 'and' which links it with other items in the series. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same list connected through the conjunction 'and'.",
        "sdp_path_text": "Dash → Ellipsis",
        "sentence": "Dash and Ellipsis are used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Dash') is the subject, depending on the verb 'are used'. Entity 2 ('Ellipsis') is coordinated with 'Dash', also depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of the same verb, indicating that they are used together in the context of news commentary texts."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Dash",
                "OtherScientificTerm"
            ],
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dash') is part of a list, depending on the conjunction 'and' with 'Semicolon'. Entity 2 ('Exclamation Mark') is also part of the same list, depending on the conjunction 'and' with 'Question Mark'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements in a list of Chinese punctuation marks.",
        "sdp_path_text": "Dash → Ellipsis → Mark",
        "sentence": "Dash, Ellipsis, and Exclamation Mark are used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Dash') is a conjunct, depending on 'are used' with the conjunction 'and'. Entity 2 ('Exclamation Mark') is also a conjunct, depending on 'are used' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list connected by 'and'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Dash",
                "OtherScientificTerm"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dash') is part of a list, depending on the preposition 'of' within the phrase 'of 6 Chinese punctuation marks'. Entity 2 ('Question Mark') is also part of the same list, depending on the conjunction 'and' which connects it to the last item in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of punctuation marks.",
        "sdp_path_text": "Dash → Ellipsis → Mark → Mark",
        "sentence": "Dash and Question Mark are among the Chinese punctuation marks discussed.",
        "sentence_llm_dp_info": "Entity 1 ('Dash') is a conjunct, depending on 'are' with the conjunction 'and'. Entity 2 ('Question Mark') is also a conjunct, depending on 'are' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated structure under the verb 'are'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Dash",
                "OtherScientificTerm"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Dash') is one of the items in a list, depending on the conjunction 'and' which links it with 'Semicolon'. Entity 2 ('Semicolon') is also an item in the same list, depending on the conjunction 'and' which directly connects it with 'Dash'. There is a direct dependency between Entity 1 and Entity 2, as they are both part of the list and are linked by the conjunction 'and'.",
        "sdp_path_text": "Dash → Ellipsis → Mark → Mark → Semicolon",
        "sentence": "Dash and Semicolon are used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Dash') is a compound, depending on 'used' with 'and'. Entity 2 ('Semicolon') is a conjunction, also depending on 'used' with 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Ellipsis') is part of a list, depending on the conjunction 'and' which links it to 'Semicolon'. Entity 2 ('Exclamation Mark') is also part of the same list, depending on the conjunction 'and' which links it to 'Question Mark'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a larger list of Chinese punctuation marks.",
        "sdp_path_text": "Ellipsis → Mark",
        "sentence": "Ellipsis and Exclamation Mark are punctuation marks used in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Ellipsis') is the subject, depending on the conjunction 'and' with 'Exclamation Mark'. Entity 2 ('Exclamation Mark') is also a subject, depending on the conjunction 'and' with 'Ellipsis'. Both 'Ellipsis' and 'Exclamation Mark' are part of a compound subject that depends on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Ellipsis') is one of the items in a list, depending on the preposition 'of' in the phrase 'of 6 Chinese punctuation marks'. Entity 2 ('Question Mark') is also one of the items in the same list, depending on the conjunction 'and' which connects it to the last item in the list. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of punctuation marks.",
        "sdp_path_text": "Ellipsis → Mark → Mark",
        "sentence": "This paper reports the usage of Ellipsis and Question Mark in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Ellipsis') is the object of the preposition 'of', depending on 'usage'. Entity 2 ('Question Mark') is also the object of the preposition 'of', depending on 'usage'. There is no direct dependency between Entity 1 and Entity 2; both are connected through the preposition 'of' to the noun 'usage'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Ellipsis",
                "OtherScientificTerm"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Ellipsis') is one of the items in a list, depending on the preposition 'of' in the phrase 'of 6 Chinese punctuation marks'. Entity 2 ('Semicolon') is also one of the items in the same list, depending on the conjunction 'and' which connects it to the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are part of the list described in the sentence.",
        "sdp_path_text": "Ellipsis → Mark → Mark → Semicolon",
        "sentence": "Ellipsis and Semicolon are punctuation marks.",
        "sentence_llm_dp_info": "Entity 1 ('Ellipsis') is the subject, depending on the verb 'are'. Entity 2 ('Semicolon') is also a subject, conjoined with 'Ellipsis' and depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in a coordinated structure."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Exclamation Mark') is part of a list, depending on the conjunction 'and' which connects it to the last item in the list. Entity 2 ('Question Mark') is also part of the same list, depending on the conjunction 'and' which connects it to the last item in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list introduced by the colon and are connected through their roles as items in the enumeration.",
        "sdp_path_text": "Mark → Mark",
        "sentence": "Exclamation Mark and Question Mark are discussed in the context of Chinese punctuation marks.",
        "sentence_llm_dp_info": "Entity 1 ('Exclamation Mark') is a conjunct, depending on 'and' with 'Question Mark'. Entity 2 ('Question Mark') is a conjunct, also depending on 'and' with 'Exclamation Mark'. Both entities are part of the compound subject of the sentence, which is the subject of the verb 'are discussed'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Exclamation Mark",
                "OtherScientificTerm"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Exclamation Mark') is one of the items in a list, depending on the conjunction 'and' which connects it to the last item 'Semicolon'. Entity 2 ('Semicolon') is also an item in the list, directly connected to 'Exclamation Mark' through the conjunction 'and'. There is a direct dependency between Entity 1 and Entity 2, established through the coordinating conjunction 'and'.",
        "sdp_path_text": "Mark → Mark → Semicolon",
        "sentence": "Exclamation Mark and Semicolon are punctuation marks.",
        "sentence_llm_dp_info": "Entity 1 ('Exclamation Mark') is the subject, depending on the verb 'are'. Entity 2 ('Semicolon') is also a subject, conjoined with 'Exclamation Mark' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in the same clause, linked by the conjunction 'and'."
    },
    {
        "raw_sentence": "Based on a corpus annotation project , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .",
        "ner_pair": [
            [
                "Question Mark",
                "OtherScientificTerm"
            ],
            [
                "Semicolon",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Question Mark') is part of a list, depending on the conjunction 'and' which connects it with 'Semicolon'. Entity 2 ('Semicolon') is also part of the same list, depending on the conjunction 'and' which connects it with 'Question Mark'. There is a direct dependency between Entity 1 and Entity 2, as they are both items in the list connected by the conjunction 'and'.",
        "sdp_path_text": "Mark → Semicolon",
        "sentence": "This paper reports the discursive usage of Question Mark and Semicolon in news commentary texts.",
        "sentence_llm_dp_info": "Entity 1 ('Question Mark') is the object of the preposition 'of', depending on 'of' in the phrase 'of Question Mark'. Entity 2 ('Semicolon') is also the object of the preposition 'of', depending on 'of' in the phrase 'of Semicolon'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'of'."
    },
    {
        "raw_sentence": "The rhetorical patterns of these marks are compared against patterns around cue phrases in general .",
        "ner_pair": [
            [
                "rhetorical patterns",
                "OtherScientificTerm"
            ],
            [
                "marks",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rhetorical patterns') is the subject, depending on the verb 'compared'. Entity 2 ('marks') is the object of the preposition 'of', depending on 'of' in the phrase 'of these marks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase and the verb 'compared'.",
        "sdp_path_text": "patterns → of → marks",
        "sentence": "The rhetorical patterns of marks are compared.",
        "sentence_llm_dp_info": "Entity 1 ('rhetorical patterns') is the subject, depending on the verb 'compared'. Entity 2 ('marks') is the object, depending on the preposition 'of' in the phrase 'of marks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'."
    },
    {
        "raw_sentence": "The rhetorical patterns of these marks are compared against patterns around cue phrases in general .",
        "ner_pair": [
            [
                "rhetorical patterns",
                "OtherScientificTerm"
            ],
            [
                "patterns around cue phrases",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rhetorical patterns') is the subject, depending on the verb 'compared'. Entity 2 ('patterns around cue phrases') is the object of the preposition 'against', depending on 'against' in the phrase 'against patterns around cue phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure involving the verb 'compared' and the preposition 'against'.",
        "sdp_path_text": "patterns → compared → against → patterns",
        "sentence": "Rhetorical patterns are compared against patterns around cue phrases.",
        "sentence_llm_dp_info": "Entity 1 ('rhetorical patterns') is the subject, depending on the verb 'compared'. Entity 2 ('patterns around cue phrases') is the object, depending on 'against' in the prepositional phrase 'against patterns around cue phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'against'."
    },
    {
        "raw_sentence": "The rhetorical patterns of these marks are compared against patterns around cue phrases in general .",
        "ner_pair": [
            [
                "marks",
                "Generic"
            ],
            [
                "patterns around cue phrases",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('marks') is the object of the preposition 'of', depending on 'patterns'. Entity 2 ('patterns around cue phrases') is the complement of the preposition 'against', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparison structure described in the sentence.",
        "sdp_path_text": "marks → of → patterns → compared → against → patterns",
        "sentence": "The patterns of marks are compared against patterns around cue phrases.",
        "sentence_llm_dp_info": "Entity 1 ('marks') is part of the noun phrase 'patterns of marks', where it depends on 'patterns' as the object of the preposition 'of'. Entity 2 ('patterns around cue phrases') is the object of the preposition 'against', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'compared' which compares the two noun phrases."
    },
    {
        "raw_sentence": "Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .",
        "ner_pair": [
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the subject, depending on the verb 'show' through the clause 'Results show that these Chinese punctuation marks...'. Entity 2 ('cue phrases') is the object of the preposition 'than', depending on the comparative adjective 'fewer'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparative structure 'fewer in number than'.",
        "sdp_path_text": "marks → are → fewer → than → phrases",
        "sentence": "Chinese punctuation marks are fewer in number than cue phrases.",
        "sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the subject, depending on the verb 'are'. Entity 2 ('cue phrases') is the object of comparison, depending on 'than' in the phrase 'than cue phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure 'fewer in number than'."
    },
    {
        "raw_sentence": "Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .",
        "ner_pair": [
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            [
                "indicators of nuclearity",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the subject of the clause 'these Chinese punctuation marks ... are easy to identify', depending on the verb 'are'. Entity 2 ('indicators of nuclearity') is the object of the preposition 'as', depending on 'used' in the phrase 'can be used as distinctive indicators of nuclearity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' which indicates that the Chinese punctuation marks can serve as the indicators of nuclearity.",
        "sdp_path_text": "marks → are → have → used → as → indicators",
        "sentence": "Chinese punctuation marks are used as indicators of nuclearity.",
        "sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the subject, depending on the verb 'are used'. Entity 2 ('indicators of nuclearity') is the complement, depending on the verb 'are used' with 'as'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are used' and the preposition 'as'."
    },
    {
        "raw_sentence": "Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .",
        "ner_pair": [
            [
                "Chinese punctuation marks",
                "OtherScientificTerm"
            ],
            [
                "Chinese texts",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the subject complement, depending on 'show' via the clause 'Results show that these Chinese punctuation marks...'. Entity 2 ('Chinese texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in Chinese texts'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the larger structure of the sentence, particularly the clause describing the properties and uses of Entity 1 within the context of Entity 2.",
        "sdp_path_text": "marks → are → have → used → in → texts",
        "sentence": "Chinese punctuation marks are used in Chinese texts.",
        "sentence_llm_dp_info": "Entity 1 ('Chinese punctuation marks') is the subject, depending on the verb 'are used'. Entity 2 ('Chinese texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in Chinese texts'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'."
    },
    {
        "raw_sentence": "Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "indicators of nuclearity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cue phrases') is the object of comparison, depending on 'fewer' with 'than'. Entity 2 ('indicators of nuclearity') is the object of the preposition 'as', depending on 'used' in the phrase 'can be used as'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence context where 'cue phrases' are compared in number and 'indicators of nuclearity' are described as a result of the analysis.",
        "sdp_path_text": "phrases → than → fewer → are → have → used → as → indicators",
        "sentence": "Cue phrases, though fewer, can be used as indicators of nuclearity.",
        "sentence_llm_dp_info": "Entity 1 ('cue phrases') is the subject, depending on the verb 'can be used'. Entity 2 ('indicators of nuclearity') is the complement, depending on 'used' with 'as'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the preposition 'as'."
    },
    {
        "raw_sentence": "Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "Chinese texts",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('cue phrases') is the object of comparison, depending on 'than' in the comparative clause 'fewer in number than cue phrases'. Entity 2 ('Chinese texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in Chinese texts'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the sentence.",
        "sdp_path_text": "phrases → than → fewer → are → have → used → in → texts",
        "sentence": "Chinese punctuation marks, though fewer than cue phrases, can be used as distinctive indicators in Chinese texts.",
        "sentence_llm_dp_info": "Entity 1 ('cue phrases') is part of a comparative clause, depending on 'fewer' with 'than'. Entity 2 ('Chinese texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in Chinese texts'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the comparison and the role of punctuation marks in differentiating them."
    },
    {
        "raw_sentence": "Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .",
        "ner_pair": [
            [
                "Chinese texts",
                "Material"
            ],
            [
                "indicators of nuclearity",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Chinese texts') is the object of the preposition 'in', depending on 'in' in the phrase 'in Chinese texts'. Entity 2 ('indicators of nuclearity') is the object complement, depending on 'used' in the phrase 'can be used as'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'indicators of nuclearity' are described as being used in 'Chinese texts'.",
        "sdp_path_text": "texts → in → used → as → indicators",
        "sentence": "Chinese texts use indicators of nuclearity.",
        "sentence_llm_dp_info": "Entity 1 ('Chinese texts') is the subject, depending on the verb 'use'. Entity 2 ('indicators of nuclearity') is the object, depending on the verb 'use'. There is a direct dependency between Entity 1 and Entity 2, as 'Chinese texts' uses 'indicators of nuclearity'."
    },
    {
        "raw_sentence": "The features based on Markov random field -LRB- MRF -RRB- models are usually sensitive to the rotation of image textures .",
        "ner_pair": [
            [
                "Markov random field -LRB- MRF -RRB- models",
                "Method"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Markov random field -LRB- MRF -RRB- models') is the object of the preposition 'on', depending on 'based' in the phrase 'based on Markov random field -LRB- MRF -RRB- models'. Entity 2 ('features') is the subject, depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on' which modifies 'features'.",
        "sdp_path_text": "models → on → based → features",
        "sentence": "{\n  \"Simplified sentence\": \"Features based on Markov random field (MRF) models are sensitive to the rotation of image textures.\"\n} \n\nHowever, to strictly follow the instructions and focus only on the relationship between the two entities as described by the SDP, the simplified sentence should be:\n\n{\n  \"Simplified sentence\": \"Features are based on Markov random field (MRF) models.\"\n}",
        "sentence_llm_dp_info": "Entity 1 ('Markov random field (MRF) models') is the object of the preposition 'on', depending on 'based'. Entity 2 ('features') is the subject, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the basis for Entity 2, indicated by the preposition 'on' in the phrase 'based on Markov random field (MRF) models'."
    },
    {
        "raw_sentence": "The features based on Markov random field -LRB- MRF -RRB- models are usually sensitive to the rotation of image textures .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "rotation of image textures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are'. Entity 2 ('rotation of image textures') is the object of the preposition 'to', depending on 'sensitive' in the phrase 'sensitive to the rotation of image textures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'sensitive' which describes the relationship between the features and the rotation of image textures.",
        "sdp_path_text": "features → are → sensitive → to → rotation",
        "sentence": "Features are sensitive to the rotation of image textures.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'are'. Entity 2 ('rotation of image textures') is the object of the preposition 'to', depending on 'sensitive' in the phrase 'sensitive to the rotation of image textures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'sensitive' and the preposition 'to'."
    },
    {
        "raw_sentence": "The features based on Markov random field -LRB- MRF -RRB- models are usually sensitive to the rotation of image textures .",
        "ner_pair": [
            [
                "Markov random field -LRB- MRF -RRB- models",
                "Method"
            ],
            [
                "rotation of image textures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Markov random field -LRB- MRF -RRB- models') is the object of the preposition 'based on', depending on 'features'. Entity 2 ('rotation of image textures') is the object of the preposition 'to', depending on 'sensitive'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where 'features' are described as being 'sensitive to' the 'rotation of image textures'.",
        "sdp_path_text": "models → on → based → features → are → sensitive → to → rotation",
        "sentence": "Features based on MRF models are sensitive to the rotation of image textures.",
        "sentence_llm_dp_info": "Entity 1 ('Markov random field (MRF) models') is the object of the preposition 'based on', depending on 'Features'. Entity 2 ('rotation of image textures') is the object of the preposition 'to', depending on 'sensitive'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'Features' are described as being 'sensitive to' the 'rotation of image textures' and are 'based on' 'Markov random field (MRF) models'."
    },
    {
        "raw_sentence": "This paper develops an anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model for modelling rotated image textures and retrieving rotation-invariant texture features .",
        "ner_pair": [
            [
                "anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model",
                "Method"
            ],
            [
                "modelling rotated image textures",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model') is the direct object, depending on the verb 'develops' with 'This paper'. Entity 2 ('modelling rotated image textures') is part of a prepositional phrase, depending on the preposition 'for' which modifies 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'for'.",
        "sdp_path_text": "model → develops → for → modelling",
        "sentence": "The anisotropic circular Gaussian MRF (ACGMRF) model is developed for modelling rotated image textures.",
        "sentence_llm_dp_info": "Entity 1 ('anisotropic circular Gaussian MRF (ACGMRF) model') is the subject, depending on the verb 'developed'. Entity 2 ('modelling rotated image textures') is the purpose or use, depending on the preposition 'for', which indicates the function of the subject. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' indicating the purpose of the development of Entity 1."
    },
    {
        "raw_sentence": "This paper develops an anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model for modelling rotated image textures and retrieving rotation-invariant texture features .",
        "ner_pair": [
            [
                "anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model",
                "Method"
            ],
            [
                "retrieving rotation-invariant texture features",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model') is the object of the preposition 'for', depending on 'develops' with 'This paper'. Entity 2 ('retrieving rotation-invariant texture features') is part of a coordination, depending on the conjunction 'and' with 'modelling rotated image textures'. There is no direct dependency between Entity 1 and Entity 2, but they are both parts of the purpose clause introduced by 'for'.",
        "sdp_path_text": "model → develops → for → modelling → retrieving",
        "sentence": "The anisotropic circular Gaussian MRF (ACGMRF) model is developed for retrieving rotation-invariant texture features.",
        "sentence_llm_dp_info": "Entity 1 ('anisotropic circular Gaussian MRF (ACGMRF) model') is the subject, depending on the verb 'developed'. Entity 2 ('retrieving rotation-invariant texture features') is the purpose or goal, depending on the preposition 'for', which modifies the verb 'developed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for', indicating that Entity 1 is developed for the purpose described by Entity 2."
    },
    {
        "raw_sentence": "This paper develops an anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model for modelling rotated image textures and retrieving rotation-invariant texture features .",
        "ner_pair": [
            [
                "modelling rotated image textures",
                "Task"
            ],
            [
                "retrieving rotation-invariant texture features",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('modelling rotated image textures') is the object of the preposition 'for', depending on 'model'. Entity 2 ('retrieving rotation-invariant texture features') is also the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but both are connected to the verb 'model' through the preposition 'for'.",
        "sdp_path_text": "modelling → retrieving",
        "sentence": "The model is used for modelling rotated image textures and retrieving rotation-invariant texture features.",
        "sentence_llm_dp_info": "Entity 1 ('modelling rotated image textures') is the object of the preposition 'for', depending on 'used'. Entity 2 ('retrieving rotation-invariant texture features') is also the object of the preposition 'for', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated objects of the preposition 'for'."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "singularity problem",
                "OtherScientificTerm"
            ],
            [
                "least squares estimate -LRB- LSE -RRB- method",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the preposition 'of', depending on 'least squares estimate -LRB- LSE -RRB- method'. Entity 2 ('least squares estimate -LRB- LSE -RRB- method') is the noun modifier, depending on 'overcome' with 'the singularity problem of the least squares estimate -LRB- LSE -RRB- method'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is described as a property or issue related to Entity 2.",
        "sdp_path_text": "problem → of → method",
        "sentence": "The singularity problem of the least squares estimate (LSE) method is addressed.",
        "sentence_llm_dp_info": "Entity 1 ('singularity problem') is the subject, depending on the verb 'is addressed'. Entity 2 ('least squares estimate (LSE) method') is the object of the preposition 'of', depending on 'of' in the phrase 'of the least squares estimate (LSE) method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "singularity problem",
                "OtherScientificTerm"
            ],
            [
                "approximate least squares estimate -LRB- ALSE -RRB- method",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the preposition 'of', depending on 'problem' in the phrase 'the singularity problem of the least squares estimate (LSE) method'. Entity 2 ('approximate least squares estimate (ALSE) method') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose of Entity 2, which is introduced to address the issue described by Entity 1.",
        "sdp_path_text": "problem → overcome → proposed → method",
        "sentence": "An approximate least squares estimate (ALSE) method is proposed to overcome the singularity problem.",
        "sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the preposition 'to', depending on 'overcome' in the phrase 'to overcome the singularity problem'. Entity 2 ('approximate least squares estimate (ALSE) method') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'overcome' which indicates the purpose of Entity 2 in relation to Entity 1."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "singularity problem",
                "OtherScientificTerm"
            ],
            [
                "parameters of the ACGMRF model",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the preposition 'of', depending on 'problem' in the phrase 'the singularity problem of the least squares estimate (LSE) method'. Entity 2 ('parameters of the ACGMRF model') is the object of the verb 'estimate', depending on 'estimate' in the phrase 'to estimate the parameters of the ACGMRF model'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the context describing the reason for proposing the ALSE method and its purpose.",
        "sdp_path_text": "problem → overcome → proposed → estimate → parameters",
        "sentence": "An approximate least squares estimate method is proposed to overcome the singularity problem and estimate the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the preposition 'the', depending on 'overcome' with 'to overcome the singularity problem'. Entity 2 ('parameters of the ACGMRF model') is the object, depending on 'estimate' with 'to estimate the parameters of the ACGMRF model'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the purpose clause introduced by 'to' and relate to the main action of proposing a method."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "singularity problem",
                "OtherScientificTerm"
            ],
            [
                "ACGMRF model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the preposition 'of', depending on 'overcome'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence, where Entity 1 is related to the context of the problem being addressed, and Entity 2 is related to the goal of the proposed solution.",
        "sdp_path_text": "problem → overcome → proposed → estimate → parameters → of → model",
        "sentence": "An approximate least squares estimate method is proposed to estimate the parameters of the ACGMRF model to overcome the singularity problem.",
        "sentence_llm_dp_info": "Entity 1 ('singularity problem') is the object of the verb 'overcome', depending on 'overcome' in the phrase 'to overcome the singularity problem'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters' in the phrase 'the parameters of the ACGMRF model'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the purpose of the proposed method."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "least squares estimate -LRB- LSE -RRB- method",
                "Method"
            ],
            [
                "approximate least squares estimate -LRB- ALSE -RRB- method",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('least squares estimate -LRB- LSE -RRB- method') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('approximate least squares estimate -LRB- ALSE -RRB- method') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of methods used for estimation, with Entity 2 being proposed as a solution to the problem associated with Entity 1.",
        "sdp_path_text": "method → of → problem → overcome → proposed → method",
        "sentence": "An approximate least squares estimate (ALSE) method is proposed to overcome the problem of the least squares estimate (LSE) method.",
        "sentence_llm_dp_info": "Entity 1 ('least squares estimate (LSE) method') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('approximate least squares estimate (ALSE) method') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where Entity 2 is proposed to address issues related to Entity 1."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "least squares estimate -LRB- LSE -RRB- method",
                "Method"
            ],
            [
                "parameters of the ACGMRF model",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('least squares estimate -LRB- LSE -RRB- method') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('parameters of the ACGMRF model') is the object of the verb 'estimate', depending on 'estimate'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of estimation methods and problems in the sentence.",
        "sdp_path_text": "method → of → problem → overcome → proposed → estimate → parameters",
        "sentence": "An approximate least squares estimate method is proposed to estimate the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('least squares estimate -LRB- LSE -RRB- method') is the subject, depending on the verb 'proposed'. Entity 2 ('parameters of the ACGMRF model') is the object of the verb 'estimate', depending on 'estimate' in the phrase 'to estimate the parameters of the ACGMRF model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to estimate'."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "least squares estimate -LRB- LSE -RRB- method",
                "Method"
            ],
            [
                "ACGMRF model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('least squares estimate -LRB- LSE -RRB- method') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2; both are part of the context describing the reason for proposing a new method (ALSE) and its application, respectively.",
        "sdp_path_text": "method → of → problem → overcome → proposed → estimate → parameters → of → model",
        "sentence": "An approximate least squares estimate method is proposed to estimate the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('least squares estimate -LRB- LSE -RRB- method') is the subject, depending on the verb 'proposed'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'proposed' and the prepositional phrase 'to estimate the parameters of the ACGMRF model'."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "approximate least squares estimate -LRB- ALSE -RRB- method",
                "Method"
            ],
            [
                "parameters of the ACGMRF model",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approximate least squares estimate -LRB- ALSE -RRB- method') is the subject, depending on the verb 'proposed'. Entity 2 ('parameters of the ACGMRF model') is the object, depending on the verb 'estimate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'estimate' where Entity 1 is used to perform the action of estimating Entity 2.",
        "sdp_path_text": "method → proposed → estimate → parameters",
        "sentence": "The approximate least squares estimate (ALSE) method is proposed to estimate the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('approximate least squares estimate (ALSE) method') is the subject, depending on the verb 'proposed'. Entity 2 ('parameters of the ACGMRF model') is the object of the verb 'estimate', depending on 'to estimate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of the proposed method, which is to estimate the parameters."
    },
    {
        "raw_sentence": "To overcome the singularity problem of the least squares estimate -LRB- LSE -RRB- method , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .",
        "ner_pair": [
            [
                "approximate least squares estimate -LRB- ALSE -RRB- method",
                "Method"
            ],
            [
                "ACGMRF model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approximate least squares estimate -LRB- ALSE -RRB- method') is the subject, depending on the verb 'proposed'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'estimate' which governs both the subject (Entity 1) and the object of the preposition (Entity 2).",
        "sdp_path_text": "method → proposed → estimate → parameters → of → model",
        "sentence": "The approximate least squares estimate (ALSE) method is proposed to estimate the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('approximate least squares estimate (ALSE) method') is the subject, depending on the verb 'proposed'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'proposed' and the purpose of estimating the parameters of the ACGMRF model."
    },
    {
        "raw_sentence": "The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB- .",
        "ner_pair": [
            [
                "parameters of the ACGMRF model",
                "OtherScientificTerm"
            ],
            [
                "rotation-invariant features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parameters of the ACGMRF model') is the object of the preposition 'from', depending on the verb 'obtained'. Entity 2 ('rotation-invariant features') is the subject, depending on the modal verb 'can be' with 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtained' which indicates that the features can be derived from the parameters.",
        "sdp_path_text": "parameters → from → obtained → features",
        "sentence": "Rotation-invariant features can be obtained from the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('parameters of the ACGMRF model') is the object of the preposition 'from', depending on 'obtained'. Entity 2 ('rotation-invariant features') is the subject, depending on the auxiliary verb 'can be' with 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtained'."
    },
    {
        "raw_sentence": "The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB- .",
        "ner_pair": [
            [
                "rotation-invariant features",
                "OtherScientificTerm"
            ],
            [
                "ACGMRF model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rotation-invariant features') is the subject, depending on the verb 'can be obtained'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from the parameters of the ACGMRF model'.",
        "sdp_path_text": "features → obtained → from → parameters → of → model",
        "sentence": "Rotation-invariant features can be obtained from the parameters of the ACGMRF model.",
        "sentence_llm_dp_info": "Entity 1 ('rotation-invariant features') is the subject, depending on the verb 'can be obtained'. Entity 2 ('ACGMRF model') is the object of the preposition 'of', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'parameters' and the preposition 'of'."
    },
    {
        "raw_sentence": "The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB- .",
        "ner_pair": [
            [
                "one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-",
                "Method"
            ],
            [
                "rotation-invariant features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-') is the agent, depending on the verb 'obtained' through the preposition 'by'. Entity 2 ('rotation-invariant features') is the subject, depending on the auxiliary verb 'can be' and the main verb 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtained' where Entity 1 is the means by which Entity 2 is obtained.",
        "sdp_path_text": "transform → by → obtained → features",
        "sentence": "Rotation-invariant features can be obtained by the one-dimensional discrete Fourier transform.",
        "sentence_llm_dp_info": "Entity 1 ('one-dimensional (1-D) discrete Fourier transform (DFT)') is the object of the preposition 'by', depending on 'obtained'. Entity 2 ('rotation-invariant features') is the subject, depending on the verb 'can be obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtained' which indicates that Entity 1 is the method by which Entity 2 can be obtained."
    },
    {
        "raw_sentence": "The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB- .",
        "ner_pair": [
            [
                "parameters of the ACGMRF model",
                "OtherScientificTerm"
            ],
            [
                "one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parameters of the ACGMRF model') is the object of the preposition 'from', depending on 'obtained'. Entity 2 ('one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-') is the object of the preposition 'by', depending on 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the verb 'obtained'.",
        "sdp_path_text": "parameters → from → obtained → by → transform",
        "sentence": "The parameters of the ACGMRF model can be obtained by the one-dimensional discrete Fourier transform.",
        "sentence_llm_dp_info": "Entity 1 ('parameters of the ACGMRF model') is the subject, depending on the verb 'obtained'. Entity 2 ('one-dimensional discrete Fourier transform') is the object of the preposition 'by', depending on 'by' in the phrase 'by the one-dimensional discrete Fourier transform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' indicating the method by which the parameters are obtained."
    },
    {
        "raw_sentence": "The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB- .",
        "ner_pair": [
            [
                "ACGMRF model",
                "Method"
            ],
            [
                "one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ACGMRF model') is the object of the preposition 'of', depending on the verb phrase 'can be obtained from the parameters of the ACGMRF model'. Entity 2 ('one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-') is the object of the preposition 'by', depending on the verb phrase 'can be obtained from the parameters of the ACGMRF model by the one-dimensional -LRB- 1-D -RRB- discrete Fourier transform -LRB- DFT -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described by the sentence, where the features are obtained from the parameters of Entity 1 using Entity 2.",
        "sdp_path_text": "model → of → parameters → from → obtained → by → transform",
        "sentence": "The ACGMRF model's parameters can be obtained by the one-dimensional discrete Fourier transform.",
        "sentence_llm_dp_info": "Entity 1 ('ACGMRF model') is part of a possessive structure, depending on 'parameters' with the possessive marker 'model’s'. Entity 2 ('one-dimensional discrete Fourier transform') is the object of the preposition 'by', depending on 'by' in the phrase 'by the one-dimensional discrete Fourier transform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtained' and the preposition 'by'."
    },
    {
        "raw_sentence": "Significantly improved accuracy can be achieved by applying the rotation-invariant features to classify SAR -LRB- synthetic aperture radar -RRB- sea ice and Brodatz imagery .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "rotation-invariant features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'can be achieved'. Entity 2 ('rotation-invariant features') is the object of the preposition 'by', depending on 'applying' in the phrase 'by applying the rotation-invariant features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the prepositional phrase 'by applying'.",
        "sdp_path_text": "accuracy → achieved → by → applying → features",
        "sentence": "Improved accuracy can be achieved by applying rotation-invariant features.",
        "sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'achieved'. Entity 2 ('rotation-invariant features') is the object of the preposition 'by', depending on 'applying' in the phrase 'by applying rotation-invariant features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'by' and the verb 'applying'."
    },
    {
        "raw_sentence": "Significantly improved accuracy can be achieved by applying the rotation-invariant features to classify SAR -LRB- synthetic aperture radar -RRB- sea ice and Brodatz imagery .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "SAR -LRB- synthetic aperture radar",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'can be achieved'. Entity 2 ('SAR -LRB- synthetic aperture radar') is part of the object complement, depending on 'classify' with 'to classify'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'accuracy' is what can be improved, and 'SAR -LRB- synthetic aperture radar' is one of the objects being classified to achieve this improvement.",
        "sdp_path_text": "accuracy → achieved → by → applying → classify → ice → radar",
        "sentence": "Improved accuracy can be achieved by applying features to classify SAR sea ice.",
        "sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'can be achieved'. Entity 2 ('SAR') is part of the compound noun 'SAR sea ice', which is the object of the verb 'classify'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where the improvement of 'accuracy' involves classifying 'SAR sea ice'."
    },
    {
        "raw_sentence": "Significantly improved accuracy can be achieved by applying the rotation-invariant features to classify SAR -LRB- synthetic aperture radar -RRB- sea ice and Brodatz imagery .",
        "ner_pair": [
            [
                "rotation-invariant features",
                "OtherScientificTerm"
            ],
            [
                "SAR -LRB- synthetic aperture radar",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rotation-invariant features') is the object of the preposition 'by', depending on 'achieved'. Entity 2 ('SAR -LRB- synthetic aperture radar') is part of a compound noun, depending on 'classify' as the object of the verb. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the same clause describing the method used to classify SAR sea ice and Brodatz imagery.",
        "sdp_path_text": "features → applying → classify → ice → radar",
        "sentence": "Applying rotation-invariant features can classify SAR (synthetic aperture radar) sea ice.",
        "sentence_llm_dp_info": "Entity 1 ('rotation-invariant features') is the object of the verb 'Applying', depending on 'can' which is part of the modal construction 'can classify'. Entity 2 ('SAR (synthetic aperture radar)') is the object of the verb 'classify', depending on 'can' which indicates the capability. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the same clause where 'rotation-invariant features' are used to 'classify' 'SAR (synthetic aperture radar) sea ice'."
    },
    {
        "raw_sentence": "Despite much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate label sequence models via Viterbi decoding .",
        "ner_pair": [
            [
                "independent classifiers",
                "Method"
            ],
            [
                "semantic role labeling",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independent classifiers') is the object, depending on the verb 'used' with 'previous work'. Entity 2 ('semantic role labeling') is the object of the preposition 'on', depending on 'progress'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the discussion of progress and methods in the field of semantic role labeling.",
        "sdp_path_text": "classifiers → used → Despite → progress → on → labeling",
        "sentence": "Independent classifiers have been used in semantic role labeling despite recent progress.",
        "sentence_llm_dp_info": "Entity 1 ('independent classifiers') is the subject, depending on the verb 'used'. Entity 2 ('semantic role labeling') is the object of the preposition 'in', depending on 'in' in the phrase 'in semantic role labeling'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "Despite much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate label sequence models via Viterbi decoding .",
        "ner_pair": [
            [
                "semantic role labeling",
                "Task"
            ],
            [
                "label sequence models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('semantic role labeling') is the object of the preposition 'on', depending on 'progress'. Entity 2 ('label sequence models') is the object of the preposition 'with', depending on 'combined'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "labeling → on → progress → Despite → used → classifiers → combined → with → models",
        "sentence": "Previous work on semantic role labeling has used classifiers combined with label sequence models.",
        "sentence_llm_dp_info": "Entity 1 ('semantic role labeling') is the object of the preposition 'on', depending on 'work'. Entity 2 ('label sequence models') is the object of the preposition 'with', depending on 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing aspects of the previous work."
    },
    {
        "raw_sentence": "Despite much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate label sequence models via Viterbi decoding .",
        "ner_pair": [
            [
                "semantic role labeling",
                "Task"
            ],
            [
                "Viterbi decoding",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('semantic role labeling') is the object of the preposition 'on', depending on 'progress'. Entity 2 ('Viterbi decoding') is part of a prepositional phrase, depending on 'combined' with 'models'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "labeling → on → progress → Despite → used → classifiers → combined → via → decoding",
        "sentence": "Previous work on semantic role labeling has used classifiers combined via Viterbi decoding.",
        "sentence_llm_dp_info": "Entity 1 ('semantic role labeling') is the object of the preposition 'on', depending on 'work'. Entity 2 ('Viterbi decoding') is the object of the preposition 'via', depending on 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the methods used in previous work."
    },
    {
        "raw_sentence": "Despite much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate label sequence models via Viterbi decoding .",
        "ner_pair": [
            [
                "independent classifiers",
                "Method"
            ],
            [
                "label sequence models",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independent classifiers') is the object of the preposition 'used', depending on 'used' in the phrase 'used independent classifiers'. Entity 2 ('label sequence models') is the object of the preposition 'with', depending on 'combined' in the phrase 'combined with separate label sequence models'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing different approaches used in previous work.",
        "sdp_path_text": "classifiers → combined → with → models",
        "sentence": "Independent classifiers have been combined with label sequence models.",
        "sentence_llm_dp_info": "Entity 1 ('independent classifiers') is the subject, depending on the verb 'combined'. Entity 2 ('label sequence models') is the object, depending on the verb 'combined'. There is a direct dependency between Entity 1 and Entity 2, as they are both part of the same verbal action described by 'have been combined'."
    },
    {
        "raw_sentence": "Despite much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate label sequence models via Viterbi decoding .",
        "ner_pair": [
            [
                "independent classifiers",
                "Method"
            ],
            [
                "Viterbi decoding",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independent classifiers') is the object of the preposition 'used', depending on 'used' in the phrase 'used independent classifiers'. Entity 2 ('Viterbi decoding') is part of a prepositional phrase, depending on 'combined' in the phrase 'combined with separate label sequence models via Viterbi decoding'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of methods used in previous work.",
        "sdp_path_text": "classifiers → combined → via → decoding",
        "sentence": "Independent classifiers have been combined via Viterbi decoding.",
        "sentence_llm_dp_info": "Entity 1 ('independent classifiers') is the subject, depending on the verb 'have been combined'. Entity 2 ('Viterbi decoding') is the object of the preposition 'via', depending on 'combined' in the phrase 'combined via Viterbi decoding'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combined' and the preposition 'via'."
    },
    {
        "raw_sentence": "Despite much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate label sequence models via Viterbi decoding .",
        "ner_pair": [
            [
                "Viterbi decoding",
                "Method"
            ],
            [
                "label sequence models",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Viterbi decoding') is part of a prepositional phrase, depending on 'combined with' as the method of combination. Entity 2 ('label sequence models') is the object of the preposition 'with', depending on 'combined with' in the phrase 'combined with separate label sequence models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase describing how they are combined.",
        "sdp_path_text": "decoding → via → combined → with → models",
        "sentence": "Viterbi decoding combines label sequence models.",
        "sentence_llm_dp_info": "Entity 1 ('Viterbi decoding') is the subject, depending on the verb 'combines'. Entity 2 ('label sequence models') is the object, depending on the verb 'combines'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 acts on Entity 2 through the verb 'combines'."
    },
    {
        "raw_sentence": "We show how to build a joint model of argument frames , incorporating novel features that model these interactions into discriminative log-linear models .",
        "ner_pair": [
            [
                "joint model of argument frames",
                "Method"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('joint model of argument frames') is the object of the verb 'build', depending on 'how' which is part of the clause 'how to build'. Entity 2 ('features') is the subject, depending on the verb 'incorporating' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the construction and characteristics of the model.",
        "sdp_path_text": "model → build → incorporating → features",
        "sentence": "We build a joint model of argument frames incorporating features.",
        "sentence_llm_dp_info": "Entity 1 ('joint model of argument frames') is the object, depending on the verb 'build'. Entity 2 ('features') is the object of the preposition 'incorporating', depending on 'incorporating' in the phrase 'incorporating features'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'incorporating' which indicates that the features are part of the joint model of argument frames."
    },
    {
        "raw_sentence": "We show how to build a joint model of argument frames , incorporating novel features that model these interactions into discriminative log-linear models .",
        "ner_pair": [
            [
                "joint model of argument frames",
                "Method"
            ],
            [
                "discriminative log-linear models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('joint model of argument frames') is the object of the verb 'build', depending on 'show' through the clause 'how to build'. Entity 2 ('discriminative log-linear models') is the object of the preposition 'into', depending on 'incorporating'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the process of building and incorporating features into the models.",
        "sdp_path_text": "model → build → incorporating → into → models",
        "sentence": "We show how to build a joint model of argument frames incorporating into discriminative log-linear models.",
        "sentence_llm_dp_info": "Entity 1 ('joint model of argument frames') is the object of the verb 'build', depending on 'how' which introduces the method of building. Entity 2 ('discriminative log-linear models') is the object of the preposition 'into', depending on the verb 'incorporating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporating' which indicates that Entity 1 is being integrated into Entity 2."
    },
    {
        "raw_sentence": "We show how to build a joint model of argument frames , incorporating novel features that model these interactions into discriminative log-linear models .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "discriminative log-linear models",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('features') is the object of the relative clause, depending on 'incorporating' with 'novel'. Entity 2 ('discriminative log-linear models') is the object, depending on 'into' in the prepositional phrase 'into discriminative log-linear models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporating' and the preposition 'into'.",
        "sdp_path_text": "features → incorporating → into → models",
        "sentence": "Features are incorporated into discriminative log-linear models.",
        "sentence_llm_dp_info": "Entity 1 ('features') is the subject, depending on the verb 'incorporated'. Entity 2 ('discriminative log-linear models') is the object, depending on 'into' in the phrase 'into discriminative log-linear models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporated' and the preposition 'into'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "error reduction",
                "Metric"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('error reduction') is the object of the preposition 'of', depending on 'achieves' with 'system'. Entity 2 ('system') is the subject, depending on the verb 'achieves'. There is a direct dependency between Entity 1 and Entity 2, as 'error reduction' is part of what the 'system' achieves.",
        "sdp_path_text": "reduction → achieves → system",
        "sentence": "The system achieves error reduction.",
        "sentence_llm_dp_info": "Entity 1 ('error reduction') is the object, depending on the verb 'achieves'. Entity 2 ('system') is the subject, depending on the verb 'achieves'. There is a direct dependency between Entity 1 and Entity 2, as 'system' is the agent that performs the action of achieving 'error reduction'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "independent classifier",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independent classifier') is the object of the preposition 'over', depending on 'reduction'. Entity 2 ('system') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieves' and the prepositional phrase 'over a state-of-the-art independent classifier'.",
        "sdp_path_text": "classifier → over → achieves → system",
        "sentence": "The system achieves error reduction over an independent classifier.",
        "sentence_llm_dp_info": "Entity 1 ('independent classifier') is the object of the preposition 'over', depending on 'over' in the phrase 'over an independent classifier'. Entity 2 ('system') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'over an independent classifier' which modifies the verb 'achieves'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "gold-standard parse trees",
                "OtherScientificTerm"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('gold-standard parse trees') is the object of the preposition 'for', depending on 'for' in the phrase 'for gold-standard parse trees'. Entity 2 ('system') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for gold-standard parse trees' which modifies the noun 'classifier'.",
        "sdp_path_text": "trees → for → classifier → over → achieves → system",
        "sentence": "The system achieves error reduction over a classifier for gold-standard parse trees.",
        "sentence_llm_dp_info": "Entity 1 ('gold-standard parse trees') is the object of the preposition 'for', depending on 'for' in the phrase 'for gold-standard parse trees'. Entity 2 ('system') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for gold-standard parse trees'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "PropBank",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'achieves'. Entity 2 ('PropBank') is the object of the preposition 'on', depending on 'trees'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'on PropBank' which modifies 'parse trees'.",
        "sdp_path_text": "system → achieves → over → classifier → on → PropBank",
        "sentence": "The system achieves error reduction over a classifier on PropBank.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'achieves'. Entity 2 ('PropBank') is the object of the preposition 'on', depending on 'classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'on PropBank' which modifies 'classifier'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "error reduction",
                "Metric"
            ],
            [
                "independent classifier",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('error reduction') is the object, depending on the verb 'achieves' with 'system'. Entity 2 ('independent classifier') is the object of the preposition 'over', depending on 'over' in the phrase 'over a state-of-the-art independent classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'achieves' and the preposition 'over'.",
        "sdp_path_text": "reduction → achieves → over → classifier",
        "sentence": "The system achieves error reduction over an independent classifier.",
        "sentence_llm_dp_info": "Entity 1 ('error reduction') is the object, depending on the verb 'achieves' with 'The system'. Entity 2 ('independent classifier') is the object of the preposition 'over', depending on 'over' in the phrase 'over an independent classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'achieves' and the preposition 'over'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "error reduction",
                "Metric"
            ],
            [
                "gold-standard parse trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('error reduction') is the object, depending on the verb 'achieves' with 'This system'. Entity 2 ('gold-standard parse trees') is the object of the preposition 'on', depending on 'classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the performance of the system over different types of data.",
        "sdp_path_text": "reduction → achieves → over → classifier → for → trees",
        "sentence": "Error reduction is achieved over classifiers for gold-standard parse trees.",
        "sentence_llm_dp_info": "Entity 1 ('error reduction') is the subject, depending on the verb 'achieved'. Entity 2 ('gold-standard parse trees') is the object of the preposition 'for', depending on 'for' in the phrase 'for gold-standard parse trees'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "error reduction",
                "Metric"
            ],
            [
                "PropBank",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('error reduction') is the object, depending on the verb 'achieves' with 'This system'. Entity 2 ('PropBank') is the object of the preposition 'on', depending on 'parse trees'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the performance of the system on different metrics.",
        "sdp_path_text": "reduction → achieves → over → classifier → on → PropBank",
        "sentence": "The system achieves error reduction over classifiers on PropBank.",
        "sentence_llm_dp_info": "Entity 1 ('error reduction') is the object, depending on 'achieves' with 'The system'. Entity 2 ('PropBank') is the object of the preposition 'on', depending on 'on' in the phrase 'on PropBank'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "gold-standard parse trees",
                "OtherScientificTerm"
            ],
            [
                "independent classifier",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('gold-standard parse trees') is the object, depending on the preposition 'on', which modifies 'classifier'. Entity 2 ('independent classifier') is the object of the preposition 'over', depending on 'over' in the phrase 'over a state-of-the-art independent classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same comparative structure, where the performance of the system is described relative to the 'independent classifier' when evaluated on 'gold-standard parse trees'.",
        "sdp_path_text": "trees → for → classifier",
        "sentence": "Gold-standard parse trees are used for an independent classifier.",
        "sentence_llm_dp_info": "Entity 1 ('gold-standard parse trees') is the subject, depending on the verb 'used'. Entity 2 ('independent classifier') is the object of the preposition 'for', depending on 'for' in the phrase 'for an independent classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "independent classifier",
                "Method"
            ],
            [
                "PropBank",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('independent classifier') is the object of the preposition 'over', depending on 'over' in the phrase 'over a state-of-the-art independent classifier'. Entity 2 ('PropBank') is the object of the preposition 'on', depending on 'on' in the phrase 'on PropBank'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the performance improvement of the system.",
        "sdp_path_text": "classifier → on → PropBank",
        "sentence": "The independent classifier performs on PropBank.",
        "sentence_llm_dp_info": "Entity 1 ('independent classifier') is the subject, depending on the verb 'performs'. Entity 2 ('PropBank') is the object, depending on 'on' in the prepositional phrase 'on PropBank'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'."
    },
    {
        "raw_sentence": "This system achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .",
        "ner_pair": [
            [
                "gold-standard parse trees",
                "OtherScientificTerm"
            ],
            [
                "PropBank",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('gold-standard parse trees') is the object, depending on the preposition 'on', which is part of the prepositional phrase 'on gold-standard parse trees'. Entity 2 ('PropBank') is the object, depending on the preposition 'on', which is part of the prepositional phrase 'on PropBank'. There is no direct dependency between Entity 1 and Entity 2; both are objects of different instances of the preposition 'on'.",
        "sdp_path_text": "trees → for → classifier → on → PropBank",
        "sentence": "Gold-standard parse trees are used for a classifier on PropBank.",
        "sentence_llm_dp_info": "Entity 1 ('gold-standard parse trees') is the subject, depending on the verb 'used'. Entity 2 ('PropBank') is the object of the preposition 'on', depending on 'classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on' and the noun 'classifier'."
    },
    {
        "raw_sentence": "One of the major problems one is faced with when decomposing words into their constituent parts is ambiguity : the generation of multiple analyses for one input word , many of which are implausible .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "generation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ambiguity') is the subject complement, depending on 'is' with 'is'. Entity 2 ('generation') is the subject, depending on the colon (:) which introduces an explanation or elaboration of 'ambiguity'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the explanatory structure introduced by the colon.",
        "sdp_path_text": "ambiguity → generation",
        "sentence": "Ambiguity involves the generation of multiple analyses for one input word.",
        "sentence_llm_dp_info": "Entity 1 ('ambiguity') is the subject, depending on the verb 'involves'. Entity 2 ('generation') is the subject complement, depending on 'involves' and modified by the prepositional phrase 'of multiple analyses for one input word'. There is a direct dependency between Entity 1 and Entity 2, as 'generation' is part of the predicate that follows 'ambiguity' and describes what it involves."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'is provided with'. Entity 2 ('ambiguity') is the object of the preposition 'with', depending on 'deal' in the phrase 'to deal with ambiguity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'in order to deal with ambiguity'.",
        "sdp_path_text": "MORPA → provided → In → order → deal → with → ambiguity",
        "sentence": "MORPA is provided to deal with ambiguity.",
        "sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'provided'. Entity 2 ('ambiguity') is the object of the preposition 'with', depending on 'deal' in the phrase 'to deal with ambiguity'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'deal' and the preposition 'with'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the verb phrase 'deal with', depending on 'deal'. Entity 2 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object of the preposition 'with', depending on 'provided'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where the parser (MORPA) is provided with the PCFG to handle the ambiguity.",
        "sdp_path_text": "ambiguity → with → deal → order → In → provided → with → grammar",
        "sentence": "To deal with ambiguity, the parser is provided with a probabilistic context-free grammar.",
        "sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on the verb phrase 'deal with'. Entity 2 ('probabilistic context-free grammar') is the object, depending on the verb 'provided'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where dealing with ambiguity is the purpose for which the parser is provided with the probabilistic context-free grammar."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on the verb 'deal' in the phrase 'to deal with ambiguity'. Entity 2 ('`` conventional '' context-free morphological grammar') is the object of the preposition 'with', depending on the verb 'combines' in the clause 'it combines a `` conventional '' context-free morphological grammar'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence.",
        "sdp_path_text": "ambiguity → with → deal → order → In → provided → combines → grammar",
        "sentence": "To deal with ambiguity, MORPA combines a conventional context-free morphological grammar.",
        "sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on 'deal'. Entity 2 ('conventional context-free morphological grammar') is the object, depending on 'combines' with 'MORPA'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combines' which indicates that the grammar is used to address the ambiguity."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on 'deal' in the phrase 'to deal with ambiguity'. Entity 2 ('ungrammatical segmentations') is the object of the preposition 'out', depending on 'filter' in the phrase 'filter out ungrammatical segmentations'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.",
        "sdp_path_text": "ambiguity → with → deal → order → In → provided → combines → filter → segmentations",
        "sentence": "To deal with ambiguity, MORPA combines a morphological grammar to filter out ungrammatical segmentations.",
        "sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on 'deal'. Entity 2 ('ungrammatical segmentations') is the object of the verb 'filter', depending on 'filter out'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose of dealing with ambiguity by filtering out ungrammatical segmentations."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "probability-based scoring function",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the infinitive 'to deal with', depending on 'deal'. Entity 2 ('probability-based scoring function') is the subject complement, depending on 'which' in the relative clause 'which determines the likelihood of each successful parse'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.",
        "sdp_path_text": "ambiguity → with → deal → order → In → provided → combines → with → function",
        "sentence": "To deal with ambiguity, the parser combines a probability-based scoring function.",
        "sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on 'deals'. Entity 2 ('probability-based scoring function') is the object of the verb 'combines', depending on 'parser'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the actions described by the verbs 'deals' and 'combines'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "parse",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'with', depending on the verb 'deal' in the phrase 'to deal with ambiguity'. Entity 2 ('parse') is part of the noun phrase 'each successful parse', where it acts as the head noun, depending on 'determines' in the clause 'which determines the likelihood of each successful parse'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the broader context of the sentence, where dealing with ambiguity involves a process that includes determining the likelihood of parses.",
        "sdp_path_text": "ambiguity → with → deal → order → In → provided → MORPA → PArser",
        "sentence": "MORPA is provided to deal with ambiguity in parsing.",
        "sentence_llm_dp_info": "Entity 1 ('ambiguity') is the object of the preposition 'in', depending on 'deal with'. Entity 2 ('parse') is part of the gerund 'parsing', which is the object of the preposition 'with', depending on 'deal with'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the prepositional phrase 'in parsing' which modifies 'ambiguity'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object, depending on the verb 'provided' with 'MORphological PArser MORPA'. Entity 2 ('MORphological PArser MORPA') is the subject, depending on the verb 'provided'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is provided to Entity 2.",
        "sdp_path_text": "grammar → with → provided → MORPA",
        "sentence": "MORPA is provided with a probabilistic context-free grammar (PCFG).",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar (PCFG)') is the object, depending on the preposition 'with' which is part of the phrase 'with a probabilistic context-free grammar (PCFG)'. Entity 2 ('MORphological PArser MORPA') is the subject, depending on the verb 'is' in the sentence 'MORPA is provided'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'is provided with'. Entity 2 ('it') is the subject, depending on the verb 'combines'. There is no direct dependency between Entity 1 and Entity 2, but they are semantically related as 'it' refers back to 'MORphological PArser MORPA'.",
        "sdp_path_text": "MORPA → provided → In → order → deal → with",
        "sentence": "MORphological PArser MORPA is provided to deal with ambiguity.",
        "sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'provided'. Entity 2 ('it') is the subject of the relative clause, referring back to 'MORphological PArser MORPA', and depends on 'provided' through the relative pronoun 'which' (implied). There is no direct dependency between Entity 1 and Entity 2, but 'it' refers back to 'MORphological PArser MORPA' in the context of the sentence."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'is provided with'. Entity 2 ('`` conventional '' context-free morphological grammar') is the object, depending on the verb 'combines' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combines' and the prepositional phrase 'with a probabilistic context-free grammar'.",
        "sdp_path_text": "MORPA → provided → combines → grammar",
        "sentence": "MORPA combines a conventional context-free morphological grammar.",
        "sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'combines'. Entity 2 ('conventional context-free morphological grammar') is the object, depending on the verb 'combines'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 combines Entity 2."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'is provided'. Entity 2 ('ungrammatical segmentations') is the object, depending on the verb 'filter' with 'conventional context-free morphological grammar'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the process described in the sentence where MORPA uses a grammar to filter out ungrammatical segmentations.",
        "sdp_path_text": "MORPA → provided → combines → filter → segmentations",
        "sentence": "MORPA combines a method to filter out ungrammatical segmentations.",
        "sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'combines'. Entity 2 ('ungrammatical segmentations') is the object of the preposition 'out', depending on 'filter' in the phrase 'filter out ungrammatical segmentations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combines' and the prepositional phrase 'to filter out ungrammatical segmentations'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            [
                "probability-based scoring function",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on 'provided' with the verb 'is provided with'. Entity 2 ('probability-based scoring function') is the subject complement, depending on 'which' in the relative clause 'which determines the likelihood'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of a larger structure where Entity 1 is provided with a probabilistic context-free grammar that uses Entity 2 to determine the likelihood of each successful parse.",
        "sdp_path_text": "MORPA → provided → combines → with → function",
        "sentence": "MORphological PArser MORPA combines a probability-based scoring function.",
        "sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'combines'. Entity 2 ('probability-based scoring function') is the object, depending on 'combines' with 'MORphological PArser MORPA'. There is a direct dependency between Entity 1 and Entity 2, as 'MORphological PArser MORPA' combines 'probability-based scoring function'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "MORphological PArser MORPA",
                "Method"
            ],
            [
                "parse",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on 'provided' with 'is'. Entity 2 ('parse') is part of a nominal clause, depending on 'determines' with 'likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the series of actions described in the sentence, where Entity 1 is equipped with tools (PCFG) that ultimately affect the process of Entity 2.",
        "sdp_path_text": "MORPA → PArser",
        "sentence": "The MORphological PArser MORPA determines the likelihood of each successful parse.",
        "sentence_llm_dp_info": "Entity 1 ('MORphological PArser MORPA') is the subject, depending on the verb 'determines'. Entity 2 ('parse') is part of the noun phrase 'each successful parse', which is the object of the preposition 'of', depending on 'likelihood'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'determines' and the noun phrase 'the likelihood of each successful parse'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object, depending on the verb 'provided' with 'MORPA'. Entity 2 ('it') is the subject, depending on the verb 'combines'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context where 'it' (referring to MORPA) is provided with the PCFG and combines different grammatical approaches.",
        "sdp_path_text": "grammar → with → provided → In → order → deal → with",
        "sentence": "The probabilistic context-free grammar (PCFG) is provided to deal with ambiguity.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar (PCFG)') is the subject, depending on the verb 'is provided'. Entity 2 ('it') is the pronoun, depending on the verb 'is provided' as the subject reference. There is no direct dependency between Entity 1 and Entity 2; however, 'it' refers back to 'probabilistic context-free grammar (PCFG)' in the sentence."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object, depending on 'provided' with 'MORPA'. Entity 2 ('`` conventional '' context-free morphological grammar') is the object, depending on 'combines' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence, with Entity 1 being part of what MORPA is provided with, and Entity 2 being one of the elements that MORPA combines to filter out ungrammatical segmentations.",
        "sdp_path_text": "grammar → with → provided → combines → grammar",
        "sentence": "The probabilistic context-free grammar (PCFG) combines a conventional context-free morphological grammar.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar (PCFG)') is the subject, depending on the verb 'combines'. Entity 2 ('conventional context-free morphological grammar') is the object, depending on 'combines' with 'probabilistic context-free grammar (PCFG)'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the direct object of the action performed by Entity 1."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object of the preposition 'with', depending on 'provided' in the phrase 'is provided with a probabilistic context-free grammar -LRB- PCFG -RRB-'. Entity 2 ('ungrammatical segmentations') is the object of the preposition 'out', depending on 'filter' in the phrase 'filter out ungrammatical segmentations'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing how the morphological parser (MORPA) processes input.",
        "sdp_path_text": "grammar → with → provided → combines → filter → segmentations",
        "sentence": "The probabilistic context-free grammar (PCFG) combines a conventional context-free morphological grammar to filter out ungrammatical segmentations.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar (PCFG)') is the subject, depending on the verb 'combines'. Entity 2 ('ungrammatical segmentations') is the object, depending on the verb 'filter out'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of the PCFG combining elements to filter out the ungrammatical segmentations."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            [
                "probability-based scoring function",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object of the preposition 'with', depending on 'provided'. Entity 2 ('probability-based scoring function') is the subject of the relative clause 'which determines the likelihood of each successful parse', depending on 'determines'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing how the MORphological PArser MORPA deals with ambiguity.",
        "sdp_path_text": "grammar → with → provided → combines → with → function",
        "sentence": "The probabilistic context-free grammar (PCFG) combines with a probability-based scoring function.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar (PCFG)') is the subject, depending on the verb 'combines'. Entity 2 ('probability-based scoring function') is the object, depending on 'combines' with 'with'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the object of the preposition 'with' that modifies Entity 1."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probabilistic context-free grammar -LRB- PCFG -RRB-",
                "Method"
            ],
            [
                "parse",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar -LRB- PCFG -RRB-') is the object of the preposition 'with', depending on 'provided'. Entity 2 ('parse') is part of the noun phrase 'each successful parse', acting as the object of the relative clause modified by 'which determines the likelihood'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger context where Entity 1 is used to determine the likelihood of Entity 2.",
        "sdp_path_text": "grammar → with → provided → MORPA → PArser",
        "sentence": "MORPA is provided with a probabilistic context-free grammar to determine the likelihood of each parse.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic context-free grammar') is the object of the preposition 'with', depending on 'provided' with 'MORPA'. Entity 2 ('parse') is part of the compound noun 'each parse', which is the object of the preposition 'of', depending on 'likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'determine' and the prepositions 'with' and 'of'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('`` conventional '' context-free morphological grammar') is the object, depending on the verb 'combines' with 'it'. Entity 2 ('it') is the subject, depending on the verb 'combines'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is combined with Entity 2 in the sentence.",
        "sdp_path_text": "grammar → combines → provided → In → order → deal → with",
        "sentence": "The 'conventional' context-free morphological grammar combines with a probabilistic context-free grammar to deal with ambiguity.",
        "sentence_llm_dp_info": "Entity 1 ('conventional context-free morphological grammar') is the subject, depending on the verb 'combines'. Entity 2 ('it') is not present in the sentence, so there is no dependency for Entity 2. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 does not appear in the sentence.\"\n\nHowever, if you intended to use a different word or entity as \"it\" (for example, \"a probabilistic context-free grammar\"), please clarify, and I can adjust the analysis accordingly."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on 'combines' as the main verb of the clause. Entity 2 ('ungrammatical segmentations') is the object, depending on 'filter' with 'out'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where 'it' refers to the MORphological PArser MORPA, which performs the action of filtering out 'ungrammatical segmentations'.",
        "sdp_path_text": "with → deal → order → In → provided → combines → filter → segmentations",
        "sentence": "It combines a context-free morphological grammar to filter out ungrammatical segmentations.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'combines'. Entity 2 ('ungrammatical segmentations') is the object, depending on the verb 'filter' in the phrase 'to filter out ungrammatical segmentations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combines' and the infinitive 'to filter out'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "parse",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on 'combines' as the main verb of the clause. Entity 2 ('parse') is part of the object complement, depending on 'determines' with 'likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where 'it' (MORPA) combines different grammars and functions, one of which affects the 'parse'.",
        "sdp_path_text": "with → deal → order → In → provided → MORPA → PArser",
        "sentence": "MORPA, the morphological parser, is provided with a probabilistic context-free grammar to deal with ambiguity and determine the likelihood of each parse.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the object, depending on 'provided' with 'MORPA'. Entity 2 ('parse') is part of the noun phrase, depending on 'likelihood' with 'each'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where 'it' refers to 'MORPA' and 'parse' is an element in the process that 'MORPA' deals with.\" \n\nHowever, it seems there might be a slight misunderstanding in the identification of \"it\" as Entity 1 in this sentence. The pronoun \"it\" does not directly appear in the sentence you provided. If we were to consider the correct entities based on your sentence, we could re-evaluate the entities as follows:\n\nEntity 1: MORPA (the morphological parser)\nEntity 2: parse\n\nRevised Answer:\nEntity 1 ('MORPA, the morphological parser') is the subject, depending on 'is provided' with 'a probabilistic context-free grammar'. Entity 2 ('parse') is the object of the preposition 'of', depending on 'likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context where 'MORPA' uses the grammar to determine the likelihood of each 'parse'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('`` conventional '' context-free morphological grammar') is the object of the verb 'combines', depending on 'combines' with 'it'. Entity 2 ('ungrammatical segmentations') is the object of the verb 'filter', depending on 'filter' with 'grammar'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'filter'.",
        "sdp_path_text": "grammar → combines → filter → segmentations",
        "sentence": "The 'conventional' context-free morphological grammar combines to filter out ungrammatical segmentations.",
        "sentence_llm_dp_info": "Entity 1 ('conventional context-free morphological grammar') is the subject, depending on the verb 'combines'. Entity 2 ('ungrammatical segmentations') is the object, depending on the verb phrase 'filter out'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'combines' which leads to the filtering out of Entity 2."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probability-based scoring function",
                "Method"
            ],
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probability-based scoring function') is the subject complement, depending on 'determines' with 'likelihood'. Entity 2 ('`` conventional '' context-free morphological grammar') is the object, depending on 'combines' with 'it'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing how the MORphological PArser MORPA processes information.",
        "sdp_path_text": "function → with → combines → grammar",
        "sentence": "The probability-based scoring function combines with the 'conventional' context-free morphological grammar.",
        "sentence_llm_dp_info": "Entity 1 ('probability-based scoring function') is the subject, depending on the verb 'combines'. Entity 2 ('conventional context-free morphological grammar') is the object, depending on 'with' in the phrase 'with the conventional context-free morphological grammar'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "`` conventional '' context-free morphological grammar",
                "Method"
            ],
            [
                "parse",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('`` conventional '' context-free morphological grammar') is the object, depending on 'combines' with 'it'. Entity 2 ('parse') is part of the compound noun 'successful parse', acting as the head noun, and is the object of the preposition 'of' in the phrase 'likelihood of each successful parse'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence, with Entity 1 being used to filter out ungrammatical segmentations and Entity 2 being evaluated for likelihood by the scoring function.",
        "sdp_path_text": "grammar → combines → provided → MORPA → PArser",
        "sentence": "The 'conventional' context-free morphological grammar combines with a probability-based scoring function to determine the likelihood of each parse.",
        "sentence_llm_dp_info": "Entity 1 ('conventional context-free morphological grammar') is the subject, depending on the verb 'combines'. Entity 2 ('parse') is part of the object of the preposition 'of', depending on 'likelihood' in the phrase 'likelihood of each parse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'determine' and the prepositional phrase 'of each parse'."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            [
                "probability-based scoring function",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ungrammatical segmentations') is the object, depending on 'filter out' with 'conventional context-free morphological grammar'. Entity 2 ('probability-based scoring function') is the subject, depending on 'which' in the relative clause 'which determines the likelihood of each successful parse'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same process described in the sentence, where the function of Entity 2 helps to determine the likelihood of parses that have filtered out Entity 1.",
        "sdp_path_text": "segmentations → filter → combines → with → function",
        "sentence": "The parser filters out ungrammatical segmentations using a probability-based scoring function.",
        "sentence_llm_dp_info": "Entity 1 ('ungrammatical segmentations') is the object of the verb 'filters out', depending on 'filters out' with 'The parser'. Entity 2 ('probability-based scoring function') is the object of the preposition 'using', depending on 'using' in the phrase 'using a probability-based scoring function'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with Entity 2 serving as the means by which Entity 1 is filtered out."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "ungrammatical segmentations",
                "OtherScientificTerm"
            ],
            [
                "parse",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ungrammatical segmentations') is the object, depending on 'filter' with 'conventional context-free morphological grammar'. Entity 2 ('parse') is part of a compound noun, depending on 'determines' with 'probability-based scoring function'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the process described in the sentence where the grammar filters out ungrammatical segmentations and the scoring function determines the likelihood of successful parses.",
        "sdp_path_text": "segmentations → filter → combines → provided → MORPA → PArser",
        "sentence": "MORPA filters out ungrammatical segmentations to determine successful parses.",
        "sentence_llm_dp_info": "Entity 1 ('ungrammatical segmentations') is the object, depending on the verb 'filters out' with 'MORPA'. Entity 2 ('parse') is part of the compound noun 'successful parses', which is the object of the verb 'determine'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the actions performed by MORPA."
    },
    {
        "raw_sentence": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .",
        "ner_pair": [
            [
                "probability-based scoring function",
                "Method"
            ],
            [
                "parse",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probability-based scoring function') is the subject, depending on 'determines' as the verb. Entity 2 ('parse') is the object, depending on 'likelihood' with the preposition 'of' in the phrase 'likelihood of each successful parse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'determines' and the prepositional phrase 'of each successful parse'.",
        "sdp_path_text": "function → with → combines → provided → MORPA → PArser",
        "sentence": "MORPA combines a probability-based scoring function to determine the likelihood of each parse.",
        "sentence_llm_dp_info": "Entity 1 ('probability-based scoring function') is the object, depending on 'combines' with 'MORPA'. Entity 2 ('parse') is the object of the preposition 'of', depending on 'likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'determine' and the preposition 'of'."
    },
    {
        "raw_sentence": "Test performance data will show that a PCFG yields good results in morphological parsing .",
        "ner_pair": [
            [
                "PCFG",
                "Method"
            ],
            [
                "morphological parsing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('PCFG') is the subject complement, depending on 'yields' with 'a'. Entity 2 ('morphological parsing') is the object of the preposition 'in', depending on 'in' in the phrase 'in morphological parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields' and the preposition 'in'.",
        "sdp_path_text": "PCFG → yields → in → parsing",
        "sentence": "PCFG yields good results in morphological parsing.",
        "sentence_llm_dp_info": "Entity 1 ('PCFG') is the subject, depending on the verb 'yields'. Entity 2 ('morphological parsing') is the object of the preposition 'in', depending on 'in' in the phrase 'in morphological parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "MORPA is a fully implemented parser developed for use in a text-to-speech conversion system .",
        "ner_pair": [
            [
                "MORPA",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORPA') is the subject, depending on the verb 'is'. Entity 2 ('parser') is the complement, depending on 'is' in the phrase 'is a fully implemented parser'. There is a direct dependency between Entity 1 and Entity 2, as 'MORPA' is described as being a 'parser'.",
        "sdp_path_text": "MORPA → is → parser",
        "sentence": "MORPA is a parser.",
        "sentence_llm_dp_info": "Entity 1 ('MORPA') is the subject, depending on the verb 'is'. Entity 2 ('parser') is the predicate nominative, depending on 'is' in the phrase 'is a parser'. There is a direct dependency between Entity 1 and Entity 2, as 'parser' directly describes what 'MORPA' is."
    },
    {
        "raw_sentence": "MORPA is a fully implemented parser developed for use in a text-to-speech conversion system .",
        "ner_pair": [
            [
                "MORPA",
                "Method"
            ],
            [
                "text-to-speech conversion system",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MORPA') is the subject, depending on the verb 'is'. Entity 2 ('text-to-speech conversion system') is the object of the preposition 'in', depending on 'in' in the phrase 'in a text-to-speech conversion system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.",
        "sdp_path_text": "MORPA → is → parser → developed → for → use → in → system",
        "sentence": "MORPA is a parser developed for use in a text-to-speech conversion system.",
        "sentence_llm_dp_info": "Entity 1 ('MORPA') is the subject, depending on the verb 'is'. Entity 2 ('text-to-speech conversion system') is the object of the preposition 'in', depending on 'in' in the phrase 'in a text-to-speech conversion system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that specifies the context or purpose of Entity 1."
    },
    {
        "raw_sentence": "MORPA is a fully implemented parser developed for use in a text-to-speech conversion system .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "text-to-speech conversion system",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on 'developed' as the main verb. Entity 2 ('text-to-speech conversion system') is the object of the preposition 'in', depending on 'in' in the phrase 'in a text-to-speech conversion system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates the context or purpose of the development of the parser.",
        "sdp_path_text": "parser → developed → for → use → in → system",
        "sentence": "The parser was developed for use in a text-to-speech conversion system.",
        "sentence_llm_dp_info": "Entity 1 ('parser') is the subject, depending on the verb 'developed'. Entity 2 ('text-to-speech conversion system') is the object of the preposition 'for', depending on 'for' in the phrase 'for use in a text-to-speech conversion system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This paper describes the framework of a Korean phonological knowledge base system using the unification-based grammar formalism : Korean Phonology Structure Grammar -LRB- KPSG -RRB- .",
        "ner_pair": [
            [
                "unification-based grammar formalism",
                "Method"
            ],
            [
                "Korean phonological knowledge base system",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unification-based grammar formalism') is the object of the preposition 'using', depending on 'framework'. Entity 2 ('Korean phonological knowledge base system') is the object of the preposition 'of', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the 'framework' described in the sentence.",
        "sdp_path_text": "formalism → using → framework → of → system",
        "sentence": "The unification-based grammar formalism is used in the framework of the Korean phonological knowledge base system.",
        "sentence_llm_dp_info": "Entity 1 ('unification-based grammar formalism') is the subject, depending on the verb 'used'. Entity 2 ('Korean phonological knowledge base system') is the object of the preposition 'of', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the framework of the Korean phonological knowledge base system'."
    },
    {
        "raw_sentence": "This paper describes the framework of a Korean phonological knowledge base system using the unification-based grammar formalism : Korean Phonology Structure Grammar -LRB- KPSG -RRB- .",
        "ner_pair": [
            [
                "Korean phonological knowledge base system",
                "Task"
            ],
            [
                "Korean Phonology Structure Grammar -LRB- KPSG -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Korean phonological knowledge base system') is the object of the preposition 'of', depending on 'framework'. Entity 2 ('Korean Phonology Structure Grammar -LRB- KPSG -RRB-') is the appositive, depending on 'formalism'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same descriptive context, where Entity 2 clarifies the type of formalism used in the system described by Entity 1.",
        "sdp_path_text": "system → of → framework → using → formalism → -LRB-",
        "sentence": "The Korean phonological knowledge base system uses the formalism of Korean Phonology Structure Grammar (KPSG).",
        "sentence_llm_dp_info": "Entity 1 ('Korean phonological knowledge base system') is the subject, depending on the verb 'uses'. Entity 2 ('Korean Phonology Structure Grammar (KPSG)') is the object, depending on 'formalism'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the prepositional phrase 'the formalism of'."
    },
    {
        "raw_sentence": "This paper describes the framework of a Korean phonological knowledge base system using the unification-based grammar formalism : Korean Phonology Structure Grammar -LRB- KPSG -RRB- .",
        "ner_pair": [
            [
                "Korean Phonology Structure Grammar -LRB- KPSG -RRB-",
                "Method"
            ],
            [
                "unification-based grammar formalism",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Korean Phonology Structure Grammar -LRB- KPSG -RRB-') is the appositive, depending on the noun 'formalism'. Entity 2 ('unification-based grammar formalism') is the object of the preposition 'using', depending on the verb 'describes'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'using the unification-based grammar formalism' which provides additional information about the system described.",
        "sdp_path_text": "-LRB- → formalism",
        "sentence": "Korean Phonology Structure Grammar (KPSG) uses the unification-based grammar formalism.",
        "sentence_llm_dp_info": "Entity 1 ('Korean Phonology Structure Grammar (KPSG)') is the subject, depending on the verb 'uses'. Entity 2 ('unification-based grammar formalism') is the object, depending on 'uses' with 'Korean Phonology Structure Grammar (KPSG)'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the direct object of the verb that Entity 1 is the subject of."
    },
    {
        "raw_sentence": "The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis system .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "KPSG",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'provides'. Entity 2 ('KPSG') is the object of the preposition 'of', depending on 'of' in the phrase 'of KPSG'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.",
        "sdp_path_text": "approach → of → KPSG",
        "sentence": "The approach of KPSG provides a development model.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'provides'. Entity 2 ('KPSG') is the modifier, depending on the noun 'approach' in the possessive construction 'of KPSG'. There is a direct dependency between Entity 1 and Entity 2, as 'KPSG' modifies 'approach' through the preposition 'of'."
    },
    {
        "raw_sentence": "The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis system .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "phonological system",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'provides'. Entity 2 ('phonological system') is the object, depending on the preposition 'for' in the phrase 'for constructing a computational phonological system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the prepositional phrase 'for constructing'.",
        "sdp_path_text": "approach → provides → model → for → constructing → system",
        "sentence": "The approach provides a model for constructing a phonological system.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'provides'. Entity 2 ('phonological system') is the object of the preposition 'for', depending on 'constructing' in the phrase 'for constructing a phonological system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' and the prepositional phrase 'for constructing'."
    },
    {
        "raw_sentence": "The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis system .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "speech recognition and synthesis system",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on 'provides' with 'of KPSG'. Entity 2 ('speech recognition and synthesis system') is the appositive, depending on the colon (:) which introduces it as an explanation or elaboration of 'computational phonological system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the explanatory structure provided by the colon.",
        "sdp_path_text": "approach → provides → model → for → constructing → system → system",
        "sentence": "The approach provides a model for constructing a speech recognition and synthesis system.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'provides'. Entity 2 ('speech recognition and synthesis system') is the object of the preposition 'for', depending on 'constructing' in the phrase 'for constructing a speech recognition and synthesis system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' and the prepositional phrase 'for constructing'."
    },
    {
        "raw_sentence": "The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis system .",
        "ner_pair": [
            [
                "KPSG",
                "Method"
            ],
            [
                "phonological system",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('KPSG') is the object of the preposition 'of', depending on 'approach'. Entity 2 ('phonological system') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the development model provided by the approach of KPSG.",
        "sdp_path_text": "KPSG → of → approach → provides → model → for → constructing → system",
        "sentence": "KPSG provides a model for constructing a phonological system.",
        "sentence_llm_dp_info": "Entity 1 ('KPSG') is the subject, depending on the verb 'provides'. Entity 2 ('phonological system') is the object of the preposition 'for', depending on 'for' in the phrase 'for constructing a phonological system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis system .",
        "ner_pair": [
            [
                "KPSG",
                "Method"
            ],
            [
                "speech recognition and synthesis system",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('KPSG') is part of a prepositional phrase, depending on 'of' with 'approach'. Entity 2 ('speech recognition and synthesis system') is the appositive, depending on the colon (:) which links it to 'computational phonological system'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where KPSG's approach leads to the development of the computational phonological system, which includes the speech recognition and synthesis system.",
        "sdp_path_text": "KPSG → of → approach → provides → model → for → constructing → system → system",
        "sentence": "KPSG provides a model for constructing a speech recognition and synthesis system.",
        "sentence_llm_dp_info": "Entity 1 ('KPSG') is the subject, depending on the verb 'provides'. Entity 2 ('speech recognition and synthesis system') is the object of the preposition 'for', depending on 'for' in the phrase 'for constructing a speech recognition and synthesis system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the verb 'constructing'."
    },
    {
        "raw_sentence": "The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis system .",
        "ner_pair": [
            [
                "phonological system",
                "Task"
            ],
            [
                "speech recognition and synthesis system",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phonological system') is the object of the preposition 'for', depending on 'model'. Entity 2 ('speech recognition and synthesis system') is an appositive, depending on 'system' in 'phonological system'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the appositive structure, where Entity 2 specifies or renames Entity 1.",
        "sdp_path_text": "system → system",
        "sentence": "The phonological system includes speech recognition and synthesis.",
        "sentence_llm_dp_info": "Entity 1 ('phonological system') is the subject, depending on the verb 'includes'. Entity 2 ('speech recognition and synthesis') is the object, depending on 'includes' with 'phonological system'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is included within Entity 1."
    },
    {
        "raw_sentence": "We show that the proposed approach is more describable than other approaches such as those employing a traditional generative phonological approach .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'is' in the clause 'the proposed approach is more describable'. Entity 2 ('those') is the subject of the relative clause 'those employing a traditional generative phonological approach', depending on the verb 'employing'. There is no direct dependency between Entity 1 and Entity 2, but they are both compared in the context of the sentence through the comparative structure 'more describable than'.",
        "sdp_path_text": "approach → is → describable → than → approaches → as → those",
        "sentence": "The proposed approach is more describable than those employing a traditional generative phonological approach.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('those') is the subject of the comparative clause, depending on 'than' in the phrase 'than those'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparative structure involving 'more describable than'."
    },
    {
        "raw_sentence": "We show that the proposed approach is more describable than other approaches such as those employing a traditional generative phonological approach .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approaches') is the object of the preposition 'than', depending on the comparative adjective 'more describable'. Entity 2 ('those') is a demonstrative pronoun, depending on 'such as' in the phrase 'such as those'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a comparative structure where 'those' refers back to 'approaches'.",
        "sdp_path_text": "approaches → as → those",
        "sentence": "The proposed approach is more describable than other approaches, including those using a traditional generative phonological method.",
        "sentence_llm_dp_info": "Entity 1 ('approaches') is the object of the preposition 'than', depending on the comparative adjective 'more describable'. Entity 2 ('those') is the subject of the relative clause, depending on 'including' with 'approaches'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'including' which introduces Entity 2 as a subset of Entity 1."
    },
    {
        "raw_sentence": "We show that the proposed approach is more describable than other approaches such as those employing a traditional generative phonological approach .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "generative phonological approach",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approaches') is the object of the comparative clause, depending on 'than' in the phrase 'more describable than other approaches'. Entity 2 ('generative phonological approach') is the object of the preposition 'employing', depending on 'those' in the phrase 'such as those employing a traditional generative phonological approach'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparative structure.",
        "sdp_path_text": "approaches → as → those → employing → approach",
        "sentence": "The proposed approach is more describable than approaches employing a generative phonological approach.",
        "sentence_llm_dp_info": "Entity 1 ('approaches') is the subject, depending on the comparative adjective 'more describable'. Entity 2 ('generative phonological approach') is the object of the preposition 'employing', depending on 'employing' in the phrase 'employing a generative phonological approach'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparative structure."
    },
    {
        "raw_sentence": "We show that the proposed approach is more describable than other approaches such as those employing a traditional generative phonological approach .",
        "ner_pair": [
            [
                "generative phonological approach",
                "Method"
            ],
            [
                "those",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative phonological approach') is the object of the preposition 'employing', depending on 'those'. Entity 2 ('those') is the subject of the relative clause, depending on 'such as' which introduces the clause modifying 'approaches'. There is a direct dependency between Entity 1 and Entity 2, as 'generative phonological approach' is part of the list of examples introduced by 'those'.",
        "sdp_path_text": "approach → employing → those",
        "sentence": "The generative phonological approach employs those.",
        "sentence_llm_dp_info": "Entity 1 ('generative phonological approach') is the subject, depending on the verb 'employs'. Entity 2 ('those') is the object, depending on the verb 'employs'. There is a direct dependency between Entity 1 and Entity 2, as 'those' is directly employed by the 'generative phonological approach'."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "domain",
                "Generic"
            ],
            [
                "combinatorial auctions",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on the preposition 'In' in the phrase 'In such a domain'. Entity 2 ('combinatorial auctions') is the subject, depending on the verb 'perform' in the clause 'standard combinatorial auctions perform poorly'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the sentence structure.",
        "sdp_path_text": "domain → In → perform → auctions",
        "sentence": "In this domain, combinatorial auctions perform poorly.",
        "sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on the preposition 'In' in the phrase 'In this domain'. Entity 2 ('combinatorial auctions') is the subject, depending on the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "domain",
                "Generic"
            ],
            [
                "they",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'in', depending on 'perform' with 'standard combinatorial auctions'. Entity 2 ('they') is the subject, depending on 'lead' with 'lead to violations'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the context and consequences of poor performance in the domain.",
        "sdp_path_text": "domain → In → perform → lead → they",
        "sentence": "In this domain, they lead to poor performance.",
        "sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on 'In' in the phrase 'In this domain'. Entity 2 ('they') is the subject, depending on the verb 'lead'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'they' leads to poor performance within the specified domain."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "domain",
                "Generic"
            ],
            [
                "violations of individual rationality -LRB- IR -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'in', depending on the prepositional phrase 'In such a domain'. Entity 2 ('violations of individual rationality -LRB- IR -RRB-') is the object of the preposition 'to', depending on 'lead' in the clause 'they lead to violations of individual rationality -LRB- IR -RRB-'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the same sentence describing the context and consequences related to the domain.",
        "sdp_path_text": "domain → In → perform → lead → to → violations",
        "sentence": "In this domain, standard combinatorial auctions lead to violations of individual rationality.",
        "sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on the preposition 'In' with the phrase 'In this domain'. Entity 2 ('violations of individual rationality') is the subject complement, depending on 'lead' with 'combinatorial auctions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'lead' which shows the consequence of actions within the domain."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "domain",
                "Generic"
            ],
            [
                "individual rationality -LRB- IR -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on the preposition 'In' in the phrase 'In such a domain'. Entity 2 ('individual rationality -LRB- IR -RRB-') is the object of the preposition 'of', depending on 'violations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause that describes the poor performance of standard combinatorial auctions in the specified domain leading to violations of individual rationality.",
        "sdp_path_text": "domain → In → perform → lead → to → violations → -LRB-",
        "sentence": "In this domain, standard combinatorial auctions lead to violations of individual rationality.",
        "sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on the preposition 'In' in the phrase 'In this domain'. Entity 2 ('individual rationality -LRB- IR -RRB-') is the object of the preposition 'of', depending on 'violations'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "combinatorial auctions",
                "Method"
            ],
            [
                "they",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('combinatorial auctions') is the subject, depending on the verb 'perform'. Entity 2 ('they') is a pronoun referring back to 'combinatorial auctions', depending on the verb 'lead'. There is a direct dependency between Entity 1 and Entity 2, as 'they' is used as a pronoun to refer to 'combinatorial auctions'.",
        "sdp_path_text": "auctions → perform → lead → they",
        "sentence": "Combinatorial auctions lead to poor performance.",
        "sentence_llm_dp_info": "Entity 1 ('combinatorial auctions') is the subject, depending on the verb 'lead'. Entity 2 ('they') does not appear in the sentence, so there is no dependency for Entity 2. Since Entity 2 is not present in the sentence, there is no direct dependency between Entity 1 and Entity 2.\"\n\nHowever, if you intended to use \"poor performance\" as Entity 2 instead of \"they,\" the analysis would be:\n\nEntity 1 ('combinatorial auctions') is the subject, depending on the verb 'lead'. Entity 2 ('poor performance') is the direct object, depending on the verb 'lead'. There is a direct dependency between Entity 1 and Entity 2, as 'combinatorial auctions' leads to 'poor performance'."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "combinatorial auctions",
                "Method"
            ],
            [
                "violations of individual rationality -LRB- IR -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('combinatorial auctions') is the subject, depending on the verb 'perform'. Entity 2 ('violations of individual rationality -LRB- IR -RRB-') is the object of the preposition 'to', depending on 'lead' in the phrase 'lead to violations of individual rationality -LRB- IR -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'lead' which indicates that the poor performance of combinatorial auctions leads to the violations.",
        "sdp_path_text": "auctions → perform → lead → to → violations",
        "sentence": "Combinatorial auctions lead to violations of individual rationality.",
        "sentence_llm_dp_info": "Entity 1 ('combinatorial auctions') is the subject, depending on the verb 'lead'. Entity 2 ('violations of individual rationality') is the object, depending on the verb 'lead'. There is a direct dependency between Entity 1 and Entity 2, as 'combinatorial auctions' leads to 'violations of individual rationality'."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "combinatorial auctions",
                "Method"
            ],
            [
                "individual rationality -LRB- IR -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('combinatorial auctions') is the subject, depending on the verb 'perform' with the adverb 'poorly'. Entity 2 ('individual rationality -LRB- IR -RRB-') is the object of the preposition 'of', depending on 'violations'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the causal relationship expressed by the conjunction 'because' and the verb 'lead'.",
        "sdp_path_text": "auctions → perform → lead → to → violations → -LRB-",
        "sentence": "Combinatorial auctions can lead to violations of individual rationality.",
        "sentence_llm_dp_info": "Entity 1 ('combinatorial auctions') is the subject, depending on the verb 'can lead'. Entity 2 ('individual rationality') is the object of the preposition 'of', depending on 'violations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'can lead' and the prepositional phrase 'to violations of individual rationality'."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "they",
                "Generic"
            ],
            [
                "violations of individual rationality -LRB- IR -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('they') is the subject, depending on the verb 'lead' in the clause 'they lead to violations'. Entity 2 ('violations of individual rationality -LRB- IR -RRB-') is the object of the preposition 'to', depending on 'lead' in the same clause. There is a direct dependency between Entity 1 and Entity 2, as 'they' leads to 'violations of individual rationality -LRB- IR -RRB-.'\"",
        "sdp_path_text": "they → lead → to → violations",
        "sentence": "They lead to violations of individual rationality.",
        "sentence_llm_dp_info": "Entity 1 ('they') is the subject, depending on the verb 'lead'. Entity 2 ('violations of individual rationality') is the object, depending on the verb 'lead'. There is a direct dependency between Entity 1 and Entity 2, where 'they' leads to 'violations of individual rationality'."
    },
    {
        "raw_sentence": "In such a domain , standard combinatorial auctions perform poorly because they lead to violations of individual rationality -LRB- IR -RRB- , even in expectation , and to very low efficiency .",
        "ner_pair": [
            [
                "they",
                "Generic"
            ],
            [
                "individual rationality -LRB- IR -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('they') is the subject, depending on the verb 'lead'. Entity 2 ('individual rationality -LRB- IR -RRB-') is the object of the preposition 'of', depending on 'violations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'lead' which indicates that 'they' cause 'violations of individual rationality'.",
        "sdp_path_text": "they → lead → to → violations → -LRB-",
        "sentence": "They lead to violations of individual rationality (IR).",
        "sentence_llm_dp_info": "Entity 1 ('they') is the subject, depending on the verb 'lead'. Entity 2 ('individual rationality -LRB- IR -RRB-') is the object of the preposition 'of', depending on 'violations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'lead' and the prepositional phrase 'to violations of individual rationality (IR)'."
    },
    {
        "raw_sentence": "In this paper , we study the design of core-selecting payment rules for such domains .",
        "ner_pair": [
            [
                "design of core-selecting payment rules",
                "Task"
            ],
            [
                "domains",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('design of core-selecting payment rules') is the object of the verb 'study', depending on 'we'. Entity 2 ('domains') is the object of the preposition 'for', depending on 'for' in the phrase 'for such domains'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'study' and the preposition 'for'.",
        "sdp_path_text": "design → of → selecting → rules → for → domains",
        "sentence": "The design of core-selecting payment rules is studied for domains.",
        "sentence_llm_dp_info": "Entity 1 ('design of core-selecting payment rules') is the subject, depending on the verb 'studied'. Entity 2 ('domains') is the object of the preposition 'for', depending on 'for' in the phrase 'for domains'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Surprisingly , we show that in this new domain , there does not exist a payment rule with is guaranteed to be ex-post core-selecting .",
        "ner_pair": [
            [
                "domain",
                "Generic"
            ],
            [
                "payment rule",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'in', depending on 'show'. Entity 2 ('payment rule') is the subject of the clause 'there does not exist a payment rule', depending on 'exist'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context within the sentence.",
        "sdp_path_text": "domain → in → exist → rule",
        "sentence": "In this domain, there does not exist a payment rule.",
        "sentence_llm_dp_info": "Entity 1 ('domain') is the object of the preposition 'In', depending on the prepositional phrase 'In this domain'. Entity 2 ('payment rule') is the subject complement, depending on 'exist' in the negated clause 'does not exist a payment rule'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "However , we show that by designing rules that are '' execution-contingent , '' i.e. , by charging payments that are conditioned on the realization of the availability of the goods , we can reduce IR violations .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "IR violations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rules') is the object of the verb 'designing', depending on the clause 'by designing rules'. Entity 2 ('IR violations') is the object of the verb 'reduce', depending on 'we can reduce IR violations'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same causal relationship where the design of the rules ('rules') aims to affect the reduction of ('IR violations').",
        "sdp_path_text": "rules → designing → by → reduce → violations",
        "sentence": "Designing rules can reduce IR violations.",
        "sentence_llm_dp_info": "Entity 1 ('rules') is the object of the clause, depending on the verb 'can reduce'. Entity 2 ('IR violations') is the direct object, depending on the verb 'can reduce'. There is a direct dependency between Entity 1 and Entity 2, as 'rules' is what reduces 'IR violations'."
    },
    {
        "raw_sentence": "We design two core-selecting rules that always satisfy IR in expectation .",
        "ner_pair": [
            [
                "core-selecting rules",
                "OtherScientificTerm"
            ],
            [
                "IR",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('core-selecting rules') is the object, depending on 'design' with 'We'. Entity 2 ('IR') is the object of the preposition 'satisfy', depending on 'satisfy' in the phrase 'satisfy IR'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'satisfy'.",
        "sdp_path_text": "rules → satisfy → IR",
        "sentence": "Core-selecting rules satisfy IR.",
        "sentence_llm_dp_info": "Entity 1 ('core-selecting rules') is the subject, depending on the verb 'satisfy'. Entity 2 ('IR') is the object, depending on 'satisfy' with 'core-selecting rules'. There is a direct dependency between Entity 1 and Entity 2, where 'core-selecting rules' satisfies 'IR'."
    },
    {
        "raw_sentence": "To study the performance of our rules we perform a computational Bayes-Nash equilibrium analysis .",
        "ner_pair": [
            [
                "computational Bayes-Nash equilibrium analysis",
                "Method"
            ],
            [
                "rules",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('computational Bayes-Nash equilibrium analysis') is the object, depending on 'perform' with 'we'. Entity 2 ('rules') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'perform' and the preposition 'of'.",
        "sdp_path_text": "analysis → perform → study → performance → of → rules",
        "sentence": "We perform a computational Bayes-Nash equilibrium analysis to study the performance of our rules.",
        "sentence_llm_dp_info": "Entity 1 ('computational Bayes-Nash equilibrium analysis') is the object of the verb 'perform', depending on 'perform' with 'We'. Entity 2 ('rules') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'study' and the preposition 'of'."
    },
    {
        "raw_sentence": "We show that , in equilibrium , our new rules have better incentives , higher efficiency , and a lower rate of ex-post IR violations than standard core-selecting rules .",
        "ner_pair": [
            [
                "rate of ex-post IR violations",
                "Metric"
            ],
            [
                "rules",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rate of ex-post IR violations') is the object of the preposition 'of', depending on 'lower'. Entity 2 ('rules') is the object, depending on 'than'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparative structure involving 'lower' and 'than'.",
        "sdp_path_text": "rate → efficiency → incentives → have → rules",
        "sentence": "The rules have a lower rate of ex-post IR violations.",
        "sentence_llm_dp_info": "Entity 1 ('rate of ex-post IR violations') is the complement of the preposition 'of', depending on 'lower'. Entity 2 ('rules') is the subject, depending on the verb 'have'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'have', which indicates that the rules possess the lower rate of ex-post IR violations."
    },
    {
        "raw_sentence": "We show that , in equilibrium , our new rules have better incentives , higher efficiency , and a lower rate of ex-post IR violations than standard core-selecting rules .",
        "ner_pair": [
            [
                "rate of ex-post IR violations",
                "Metric"
            ],
            [
                "core-selecting rules",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rate of ex-post IR violations') is part of a list of comparative attributes, depending on 'have' with 'rules'. Entity 2 ('core-selecting rules') is the object of comparison, depending on 'than' in the phrase 'than standard core-selecting rules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure of the sentence.",
        "sdp_path_text": "rate → than → rules",
        "sentence": "The rate of ex-post IR violations is lower than for core-selecting rules.",
        "sentence_llm_dp_info": "Entity 1 ('rate of ex-post IR violations') is the subject, depending on the verb 'is'. Entity 2 ('core-selecting rules') is the object of the preposition 'for', depending on 'for' in the phrase 'for core-selecting rules'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the comparative clause introduced by 'than'."
    },
    {
        "raw_sentence": "In this paper , we will describe a search tool for a huge set of ngrams .",
        "ner_pair": [
            [
                "search tool",
                "Method"
            ],
            [
                "ngrams",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('search tool') is the object, depending on the verb 'describe'. Entity 2 ('ngrams') is the object of the preposition 'for', depending on 'for' in the phrase 'for a huge set of ngrams'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "tool → for → set → of → ngrams",
        "sentence": "A search tool is described for a set of ngrams.",
        "sentence_llm_dp_info": "Entity 1 ('search tool') is the subject, depending on the verb 'described'. Entity 2 ('ngrams') is the object of the preposition 'for', depending on 'for' in the phrase 'for a set of ngrams'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "The system runs on a single Linux PC with reasonable size memory -LRB- less than 4GB -RRB- and disk space -LRB- less than 400GB -RRB- .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "memory",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'runs'. Entity 2 ('memory') is the object of the preposition 'with', depending on 'with' in the phrase 'with reasonable size memory'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase describing the system's specifications.",
        "sdp_path_text": "system → runs → on → PC → with → memory",
        "sentence": "The system runs on a PC with memory.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'runs'. Entity 2 ('memory') is the object of the preposition 'with', depending on 'with' in the phrase 'with memory'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The system runs on a single Linux PC with reasonable size memory -LRB- less than 4GB -RRB- and disk space -LRB- less than 400GB -RRB- .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "disk space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'runs'. Entity 2 ('disk space') is the object of the preposition 'with', depending on 'with' in the phrase 'with reasonable size memory -LRB- less than 4GB -RRB- and disk space -LRB- less than 400GB -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.",
        "sdp_path_text": "system → runs → on → PC → with → memory → space",
        "sentence": "The system runs on a PC with disk space.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'runs'. Entity 2 ('disk space') is the object of the preposition 'with', depending on 'with' in the phrase 'with disk space'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'."
    },
    {
        "raw_sentence": "The system runs on a single Linux PC with reasonable size memory -LRB- less than 4GB -RRB- and disk space -LRB- less than 400GB -RRB- .",
        "ner_pair": [
            [
                "memory",
                "OtherScientificTerm"
            ],
            [
                "disk space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('memory') is the object of the preposition 'with', depending on 'PC'. Entity 2 ('disk space') is also the object of the preposition 'with', depending on 'PC'. There is no direct dependency between Entity 1 and Entity 2; both are related to the noun 'PC' through the preposition 'with'.",
        "sdp_path_text": "memory → space",
        "sentence": "The system requires memory and disk space.",
        "sentence_llm_dp_info": "Entity 1 ('memory') is the first object, depending on the verb 'requires' with 'The system'. Entity 2 ('disk space') is the second object, also depending on the verb 'requires' with 'The system'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same verb 'requires'."
    },
    {
        "raw_sentence": "This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "tool",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'can be'. Entity 2 ('tool') is the complement, depending on the verb 'be' in the phrase 'can be a very useful tool'. There is a direct dependency between Entity 1 and Entity 2, as 'system' is described as being a 'tool'.",
        "sdp_path_text": "system → be → tool",
        "sentence": "The system can be a useful tool.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'can be'. Entity 2 ('tool') is the object, depending on the verb 'can be' as part of the predicate 'a useful tool'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'can be' which describes the potential role of the system as a tool."
    },
    {
        "raw_sentence": "This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "linguistic knowledge discovery",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'can be'. Entity 2 ('linguistic knowledge discovery') is part of the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic knowledge discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "system → be → tool → for → discovery",
        "sentence": "The system can be a useful tool for linguistic knowledge discovery.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'can be'. Entity 2 ('linguistic knowledge discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic knowledge discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating the purpose or use of the system."
    },
    {
        "raw_sentence": "This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "NLP tasks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'can be'. Entity 2 ('NLP tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic knowledge discovery and other NLP tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "system → be → tool → for → discovery → tasks",
        "sentence": "The system can be a useful tool for NLP tasks.",
        "sentence_llm_dp_info": "Entity 1 ('system') is the subject, depending on the verb 'can be'. Entity 2 ('NLP tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for NLP tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks .",
        "ner_pair": [
            [
                "tool",
                "Generic"
            ],
            [
                "linguistic knowledge discovery",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tool') is the subject complement, depending on the copula 'be' with 'can be'. Entity 2 ('linguistic knowledge discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic knowledge discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating the purpose or use of the tool.",
        "sdp_path_text": "tool → for → discovery",
        "sentence": "This tool is useful for linguistic knowledge discovery.",
        "sentence_llm_dp_info": "Entity 1 ('tool') is the subject, depending on the verb 'is'. Entity 2 ('linguistic knowledge discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic knowledge discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks .",
        "ner_pair": [
            [
                "tool",
                "Generic"
            ],
            [
                "NLP tasks",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('tool') is the subject complement, depending on 'be' with 'can be'. Entity 2 ('NLP tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic knowledge discovery and other NLP tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger prepositional phrase that describes the utility of the system.",
        "sdp_path_text": "tool → for → discovery → tasks",
        "sentence": "This tool can be useful for NLP tasks.",
        "sentence_llm_dp_info": "Entity 1 ('tool') is the subject, depending on the verb 'can be'. Entity 2 ('NLP tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for NLP tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks .",
        "ner_pair": [
            [
                "linguistic knowledge discovery",
                "Task"
            ],
            [
                "NLP tasks",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linguistic knowledge discovery') is part of a coordination, depending on 'and' with 'NLP tasks'. Entity 2 ('NLP tasks') is also part of the coordination, depending on 'for' with 'tool'. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated elements in the prepositional phrase 'for linguistic knowledge discovery and other NLP tasks'.",
        "sdp_path_text": "discovery → tasks",
        "sentence": "Linguistic knowledge discovery and NLP tasks are related.",
        "sentence_llm_dp_info": "Entity 1 ('linguistic knowledge discovery') is the subject, depending on the verb 'are'. Entity 2 ('NLP tasks') is also a subject, coordinated with 'linguistic knowledge discovery' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects of the same clause, indicating a parallel relationship."
    },
    {
        "raw_sentence": "For intelligent interactive systems to communicate with humans in a natural manner , they must have knowledge about the system users .",
        "ner_pair": [
            [
                "intelligent interactive systems",
                "Method"
            ],
            [
                "they",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('intelligent interactive systems') is the subject, depending on the infinitive 'to communicate'. Entity 2 ('they') is the subject, depending on the verb 'must have'. There is no direct dependency between Entity 1 and Entity 2, but 'they' refers back to 'intelligent interactive systems', indicating a coreference relationship.",
        "sdp_path_text": "systems → communicate → have → they",
        "sentence": "Intelligent interactive systems must have knowledge to communicate naturally with humans.",
        "sentence_llm_dp_info": "Entity 1 ('intelligent interactive systems') is the subject, depending on the verb 'must have'. Entity 2 ('they') is not present in the given sentence, so it does not form any dependency within this context. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not part of the provided sentence."
    },
    {
        "raw_sentence": "This paper explores the role of user modeling in such systems .",
        "ner_pair": [
            [
                "user modeling",
                "Task"
            ],
            [
                "systems",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('user modeling') is the object of the preposition 'of', depending on 'role'. Entity 2 ('systems') is the object of the preposition 'in', depending on 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what the paper explores.",
        "sdp_path_text": "modeling → of → role → in → systems",
        "sentence": "User modeling plays a role in systems.",
        "sentence_llm_dp_info": "Entity 1 ('user modeling') is the subject, depending on the verb 'plays'. Entity 2 ('systems') is the object of the preposition 'in', depending on 'in' in the phrase 'in systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'."
    },
    {
        "raw_sentence": "It begins with a characterization of what a user model is and how it can be used .",
        "ner_pair": [
            [
                "user model",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('user model') is the subject of the relative clause 'what a user model is', depending on the verb 'is'. Entity 2 ('it') is the subject of the main clause, depending on the verb 'begins'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related as 'it' refers to a process or document that characterizes the 'user model'.",
        "sdp_path_text": "model → is → of → characterization → with → begins → It",
        "sentence": "It begins with a characterization of what a user model is.",
        "sentence_llm_dp_info": "Entity 1 ('user model') is the object of the preposition 'of', depending on 'characterization'. Entity 2 ('it') is the subject, depending on the verb 'begins'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'it' refers to a process or action that involves the characterization of 'user model'."
    },
    {
        "raw_sentence": "User models themselves can vary greatly depending on the requirements of the situation and the implementation , so several dimensions along which they can be classified are presented .",
        "ner_pair": [
            [
                "User models",
                "Method"
            ],
            [
                "they",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('User models') is the subject, depending on the verb 'vary'. Entity 2 ('they') is a pronoun referring back to 'User models', depending on 'models' with a reflexive relation. There is a direct dependency between Entity 1 and Entity 2, where 'they' refers back to 'User models'.",
        "sdp_path_text": "models → vary → presented → dimensions → classified → they",
        "sentence": "User models vary and can be classified along several dimensions.",
        "sentence_llm_dp_info": "Entity 1 ('User models') is the subject, depending on the verb 'vary'. Entity 2 ('they') is the pronoun, depending on 'can be' as the subject of the clause 'they can be classified'. There is no direct dependency between Entity 1 and Entity 2, but 'they' refers back to 'User models' in the context of the sentence."
    },
    {
        "raw_sentence": "Next , the benefits and costs of implementing a user modeling component for a system are weighed in light of several aspects of the interaction requirements that may be imposed by the system .",
        "ner_pair": [
            [
                "user modeling component",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('user modeling component') is the object of the preposition 'of', depending on 'implementing'. Entity 2 ('system') is the object of the preposition 'for', depending on 'implementing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'for a system' which modifies 'implementing'.",
        "sdp_path_text": "component → implementing → for → system",
        "sentence": "The benefits and costs of implementing a user modeling component for the system are considered.",
        "sentence_llm_dp_info": "Entity 1 ('user modeling component') is the object of the preposition 'of', depending on 'implementing'. Entity 2 ('system') is the object of the preposition 'for', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different parts of the sentence."
    },
    {
        "raw_sentence": "Next , the benefits and costs of implementing a user modeling component for a system are weighed in light of several aspects of the interaction requirements that may be imposed by the system .",
        "ner_pair": [
            [
                "user modeling component",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('user modeling component') is the object of the preposition 'of', depending on 'implementing'. Entity 2 ('system') is the object of the preposition 'for', depending on 'implementing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases describing what is being implemented and for whom it is being implemented.",
        "sdp_path_text": "component → implementing → for → system",
        "sentence": "The benefits and costs of implementing a user modeling component for the system are considered.",
        "sentence_llm_dp_info": "Entity 1 ('user modeling component') is the object of the preposition 'of', depending on 'implementing'. Entity 2 ('system') is the object of the preposition 'for', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'of implementing' and 'for the system'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "Information extraction techniques",
                "Method"
            ],
            [
                "structured databases",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Information extraction techniques') is the subject, depending on the verb 'create'. Entity 2 ('structured databases') is the direct object, depending on 'create' in the phrase 'create structured databases'. There is a direct dependency between Entity 1 and Entity 2, as 'Information extraction techniques' are responsible for creating 'structured databases'.",
        "sdp_path_text": "techniques → create → databases",
        "sentence": "Information extraction techniques create structured databases.",
        "sentence_llm_dp_info": "Entity 1 ('Information extraction techniques') is the subject, depending on the verb 'create'. Entity 2 ('structured databases') is the direct object, depending on 'create' in the phrase 'create structured databases'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the agent performing the action that results in the creation of Entity 2."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "unstructured data sources",
                "Material"
            ],
            [
                "Information extraction techniques",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unstructured data sources') is the object, depending on the preposition 'from', which is part of the prepositional phrase 'from unstructured data sources'. Entity 2 ('Information extraction techniques') is the subject, depending on the verb 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the preposition 'from'.",
        "sdp_path_text": "sources → from → create → techniques",
        "sentence": "Information extraction techniques create structured databases from unstructured data sources.",
        "sentence_llm_dp_info": "Entity 1 ('unstructured data sources') is the object, depending on 'from' in the prepositional phrase 'from unstructured data sources'. Entity 2 ('Information extraction techniques') is the subject, depending on the verb 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the preposition 'from'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "Information extraction techniques",
                "Method"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Information extraction techniques') is the subject, depending on the verb 'create'. Entity 2 ('Web') is part of a prepositional phrase, depending on 'such as' which modifies 'data sources'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "techniques → create → from → sources → as → Web",
        "sentence": "Information extraction techniques create structured databases from sources like the Web.",
        "sentence_llm_dp_info": "Entity 1 ('Information extraction techniques') is the subject, depending on the verb 'create'. Entity 2 ('Web') is the object of the preposition 'from', depending on 'from' in the phrase 'from sources like the Web'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "Information extraction techniques",
                "Method"
            ],
            [
                "newswire documents",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Information extraction techniques') is the subject, depending on the verb 'create'. Entity 2 ('newswire documents') is part of a prepositional phrase, depending on 'such as' which modifies 'data sources'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase describing examples of 'data sources'.",
        "sdp_path_text": "techniques → create → from → sources → as → Web → documents",
        "sentence": "Information extraction techniques create structured databases from newswire documents.",
        "sentence_llm_dp_info": "Entity 1 ('Information extraction techniques') is the subject, depending on the verb 'create'. Entity 2 ('newswire documents') is the object, depending on 'from' in the prepositional phrase 'from newswire documents'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the preposition 'from'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "structured databases",
                "Material"
            ],
            [
                "unstructured data sources",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('structured databases') is the object, depending on the verb 'create' which is part of the phrase 'automatically create'. Entity 2 ('unstructured data sources') is the object of the preposition 'from', depending on 'from' in the phrase 'from unstructured data sources'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the preposition 'from'.",
        "sdp_path_text": "databases → create → from → sources",
        "sentence": "Information extraction techniques create structured databases from unstructured data sources.",
        "sentence_llm_dp_info": "Entity 1 ('structured databases') is the object, depending on the verb 'create' with 'Information extraction techniques'. Entity 2 ('unstructured data sources') is the object of the preposition 'from', depending on 'from' in the phrase 'from unstructured data sources'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the preposition 'from'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "structured databases",
                "Material"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('structured databases') is the object of the verb 'create', depending on 'create' which is part of the verb phrase 'automatically create'. Entity 2 ('Web') is the object of the preposition 'such as', depending on 'such as' in the phrase 'such as the Web or newswire documents'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "databases → create → from → sources → as → Web",
        "sentence": "Information extraction techniques create structured databases from sources like the Web.",
        "sentence_llm_dp_info": "Entity 1 ('structured databases') is the object, depending on 'create' with 'techniques'. Entity 2 ('Web') is the object of the preposition 'like', depending on 'sources'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "structured databases",
                "Material"
            ],
            [
                "newswire documents",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('structured databases') is the object, depending on 'create' with 'techniques'. Entity 2 ('newswire documents') is the object of the preposition 'such as', depending on 'sources'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'structured databases' is what is created, and 'newswire documents' is an example of the data sources from which the creation occurs.",
        "sdp_path_text": "databases → create → from → sources → as → Web → documents",
        "sentence": "Information extraction techniques create structured databases from newswire documents.",
        "sentence_llm_dp_info": "Entity 1 ('structured databases') is the direct object, depending on the verb 'create'. Entity 2 ('newswire documents') is the object of the preposition 'from', depending on 'from' in the phrase 'from newswire documents'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the preposition 'from'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "Web",
                "Material"
            ],
            [
                "unstructured data sources",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Web') is part of a list, depending on 'such as' which modifies 'unstructured data sources'. Entity 2 ('unstructured data sources') is the object of the preposition 'from', depending on 'create' in the phrase 'create structured databases from unstructured data sources'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'such as' indicating that 'Web' is an example of 'unstructured data sources'.",
        "sdp_path_text": "Web → as → sources",
        "sentence": "The Web is an unstructured data source.",
        "sentence_llm_dp_info": "Entity 1 ('Web') is the subject, depending on the verb 'is'. Entity 2 ('unstructured data source') is the predicate nominative, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'Web' is described as being 'an unstructured data source'."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "newswire documents",
                "Material"
            ],
            [
                "unstructured data sources",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('newswire documents') is the complement of the preposition 'such as', depending on 'unstructured data sources'. Entity 2 ('unstructured data sources') is the object of the preposition 'from', depending on 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional structure indicating that newswire documents are examples of unstructured data sources.",
        "sdp_path_text": "documents → Web → as → sources",
        "sentence": "Newswire documents are unstructured data sources.",
        "sentence_llm_dp_info": "Entity 1 ('newswire documents') is the subject, depending on the copula 'are'. Entity 2 ('unstructured data sources') is the predicate nominative, also depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, as they are linked by the copula 'are' to form the main clause of the sentence."
    },
    {
        "raw_sentence": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the Web or newswire documents .",
        "ner_pair": [
            [
                "Web",
                "Material"
            ],
            [
                "newswire documents",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Web') is the object of the preposition 'such as', depending on 'such as' in the phrase 'such as the Web'. Entity 2 ('newswire documents') is also the object of the preposition 'such as', depending on 'such as' in the phrase 'such as the Web or newswire documents'. There is no direct dependency between Entity 1 and Entity 2; both are listed as examples of unstructured data sources.",
        "sdp_path_text": "Web → documents",
        "sentence": "Information extraction techniques process data from the Web and newswire documents.",
        "sentence_llm_dp_info": "Entity 1 ('Web') is part of a coordination, depending on 'and' with 'newswire documents'. Entity 2 ('newswire documents') is also part of a coordination, depending on 'and' with 'Web'. Both are objects of the preposition 'from', which depends on the verb 'process'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as the source of the data being processed."
    },
    {
        "raw_sentence": "Despite the successes of these systems , accuracy will always be imperfect .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "systems",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the modal verb 'will' and further linked to the adjective 'imperfect'. Entity 2 ('systems') is the object of the preposition 'of', depending on 'successes'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the sentence.",
        "sdp_path_text": "accuracy → be → Despite → successes → of → systems",
        "sentence": "Accuracy is affected by the successes of systems.",
        "sentence_llm_dp_info": "Entity 1 ('accuracy') is the subject, depending on the verb 'affected'. Entity 2 ('systems') is the object of the preposition 'of', depending on 'successes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'affected' and the prepositional phrase 'by the successes of systems'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "linear-chain conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "information extraction system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field -LRB- CRF -RRB-') is the complement of the preposition 'on', depending on the preposition 'on' within the clause 'is based on a linear-chain conditional random field -LRB- CRF -RRB-'. Entity 2 ('information extraction system') is the subject, depending on the verb 'is' in the clause 'The information extraction system we evaluate is based on...'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 specifies what Entity 2 is based on.",
        "sdp_path_text": "field → on → based → system",
        "sentence": "The information extraction system is based on a linear-chain conditional random field (CRF).",
        "sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field (CRF)') is the complement, depending on 'based' with 'is based on'. Entity 2 ('information extraction system') is the subject, depending on 'is' as the main verb. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 specifies what the information extraction system is based on."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction system",
                "Method"
            ],
            [
                "probabilistic model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'evaluate' with 'we'. Entity 2 ('probabilistic model') is the subject complement, depending on the verb 'is' in the clause 'is based on a linear-chain conditional random field...which has performed well...because of its ability to capture arbitrary, overlapping features'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the prepositional phrase 'based on' and the relative clause that describes the 'probabilistic model'.",
        "sdp_path_text": "system → based → on → field → model",
        "sentence": "The information extraction system is based on a probabilistic model.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'is'. Entity 2 ('probabilistic model') is the complement, depending on 'based' in the phrase 'based on a probabilistic model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' in the phrase 'based on'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction system",
                "Method"
            ],
            [
                "information extraction tasks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on 'evaluate' with 'we'. Entity 2 ('information extraction tasks') is the object, depending on 'performed' with 'well'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the discussion of the performance of the probabilistic model (CRF) on tasks related to Entity 1.",
        "sdp_path_text": "system → based → on → field → model → performed → on → tasks",
        "sentence": "The information extraction system is based on a model that performs well on information extraction tasks.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'is' which describes its basis. Entity 2 ('information extraction tasks') is the object of the preposition 'on', depending on 'well' in the clause 'that performs well on information extraction tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the clause that describes the performance of the model on which the system is based."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction system",
                "Method"
            ],
            [
                "arbitrary , overlapping features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'evaluate' with 'we'. Entity 2 ('arbitrary, overlapping features') is the object, depending on 'capture' with 'ability'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the chain of dependencies involving 'based on', 'conditional random field (CRF)', and 'ability to capture'.",
        "sdp_path_text": "system → based → on → field → model → performed → because → ability → capture → features",
        "sentence": "The information extraction system captures arbitrary, overlapping features.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'captures'. Entity 2 ('arbitrary, overlapping features') is the object, depending on the verb 'captures'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 performs the action of capturing Entity 2."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction system",
                "Method"
            ],
            [
                "input",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'evaluate' with 'we'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure describing the capabilities of the model used in the system.",
        "sdp_path_text": "system → based → on → field → model → performed → because → ability → capture → features → of → input",
        "sentence": "The information extraction system captures features of the input.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'captures'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'features' which is the object of the verb 'captures'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction system",
                "Method"
            ],
            [
                "Markov model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'evaluate'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'in' in the phrase 'in a Markov model'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the clause that describes the capabilities of the 'information extraction system', which includes the use of a 'Markov model'.",
        "sdp_path_text": "system → based → on → field → model → performed → because → ability → capture → in → model",
        "sentence": "The information extraction system is based on a model that captures features in a Markov model.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction system') is the subject, depending on the verb 'is based'. Entity 2 ('Markov model') is the object of the preposition 'on', depending on 'based' in the phrase 'based on a model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on a model that captures features in a Markov model'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "linear-chain conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "probabilistic model",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field -LRB- CRF -RRB-') is the subject complement, depending on 'is' with 'system'. Entity 2 ('probabilistic model') is the appositive, depending on 'which' in the relative clause 'which has performed well'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the same noun 'system' and the relative clause describing it.",
        "sdp_path_text": "field → model",
        "sentence": "A linear-chain conditional random field (CRF) is a probabilistic model.",
        "sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field (CRF)') is the subject, depending on the verb 'is'. Entity 2 ('probabilistic model') is the predicate nominative, also depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as they are linked by the copular verb 'is', indicating that Entity 1 is identified as or equated with Entity 2."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "linear-chain conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "information extraction tasks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field -LRB- CRF -RRB-') is the complement of the preposition 'on', depending on 'based' in the phrase 'is based on'. Entity 2 ('information extraction tasks') is the object of the preposition 'on', depending on 'performed well' in the phrase 'has performed well on'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of performance in the context of the sentence.",
        "sdp_path_text": "field → model → performed → on → tasks",
        "sentence": "The linear-chain conditional random field (CRF) model has performed well on information extraction tasks.",
        "sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field (CRF)') is the subject, depending on the verb 'has performed'. Entity 2 ('information extraction tasks') is the object of the preposition 'on', depending on 'on' in the phrase 'on information extraction tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "linear-chain conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "arbitrary , overlapping features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field -LRB- CRF -RRB-') is the subject complement, depending on the verb 'is' with 'information extraction system'. Entity 2 ('arbitrary, overlapping features') is the object of the preposition 'of', depending on 'ability'. There is no direct dependency between Entity 1 and Entity 2; however, they are indirectly connected through the clause describing the CRF's ability to capture these features.",
        "sdp_path_text": "field → model → performed → because → ability → capture → features",
        "sentence": "The linear-chain conditional random field (CRF) model captures arbitrary, overlapping features.",
        "sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field (CRF)') is the subject, depending on the verb 'captures'. Entity 2 ('arbitrary, overlapping features') is the object, depending on 'captures' with 'linear-chain conditional random field (CRF)'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the agent performing the action of capturing Entity 2."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "linear-chain conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "input",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field -LRB- CRF -RRB-') is the subject complement, depending on 'is' with 'information extraction system'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the capabilities of the CRF model, where 'input' is part of the features that the model can capture.",
        "sdp_path_text": "field → model → performed → because → ability → capture → features → of → input",
        "sentence": "The linear-chain conditional random field (CRF) model captures features of the input.",
        "sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field (CRF)') is the subject, depending on the verb 'captures'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'captures' and the prepositional phrase 'of the input'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "linear-chain conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "Markov model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field -LRB- CRF -RRB-') is the complement of the preposition 'on', depending on 'based' in the phrase 'is based on a linear-chain conditional random field -LRB- CRF -RRB-'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'features' in the phrase 'features of the input in a Markov model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing aspects of the information extraction system.",
        "sdp_path_text": "field → model → performed → because → ability → capture → in → model",
        "sentence": "The linear-chain conditional random field (CRF) performs well on information extraction tasks due to its ability to capture features in a Markov model.",
        "sentence_llm_dp_info": "Entity 1 ('linear-chain conditional random field (CRF)') is the subject, depending on the verb 'performs'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'capture'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in a Markov model' which modifies 'features' that 'CRF' captures."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "probabilistic model",
                "Method"
            ],
            [
                "information extraction tasks",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the appositive, depending on 'is based on' with 'a linear-chain conditional random field (CRF)'. Entity 2 ('information extraction tasks') is the object, depending on 'performed well on' with 'which'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the clause describing the performance of the probabilistic model on the information extraction tasks.",
        "sdp_path_text": "model → performed → on → tasks",
        "sentence": "The probabilistic model has performed well on information extraction tasks.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the subject, depending on the verb 'has performed'. Entity 2 ('information extraction tasks') is the object of the preposition 'on', depending on 'performed' in the phrase 'performed well on information extraction tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'performed' and the preposition 'on'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "probabilistic model",
                "Method"
            ],
            [
                "arbitrary , overlapping features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the appositive, depending on 'is' with 'CRF'. Entity 2 ('arbitrary, overlapping features') is the object of the preposition 'of', depending on 'ability'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the capabilities of the probabilistic model.",
        "sdp_path_text": "model → performed → because → ability → capture → features",
        "sentence": "The probabilistic model performs well because of its ability to capture arbitrary, overlapping features.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the subject, depending on the verb 'performs'. Entity 2 ('arbitrary, overlapping features') is the object of the preposition 'to', depending on 'capture' in the phrase 'to capture arbitrary, overlapping features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' which is part of the clause describing why the model performs well."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "probabilistic model",
                "Method"
            ],
            [
                "input",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the appositive, depending on 'CRF' with the preposition 'which'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the capabilities of the probabilistic model.",
        "sdp_path_text": "model → performed → because → ability → capture → features → of → input",
        "sentence": "The probabilistic model performs well because of its ability to capture features of the input.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the subject, depending on the verb 'performs'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the model's ability to capture features of the input."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "probabilistic model",
                "Method"
            ],
            [
                "Markov model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the appositive, depending on 'is' with 'CRF'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'in' in the phrase 'in a Markov model'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where the 'probabilistic model' (CRF) is described as capturing features within a 'Markov model'.",
        "sdp_path_text": "model → performed → because → ability → capture → in → model",
        "sentence": "The probabilistic model has performed well because of its ability to capture features in a Markov model.",
        "sentence_llm_dp_info": "Entity 1 ('probabilistic model') is the subject, depending on the verb 'has performed'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'in' in the phrase 'in a Markov model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in a Markov model' that modifies the noun 'features'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction tasks",
                "Task"
            ],
            [
                "arbitrary , overlapping features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction tasks') is the object, depending on 'performed' with 'well'. Entity 2 ('arbitrary, overlapping features') is the object, depending on 'capture' with 'ability'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the performance and capabilities of the probabilistic model (CRF).",
        "sdp_path_text": "tasks → on → performed → because → ability → capture → features",
        "sentence": "The system performs well on information extraction tasks because of its ability to capture arbitrary, overlapping features.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction tasks') is the object, depending on the preposition 'on', which modifies 'performs'. Entity 2 ('arbitrary, overlapping features') is the object of the preposition 'to', depending on 'ability'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause that explains why the system performs well."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction tasks",
                "Task"
            ],
            [
                "input",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction tasks') is the object of the preposition 'on', depending on 'performed'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the performance and capabilities of the probabilistic model (CRF).",
        "sdp_path_text": "tasks → on → performed → because → ability → capture → features → of → input",
        "sentence": "The system performs well on information extraction tasks because of its ability to capture features of the input.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction tasks') is the object of the preposition 'on', depending on 'performs'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the performance and capabilities of the system."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "information extraction tasks",
                "Task"
            ],
            [
                "Markov model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information extraction tasks') is the object, depending on 'performed' with 'well'. Entity 2 ('Markov model') is the object, depending on 'in' with 'features'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context where the 'Markov model' is used to perform well on 'information extraction tasks'.",
        "sdp_path_text": "tasks → on → performed → because → ability → capture → in → model",
        "sentence": "The Markov model performs well on information extraction tasks due to its ability to capture features.",
        "sentence_llm_dp_info": "Entity 1 ('information extraction tasks') is the object of the preposition 'on', depending on 'performs'. Entity 2 ('Markov model') is the subject, depending on the verb 'performs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'performs' and the preposition 'on'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "arbitrary , overlapping features",
                "OtherScientificTerm"
            ],
            [
                "input",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('arbitrary, overlapping features') is the object, depending on 'capture' with 'ability'. Entity 2 ('input') is the object of the preposition 'of', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture' and the preposition 'of'.",
        "sdp_path_text": "features → of → input",
        "sentence": "The system captures arbitrary, overlapping features of the input.",
        "sentence_llm_dp_info": "Entity 1 ('arbitrary, overlapping features') is the object, depending on 'captures' with 'system'. Entity 2 ('input') is the object of the preposition 'of', depending on 'of' in the phrase 'of the input'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'captures' and the preposition 'of'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "arbitrary , overlapping features",
                "OtherScientificTerm"
            ],
            [
                "Markov model",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('arbitrary, overlapping features') is the object, depending on the verb 'capture' which is part of the clause 'its ability to capture arbitrary, overlapping features'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'in' in the phrase 'in a Markov model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the capabilities of the probabilistic model.",
        "sdp_path_text": "features → capture → in → model",
        "sentence": "The system captures arbitrary, overlapping features in a Markov model.",
        "sentence_llm_dp_info": "Entity 1 ('arbitrary, overlapping features') is the direct object, depending on the verb 'captures' with 'The system'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'in' in the phrase 'in a Markov model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'features' are captured 'in' the 'Markov model'."
    },
    {
        "raw_sentence": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model .",
        "ner_pair": [
            [
                "input",
                "Generic"
            ],
            [
                "Markov model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('input') is the object of the preposition 'of', depending on 'features'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'capture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the features that the model captures.",
        "sdp_path_text": "input → of → features → capture → in → model",
        "sentence": "The input features are captured in a Markov model.",
        "sentence_llm_dp_info": "Entity 1 ('input') is part of the noun phrase 'input features', which is the subject, depending on the verb 'captured'. Entity 2 ('Markov model') is the object of the preposition 'in', depending on 'in' in the phrase 'in a Markov model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'captured' and the preposition 'in'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "extracted fields",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('techniques') is the object of the verb 'implement', depending on 'We'. Entity 2 ('extracted fields') is part of the prepositional phrase 'of both extracted fields and entire multi-field records', where it depends on 'both'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "techniques → implement → estimate → confidence → of → fields",
        "sentence": "We implement techniques to estimate the confidence of extracted fields.",
        "sentence_llm_dp_info": "Entity 1 ('techniques') is the direct object, depending on the verb 'implement'. Entity 2 ('extracted fields') is the object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'estimate' and the preposition 'of'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "multi-field records",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('techniques') is the object, depending on 'implement' with 'We'. Entity 2 ('multi-field records') is the object of the preposition 'for', depending on 'for' in the phrase 'for multi-field records'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure, where 'techniques' are used to achieve results related to 'multi-field records'.",
        "sdp_path_text": "techniques → implement → estimate → confidence → of → fields → records",
        "sentence": "We implement techniques to estimate the confidence of multi-field records.",
        "sentence_llm_dp_info": "Entity 1 ('techniques') is the object, depending on the verb 'implement' with 'We'. Entity 2 ('multi-field records') is the object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'techniques' being used to 'estimate the confidence of multi-field records'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "average precision",
                "Metric"
            ],
            [
                "techniques",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('average precision') is the subject complement, depending on the verb 'obtaining'. Entity 2 ('techniques') is the object, depending on the verb 'implement'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the outcomes of implementing the techniques.",
        "sdp_path_text": "precision → obtaining → implement → techniques",
        "sentence": "We implement techniques to obtain an average precision.",
        "sentence_llm_dp_info": "Entity 1 ('average precision') is the object, depending on 'obtain' with 'techniques'. Entity 2 ('techniques') is the subject, depending on the verb 'implement'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtain'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "multi-field records",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('techniques') is the object, depending on 'implement' with 'We'. Entity 2 ('multi-field records') is the object of the preposition 'for', depending on 'for' in the phrase 'for multi-field records'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'techniques' is implemented to achieve certain outcomes, including the precision for 'multi-field records'.",
        "sdp_path_text": "techniques → implement → estimate → confidence → of → fields → records",
        "sentence": "We implement techniques to estimate the confidence of multi-field records.",
        "sentence_llm_dp_info": "Entity 1 ('techniques') is the object, depending on the verb 'implement'. Entity 2 ('multi-field records') is the object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'estimate' and the preposition 'of'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "extracted fields",
                "Generic"
            ],
            [
                "multi-field records",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('extracted fields') is part of the object of the preposition 'of', depending on 'confidence'. Entity 2 ('multi-field records') is also part of the object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the noun 'confidence' through the preposition 'of'.",
        "sdp_path_text": "fields → records",
        "sentence": "We estimate the confidence of extracted fields and multi-field records.",
        "sentence_llm_dp_info": "Entity 1 ('extracted fields') is the object of the preposition 'of', depending on 'confidence'. Entity 2 ('multi-field records') is also the object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'of' in the phrase 'the confidence of extracted fields and multi-field records'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "extracted fields",
                "Generic"
            ],
            [
                "average precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('extracted fields') is part of the object of the preposition 'of', depending on 'confidence'. Entity 2 ('average precision') is the subject complement, depending on the verb 'obtaining'. There is no direct dependency between Entity 1 and Entity 2; however, they are both related to the concept of confidence and precision in the context of the implemented techniques.",
        "sdp_path_text": "fields → of → confidence → estimate → implement → obtaining → precision",
        "sentence": "Implementing techniques to estimate the confidence of extracted fields obtains an average precision.",
        "sentence_llm_dp_info": "Entity 1 ('extracted fields') is the object of the preposition 'of', depending on 'confidence'. Entity 2 ('average precision') is the subject complement, depending on 'obtains'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'obtains' and the noun 'confidence'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "extracted fields",
                "Generic"
            ],
            [
                "multi-field records",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('extracted fields') is the object of the preposition 'of', depending on 'confidence'. Entity 2 ('multi-field records') is also the object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the same noun 'confidence' through the preposition 'of'.",
        "sdp_path_text": "fields → records",
        "sentence": "We estimate the confidence of extracted fields and multi-field records.",
        "sentence_llm_dp_info": "Entity 1 ('extracted fields') is the object of the preposition 'of', depending on 'confidence'. Entity 2 ('multi-field records') is coordinated with 'fields' through the conjunction 'and', also being an object of the preposition 'of', depending on 'confidence'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'of'."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "multi-field records",
                "Material"
            ],
            [
                "average precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-field records') is part of the object of the preposition 'for', depending on 'retrieving' in the phrase 'for retrieving correct fields and 87 % for multi-field records'. Entity 2 ('average precision') is the subject complement, depending on 'obtaining' in the phrase 'obtaining an average precision of 98 %'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the outcomes of the implemented techniques described in the sentence.",
        "sdp_path_text": "records → fields → of → confidence → estimate → implement → obtaining → precision",
        "sentence": "Implementing techniques to estimate confidence in multi-field records obtains average precision.",
        "sentence_llm_dp_info": "Entity 1 ('multi-field records') is the object of the preposition 'in', depending on 'estimate'. Entity 2 ('average precision') is the subject complement, depending on 'obtains'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtains' which indicates the outcome of implementing the techniques for estimating confidence in Entity 1."
    },
    {
        "raw_sentence": "We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records , obtaining an average precision of 98 % for retrieving correct fields and 87 % for multi-field records .",
        "ner_pair": [
            [
                "average precision",
                "Metric"
            ],
            [
                "multi-field records",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('average precision') is the subject, depending on 'obtaining' as the object of the verb. Entity 2 ('multi-field records') is the object of the preposition 'for', depending on 'for' in the phrase 'for multi-field records'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different outcomes of the action 'obtaining'.",
        "sdp_path_text": "precision → obtaining → implement → estimate → confidence → of → fields → records",
        "sentence": "We obtain an average precision for multi-field records.",
        "sentence_llm_dp_info": "Entity 1 ('average precision') is the object, depending on 'obtain' with 'We'. Entity 2 ('multi-field records') is the object of the preposition 'for', depending on 'for' in the phrase 'for multi-field records'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "In this paper , we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries .",
        "ner_pair": [
            [
                "information redundancy in multilingual input",
                "OtherScientificTerm"
            ],
            [
                "machine translation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information redundancy in multilingual input') is the object of the preposition 'in', depending on 'use' with 'we'. Entity 2 ('machine translation') is the object of the preposition 'in', depending on 'errors' in the phrase 'errors in machine translation'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context where 'information redundancy in multilingual input' is used to correct 'errors in machine translation'.",
        "sdp_path_text": "redundancy → use → correct → errors → in → translation",
        "sentence": "Information redundancy in multilingual input is used to correct errors in machine translation.",
        "sentence_llm_dp_info": "Entity 1 ('information redundancy in multilingual input') is the subject, depending on the verb 'used'. Entity 2 ('machine translation') is part of the object, depending on 'in' within the prepositional phrase 'in machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of using Entity 1 to correct errors in Entity 2."
    },
    {
        "raw_sentence": "In this paper , we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries .",
        "ner_pair": [
            [
                "information redundancy in multilingual input",
                "OtherScientificTerm"
            ],
            [
                "multilingual summaries",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information redundancy in multilingual input') is the object of the preposition 'in', depending on 'use'. Entity 2 ('multilingual summaries') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where 'information redundancy in multilingual input' is used to improve the 'quality of multilingual summaries'.",
        "sdp_path_text": "redundancy → use → correct → improve → quality → of → summaries",
        "sentence": "Information redundancy in multilingual input is used to improve the quality of multilingual summaries.",
        "sentence_llm_dp_info": "Entity 1 ('information redundancy in multilingual input') is the subject, depending on the verb 'is used'. Entity 2 ('multilingual summaries') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is used' and the prepositional phrase 'to improve the quality of'."
    },
    {
        "raw_sentence": "In this paper , we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries .",
        "ner_pair": [
            [
                "machine translation",
                "Task"
            ],
            [
                "multilingual summaries",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('machine translation') is the object of the preposition 'in', depending on 'correct' with the phrase 'to correct errors in machine translation'. Entity 2 ('multilingual summaries') is the object of the preposition 'of', depending on 'improve' with the phrase 'improve the quality of multilingual summaries'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of improving the quality of outputs in a multilingual setting.",
        "sdp_path_text": "translation → in → errors → correct → improve → quality → of → summaries",
        "sentence": "Correcting errors in machine translation improves the quality of multilingual summaries.",
        "sentence_llm_dp_info": "Entity 1 ('machine translation') is the object of the preposition 'in', depending on 'correcting'. Entity 2 ('multilingual summaries') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the cause-and-effect relationship expressed in the sentence."
    },
    {
        "raw_sentence": "We consider the case of multi-document summarization , where the input documents are in Arabic , and the output summary is in English .",
        "ner_pair": [
            [
                "multi-document summarization",
                "Task"
            ],
            [
                "Arabic",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-document summarization') is the object of the preposition 'of', depending on 'case'. Entity 2 ('Arabic') is the complement of the preposition 'in', depending on 'documents'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the conditions of the case being considered.",
        "sdp_path_text": "summarization → of → case → are → in → Arabic",
        "sentence": "Multi-document summarization involves input documents in Arabic.",
        "sentence_llm_dp_info": "Entity 1 ('multi-document summarization') is the subject, depending on the verb 'involves'. Entity 2 ('Arabic') is the object of the preposition 'in', depending on 'documents'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in' and the noun 'documents'."
    },
    {
        "raw_sentence": "We consider the case of multi-document summarization , where the input documents are in Arabic , and the output summary is in English .",
        "ner_pair": [
            [
                "multi-document summarization",
                "Task"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-document summarization') is the object of the preposition 'of', depending on 'case'. Entity 2 ('English') is the complement of the preposition 'in', depending on 'summary'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "summarization → of → case → are → is → in → English",
        "sentence": "The case of multi-document summarization is considered where the output summary is in English.",
        "sentence_llm_dp_info": "Entity 1 ('multi-document summarization') is the object of the preposition 'of', depending on 'case'. Entity 2 ('English') is the complement of the preposition 'in', depending on 'summary'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the conditions of the case being considered."
    },
    {
        "raw_sentence": "We consider the case of multi-document summarization , where the input documents are in Arabic , and the output summary is in English .",
        "ner_pair": [
            [
                "Arabic",
                "Material"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Arabic') is the complement of the preposition 'in', depending on 'documents'. Entity 2 ('English') is also the complement of the preposition 'in', depending on 'summary'. There is no direct dependency between Entity 1 and Entity 2; both are related to their respective nouns through the preposition 'in'.",
        "sdp_path_text": "Arabic → in → are → is → in → English",
        "sentence": "The input documents are in Arabic, and the output summary is in English.",
        "sentence_llm_dp_info": "Entity 1 ('Arabic') is the complement of the preposition 'in', depending on 'documents'. Entity 2 ('English') is also the complement of the preposition 'in', depending on 'summary'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Further , the use of multiple machine translation systems provides yet more redundancy , yielding different ways to realize that information in English .",
        "ner_pair": [
            [
                "machine translation systems",
                "Method"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('machine translation systems') is the object of the preposition 'of', depending on 'use'. Entity 2 ('English') is the complement of the preposition 'in', depending on 'in' in the phrase 'in English'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the effect of using multiple machine translation systems.",
        "sdp_path_text": "systems → of → use → provides → yielding → ways → realize → in → English",
        "sentence": "The use of machine translation systems yields different ways to realize information in English.",
        "sentence_llm_dp_info": "Entity 1 ('machine translation systems') is the object of the preposition 'of', depending on 'use'. Entity 2 ('English') is the complement of the preposition 'in', depending on 'in' in the phrase 'in English'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the outcome of using machine translation systems."
    },
    {
        "raw_sentence": "We demonstrate how errors in the machine translations of the input Arabic documents can be corrected by identifying and generating from such redundancy , focusing on noun phrases .",
        "ner_pair": [
            [
                "Arabic documents",
                "Material"
            ],
            [
                "machine translations",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Arabic documents') is the object of the preposition 'of', depending on 'translations'. Entity 2 ('machine translations') is the subject, depending on the verb 'demonstrate' through the prepositional phrase 'in the machine translations'. There is a direct dependency between Entity 1 and Entity 2, as 'Arabic documents' is part of the prepositional phrase that modifies 'machine translations'.",
        "sdp_path_text": "documents → of → translations",
        "sentence": "Errors in the machine translations of Arabic documents can be corrected.",
        "sentence_llm_dp_info": "Entity 1 ('Arabic documents') is the object of the preposition 'of', depending on 'translations'. Entity 2 ('machine translations') is the subject, depending on the verb 'can be corrected'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of' in the phrase 'machine translations of Arabic documents'."
    },
    {
        "raw_sentence": "In this paper , we propose a new approach to generate oriented object proposals -LRB- OOPs -RRB- to reduce the detection error caused by various orientations of the object .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "oriented object proposals -LRB- OOPs -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the object of the verb 'propose', depending on 'we'. Entity 2 ('oriented object proposals -LRB- OOPs -RRB-') is the object of the preposition 'to', depending on 'generate'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'generate' and the preposition 'to'.",
        "sdp_path_text": "approach → generate → proposals",
        "sentence": "A new approach generates oriented object proposals (OOPs).",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'generates'. Entity 2 ('oriented object proposals -LRB- OOPs -RRB-') is the object, depending on 'generates' with 'approach'. There is a direct dependency between Entity 1 and Entity 2, as 'approach' generates 'oriented object proposals -LRB- OOPs -RRB-.'\""
    },
    {
        "raw_sentence": "In this paper , we propose a new approach to generate oriented object proposals -LRB- OOPs -RRB- to reduce the detection error caused by various orientations of the object .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "detection error",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'propose'. Entity 2 ('detection error') is the object, depending on the verb 'reduce'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'reduce' and the purpose it serves in the sentence.",
        "sdp_path_text": "approach → generate → reduce → error",
        "sentence": "A new approach generates oriented object proposals to reduce detection error.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'generates'. Entity 2 ('detection error') is the object, depending on the verb 'reduce'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'to reduce detection error'."
    },
    {
        "raw_sentence": "In this paper , we propose a new approach to generate oriented object proposals -LRB- OOPs -RRB- to reduce the detection error caused by various orientations of the object .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "orientations of the object",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'propose' with 'we'. Entity 2 ('orientations of the object') is the object of the preposition 'by', depending on 'caused' in the phrase 'caused by various orientations of the object'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose of the approach, which aims to reduce the detection error that is influenced by the orientations of the object.",
        "sdp_path_text": "approach → generate → reduce → error → caused → by → orientations",
        "sentence": "The approach generates to reduce error caused by orientations of the object.",
        "sentence_llm_dp_info": "Entity 1 ('approach') is the subject, depending on the verb 'generates'. Entity 2 ('orientations of the object') is the object of the preposition 'by', depending on 'caused' in the phrase 'caused by orientations of the object'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'caused' and the preposition 'by'."
    },
    {
        "raw_sentence": "In this paper , we propose a new approach to generate oriented object proposals -LRB- OOPs -RRB- to reduce the detection error caused by various orientations of the object .",
        "ner_pair": [
            [
                "detection error",
                "Metric"
            ],
            [
                "oriented object proposals -LRB- OOPs -RRB-",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('detection error') is the object of the verb 'reduce', depending on 'reduce' with 'to reduce'. Entity 2 ('oriented object proposals -LRB- OOPs -RRB-') is the object of the preposition 'to', depending on 'generate' in the phrase 'to generate oriented object proposals -LRB- OOPs -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'oriented object proposals' are generated to help 'reduce the detection error'.",
        "sdp_path_text": "error → reduce → generate → proposals",
        "sentence": "Oriented object proposals (OOPs) are generated to reduce detection error.",
        "sentence_llm_dp_info": "Entity 1 ('detection error') is the object, depending on the verb 'reduce'. Entity 2 ('oriented object proposals (OOPs)') is the subject, depending on the verb 'are generated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to reduce'."
    },
    {
        "raw_sentence": "In this paper , we propose a new approach to generate oriented object proposals -LRB- OOPs -RRB- to reduce the detection error caused by various orientations of the object .",
        "ner_pair": [
            [
                "oriented object proposals -LRB- OOPs -RRB-",
                "Task"
            ],
            [
                "orientations of the object",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('oriented object proposals -LRB- OOPs -RRB-') is the object of the preposition 'to', depending on 'generate' in the phrase 'to generate oriented object proposals'. Entity 2 ('orientations of the object') is the object of the preposition 'by', depending on 'caused' in the phrase 'caused by various orientations of the object'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of reducing detection error.",
        "sdp_path_text": "proposals → generate → reduce → error → caused → by → orientations",
        "sentence": "Oriented object proposals are generated to reduce error caused by object orientations.",
        "sentence_llm_dp_info": "Entity 1 ('oriented object proposals') is the subject, depending on the verb 'generated'. Entity 2 ('orientations of the object') is the object of the preposition 'by', depending on 'caused' in the phrase 'caused by object orientations'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the purpose of reducing error, where Entity 1 is generated to mitigate issues related to Entity 2."
    },
    {
        "raw_sentence": "In this paper , we propose a new approach to generate oriented object proposals -LRB- OOPs -RRB- to reduce the detection error caused by various orientations of the object .",
        "ner_pair": [
            [
                "detection error",
                "Metric"
            ],
            [
                "orientations of the object",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('detection error') is the object, depending on 'reduce' with 'approach'. Entity 2 ('orientations of the object') is the object of the preposition 'by', depending on 'caused' in the phrase 'caused by various orientations of the object'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by 'caused by'.",
        "sdp_path_text": "error → caused → by → orientations",
        "sentence": "Detection error is caused by orientations of the object.",
        "sentence_llm_dp_info": "Entity 1 ('detection error') is the subject, depending on the verb 'caused'. Entity 2 ('orientations of the object') is the object, depending on the preposition 'by' which links it to the verb 'caused'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by the verb 'caused' and the preposition 'by'."
    },
    {
        "raw_sentence": "To this end , we propose to efficiently locate object regions according to pixelwise object probability , rather than measuring the objectness from a set of sampled windows .",
        "ner_pair": [
            [
                "pixelwise object probability",
                "OtherScientificTerm"
            ],
            [
                "object regions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('pixelwise object probability') is the object of the preposition 'according to', depending on the preposition 'according to'. Entity 2 ('object regions') is the object of the verb 'locate', depending on 'to efficiently locate'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the method described for locating object regions.",
        "sdp_path_text": "probability → to → according → locate → regions",
        "sentence": "We propose to locate object regions according to pixelwise object probability.",
        "sentence_llm_dp_info": "Entity 1 ('pixelwise object probability') is the object of the preposition 'according to', depending on 'according'. Entity 2 ('object regions') is the direct object, depending on the verb 'locate'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'locate' and the prepositional phrase 'according to pixelwise object probability' which provides the basis for locating the object regions."
    },
    {
        "raw_sentence": "To this end , we propose to efficiently locate object regions according to pixelwise object probability , rather than measuring the objectness from a set of sampled windows .",
        "ner_pair": [
            [
                "object regions",
                "OtherScientificTerm"
            ],
            [
                "objectness",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object regions') is the object of the verb 'locate', depending on the verb 'locate' with the adverb 'efficiently'. Entity 2 ('objectness') is the subject complement, depending on the verb 'measuring' with the prepositional phrase 'from a set of sampled windows'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process of locating or measuring aspects of objects in the context of the sentence.",
        "sdp_path_text": "regions → locate → measuring → objectness",
        "sentence": "We propose to locate object regions rather than measure objectness.",
        "sentence_llm_dp_info": "Entity 1 ('object regions') is the object of the verb 'locate', depending on 'to locate' in the phrase 'to locate object regions'. Entity 2 ('objectness') is the object of the verb 'measure', depending on 'measure' in the phrase 'measure objectness'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted in the sentence through the coordinating conjunction 'rather than'."
    },
    {
        "raw_sentence": "To this end , we propose to efficiently locate object regions according to pixelwise object probability , rather than measuring the objectness from a set of sampled windows .",
        "ner_pair": [
            [
                "pixelwise object probability",
                "OtherScientificTerm"
            ],
            [
                "objectness",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('pixelwise object probability') is the object of the preposition 'according to', depending on 'locate'. Entity 2 ('objectness') is the object of the preposition 'from', depending on 'measuring'. There is no direct dependency between Entity 1 and Entity 2, but both are part of contrasting methods described in the sentence.",
        "sdp_path_text": "probability → to → according → locate → measuring → objectness",
        "sentence": "Pixelwise object probability is used to locate object regions, rather than measuring objectness.",
        "sentence_llm_dp_info": "Entity 1 ('pixelwise object probability') is the subject, depending on the verb 'is used'. Entity 2 ('objectness') is the object of the preposition 'than', depending on 'rather than measuring'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted through the comparative structure 'rather than'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "generative proba-bilistic model",
                "Method"
            ],
            [
                "proposal generation problem",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative proba-bilistic model') is the object, depending on the verb 'formulate'. Entity 2 ('proposal generation problem') is the direct object of the verb 'formulate', and it is being described or defined by 'as' in the phrase 'as a generative proba-bilistic model'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is formulated as Entity 1.",
        "sdp_path_text": "model → as → formulate → problem",
        "sentence": "We formulate the proposal generation problem as a generative probabilistic model.",
        "sentence_llm_dp_info": "Entity 1 ('generative probabilistic model') is the complement, depending on the verb 'formulate'. Entity 2 ('proposal generation problem') is the object, depending on the verb 'formulate'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the complement that completes the meaning of the verb 'formulate' with respect to Entity 2."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "proposal generation problem",
                "Task"
            ],
            [
                "object proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the object of the verb 'formulate', depending on 'formulate' with 'We'. Entity 2 ('object proposals') is the subject, depending on 'can be produced' with 'produced'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the sentence structure where the formulation of the 'proposal generation problem' leads to the production of 'object proposals'.",
        "sdp_path_text": "problem → formulate → as → model → produced → proposals",
        "sentence": "The proposal generation problem is formulated as a model that produces object proposals.",
        "sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the subject, depending on the verb 'is formulated'. Entity 2 ('object proposals') is the object, depending on the verb 'produces' within the relative clause 'that produces object proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'proposal generation problem' is formulated into a model that has the capability to produce 'object proposals'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "proposal generation problem",
                "Task"
            ],
            [
                "shapes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the subject, depending on the verb 'formulate' with 'We'. Entity 2 ('shapes') is the object of the preposition 'of', depending on 'different' in the phrase 'different shapes'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the context where 'shapes' is part of the description of what can be produced by the model formulated for the 'proposal generation problem'.",
        "sdp_path_text": "problem → formulate → as → model → produced → proposals → of → shapes",
        "sentence": "The proposal generation problem is formulated as a model producing proposals of different shapes.",
        "sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the subject, depending on the verb 'formulated'. Entity 2 ('shapes') is the object of the preposition 'of', depending on 'proposals'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun 'proposals' and the preposition 'of'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "proposal generation problem",
                "Task"
            ],
            [
                "sizes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the object of the verb 'formulate', depending on 'formulate' with 'We'. Entity 2 ('sizes') is part of a compound noun, depending on 'shapes' within the phrase 'different shapes (i.e., sizes and orientations)'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence structure, specifically through the phrase describing the characteristics of the object proposals.",
        "sdp_path_text": "problem → formulate → as → model → produced → proposals → of → shapes → -LRB- → sizes",
        "sentence": "The proposal generation problem is formulated to produce object proposals of different sizes.",
        "sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the subject, depending on the verb 'is formulated'. Entity 2 ('sizes') is the object of the preposition 'of', depending on 'proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence 'object proposals of different sizes'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "proposal generation problem",
                "Task"
            ],
            [
                "orientations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the object of the verb 'formulate', depending on 'We'. Entity 2 ('orientations') is part of a list (sizes and orientations), which is the object of the preposition 'of', depending on 'shapes'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "problem → formulate → as → model → produced → proposals → of → shapes → -LRB- → sizes → orientations",
        "sentence": "The proposal generation problem is formulated as a model that produces object proposals of different shapes, including orientations.",
        "sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the subject, depending on the verb 'formulated'. Entity 2 ('orientations') is the object of the preposition 'including', depending on 'shapes'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'orientations' is listed as one of the aspects of the 'object proposals' produced by the model formulated from the 'proposal generation problem'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "proposal generation problem",
                "Task"
            ],
            [
                "local maximum likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the object of the verb 'formulate', depending on 'formulate' with 'We'. Entity 2 ('local maximum likelihoods') is the object of the verb 'locating', depending on 'can be produced' with 'such that'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause where the formulation of Entity 1 enables the production of Entity 2.",
        "sdp_path_text": "problem → formulate → as → model → produced → by → locating → likelihoods",
        "sentence": "The proposal generation problem is formulated as a model where proposals are produced by locating local maximum likelihoods.",
        "sentence_llm_dp_info": "Entity 1 ('proposal generation problem') is the subject, depending on the verb 'formulated'. Entity 2 ('local maximum likelihoods') is the object of the verb 'locating', which is part of the relative clause modifying 'model'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where the 'problem' is formulated into a 'model' that involves 'locating local maximum likelihoods'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "generative proba-bilistic model",
                "Method"
            ],
            [
                "object proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative proba-bilistic model') is the object of the preposition 'as', depending on 'formulate' with 'We'. Entity 2 ('object proposals') is the subject, depending on 'can be produced' with 'be produced'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose of the model, which is to produce the object proposals.",
        "sdp_path_text": "model → produced → proposals",
        "sentence": "A generative probabilistic model produces object proposals.",
        "sentence_llm_dp_info": "Entity 1 ('generative probabilistic model') is the subject, depending on the verb 'produces'. Entity 2 ('object proposals') is the object, depending on 'produces' with 'generative probabilistic model'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the producer of Entity 2."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "generative proba-bilistic model",
                "Method"
            ],
            [
                "shapes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative proba-bilistic model') is the object of the preposition 'as', depending on 'formulate' with 'We'. Entity 2 ('shapes') is part of a prepositional phrase, depending on 'of' with 'proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how the proposal generation problem is formulated.",
        "sdp_path_text": "model → produced → proposals → of → shapes",
        "sentence": "A generative probabilistic model produces object proposals of different shapes.",
        "sentence_llm_dp_info": "Entity 1 ('generative probabilistic model') is the subject, depending on the verb 'produces'. Entity 2 ('shapes') is the object of the preposition 'of', depending on 'proposals' in the phrase 'object proposals of different shapes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'proposals' and the preposition 'of'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "generative proba-bilistic model",
                "Method"
            ],
            [
                "sizes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative proba-bilistic model') is the object of the preposition 'as', depending on 'formulate' with 'We'. Entity 2 ('sizes') is part of a list, depending on 'shapes' within the phrase 'different shapes (i.e., sizes and orientations)'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "model → produced → proposals → of → shapes → -LRB- → sizes",
        "sentence": "The generative probabilistic model produces object proposals of different sizes.",
        "sentence_llm_dp_info": "Entity 1 ('generative probabilistic model') is the subject, depending on the verb 'produces'. Entity 2 ('sizes') is the object of the preposition 'of', depending on 'proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'proposals'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "generative proba-bilistic model",
                "Method"
            ],
            [
                "orientations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative proba-bilistic model') is the object of the preposition 'as', depending on 'formulate' with 'We'. Entity 2 ('orientations') is part of a list, depending on 'shapes' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "model → produced → proposals → of → shapes → -LRB- → sizes → orientations",
        "sentence": "The generative probabilistic model produces object proposals of different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('generative probabilistic model') is the subject, depending on the verb 'produces'. Entity 2 ('orientations') is the object of the preposition 'of', depending on 'proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'proposals' and the preposition 'of'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "generative proba-bilistic model",
                "Method"
            ],
            [
                "local maximum likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generative proba-bilistic model') is the object of the preposition 'as', depending on 'formulate' with 'We'. Entity 2 ('local maximum likelihoods') is the object of the verb 'locating', depending on 'can be produced by locating'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the model is used to produce the likelihoods.",
        "sdp_path_text": "model → produced → by → locating → likelihoods",
        "sentence": "The generative probabilistic model produces object proposals by locating local maximum likelihoods.",
        "sentence_llm_dp_info": "Entity 1 ('generative probabilistic model') is the subject, depending on the verb 'produces'. Entity 2 ('local maximum likelihoods') is the object, depending on 'locating' in the phrase 'locating local maximum likelihoods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the gerund 'locating'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "shapes",
                "OtherScientificTerm"
            ],
            [
                "object proposals",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('shapes') is the object of the preposition 'of', depending on 'sizes and orientations'. Entity 2 ('object proposals') is the subject, depending on the verb 'can be produced'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the characteristics of 'object proposals' which can have different 'shapes'.",
        "sdp_path_text": "shapes → of → proposals",
        "sentence": "Object proposals of different shapes can be produced.",
        "sentence_llm_dp_info": "Entity 1 ('shapes') is the complement, depending on the adjective 'different' with 'of' in the phrase 'of different shapes'. Entity 2 ('object proposals') is the subject, depending on the verb 'can be produced'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of different shapes' which modifies 'object proposals'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "object proposals",
                "OtherScientificTerm"
            ],
            [
                "sizes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object proposals') is the object of the preposition 'of', depending on 'shapes' in the phrase 'of different shapes'. Entity 2 ('sizes') is part of a conjunction, depending on 'and' in the phrase 'sizes and orientations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the description of 'shapes'.",
        "sdp_path_text": "proposals → of → shapes → -LRB- → sizes",
        "sentence": "Object proposals of different sizes can be produced.",
        "sentence_llm_dp_info": "Entity 1 ('object proposals') is the subject, depending on the verb 'can be produced'. Entity 2 ('sizes') is the object of the preposition 'of', depending on 'of' in the phrase 'of different sizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of different sizes'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "object proposals",
                "OtherScientificTerm"
            ],
            [
                "orientations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object proposals') is the subject, depending on 'can be produced' with 'produced'. Entity 2 ('orientations') is part of a list, depending on 'shapes' within the prepositional phrase 'of different shapes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of different shapes' which describes the characteristics of 'object proposals'.",
        "sdp_path_text": "proposals → of → shapes → -LRB- → sizes → orientations",
        "sentence": "Object proposals of different shapes, including orientations, can be produced.",
        "sentence_llm_dp_info": "Entity 1 ('object proposals') is the subject, depending on the verb 'can be produced'. Entity 2 ('orientations') is part of a prepositional phrase, depending on 'including' which modifies 'shapes'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what can be produced."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "local maximum likelihoods",
                "OtherScientificTerm"
            ],
            [
                "object proposals",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('local maximum likelihoods') is the object of the verb 'locating', depending on 'can be produced by locating'. Entity 2 ('object proposals') is the subject, depending on 'can be produced'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing how 'object proposals' can be produced by locating 'local maximum likelihoods'.",
        "sdp_path_text": "likelihoods → locating → by → produced → proposals",
        "sentence": "Locating local maximum likelihoods produces object proposals.",
        "sentence_llm_dp_info": "Entity 1 ('local maximum likelihoods') is the object of the gerund 'Locating', depending on the verb 'produces'. Entity 2 ('object proposals') is the direct object, depending on the verb 'produces'. There is a direct dependency between Entity 1 and Entity 2, as 'local maximum likelihoods' are what produces 'object proposals'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "sizes",
                "OtherScientificTerm"
            ],
            [
                "shapes",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sizes') is part of a coordination, depending on 'shapes' with the conjunction 'and'. Entity 2 ('shapes') is the object of the preposition 'of', depending on 'different'. There is a direct dependency between Entity 1 and Entity 2, as 'sizes' is coordinated with 'shapes' through the conjunction 'and'.",
        "sdp_path_text": "sizes → -LRB- → shapes",
        "sentence": "Sizes and orientations define different shapes.",
        "sentence_llm_dp_info": "Entity 1 ('sizes') is the subject, depending on the verb 'define'. Entity 2 ('shapes') is the object, depending on 'define' with 'sizes'. There is a direct dependency between Entity 1 and Entity 2, as 'sizes' defines 'shapes'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "orientations",
                "OtherScientificTerm"
            ],
            [
                "shapes",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('orientations') is part of a conjunction, depending on 'shapes' with the conjunction 'and'. Entity 2 ('shapes') is the object of the preposition 'of', depending on 'different' in the phrase 'different shapes'. There is a direct dependency between Entity 1 and Entity 2, as 'orientations' is conjoined with 'sizes' under the same prepositional phrase 'of different shapes'.",
        "sdp_path_text": "orientations → sizes → -LRB- → shapes",
        "sentence": "Orientations and sizes are aspects of shapes.",
        "sentence_llm_dp_info": "Entity 1 ('orientations') is the subject, depending on the conjunction 'and' with 'sizes'. Together, 'orientations and sizes' form a compound subject that depends on the verb 'are'. Entity 2 ('shapes') is the object of the preposition 'of', depending on 'aspects'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate 'are aspects of'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "shapes",
                "OtherScientificTerm"
            ],
            [
                "local maximum likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('shapes') is the object of the preposition 'of', depending on 'sizes and orientations'. Entity 2 ('local maximum likelihoods') is the object of the verb 'locating', depending on the verb 'can be produced'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the clause describing how the model produces object proposals.",
        "sdp_path_text": "shapes → of → proposals → produced → by → locating → likelihoods",
        "sentence": "Shapes of proposals can be produced by locating local maximum likelihoods.",
        "sentence_llm_dp_info": "Entity 1 ('shapes') is the subject, depending on the verb 'can be produced'. Entity 2 ('local maximum likelihoods') is the object, depending on the verb 'locating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produced' and the prepositional phrase 'by locating local maximum likelihoods'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "sizes",
                "OtherScientificTerm"
            ],
            [
                "orientations",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sizes') is the object of the preposition 'of', depending on 'shapes'. Entity 2 ('orientations') is also the object of the preposition 'of', depending on 'shapes'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list within the same prepositional phrase.",
        "sdp_path_text": "sizes → orientations",
        "sentence": "Sizes and orientations can be produced.",
        "sentence_llm_dp_info": "Entity 1 ('sizes') is the subject, depending on the verb 'produced'. Entity 2 ('orientations') is coordinated with 'sizes' as part of the subject, depending on 'and' in the phrase 'sizes and orientations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same subject coordinated by 'and'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "sizes",
                "OtherScientificTerm"
            ],
            [
                "local maximum likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('sizes') is part of a compound noun, depending on the conjunction 'and' with 'orientations' in the phrase 'sizes and orientations'. Entity 2 ('local maximum likelihoods') is the object of the preposition 'by', depending on 'produced' in the phrase 'can be produced by locating the local maximum likelihoods'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "sizes → -LRB- → shapes → of → proposals → produced → by → locating → likelihoods",
        "sentence": "Sizes and orientations of proposals can be produced by locating local maximum likelihoods.",
        "sentence_llm_dp_info": "Entity 1 ('sizes') is part of the subject, depending on the verb 'can be produced'. Entity 2 ('local maximum likelihoods') is the object of the verb 'locating', depending on 'locating' in the phrase 'locating local maximum likelihoods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction and the process described by the verb 'locating'."
    },
    {
        "raw_sentence": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the local maximum likelihoods .",
        "ner_pair": [
            [
                "orientations",
                "OtherScientificTerm"
            ],
            [
                "local maximum likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('orientations') is part of a list, depending on the conjunction 'and' with 'sizes' within the phrase 'sizes and orientations'. Entity 2 ('local maximum likelihoods') is the object of the preposition 'by', depending on the verb 'produced'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing how object proposals can be produced.",
        "sdp_path_text": "orientations → sizes → -LRB- → shapes → of → proposals → produced → by → locating → likelihoods",
        "sentence": "Orientations and sizes of object proposals can be produced by locating local maximum likelihoods.",
        "sentence_llm_dp_info": "Entity 1 ('orientations') is part of a compound subject, depending on the verb 'can be produced'. Entity 2 ('local maximum likelihoods') is the object of the preposition 'by', depending on the verb 'locating'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the process described by the verb 'can be produced' and the prepositional phrase 'by locating local maximum likelihoods'."
    },
    {
        "raw_sentence": "First , it helps the object detector handle objects of different orientations .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "object detector",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'helps'. Entity 2 ('object detector') is the object of the preposition 'the', depending on 'helps' in the phrase 'helps the object detector'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps'.",
        "sdp_path_text": "it → helps → handle → detector",
        "sentence": "It helps the object detector handle objects.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'helps'. Entity 2 ('object detector') is the object of the preposition 'the', depending on 'helps' in the phrase 'helps the object detector'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps'."
    },
    {
        "raw_sentence": "First , it helps the object detector handle objects of different orientations .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "orientations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'helps'. Entity 2 ('orientations') is the object of the preposition 'of', depending on 'objects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'helps' and the noun phrase 'objects of different orientations'.",
        "sdp_path_text": "it → helps → handle → objects → of → orientations",
        "sentence": "It helps handle objects of different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'helps'. Entity 2 ('orientations') is part of a noun phrase, depending on 'objects' with the preposition 'of' in the phrase 'of different orientations'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "First , it helps the object detector handle objects of different orientations .",
        "ner_pair": [
            [
                "object detector",
                "Method"
            ],
            [
                "orientations",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object detector') is the object of the preposition 'the', depending on 'helps' with 'it'. Entity 2 ('orientations') is the object of the preposition 'of', depending on 'objects'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'object detector' is being helped to 'handle objects of different orientations'.",
        "sdp_path_text": "detector → handle → objects → of → orientations",
        "sentence": "The object detector handles objects of different orientations.",
        "sentence_llm_dp_info": "Entity 1 ('object detector') is the subject, depending on the verb 'handles'. Entity 2 ('orientations') is the object of the preposition 'of', depending on 'objects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'objects' and the preposition 'of'."
    },
    {
        "raw_sentence": "Second , as the shapes of the proposals may vary to fit the objects , the resulting proposals are tighter than the sampling windows with fixed sizes .",
        "ner_pair": [
            [
                "shapes of the proposals",
                "OtherScientificTerm"
            ],
            [
                "sampling windows",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('shapes of the proposals') is the subject, depending on 'may vary' as the verb. Entity 2 ('sampling windows') is the object of comparison, depending on 'than' in the comparative clause 'tighter than the sampling windows'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicating that the 'shapes of the proposals' lead to 'proposals' being 'tighter' compared to 'sampling windows'.",
        "sdp_path_text": "shapes → vary → are → tighter → than → windows",
        "sentence": "Shapes of the proposals vary, making them tighter than sampling windows.",
        "sentence_llm_dp_info": "Entity 1 ('shapes of the proposals') is the subject, depending on the verb 'vary'. Entity 2 ('sampling windows') is the complement of the preposition 'than', depending on 'than' in the phrase 'than sampling windows'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the comparative structure introduced by 'than'."
    },
    {
        "raw_sentence": "Third , it avoids massive window sampling , and thereby reducing the number of proposals while maintaining a high recall .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "massive window sampling",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'avoids'. Entity 2 ('massive window sampling') is the object, depending on 'avoids' with 'it'. There is a direct dependency between Entity 1 and Entity 2, as 'it' is the agent that performs the action of avoiding 'massive window sampling'.",
        "sdp_path_text": "it → avoids → sampling",
        "sentence": "It avoids massive window sampling.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'avoids'. Entity 2 ('massive window sampling') is the object, depending on 'avoids'. There is a direct dependency between Entity 1 and Entity 2, where 'it' avoids 'massive window sampling'."
    },
    {
        "raw_sentence": "Third , it avoids massive window sampling , and thereby reducing the number of proposals while maintaining a high recall .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "number of proposals",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'avoids'. Entity 2 ('number of proposals') is the object of the preposition 'of', depending on 'reducing' in the phrase 'reducing the number of proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions described in the sentence, where 'it' avoids something that leads to reducing the 'number of proposals'.",
        "sdp_path_text": "it → avoids → reducing → number",
        "sentence": "It avoids reducing the number of proposals.",
        "sentence_llm_dp_info": "Entity 1 ('it') is the subject, depending on the verb 'avoids'. Entity 2 ('number of proposals') is the object of the preposition 'of', depending on 'reducing' in the phrase 'reducing the number of proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'avoids' and the action 'reducing'."
    },
    {
        "raw_sentence": "Third , it avoids massive window sampling , and thereby reducing the number of proposals while maintaining a high recall .",
        "ner_pair": [
            [
                "recall",
                "Metric"
            ],
            [
                "it",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('recall') is the object, depending on 'maintaining' which is part of the verb phrase 'maintaining a high recall'. Entity 2 ('it') is the subject, depending on 'avoids' in the clause 'it avoids massive window sampling'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "recall → maintaining → reducing → avoids → it",
        "sentence": "It avoids reducing the number of proposals while maintaining recall.",
        "sentence_llm_dp_info": "Entity 1 ('recall') is the object, depending on the verb 'maintaining'. Entity 2 ('it') is the subject, depending on the verb 'avoids'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' (the subject) performs actions that affect 'recall' (the object)."
    },
    {
        "raw_sentence": "Third , it avoids massive window sampling , and thereby reducing the number of proposals while maintaining a high recall .",
        "ner_pair": [
            [
                "massive window sampling",
                "Method"
            ],
            [
                "number of proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('massive window sampling') is the object of the verb 'avoids', depending on 'it'. Entity 2 ('number of proposals') is the object of the verb 'reducing', depending on 'thereby'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the causal relationship expressed by 'thereby'.",
        "sdp_path_text": "sampling → avoids → reducing → number",
        "sentence": "Avoiding massive window sampling reduces the number of proposals.",
        "sentence_llm_dp_info": "Entity 1 ('massive window sampling') is the subject, depending on the verb 'Avoiding'. Entity 2 ('number of proposals') is the object, depending on the verb 'reduces'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the causal relationship expressed by the verb 'reduces'."
    },
    {
        "raw_sentence": "Third , it avoids massive window sampling , and thereby reducing the number of proposals while maintaining a high recall .",
        "ner_pair": [
            [
                "massive window sampling",
                "Method"
            ],
            [
                "recall",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('massive window sampling') is the object of the verb 'avoids', depending on 'it'. Entity 2 ('recall') is part of a clause complement, depending on 'maintaining' with 'while maintaining a high recall'. There is no direct dependency between Entity 1 and Entity 2, but they are both influenced by the actions described in the sentence.",
        "sdp_path_text": "sampling → avoids → reducing → maintaining → recall",
        "sentence": "Avoiding massive window sampling maintains high recall.",
        "sentence_llm_dp_info": "Entity 1 ('massive window sampling') is the object of the verb 'Avoiding', which acts as the subject of the sentence. Entity 2 ('recall') is the object of the verb 'maintains', depending on 'high' as an adjective modifier. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where avoiding Entity 1 helps maintain the state of Entity 2."
    },
    {
        "raw_sentence": "Third , it avoids massive window sampling , and thereby reducing the number of proposals while maintaining a high recall .",
        "ner_pair": [
            [
                "number of proposals",
                "OtherScientificTerm"
            ],
            [
                "recall",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('number of proposals') is the object, depending on 'reducing' with 'thereby reducing the number of proposals'. Entity 2 ('recall') is the object of the preposition 'of', depending on 'maintaining' in the phrase 'maintaining a high recall'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "number → reducing → maintaining → recall",
        "sentence": "Reducing the number of proposals maintains high recall.",
        "sentence_llm_dp_info": "Entity 1 ('number of proposals') is the object of the verb 'reducing'. Entity 2 ('recall') is the object complement, depending on the verb 'maintains'. There is no direct dependency between Entity 1 and Entity 2, but they are both influenced by the action described in the sentence, with 'number of proposals' being reduced to maintain 'recall'."
    },
    {
        "raw_sentence": "Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods .",
        "ner_pair": [
            [
                "PASCAL VOC 2007 dataset",
                "Material"
            ],
            [
                "OOP",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('PASCAL VOC 2007 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('OOP') is the subject of the clause, depending on 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence context where experiments are conducted on the dataset, and the results show the performance of OOP.",
        "sdp_path_text": "dataset → on → Experiments → show → outperforms → OOP",
        "sentence": "Experiments on the PASCAL VOC 2007 dataset show that OOP outperforms other methods.",
        "sentence_llm_dp_info": "Entity 1 ('PASCAL VOC 2007 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('OOP') is the subject of the clause, depending on 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence context where experiments conducted on Entity 1 demonstrate the performance of Entity 2."
    },
    {
        "raw_sentence": "Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods .",
        "ner_pair": [
            [
                "PASCAL VOC 2007 dataset",
                "Material"
            ],
            [
                "state-of-the-art fast methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('PASCAL VOC 2007 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('state-of-the-art fast methods') is the object of the verb 'outperforms', depending on 'OOP'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'OOP' outperforms 'state-of-the-art fast methods' in the context of experiments conducted on the 'PASCAL VOC 2007 dataset'.",
        "sdp_path_text": "dataset → on → Experiments → show → outperforms → methods",
        "sentence": "Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms state-of-the-art fast methods.",
        "sentence_llm_dp_info": "Entity 1 ('PASCAL VOC 2007 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('state-of-the-art fast methods') is the object of the verb 'outperforms', depending on 'OOP'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the results of the experiments."
    },
    {
        "raw_sentence": "Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods .",
        "ner_pair": [
            [
                "OOP",
                "Method"
            ],
            [
                "state-of-the-art fast methods",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('OOP') is the subject, depending on 'outperforms' as the verb. Entity 2 ('state-of-the-art fast methods') is the object, depending on 'outperforms' with 'OOP'. There is a direct dependency between Entity 1 and Entity 2, where 'OOP' is the subject performing the action of outperforming 'state-of-the-art fast methods'.",
        "sdp_path_text": "OOP → outperforms → methods",
        "sentence": "The proposed OOP outperforms state-of-the-art fast methods.",
        "sentence_llm_dp_info": "Entity 1 ('OOP') is the subject, depending on the verb 'outperforms'. Entity 2 ('state-of-the-art fast methods') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, where 'OOP' is performing the action of 'outperforming' 'state-of-the-art fast methods'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "rotation invariant property",
                "OtherScientificTerm"
            ],
            [
                "class-specific object detector",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject, depending on the verb 'helps'. Entity 2 ('class-specific object detector') is the object, depending on 'achieve' which is part of the clause 'achieve better performance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps', indicating that Entity 1 assists Entity 2 in achieving better performance.",
        "sdp_path_text": "property → helps → achieve → detector",
        "sentence": "The rotation invariant property helps a class-specific object detector achieve better performance.",
        "sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject, depending on the verb 'helps'. Entity 2 ('class-specific object detector') is the object, depending on the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps', which indicates that Entity 1 assists Entity 2 in achieving better performance."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "rotation invariant property",
                "OtherScientificTerm"
            ],
            [
                "proposal generation methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject complement, depending on 'helps' with 'the'. Entity 2 ('proposal generation methods') is the object of the preposition 'than', depending on 'better' in the phrase 'better performance than the state-of-the-art proposal generation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure involving 'better performance'.",
        "sdp_path_text": "property → helps → achieve → performance → than → methods",
        "sentence": "The rotation invariant property helps achieve better performance than proposal generation methods.",
        "sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject, depending on the verb 'helps'. Entity 2 ('proposal generation methods') is the object of comparison, depending on the comparative construction 'than' in the phrase 'than proposal generation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure involving the verb 'achieve' and the preposition 'than'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "rotation invariant property",
                "OtherScientificTerm"
            ],
            [
                "object rotation scenarios",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject, depending on the verb 'helps'. Entity 2 ('object rotation scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in either object rotation scenarios or general scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps' and the prepositional phrase 'in either object rotation scenarios or general scenarios'.",
        "sdp_path_text": "property → helps → achieve → in → scenarios",
        "sentence": "The rotation invariant property helps achieve better performance in object rotation scenarios.",
        "sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject, depending on the verb 'helps'. Entity 2 ('object rotation scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in object rotation scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps' and the preposition 'in'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "rotation invariant property",
                "OtherScientificTerm"
            ],
            [
                "general scenarios",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject complement, depending on 'helps' with 'the rotation invariant property helps'. Entity 2 ('general scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in either object rotation scenarios or general scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where Entity 1 influences the outcome described in the context that includes Entity 2.",
        "sdp_path_text": "property → helps → achieve → in → scenarios → scenarios",
        "sentence": "The rotation invariant property helps achieve better performance in general scenarios.",
        "sentence_llm_dp_info": "Entity 1 ('rotation invariant property') is the subject, depending on the verb 'helps'. Entity 2 ('general scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in general scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'helps' and the preposition 'in'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "class-specific object detector",
                "Method"
            ],
            [
                "proposal generation methods",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('class-specific object detector') is the subject of the clause, depending on the verb 'achieve'. Entity 2 ('proposal generation methods') is the object of the preposition 'than', depending on the comparative adjective 'better'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in terms of performance within the same clause.",
        "sdp_path_text": "detector → achieve → performance → than → methods",
        "sentence": "A class-specific object detector achieves better performance than proposal generation methods.",
        "sentence_llm_dp_info": "Entity 1 ('class-specific object detector') is the subject, depending on the verb 'achieves'. Entity 2 ('proposal generation methods') is the object of the preposition 'than', depending on 'than' in the phrase 'than proposal generation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the comparative structure 'better performance than'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "object rotation scenarios",
                "Material"
            ],
            [
                "class-specific object detector",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object rotation scenarios') is part of a compound noun, depending on 'scenarios' with 'rotation'. It is also an element in a prepositional phrase 'in object rotation scenarios', which modifies the comparative clause. Entity 2 ('class-specific object detector') is the subject of the verb 'achieve', indicating what achieves better performance. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the performance comparison described in the sentence.",
        "sdp_path_text": "scenarios → in → achieve → detector",
        "sentence": "The class-specific object detector achieves better performance in object rotation scenarios.",
        "sentence_llm_dp_info": "Entity 1 ('object rotation scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in object rotation scenarios'. Entity 2 ('class-specific object detector') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'achieves' which describes the performance of Entity 2 in the context of Entity 1."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "general scenarios",
                "Material"
            ],
            [
                "class-specific object detector",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('general scenarios') is the object of the preposition 'in', depending on 'in' within the phrase 'in either object rotation scenarios or general scenarios'. Entity 2 ('class-specific object detector') is the subject, depending on 'helps' with 'the rotation invariant property'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the context in which the 'class-specific object detector' achieves better performance.",
        "sdp_path_text": "scenarios → scenarios → in → achieve → detector",
        "sentence": "The class-specific object detector achieves better performance in general scenarios.",
        "sentence_llm_dp_info": "Entity 1 ('general scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in general scenarios'. Entity 2 ('class-specific object detector') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieves' which describes the performance of the 'class-specific object detector' in 'general scenarios'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "object rotation scenarios",
                "Material"
            ],
            [
                "proposal generation methods",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object rotation scenarios') is the object of the preposition 'in', depending on 'in' within the comparative clause 'than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios'. Entity 2 ('proposal generation methods') is the object of the preposition 'than', depending on 'than' in the same comparative clause. There is no direct dependency between Entity 1 and Entity 2; both are part of the comparative structure describing the conditions under which the performance is measured.",
        "sdp_path_text": "scenarios → in → achieve → performance → than → methods",
        "sentence": "The rotation invariant property helps achieve better performance in object rotation scenarios than proposal generation methods.",
        "sentence_llm_dp_info": "Entity 1 ('object rotation scenarios') is the object of the preposition 'in', depending on 'achieve'. Entity 2 ('proposal generation methods') is the complement of the comparative construction, depending on 'than'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparative clause that modifies 'better performance'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "general scenarios",
                "Material"
            ],
            [
                "proposal generation methods",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('general scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in either object rotation scenarios or general scenarios'. Entity 2 ('proposal generation methods') is the object of the preposition 'than', depending on 'than' in the phrase 'better performance than the state-of-the-art proposal generation methods'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the comparative structure describing the performance of the class-specific object detector.",
        "sdp_path_text": "scenarios → scenarios → in → achieve → performance → than → methods",
        "sentence": "General scenarios help achieve better performance than proposal generation methods.",
        "sentence_llm_dp_info": "Entity 1 ('general scenarios') is the subject, depending on the verb 'help'. Entity 2 ('proposal generation methods') is the object of the preposition 'than', depending on 'than' in the phrase 'than proposal generation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the comparative structure indicated by 'than'."
    },
    {
        "raw_sentence": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios .",
        "ner_pair": [
            [
                "object rotation scenarios",
                "Material"
            ],
            [
                "general scenarios",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object rotation scenarios') is the object of the preposition 'in', depending on 'in' in the phrase 'in object rotation scenarios'. Entity 2 ('general scenarios') is also the object of the preposition 'in', depending on 'in' in the phrase 'in general scenarios'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the preposition 'in' which modifies the comparative clause 'better performance than the state-of-the-art proposal generation methods'.",
        "sdp_path_text": "scenarios → scenarios",
        "sentence": "The rotation invariant property helps achieve better performance in both object rotation scenarios and general scenarios.",
        "sentence_llm_dp_info": "Entity 1 ('object rotation scenarios') is part of the prepositional phrase 'in both object rotation scenarios and general scenarios', depending on 'in'. Entity 2 ('general scenarios') is also part of the same prepositional phrase, depending on 'and'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and' within the prepositional phrase."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "domain-independent capabilities",
                "Generic"
            ],
            [
                "Paramax spoken language understanding system",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('domain-independent capabilities') is the object, depending on the verb 'describes' from 'This paper'. Entity 2 ('Paramax spoken language understanding system') is the object of the preposition 'to', depending on 'added' in the phrase 'added to the Paramax spoken language understanding system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'added' which indicates that the capabilities were added to the system.",
        "sdp_path_text": "capabilities → added → to → system",
        "sentence": "Domain-independent capabilities have been added to the Paramax spoken language understanding system.",
        "sentence_llm_dp_info": "Entity 1 ('domain-independent capabilities') is the subject, depending on the verb 'added'. Entity 2 ('Paramax spoken language understanding system') is the object of the preposition 'to', depending on 'to' in the phrase 'to the Paramax spoken language understanding system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'added' and the preposition 'to'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "non-monotonic reasoning",
                "Task"
            ],
            [
                "domain-independent capabilities",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('non-monotonic reasoning') is one of the items in a list, depending on the conjunction 'and' that connects it with other items, all of which are part of the object of the preposition 'to'. Entity 2 ('domain-independent capabilities') is the direct object, depending on the verb 'added'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where Entity 1 is part of the list of things that were added to the system, which are described as Entity 2.",
        "sdp_path_text": "reasoning → capabilities",
        "sentence": "Non-monotonic reasoning is one of the domain-independent capabilities.",
        "sentence_llm_dp_info": "Entity 1 ('non-monotonic reasoning') is the subject, depending on the copula 'is'. Entity 2 ('domain-independent capabilities') is the complement, depending on the copula 'is'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the copula 'is' which establishes that Entity 1 is a part of Entity 2."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "implicit reference resolution",
                "Task"
            ],
            [
                "domain-independent capabilities",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('implicit reference resolution') is one of the items in a list, depending on the conjunction 'and' with 'non-monotonic reasoning' and 'database query paraphrase'. Entity 2 ('domain-independent capabilities') is the direct object, depending on the verb 'added' in the phrase 'added to the Paramax spoken language understanding system'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 1 is part of the list of capabilities that are described as 'domain-independent capabilities'.",
        "sdp_path_text": "resolution → reasoning → capabilities",
        "sentence": "Implicit reference resolution is one of the domain-independent capabilities.",
        "sentence_llm_dp_info": "Entity 1 ('implicit reference resolution') is the subject, depending on the verb 'is'. Entity 2 ('domain-independent capabilities') is the complement of the copula 'is', depending on 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is identified as being part of Entity 2 through the copula 'is'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "database query paraphrase",
                "Task"
            ],
            [
                "domain-independent capabilities",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('database query paraphrase') is part of a list, depending on the conjunction 'and', which connects it to the other items listed after the colon. Entity 2 ('domain-independent capabilities') is the direct object, depending on the verb 'describes' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where Entity 1 is one of the items listed as part of Entity 2.",
        "sdp_path_text": "paraphrase → resolution → reasoning → capabilities",
        "sentence": "Database query paraphrase is one of the domain-independent capabilities.",
        "sentence_llm_dp_info": "Entity 1 ('database query paraphrase') is the subject, depending on the verb 'is'. Entity 2 ('domain-independent capabilities') is the complement, depending on the verb 'is' and modified by 'one of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the copular verb 'is' and the prepositional phrase 'one of'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "Paramax spoken language understanding system",
                "Method"
            ],
            [
                "non-monotonic reasoning",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Paramax spoken language understanding system') is the object of the preposition 'to', depending on 'added'. Entity 2 ('non-monotonic reasoning') is part of a list of objects, depending on the colon (:) which introduces the list of capabilities. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context that Entity 2 is one of the capabilities added to Entity 1.",
        "sdp_path_text": "system → to → added → capabilities → reasoning",
        "sentence": "The Paramax spoken language understanding system has added capabilities including non-monotonic reasoning.",
        "sentence_llm_dp_info": "Entity 1 ('Paramax spoken language understanding system') is the subject, depending on the verb 'has added'. Entity 2 ('non-monotonic reasoning') is part of the list of objects, depending on 'including' which itself depends on 'capabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has added' and the preposition 'including'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "Paramax spoken language understanding system",
                "Method"
            ],
            [
                "implicit reference resolution",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Paramax spoken language understanding system') is the object of the preposition 'to', depending on 'added'. Entity 2 ('implicit reference resolution') is one of the list items, depending on the colon (:) that introduces the list of capabilities. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as Entity 2 is part of the capabilities added to Entity 1.",
        "sdp_path_text": "system → to → added → capabilities → reasoning → resolution",
        "sentence": "The Paramax spoken language understanding system has added capabilities including implicit reference resolution.",
        "sentence_llm_dp_info": "Entity 1 ('Paramax spoken language understanding system') is the subject, depending on the verb 'has added'. Entity 2 ('implicit reference resolution') is the object, depending on 'including' which modifies 'capabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has added' and the preposition 'including'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "Paramax spoken language understanding system",
                "Method"
            ],
            [
                "database query paraphrase",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Paramax spoken language understanding system') is the object of the preposition 'to', depending on 'added'. Entity 2 ('database query paraphrase') is one of the items in a list of capabilities, depending on 'capabilities' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same descriptive context where Entity 2 is one of the capabilities added to Entity 1.",
        "sdp_path_text": "system → to → added → capabilities → reasoning → resolution → paraphrase",
        "sentence": "The Paramax spoken language understanding system has added capabilities including database query paraphrase.",
        "sentence_llm_dp_info": "Entity 1 ('Paramax spoken language understanding system') is the subject, depending on the verb 'has added'. Entity 2 ('database query paraphrase') is the object, depending on 'including' which modifies 'capabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has added' and the preposition 'including'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "non-monotonic reasoning",
                "Task"
            ],
            [
                "implicit reference resolution",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('non-monotonic reasoning') is part of a list, depending on the preposition 'to' within the prepositional phrase 'added to the Paramax spoken language understanding system'. Entity 2 ('implicit reference resolution') is also part of the same list, depending on the coordinating conjunction 'and' that links it with 'non-monotonic reasoning'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a list introduced by the colon and are linked by the conjunction 'and'.",
        "sdp_path_text": "reasoning → resolution",
        "sentence": "The Paramax system includes capabilities for non-monotonic reasoning and implicit reference resolution.",
        "sentence_llm_dp_info": "Entity 1 ('non-monotonic reasoning') is part of the compound object, depending on 'includes' with 'capabilities'. Entity 2 ('implicit reference resolution') is also part of the compound object, depending on 'includes' with 'capabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are both listed as capabilities included by the 'Paramax system'."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "non-monotonic reasoning",
                "Task"
            ],
            [
                "database query paraphrase",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('non-monotonic reasoning') is part of a list, depending on the preposition 'to' in the phrase 'added to the Paramax spoken language understanding system'. Entity 2 ('database query paraphrase') is also part of the same list, depending on the conjunction 'and' which connects it to the other items in the list. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of the list described as 'capabilities recently added to the Paramax spoken language understanding system'.",
        "sdp_path_text": "reasoning → resolution → paraphrase",
        "sentence": "The Paramax system includes capabilities for non-monotonic reasoning and database query paraphrase.",
        "sentence_llm_dp_info": "Entity 1 ('non-monotonic reasoning') is the object of the preposition 'for', depending on 'includes'. Entity 2 ('database query paraphrase') is also the object of the preposition 'for', depending on 'includes'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'for' in the context of what the Paramax system includes."
    },
    {
        "raw_sentence": "This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit reference resolution , and database query paraphrase .",
        "ner_pair": [
            [
                "implicit reference resolution",
                "Task"
            ],
            [
                "database query paraphrase",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('implicit reference resolution') is part of a list, depending on the conjunction 'and', which connects it to the last item in the list. Entity 2 ('database query paraphrase') is also part of a list, directly connected to the previous items through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a list described as 'capabilities recently added to the Paramax spoken language understanding system'.",
        "sdp_path_text": "resolution → paraphrase",
        "sentence": "The Paramax system includes capabilities for implicit reference resolution and database query paraphrase.",
        "sentence_llm_dp_info": "Entity 1 ('implicit reference resolution') is the object of the preposition 'for', depending on 'includes' in the phrase 'capabilities for implicit reference resolution'. Entity 2 ('database query paraphrase') is also the object of the preposition 'for', depending on 'includes' in the phrase 'capabilities for database query paraphrase'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of capabilities included by the Paramax system."
    },
    {
        "raw_sentence": "Finally , we briefly describe an experiment which we have done in extending the n-best speech/language integration architecture to improving OCR accuracy .",
        "ner_pair": [
            [
                "OCR accuracy",
                "Metric"
            ],
            [
                "n-best speech/language integration architecture",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('OCR accuracy') is the object, depending on 'improving' as part of the gerund phrase 'improving OCR accuracy'. Entity 2 ('n-best speech/language integration architecture') is the object of the preposition 'in', depending on 'extending' in the phrase 'extending the n-best speech/language integration architecture'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the purpose and method of the experiment.",
        "sdp_path_text": "accuracy → improving → to → extending → architecture",
        "sentence": "The n-best speech/language integration architecture was extended to improve OCR accuracy.",
        "sentence_llm_dp_info": "Entity 1 ('OCR accuracy') is the object, depending on 'improve' with 'to'. Entity 2 ('n-best speech/language integration architecture') is the subject, depending on 'was extended' with 'to'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of extending the architecture to improve the accuracy."
    },
    {
        "raw_sentence": "We investigate the problem of fine-grained sketch-based image retrieval -LRB- SBIR -RRB- , where free-hand human sketches are used as queries to perform instance-level retrieval of images .",
        "ner_pair": [
            [
                "fine-grained sketch-based image retrieval -LRB- SBIR -RRB-",
                "Task"
            ],
            [
                "free-hand human sketches",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('fine-grained sketch-based image retrieval -LRB- SBIR -RRB-') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('free-hand human sketches') is the subject, depending on 'are used' with 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where Entity 2 serves as the query for the process described by Entity 1.",
        "sdp_path_text": "retrieval → used → sketches",
        "sentence": "Free-hand human sketches are used for fine-grained sketch-based image retrieval.",
        "sentence_llm_dp_info": "Entity 1 ('fine-grained sketch-based image retrieval (SBIR)') is the object of the preposition 'for', depending on 'used'. Entity 2 ('free-hand human sketches') is the subject, depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for', indicating the purpose or function of Entity 2 in relation to Entity 1."
    },
    {
        "raw_sentence": "We investigate the problem of fine-grained sketch-based image retrieval -LRB- SBIR -RRB- , where free-hand human sketches are used as queries to perform instance-level retrieval of images .",
        "ner_pair": [
            [
                "fine-grained sketch-based image retrieval -LRB- SBIR -RRB-",
                "Task"
            ],
            [
                "instance-level retrieval of images",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('fine-grained sketch-based image retrieval -LRB- SBIR -RRB-') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('instance-level retrieval of images') is the object of the preposition 'to', depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the problem being investigated.",
        "sdp_path_text": "retrieval → used → perform → retrieval",
        "sentence": "Fine-grained sketch-based image retrieval uses free-hand human sketches to perform instance-level retrieval of images.",
        "sentence_llm_dp_info": "Entity 1 ('fine-grained sketch-based image retrieval (SBIR)') is the subject, depending on the verb 'uses'. Entity 2 ('instance-level retrieval of images') is the object, depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'perform' which describes the action taken by Entity 1 to achieve Entity 2."
    },
    {
        "raw_sentence": "We investigate the problem of fine-grained sketch-based image retrieval -LRB- SBIR -RRB- , where free-hand human sketches are used as queries to perform instance-level retrieval of images .",
        "ner_pair": [
            [
                "free-hand human sketches",
                "OtherScientificTerm"
            ],
            [
                "instance-level retrieval of images",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('free-hand human sketches') is the subject, depending on the verb 'used' in the clause 'are used as queries'. Entity 2 ('instance-level retrieval of images') is the object, depending on the verb 'perform' in the clause 'to perform instance-level retrieval of images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to perform'.",
        "sdp_path_text": "sketches → used → perform → retrieval",
        "sentence": "Free-hand human sketches are used to perform instance-level retrieval of images.",
        "sentence_llm_dp_info": "Entity 1 ('free-hand human sketches') is the subject, depending on the verb 'are used'. Entity 2 ('instance-level retrieval of images') is the object, depending on the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'perform' which indicates that the sketches are used to carry out the retrieval process."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "visual comparisons",
                "OtherScientificTerm"
            ],
            [
                "free-hand -LRB- finger -RRB- sketches",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on the verb 'need' in the phrase 'not only need to be fine-grained'. Entity 2 ('free-hand (finger) sketches') is the subject, depending on the verb 'are' in the clause 'sketches are highly abstract'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses within the larger sentence.",
        "sdp_path_text": "comparisons → need → are → sketches",
        "sentence": "Visual comparisons need to be made with free-hand sketches.",
        "sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on the verb 'need'. Entity 2 ('free-hand -LRB- finger -RRB- sketches') is the object of the preposition 'with', depending on 'with' in the phrase 'with free-hand -LRB- finger -RRB- sketches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "visual comparisons",
                "OtherScientificTerm"
            ],
            [
                "fine-grained matching",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on the verb 'need' in the clause 'not only need to be fine-grained'. Entity 2 ('fine-grained matching') is the object, depending on the adjective 'harder' in the clause 'making fine-grained matching harder'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where the requirement for 'visual comparisons' being 'fine-grained' influences the difficulty of 'fine-grained matching'.",
        "sdp_path_text": "comparisons → need → are → making → harder → matching",
        "sentence": "Visual comparisons need to be fine-grained, making fine-grained matching harder.",
        "sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on the verb 'need' with the phrase 'to be fine-grained'. Entity 2 ('fine-grained matching') is the subject complement, depending on the adjective 'harder' with the verb 'making'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the logical flow of the sentence."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "visual comparisons",
                "OtherScientificTerm"
            ],
            [
                "annotated cross-domain sketch-photo datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on 'need' with the adverbial phrase 'not only need to be fine-grained but also executed cross-domain'. Entity 2 ('annotated cross-domain sketch-photo datasets') is the subject, depending on 'are' with the adjective 'scarce'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the complex sentence.",
        "sdp_path_text": "comparisons → need → are → are → datasets",
        "sentence": "Visual comparisons require annotated cross-domain sketch-photo datasets.",
        "sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on the verb 'require'. Entity 2 ('annotated cross-domain sketch-photo datasets') is the object, depending on 'require' with 'visual comparisons'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the object required by Entity 1."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "visual comparisons",
                "OtherScientificTerm"
            ],
            [
                "machine learning techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on 'need' with the verb 'to be' in the clause 'not only need to be fine-grained'. Entity 2 ('machine learning techniques') is the object, depending on 'challenging' with the adverb 'many'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same complex sentence.",
        "sdp_path_text": "comparisons → need → are → are → challenging → techniques",
        "sentence": "Visual comparisons need to be fine-grained and cross-domain, challenging machine learning techniques.",
        "sentence_llm_dp_info": "Entity 1 ('visual comparisons') is the subject, depending on the verb 'need'. Entity 2 ('machine learning techniques') is the object, depending on the adjective 'challenging'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where 'visual comparisons' pose a challenge to 'machine learning techniques'."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "free-hand -LRB- finger -RRB- sketches",
                "OtherScientificTerm"
            ],
            [
                "fine-grained matching",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('free-hand -LRB- finger -RRB- sketches') is the subject, depending on the verb 'are' in the clause 'sketches are highly abstract'. Entity 2 ('fine-grained matching') is the object, depending on the verb 'making' in the phrase 'making fine-grained matching harder'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the causal relationship expressed by the verb 'making'.",
        "sdp_path_text": "sketches → are → making → harder → matching",
        "sentence": "Free-hand sketches make fine-grained matching harder.",
        "sentence_llm_dp_info": "Entity 1 ('free-hand (finger) sketches') is the subject, depending on the verb 'make'. Entity 2 ('fine-grained matching') is the object, depending on 'make' with 'free-hand (finger) sketches'. There is a direct dependency between Entity 1 and Entity 2, as 'free-hand (finger) sketches' directly affects 'fine-grained matching' by making it harder."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "free-hand -LRB- finger -RRB- sketches",
                "OtherScientificTerm"
            ],
            [
                "annotated cross-domain sketch-photo datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('free-hand (finger) sketches') is the subject, depending on the adjective 'abstract', which modifies it. Entity 2 ('annotated cross-domain sketch-photo datasets') is the subject, depending on the verb 'are' and modified by the adjective 'scarce'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger list of reasons that make the task challenging, connected through the conjunction 'and'.",
        "sdp_path_text": "sketches → are → are → datasets",
        "sentence": "Free-hand sketches are highly abstract, making annotated cross-domain sketch-photo datasets scarce.",
        "sentence_llm_dp_info": "Entity 1 ('free-hand sketches') is the subject, depending on the verb 'are' with the adjective 'abstract'. Entity 2 ('annotated cross-domain sketch-photo datasets') is the subject complement, depending on 'making' which is part of the clause describing the effect of the abstraction of free-hand sketches. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the causal relationship expressed by 'making'."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "free-hand -LRB- finger -RRB- sketches",
                "OtherScientificTerm"
            ],
            [
                "machine learning techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('free-hand (finger) sketches') is the subject, depending on the adjective 'abstract', which modifies it. It is part of a larger clause where it is the subject of the verb 'are', describing its characteristics. Entity 2 ('machine learning techniques') is the object of the preposition 'of', depending on 'techniques' in the phrase 'machine learning techniques', which is modified by the adjective phrase 'state-of-the-art'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of challenges in the task described.",
        "sdp_path_text": "sketches → are → are → challenging → techniques",
        "sentence": "Free-hand sketches challenge machine learning techniques.",
        "sentence_llm_dp_info": "Entity 1 ('free-hand sketches') is the subject, depending on the verb 'challenge'. Entity 2 ('machine learning techniques') is the object, depending on the verb 'challenge'. There is a direct dependency between Entity 1 and Entity 2, as 'free-hand sketches' directly challenges 'machine learning techniques'."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "fine-grained matching",
                "Task"
            ],
            [
                "annotated cross-domain sketch-photo datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('fine-grained matching') is part of a complex clause, where it serves as the complement of the adjective 'harder', which itself modifies the verb 'making'. Entity 2 ('annotated cross-domain sketch-photo datasets') is the subject of the clause 'are scarce', which is part of a larger list of reasons introduced by 'and most importantly'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses that contribute to explaining why the task is challenging.",
        "sdp_path_text": "matching → harder → making → are → are → datasets",
        "sentence": "Fine-grained matching is harder due to the scarcity of annotated cross-domain sketch-photo datasets.",
        "sentence_llm_dp_info": "Entity 1 ('fine-grained matching') is the subject, depending on the verb 'is'. Entity 2 ('annotated cross-domain sketch-photo datasets') is the object of the preposition 'of', depending on 'scarcity'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'due to' which links the difficulty of 'fine-grained matching' to the 'scarcity' of 'annotated cross-domain sketch-photo datasets'."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "fine-grained matching",
                "Task"
            ],
            [
                "machine learning techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('fine-grained matching') is part of the clause describing what needs to be done, depending on 'need' and modified by 'making' which indicates that it is affected by the abstract nature of the sketches. Entity 2 ('machine learning techniques') is the object of the preposition 'of', depending on 'challenging' which describes the impact of the scarcity of annotated datasets on these techniques. There is no direct dependency between Entity 1 and Entity 2, but both are related to the challenges described in the sentence.",
        "sdp_path_text": "matching → harder → making → are → are → challenging → techniques",
        "sentence": "Fine-grained matching makes machine learning techniques challenging.",
        "sentence_llm_dp_info": "Entity 1 ('fine-grained matching') is the subject, depending on the verb 'makes'. Entity 2 ('machine learning techniques') is the object, depending on the verb 'makes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'makes' which indicates that Entity 1 affects Entity 2."
    },
    {
        "raw_sentence": "This is an extremely challenging task because -LRB- i -RRB- visual comparisons not only need to be fine-grained but also executed cross-domain , -LRB- ii -RRB- free-hand -LRB- finger -RRB- sketches are highly abstract , making fine-grained matching harder , and most importantly -LRB- iii -RRB- annotated cross-domain sketch-photo datasets required for training are scarce , challenging many state-of-the-art machine learning techniques .",
        "ner_pair": [
            [
                "annotated cross-domain sketch-photo datasets",
                "Material"
            ],
            [
                "machine learning techniques",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('annotated cross-domain sketch-photo datasets') is the subject, depending on 'are' with 'scarce'. Entity 2 ('machine learning techniques') is the object, depending on 'challenging' with 'datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'challenging' which indicates that the scarcity of Entity 1 poses a challenge to Entity 2.",
        "sdp_path_text": "datasets → are → challenging → techniques",
        "sentence": "Annotated cross-domain sketch-photo datasets are challenging for machine learning techniques.",
        "sentence_llm_dp_info": "Entity 1 ('annotated cross-domain sketch-photo datasets') is the subject, depending on the verb 'are'. Entity 2 ('machine learning techniques') is the object of the preposition 'for', depending on 'challenging'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'challenging' which describes the challenge posed by Entity 1 to Entity 2."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "deep triplet-ranking model",
                "Method"
            ],
            [
                "instance-level SBIR",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('deep triplet-ranking model') is the object, depending on the verb 'develop'. Entity 2 ('instance-level SBIR') is the object of the preposition 'for', depending on 'for' in the phrase 'for instance-level SBIR'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.",
        "sdp_path_text": "model → for → SBIR",
        "sentence": "We develop a deep triplet-ranking model for instance-level SBIR.",
        "sentence_llm_dp_info": "Entity 1 ('deep triplet-ranking model') is the object, depending on the verb 'develop' with 'We'. Entity 2 ('instance-level SBIR') is the object of the preposition 'for', depending on 'for' in the phrase 'for instance-level SBIR'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "data augmentation",
                "Method"
            ],
            [
                "deep triplet-ranking model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data augmentation') is part of a compound noun, depending on 'novel' with the role of modifying the noun phrase 'novel data augmentation and staged pre-training strategy'. Entity 2 ('deep triplet-ranking model') is the object of the verb 'develop', depending on 'develop' with 'We'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of the larger context describing the development and strategies used to enhance the model.",
        "sdp_path_text": "augmentation → with → develop → model",
        "sentence": "We develop a deep triplet-ranking model with data augmentation.",
        "sentence_llm_dp_info": "Entity 1 ('data augmentation') is the object of the preposition 'with', depending on 'model'. Entity 2 ('deep triplet-ranking model') is the direct object, depending on the verb 'develop'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "staged pre-training strategy",
                "Method"
            ],
            [
                "deep triplet-ranking model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('staged pre-training strategy') is part of a prepositional phrase modifying the noun 'model', depending on the preposition 'with'. Entity 2 ('deep triplet-ranking model') is the direct object of the verb 'develop', depending on 'develop' in the clause 'develop a deep triplet-ranking model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which links the strategy to the model.",
        "sdp_path_text": "strategy → augmentation → with → develop → model",
        "sentence": "A staged pre-training strategy is used to develop a deep triplet-ranking model.",
        "sentence_llm_dp_info": "Entity 1 ('staged pre-training strategy') is the subject, depending on the verb 'used'. Entity 2 ('deep triplet-ranking model') is the object of the preposition 'to', depending on 'to' in the phrase 'to develop a deep triplet-ranking model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the preposition 'to'."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "deep triplet-ranking model",
                "Method"
            ],
            [
                "insufficient fine-grained training data",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('deep triplet-ranking model') is the object, depending on 'develop' with 'We'. Entity 2 ('insufficient fine-grained training data') is the object, depending on 'alleviate' with 'strategy'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where the model is developed to help address the issue of insufficient fine-grained training data.",
        "sdp_path_text": "model → develop → alleviate → issue → of → data",
        "sentence": "A deep triplet-ranking model is developed to alleviate the issue of insufficient fine-grained training data.",
        "sentence_llm_dp_info": "Entity 1 ('deep triplet-ranking model') is the subject, depending on the verb 'developed'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of', depending on 'issue'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose of developing the model to address the issue related to Entity 2."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "instance-level SBIR",
                "Task"
            ],
            [
                "data augmentation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('instance-level SBIR') is the object of the preposition 'for', depending on 'model'. Entity 2 ('data augmentation') is part of a compound noun, depending on 'and' which connects it to 'staged pre-training strategy'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the components and purpose of the model.",
        "sdp_path_text": "SBIR → for → model → develop → with → augmentation",
        "sentence": "We develop a deep triplet-ranking model for instance-level SBIR with data augmentation.",
        "sentence_llm_dp_info": "Entity 1 ('instance-level SBIR') is the object of the preposition 'for', depending on 'model'. Entity 2 ('data augmentation') is the object of the preposition 'with', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the 'model' through different prepositions."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "instance-level SBIR",
                "Task"
            ],
            [
                "staged pre-training strategy",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('instance-level SBIR') is the object of the preposition 'for', depending on 'model'. Entity 2 ('staged pre-training strategy') is part of a compound noun, depending on 'with' in the phrase 'with a novel data augmentation and staged pre-training strategy'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the development of the model described in the sentence.",
        "sdp_path_text": "SBIR → for → model → develop → with → augmentation → strategy",
        "sentence": "We develop a deep triplet-ranking model for instance-level SBIR with a staged pre-training strategy.",
        "sentence_llm_dp_info": "Entity 1 ('instance-level SBIR') is the object of the preposition 'for', depending on 'model'. Entity 2 ('staged pre-training strategy') is the object of the preposition 'with', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the 'model' through different prepositions."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "instance-level SBIR",
                "Task"
            ],
            [
                "insufficient fine-grained training data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('instance-level SBIR') is the object of the preposition 'for', depending on 'model'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of', depending on 'issue'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the purpose and context of the model development.",
        "sdp_path_text": "SBIR → for → model → develop → alleviate → issue → of → data",
        "sentence": "A deep triplet-ranking model for instance-level SBIR is developed to alleviate the issue of insufficient fine-grained training data.",
        "sentence_llm_dp_info": "Entity 1 ('instance-level SBIR') is the object of the preposition 'for', depending on 'model'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of', depending on 'issue'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the purpose and context of the model development."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "data augmentation",
                "Method"
            ],
            [
                "staged pre-training strategy",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data augmentation') is part of a compound noun, depending on 'novel' with 'a novel data augmentation and staged pre-training strategy'. Entity 2 ('staged pre-training strategy') is also part of the same compound noun, depending on 'and' with 'data augmentation'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of a larger noun phrase connected by 'and'.",
        "sdp_path_text": "augmentation → strategy",
        "sentence": "A novel data augmentation and staged pre-training strategy is used.",
        "sentence_llm_dp_info": "Entity 1 ('data augmentation') is part of a conjunction, depending on 'and' with 'staged pre-training strategy'. Entity 2 ('staged pre-training strategy') is also part of a conjunction, depending on 'and' with 'data augmentation'. Both entities together form the subject, depending on the verb 'is used'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "data augmentation",
                "Method"
            ],
            [
                "insufficient fine-grained training data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data augmentation') is part of a compound noun, depending on 'novel' as a modifier and is part of the larger phrase 'a novel data augmentation and staged pre-training strategy'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of', depending on 'issue'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the strategy aimed at addressing the issue described by Entity 2.",
        "sdp_path_text": "augmentation → with → develop → alleviate → issue → of → data",
        "sentence": "Data augmentation helps alleviate the issue of insufficient fine-grained training data.",
        "sentence_llm_dp_info": "Entity 1 ('data augmentation') is the subject, depending on the verb 'helps'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of', depending on 'issue'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'alleviate' and the preposition 'of'."
    },
    {
        "raw_sentence": "We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .",
        "ner_pair": [
            [
                "staged pre-training strategy",
                "Method"
            ],
            [
                "insufficient fine-grained training data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('staged pre-training strategy') is part of the prepositional phrase 'with a novel data augmentation and staged pre-training strategy', depending on 'develop' with 'model'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of' in the phrase 'the issue of insufficient fine-grained training data', which modifies 'issue'. There is no direct dependency between Entity 1 and Entity 2; both are parts of different clauses that are connected through the main clause of the sentence.",
        "sdp_path_text": "strategy → augmentation → with → develop → alleviate → issue → of → data",
        "sentence": "A staged pre-training strategy alleviates the issue of insufficient fine-grained training data.",
        "sentence_llm_dp_info": "Entity 1 ('staged pre-training strategy') is the subject, depending on the verb 'alleviates'. Entity 2 ('insufficient fine-grained training data') is the object of the preposition 'of', depending on 'issue'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'alleviates' and the prepositional phrase 'the issue of'."
    },
    {
        "raw_sentence": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks .",
        "ner_pair": [
            [
                "data sufficiency",
                "OtherScientificTerm"
            ],
            [
                "over-fitting avoidance",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data sufficiency') is part of the object of the preposition 'into', depending on 'insights'. Entity 2 ('over-fitting avoidance') is also part of the object of the preposition 'into', depending on 'insights'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list that describes the challenges addressed by the insights.",
        "sdp_path_text": "sufficiency → avoidance",
        "sentence": "Experiments contribute insights into the challenges of data sufficiency and over-fitting avoidance.",
        "sentence_llm_dp_info": "Entity 1 ('data sufficiency') is the object of the preposition 'into', depending on 'insights'. Entity 2 ('over-fitting avoidance') is also the object of the preposition 'into', depending on 'insights'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'into' in the phrase 'into the challenges of data sufficiency and over-fitting avoidance'."
    },
    {
        "raw_sentence": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks .",
        "ner_pair": [
            [
                "data sufficiency",
                "OtherScientificTerm"
            ],
            [
                "deep networks",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data sufficiency') is part of the object of the preposition 'into', depending on 'insights'. Entity 2 ('deep networks') is the object of the preposition 'for', depending on 'tasks'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context of the sentence describing the challenges addressed in the experiments.",
        "sdp_path_text": "sufficiency → of → challenges → training → networks",
        "sentence": "Experiments contribute insights into the challenges of data sufficiency when training deep networks.",
        "sentence_llm_dp_info": "Entity 1 ('data sufficiency') is the object of the preposition 'into', depending on 'insights'. Entity 2 ('deep networks') is the object of the preposition 'of', depending on 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify 'insights' and 'challenges', respectively."
    },
    {
        "raw_sentence": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks .",
        "ner_pair": [
            [
                "data sufficiency",
                "OtherScientificTerm"
            ],
            [
                "fine-grained cross-domain ranking tasks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('data sufficiency') is part of the prepositional phrase 'into the challenges of data sufficiency and over-fitting avoidance', where it depends on 'challenges' as an object of the preposition 'of'. Entity 2 ('fine-grained cross-domain ranking tasks') is the object of the preposition 'for', which itself depends on 'training'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that describe different aspects of the challenges and the context of the training.",
        "sdp_path_text": "sufficiency → of → challenges → training → for → tasks",
        "sentence": "Experiments contribute insights into the challenges of data sufficiency for fine-grained cross-domain ranking tasks.",
        "sentence_llm_dp_info": "Entity 1 ('data sufficiency') is the object of the preposition 'for', depending on 'challenges'. Entity 2 ('fine-grained cross-domain ranking tasks') is the object of the preposition 'for', also depending on 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase modifying 'challenges'."
    },
    {
        "raw_sentence": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks .",
        "ner_pair": [
            [
                "over-fitting avoidance",
                "OtherScientificTerm"
            ],
            [
                "deep networks",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('over-fitting avoidance') is part of the object of the preposition 'into', depending on 'insights'. Entity 2 ('deep networks') is the object of the preposition 'for', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2; both are related to different aspects of the challenges discussed in the sentence.",
        "sdp_path_text": "avoidance → sufficiency → of → challenges → training → networks",
        "sentence": "Experiments contribute insights into the challenges of over-fitting avoidance when training deep networks.",
        "sentence_llm_dp_info": "Entity 1 ('over-fitting avoidance') is the object of the preposition 'of', depending on 'challenges'. Entity 2 ('deep networks') is the object of the preposition 'when training', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the context in which experiments contribute insights."
    },
    {
        "raw_sentence": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks .",
        "ner_pair": [
            [
                "over-fitting avoidance",
                "OtherScientificTerm"
            ],
            [
                "fine-grained cross-domain ranking tasks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('over-fitting avoidance') is part of the object of the preposition 'into', depending on 'into' in the phrase 'into the challenges of data sufficiency and over-fitting avoidance'. Entity 2 ('fine-grained cross-domain ranking tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for fine-grained cross-domain ranking tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, specifically within the challenges and the purpose of the experiments.",
        "sdp_path_text": "avoidance → sufficiency → of → challenges → training → for → tasks",
        "sentence": "Experiments contribute insights into challenges of over-fitting avoidance when training for fine-grained cross-domain ranking tasks.",
        "sentence_llm_dp_info": "Entity 1 ('over-fitting avoidance') is the object of the preposition 'of', depending on 'challenges'. Entity 2 ('fine-grained cross-domain ranking tasks') is the object of the preposition 'for', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the context of the experiments."
    },
    {
        "raw_sentence": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks .",
        "ner_pair": [
            [
                "deep networks",
                "Method"
            ],
            [
                "fine-grained cross-domain ranking tasks",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('deep networks') is the object of the preposition 'for', depending on 'for' in the phrase 'for fine-grained cross-domain ranking tasks'. Entity 2 ('fine-grained cross-domain ranking tasks') is the complement of the preposition 'for', also depending on 'for'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrase that specifies the context in which the deep networks are being trained.",
        "sdp_path_text": "networks → training → for → tasks",
        "sentence": "Deep networks are trained for fine-grained cross-domain ranking tasks.",
        "sentence_llm_dp_info": "Entity 1 ('deep networks') is the subject, depending on the verb 'trained'. Entity 2 ('fine-grained cross-domain ranking tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for fine-grained cross-domain ranking tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "In this paper we target at generating generic action proposals in unconstrained videos .",
        "ner_pair": [
            [
                "unconstrained videos",
                "Material"
            ],
            [
                "generic action proposals",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('unconstrained videos') is the object of the preposition 'in', depending on 'generating'. Entity 2 ('generic action proposals') is the direct object, depending on 'target at generating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'target at generating' is the main action.",
        "sdp_path_text": "videos → in → generating → proposals",
        "sentence": "Generic action proposals are generated in unconstrained videos.",
        "sentence_llm_dp_info": "Entity 1 ('unconstrained videos') is the object, depending on the preposition 'in', which modifies the verb 'generated'. Entity 2 ('generic action proposals') is the subject, depending on the verb 'are generated'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'in unconstrained videos' that specifies the context in which the proposals are generated."
    },
    {
        "raw_sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a spatio-temporal video tube , which has a good potential to locate one human action .",
        "ner_pair": [
            [
                "action proposal",
                "OtherScientificTerm"
            ],
            [
                "temporal series of spatial bounding boxes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal') is the subject, depending on the verb 'corresponds'. Entity 2 ('temporal series of spatial bounding boxes') is the object of the preposition 'to', depending on 'corresponds' in the phrase 'corresponds to a temporal series of spatial bounding boxes'. There is a direct dependency between Entity 1 and Entity 2, as 'action proposal' corresponds directly to 'temporal series of spatial bounding boxes'.",
        "sdp_path_text": "proposal → corresponds → to → series",
        "sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal') is the subject, depending on the verb 'corresponds'. Entity 2 ('temporal series of spatial bounding boxes') is the object, depending on 'corresponds' with 'action proposal'. There is a direct dependency between Entity 1 and Entity 2, as 'action proposal' corresponds directly to 'temporal series of spatial bounding boxes'."
    },
    {
        "raw_sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a spatio-temporal video tube , which has a good potential to locate one human action .",
        "ner_pair": [
            [
                "action proposal",
                "OtherScientificTerm"
            ],
            [
                "spatio-temporal video tube",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal') is the subject, depending on the verb 'corresponds'. Entity 2 ('spatio-temporal video tube') is the appositive, depending on the conjunction 'i.e.' which clarifies the preceding noun phrase 'temporal series of spatial bounding boxes'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the explanatory clause introduced by 'i.e.,' which provides an alternative description of what the 'action proposal' corresponds to.",
        "sdp_path_text": "proposal → corresponds → to → series → tube",
        "sentence": "Each action proposal corresponds to a spatio-temporal video tube.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal') is the subject, depending on the verb 'corresponds'. Entity 2 ('spatio-temporal video tube') is the object, depending on the verb 'corresponds'. There is a direct dependency between Entity 1 and Entity 2, as they are directly connected through the verb 'corresponds'."
    },
    {
        "raw_sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a spatio-temporal video tube , which has a good potential to locate one human action .",
        "ner_pair": [
            [
                "action proposal",
                "OtherScientificTerm"
            ],
            [
                "human action",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal') is the subject, depending on the verb 'corresponds'. Entity 2 ('human action') is the object, depending on 'locate' with 'potential'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the potential of the spatio-temporal video tube to locate a human action.",
        "sdp_path_text": "proposal → corresponds → to → series → has → potential → locate → action",
        "sentence": "An action proposal corresponds to a series that has the potential to locate a human action.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal') is the subject, depending on the verb 'corresponds'. Entity 2 ('human action') is the object, depending on 'locate' with 'potential'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'corresponds' and the clause 'that has the potential to locate a human action'."
    },
    {
        "raw_sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a spatio-temporal video tube , which has a good potential to locate one human action .",
        "ner_pair": [
            [
                "spatio-temporal video tube",
                "OtherScientificTerm"
            ],
            [
                "temporal series of spatial bounding boxes",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatio-temporal video tube') is the appositive, depending on the noun 'series' in the phrase 'temporal series of spatial bounding boxes'. Entity 2 ('temporal series of spatial bounding boxes') is the object of the preposition 'to', depending on 'corresponds' in the clause 'Each action proposal corresponds to a temporal series of spatial bounding boxes'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 serves as an appositive that renames or describes Entity 2.",
        "sdp_path_text": "tube → series",
        "sentence": "A spatio-temporal video tube corresponds to a temporal series of spatial bounding boxes.",
        "sentence_llm_dp_info": "Entity 1 ('spatio-temporal video tube') is the subject, depending on the verb 'corresponds'. Entity 2 ('temporal series of spatial bounding boxes') is the object, depending on 'corresponds' with 'spatio-temporal video tube'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the direct object that Entity 1 corresponds to."
    },
    {
        "raw_sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a spatio-temporal video tube , which has a good potential to locate one human action .",
        "ner_pair": [
            [
                "temporal series of spatial bounding boxes",
                "OtherScientificTerm"
            ],
            [
                "human action",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('temporal series of spatial bounding boxes') is the object of the preposition 'to', depending on 'corresponds' with 'action proposal'. Entity 2 ('human action') is the object of the infinitive 'to locate', depending on 'potential'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where Entity 1 is part of what an 'action proposal' corresponds to, and Entity 2 is what has the potential to be located by this correspondence.",
        "sdp_path_text": "series → has → potential → locate → action",
        "sentence": "A temporal series of spatial bounding boxes has potential to locate a human action.",
        "sentence_llm_dp_info": "Entity 1 ('temporal series of spatial bounding boxes') is the subject, depending on the verb 'has'. Entity 2 ('human action') is the object, depending on 'locate' with 'potential'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the potential capability described in the sentence."
    },
    {
        "raw_sentence": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a spatio-temporal video tube , which has a good potential to locate one human action .",
        "ner_pair": [
            [
                "spatio-temporal video tube",
                "OtherScientificTerm"
            ],
            [
                "human action",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('spatio-temporal video tube') is the appositive, depending on 'series' with 'i.e., a spatio-temporal video tube'. Entity 2 ('human action') is the object of the infinitive 'to locate', depending on 'locate' in the phrase 'to locate one human action'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where the 'spatio-temporal video tube' is described as having the potential to locate a 'human action'.",
        "sdp_path_text": "tube → series → has → potential → locate → action",
        "sentence": "A spatio-temporal video tube has the potential to locate a human action.",
        "sentence_llm_dp_info": "Entity 1 ('spatio-temporal video tube') is the subject, depending on the verb 'has'. Entity 2 ('human action') is the object, depending on 'locate' with 'potential'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'locate' which is part of the potential that the 'spatio-temporal video tube' has."
    },
    {
        "raw_sentence": "Assuming each action is performed by a human with meaningful motion , both appearance and motion cues are utilized to measure the ac-tionness of the video tubes .",
        "ner_pair": [
            [
                "appearance and motion cues",
                "OtherScientificTerm"
            ],
            [
                "ac-tionness",
                "Metric"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('appearance and motion cues') is the subject, depending on the verb 'are utilized'. Entity 2 ('ac-tionness') is the object of the preposition 'of', depending on 'measure' in the phrase 'to measure the ac-tionness of the video tubes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'measure'.",
        "sdp_path_text": "cues → utilized → measure → ac",
        "sentence": "Appearance and motion cues are utilized to measure the ac-tionness.",
        "sentence_llm_dp_info": "Entity 1 ('appearance and motion cues') is the subject, depending on the verb 'utilized'. Entity 2 ('ac-tionness') is the object of the preposition 'the', depending on 'measure' in the phrase 'to measure the ac-tionness'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'utilized' and the purpose clause 'to measure the ac-tionness'."
    },
    {
        "raw_sentence": "Assuming each action is performed by a human with meaningful motion , both appearance and motion cues are utilized to measure the ac-tionness of the video tubes .",
        "ner_pair": [
            [
                "appearance and motion cues",
                "OtherScientificTerm"
            ],
            [
                "video tubes",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('appearance and motion cues') is the subject, depending on the verb 'are utilized'. Entity 2 ('video tubes') is the object of the preposition 'of', depending on 'measure' in the phrase 'to measure the ac-tionness of the video tubes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are utilized' and the purpose clause 'to measure the ac-tionness of the video tubes'.",
        "sdp_path_text": "cues → utilized → measure → tionness → of → tubes",
        "sentence": "Appearance and motion cues are utilized to measure the actionness of video tubes.",
        "sentence_llm_dp_info": "Entity 1 ('appearance and motion cues') is the subject, depending on the verb 'utilized'. Entity 2 ('video tubes') is the object of the preposition 'of', depending on 'actionness'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilized' and the prepositional phrase 'to measure the actionness of video tubes'."
    },
    {
        "raw_sentence": "Assuming each action is performed by a human with meaningful motion , both appearance and motion cues are utilized to measure the ac-tionness of the video tubes .",
        "ner_pair": [
            [
                "ac-tionness",
                "Metric"
            ],
            [
                "video tubes",
                "Material"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('ac-tionness') is the object of the verb 'measure', depending on 'measure' in the clause 'to measure the ac-tionness'. Entity 2 ('video tubes') is the object of the preposition 'of', depending on 'of' in the phrase 'of the video tubes'. There is a direct dependency between Entity 1 and Entity 2, as 'video tubes' specifies what the 'ac-tionness' is being measured of.",
        "sdp_path_text": "ac → measure → tionness → of → tubes",
        "sentence": "The ac-tionness of the video tubes is measured.",
        "sentence_llm_dp_info": "Entity 1 ('ac-tionness') is the subject, depending on the verb 'measured'. Entity 2 ('video tubes') is the object of the preposition 'of', depending on 'of' in the phrase 'of the video tubes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "actionness scores",
                "Metric"
            ],
            [
                "action proposal generation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object of the preposition 'of', depending on 'paths'. Entity 2 ('action proposal generation') is the subject, depending on the verb 'formulated'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same context, where 'actionness scores' influence the selection process described in 'action proposal generation'.",
        "sdp_path_text": "scores → of → paths → picking → After → formulated → generation",
        "sentence": "Action proposal generation is formulated after picking paths with high actionness scores.",
        "sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object of the preposition 'with', depending on 'picking'. Entity 2 ('action proposal generation') is the subject, depending on the verb 'is formulated'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence of actions described in the sentence."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "actionness scores",
                "Metric"
            ],
            [
                "maximum set coverage problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object of the preposition 'of', depending on 'paths'. Entity 2 ('maximum set coverage problem') is the complement of the verb 'formulated', depending on 'is' in the phrase 'is formulated as'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the action proposal generation process.",
        "sdp_path_text": "scores → of → paths → picking → After → formulated → as → problem",
        "sentence": "Actionness scores are used in formulating the action proposal generation as a maximum set coverage problem.",
        "sentence_llm_dp_info": "Entity 1 ('actionness scores') is the subject, depending on the verb 'are used'. Entity 2 ('maximum set coverage problem') is the object of the preposition 'as', depending on 'formulating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described by the verb 'formulating' and the preposition 'as'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "actionness scores",
                "Metric"
            ],
            [
                "greedy search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object of the preposition 'of', depending on 'paths'. Entity 2 ('greedy search') is the subject, depending on 'is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context within the sentence, where 'actionness scores' influence the selection process described by 'greedy search'.",
        "sdp_path_text": "scores → of → paths → picking → After → formulated → as → problem → performed → search",
        "sentence": "Greedy search is performed to select action proposals with high actionness scores.",
        "sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object of the preposition 'with', depending on 'select'. Entity 2 ('greedy search') is the subject, depending on the verb 'is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'select' which is part of the clause describing the purpose of the greedy search."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "actionness scores",
                "Metric"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object of the preposition 'of', depending on 'paths'. Entity 2 ('action proposals') is the object of the relative clause, depending on 'select' within the clause 'to select a set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'actionness' in the context of the sentence.",
        "sdp_path_text": "scores → of → paths → picking → After → formulated → as → problem → performed → select → set → of → proposals",
        "sentence": "Action proposals are selected to maximize actionness scores.",
        "sentence_llm_dp_info": "Entity 1 ('actionness scores') is the object, depending on the verb 'maximize'. Entity 2 ('action proposals') is the subject, depending on the verb 'selected'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to maximize'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "maximum set coverage problem",
                "Task"
            ],
            [
                "action proposal generation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the complement of the verb 'formulated', depending on 'is formulated'. Entity 2 ('action proposal generation') is the subject, depending on 'is formulated' with 'our'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the problem that Entity 2 is formulated as.",
        "sdp_path_text": "problem → as → formulated → generation",
        "sentence": "Action proposal generation is formulated as a maximum set coverage problem.",
        "sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the complement of the verb 'formulated', depending on the verb 'formulated'. Entity 2 ('action proposal generation') is the subject, depending on the verb 'formulated'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is being formulated as Entity 1."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "action proposal generation",
                "Task"
            ],
            [
                "greedy search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal generation') is the subject, depending on 'formulated' as part of the clause 'is formulated as a maximum set coverage problem'. Entity 2 ('greedy search') is the subject, depending on 'performed' in the clause 'where greedy search is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same process described in the sentence.",
        "sdp_path_text": "generation → formulated → as → problem → performed → search",
        "sentence": "Action proposal generation is formulated as a problem where greedy search is performed.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal generation') is the subject, depending on the verb 'is formulated'. Entity 2 ('greedy search') is the subject complement, depending on the verb 'is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the structure of the sentence."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "action proposal generation",
                "Task"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal generation') is the subject, depending on the verb 'formulated'. Entity 2 ('action proposals') is the object, depending on 'select' within the clause 'to select a set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where the selection of 'action proposals' is part of the process of 'action proposal generation'.",
        "sdp_path_text": "generation → formulated → as → problem → performed → select → set → of → proposals",
        "sentence": "Action proposal generation is formulated as a problem to select a set of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal generation') is the subject, depending on the verb 'formulated'. Entity 2 ('action proposals') is the object, depending on 'select' in the phrase 'to select a set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the formulation of the problem described in the sentence."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "action proposal generation",
                "Task"
            ],
            [
                "actionness score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal generation') is the subject, depending on the verb 'formulated'. Entity 2 ('actionness score') is the object of the noun 'maximize', depending on 'maximize' in the phrase 'can maximize the overall actionness score'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where 'action proposal generation' is part of a process that aims to maximize 'actionness score'.",
        "sdp_path_text": "generation → formulated → After → picking → paths → of → scores",
        "sentence": "Action proposal generation is formulated after picking paths of high actionness scores.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal generation') is the subject, depending on the verb 'is formulated'. Entity 2 ('actionness score') is part of the noun phrase 'paths of high actionness scores', where it modifies 'paths' through the prepositional phrase 'of high actionness scores'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the process described in the sentence, where 'action proposal generation' is formulated based on 'paths' that have 'high actionness scores'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "maximum set coverage problem",
                "Task"
            ],
            [
                "greedy search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the object of the verb 'formulated', depending on the verb 'is formulated'. Entity 2 ('greedy search') is the subject of the clause 'is performed', depending on the verb 'is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the same process, where 'greedy search' is used to solve the 'maximum set coverage problem'.",
        "sdp_path_text": "problem → performed → search",
        "sentence": "Greedy search is performed to solve the maximum set coverage problem.",
        "sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the object, depending on the verb 'solve'. Entity 2 ('greedy search') is the subject, depending on the verb 'is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to solve'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "maximum set coverage problem",
                "Task"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the object of the verb 'formulated', depending on 'is' in the clause 'our action proposal generation is formulated as a maximum set coverage problem'. Entity 2 ('action proposals') is the object of the verb 'select', depending on 'to select' in the clause 'greedy search is performed to select a set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same context where 'action proposal generation' is being described.",
        "sdp_path_text": "problem → performed → select → set → of → proposals",
        "sentence": "A maximum set coverage problem is performed to select a set of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the subject, depending on the verb 'performed'. Entity 2 ('action proposals') is the object of the preposition 'of', depending on 'set' in the phrase 'a set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "maximum set coverage problem",
                "Task"
            ],
            [
                "actionness score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the object, depending on the verb 'formulated'. Entity 2 ('actionness score') is the object of the noun 'maximize', depending on 'maximize' in the phrase 'maximize the overall actionness score'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where the 'maximum set coverage problem' is used to 'maximize the overall actionness score'.",
        "sdp_path_text": "problem → as → formulated → After → picking → paths → of → scores",
        "sentence": "The maximum set coverage problem is formulated to select action proposals that maximize the actionness score.",
        "sentence_llm_dp_info": "Entity 1 ('maximum set coverage problem') is the subject, depending on the verb 'formulated'. Entity 2 ('actionness score') is the object of the clause, depending on 'maximize' which is part of the infinitive phrase 'to maximize the actionness score'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to maximize'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "greedy search",
                "Method"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('greedy search') is the subject, depending on the verb 'is performed'. Entity 2 ('action proposals') is the object, depending on the verb 'select' in the clause 'to select a set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same process described in the sentence.",
        "sdp_path_text": "search → performed → select → set → of → proposals",
        "sentence": "Greedy search is performed to select a set of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('greedy search') is the subject, depending on the verb 'is performed'. Entity 2 ('action proposals') is the object, depending on 'select' with the prepositional phrase 'to select a set of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of selection described by the verb 'select'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "greedy search",
                "Method"
            ],
            [
                "actionness score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('greedy search') is the subject, depending on 'is performed' as the main verb of the clause. Entity 2 ('actionness score') is the object, depending on 'maximize' as the verb in the relative clause modifying 'set of action proposals'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same complex sentence structure, with 'greedy search' being used to achieve the goal of maximizing the 'actionness score'.",
        "sdp_path_text": "search → performed → problem → as → formulated → After → picking → paths → of → scores",
        "sentence": "Greedy search is performed to maximize the actionness score.",
        "sentence_llm_dp_info": "Entity 1 ('greedy search') is the subject, depending on the verb 'is performed'. Entity 2 ('actionness score') is the object of the preposition 'the', depending on 'maximize' in the phrase 'to maximize the actionness score'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to maximize'."
    },
    {
        "raw_sentence": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where greedy search is performed to select a set of action proposals that can maximize the overall actionness score .",
        "ner_pair": [
            [
                "actionness score",
                "Metric"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('actionness score') is the object of the preposition 'of', depending on 'paths'. It also appears as the object of the verb 'maximize', depending on 'can maximize'. Entity 2 ('action proposals') is the object of the verb 'select', depending on 'is performed'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the context of maximizing the overall actionness score.",
        "sdp_path_text": "scores → of → paths → picking → After → formulated → as → problem → performed → select → set → of → proposals",
        "sentence": "Action proposals are selected to maximize the actionness score.",
        "sentence_llm_dp_info": "Entity 1 ('actionness score') is the object, depending on the verb 'maximize'. Entity 2 ('action proposals') is the subject, depending on the verb 'selected'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the purpose of the selection process described by the verb 'to maximize'."
    },
    {
        "raw_sentence": "Compared with existing action proposal approaches , our action proposals do not rely on video segmentation and can be generated in nearly real-time .",
        "ner_pair": [
            [
                "action proposal approaches",
                "Method"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal approaches') is the object of the preposition 'with', depending on 'Compared'. Entity 2 ('action proposals') is the subject, depending on the negation 'do not rely'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually contrasted within the sentence.",
        "sdp_path_text": "approaches → with → Compared → rely → proposals",
        "sentence": "Compared with existing approaches, our action proposals do not rely on video segmentation.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal approaches') is the object of the preposition 'with', depending on 'Compared'. Entity 2 ('action proposals') is the subject, depending on the negated verb 'do not rely'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the comparison and the main clause of the sentence."
    },
    {
        "raw_sentence": "Compared with existing action proposal approaches , our action proposals do not rely on video segmentation and can be generated in nearly real-time .",
        "ner_pair": [
            [
                "action proposal approaches",
                "Method"
            ],
            [
                "video segmentation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposal approaches') is the object of the preposition 'with', depending on 'Compared'. Entity 2 ('video segmentation') is the object of the preposition 'on', depending on 'rely'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the characteristics of 'our action proposals'.",
        "sdp_path_text": "approaches → with → Compared → rely → on → segmentation",
        "sentence": "Our action proposal approaches do not rely on video segmentation.",
        "sentence_llm_dp_info": "Entity 1 ('action proposal approaches') is the subject, depending on the negated verb 'do not rely'. Entity 2 ('video segmentation') is the object of the preposition 'on', depending on 'rely' in the phrase 'rely on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the negated verb 'do not rely on'."
    },
    {
        "raw_sentence": "Compared with existing action proposal approaches , our action proposals do not rely on video segmentation and can be generated in nearly real-time .",
        "ner_pair": [
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            [
                "video segmentation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action proposals') is the subject, depending on the negation 'do not rely' with 'rely'. Entity 2 ('video segmentation') is the object, depending on 'rely' with 'action proposals'. There is a direct dependency between Entity 1 and Entity 2, as 'video segmentation' is what 'action proposals' do not rely on.",
        "sdp_path_text": "proposals → rely → on → segmentation",
        "sentence": "Action proposals do not rely on video segmentation.",
        "sentence_llm_dp_info": "Entity 1 ('action proposals') is the subject, depending on the negated verb 'do not rely'. Entity 2 ('video segmentation') is the object of the preposition 'on', depending on 'on' in the phrase 'on video segmentation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "MSRII",
                "Material"
            ],
            [
                "datasets",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MSRII') is part of a compound noun, depending on 'datasets' with the conjunction 'and'. Entity 2 ('datasets') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the compound noun where 'MSRII' is an element of the 'datasets' mentioned.",
        "sdp_path_text": "MSRII → datasets",
        "sentence": "MSRII is one of the datasets used.",
        "sentence_llm_dp_info": "Entity 1 ('MSRII') is the subject, depending on 'is' as part of the copular construction. Entity 2 ('datasets') is the complement, depending on 'one of' which modifies it. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the copular verb 'is' and the prepositional phrase 'one of the datasets'."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "UCF 101",
                "Material"
            ],
            [
                "datasets",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('UCF 101') is part of a coordinated list, depending on the conjunction 'and' with 'MSRII'. Entity 2 ('datasets') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'on two challenging datasets'.",
        "sdp_path_text": "UCF → MSRII → datasets",
        "sentence": "UCF 101 is one of the datasets used in the experiments.",
        "sentence_llm_dp_info": "Entity 1 ('UCF 101') is the subject, depending on the verb 'is'. Entity 2 ('datasets') is part of the noun phrase functioning as the predicate complement, depending on the preposition 'of' in the phrase 'one of the datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the datasets'."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "datasets",
                "Generic"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('datasets') is the object of the preposition 'on', depending on 'results'. Entity 2 ('action proposals') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that describe different aspects of the experimental findings.",
        "sdp_path_text": "datasets → on → results → validate → performance → of → proposals",
        "sentence": "Results on datasets validate the performance of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('datasets') is the object of the preposition 'on', depending on 'validate'. Entity 2 ('action proposals') is the object, depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what is being validated by the results."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "datasets",
                "Generic"
            ],
            [
                "action detection and search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('datasets') is the object of the preposition 'on', depending on 'results'. Entity 2 ('action detection and search') is part of the compound object, depending on 'results' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the 'results' described in the sentence.",
        "sdp_path_text": "datasets → on → results → validate → performance → results → on → detection",
        "sentence": "Results on datasets validate performance on action detection and search.",
        "sentence_llm_dp_info": "Entity 1 ('datasets') is the object of the preposition 'on', depending on 'validate' in the phrase 'on datasets'. Entity 2 ('action detection and search') is the object of the preposition 'on', depending on 'performance' in the phrase 'on action detection and search'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different prepositional phrases that modify 'validate' and 'performance' respectively."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "MSRII",
                "Material"
            ],
            [
                "UCF 101",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MSRII') is part of a compound noun, depending on 'datasets' with the conjunction 'and'. Entity 2 ('UCF 101') is also part of the same compound noun, depending on 'datasets' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of datasets.",
        "sdp_path_text": "MSRII → UCF",
        "sentence": "MSRII and UCF 101 validate the performance of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('MSRII') is the subject, depending on the verb 'validate'. Entity 2 ('UCF 101') is the conjunct, coordinated with 'MSRII' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a coordinated subject validating the performance of action proposals."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "MSRII",
                "Material"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MSRII') is the object of the preposition 'on', depending on 'datasets'. Entity 2 ('action proposals') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the validation of the experimental results.",
        "sdp_path_text": "MSRII → datasets → on → results → validate → performance → of → proposals",
        "sentence": "Results on MSRII validate the performance of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('MSRII') is the object of the preposition 'on', depending on 'Results'. Entity 2 ('action proposals') is the object, depending on 'validate' with 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the validation of the performance."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "MSRII",
                "Material"
            ],
            [
                "action detection and search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('MSRII') is part of a list of objects, depending on the preposition 'on' in the phrase 'on two challenging datasets, MSRII and UCF 101'. Entity 2 ('action detection and search') is the object of the preposition 'on', depending on 'results' in the phrase 'competitive results on action detection and search'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "MSRII → datasets → on → results → validate → performance → results → on → detection",
        "sentence": "Results on MSRII validate performance on action detection and search.",
        "sentence_llm_dp_info": "Entity 1 ('MSRII') is the object of the preposition 'on', depending on 'validate' in the phrase 'Results on MSRII'. Entity 2 ('action detection and search') is the object of the preposition 'on', depending on 'performance' in the phrase 'performance on action detection and search'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the structure validating the performance."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "UCF 101",
                "Material"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('UCF 101') is part of the list of objects, depending on the preposition 'on' with 'datasets'. Entity 2 ('action proposals') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence, where 'UCF 101' is one of the datasets used to validate the performance of 'action proposals'.",
        "sdp_path_text": "UCF → MSRII → datasets → on → results → validate → performance → of → proposals",
        "sentence": "Results on UCF 101 validate the performance of action proposals.",
        "sentence_llm_dp_info": "Entity 1 ('UCF 101') is the object of the preposition 'on', depending on 'Results'. Entity 2 ('action proposals') is the object, depending on 'performance' in the phrase 'performance of action proposals'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "UCF 101",
                "Material"
            ],
            [
                "action detection and search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('UCF 101') is part of a compound noun, depending on 'datasets' with the conjunction 'and'. Entity 2 ('action detection and search') is the object of the preposition 'on', depending on 'results' in the phrase 'on action detection and search'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "UCF → MSRII → datasets → on → results → validate → performance → results → on → detection",
        "sentence": "Results on UCF 101 validate performance on action detection and search.",
        "sentence_llm_dp_info": "Entity 1 ('UCF 101') is the object of the preposition 'on', depending on 'validate' in the phrase 'Results on UCF 101 validate'. Entity 2 ('action detection and search') is the object of the preposition 'on', depending on 'performance' in the phrase 'performance on action detection and search'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of prepositions that depend on the verb 'validate'."
    },
    {
        "raw_sentence": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our action proposals as well as competitive results on action detection and search .",
        "ner_pair": [
            [
                "action detection and search",
                "Task"
            ],
            [
                "action proposals",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('action detection and search') is the object of the preposition 'on', depending on 'results'. Entity 2 ('action proposals') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context provided by the sentence, where they are related through the validation of their respective performances.",
        "sdp_path_text": "detection → on → results → performance → of → proposals",
        "sentence": "Action proposals show competitive results on action detection and search.",
        "sentence_llm_dp_info": "Entity 1 ('action detection and search') is the object, depending on the preposition 'on', which is part of the prepositional phrase 'on action detection and search'. Entity 2 ('action proposals') is the subject, depending on the verb 'show'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on action detection and search' which modifies 'results'."
    },
    {
        "raw_sentence": "This paper reports recent research into methods for creating natural language text .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "creating natural language text",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methods') is the object of the preposition 'into', depending on 'research'. Entity 2 ('creating natural language text') is the complement of 'for', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose of the methods.",
        "sdp_path_text": "methods → for → creating",
        "sentence": "Methods for creating natural language text are reported.",
        "sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'reported'. Entity 2 ('creating natural language text') is the object of the preposition 'for', depending on 'for' in the phrase 'for creating natural language text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "A new processing paradigm called Fragment-and-Compose has been created and an experimental system implemented in it .",
        "ner_pair": [
            [
                "processing paradigm",
                "Generic"
            ],
            [
                "Fragment-and-Compose",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('processing paradigm') is the subject complement, depending on 'called' with 'has been created'. Entity 2 ('Fragment-and-Compose') is the object of the verb 'called', depending on 'called' in the phrase 'called Fragment-and-Compose'. There is a direct dependency between Entity 1 and Entity 2, as 'Fragment-and-Compose' names or specifies 'processing paradigm'.",
        "sdp_path_text": "paradigm → called → Fragment",
        "sentence": "A new processing paradigm called Fragment-and-Compose has been created.",
        "sentence_llm_dp_info": "Entity 1 ('processing paradigm') is the subject complement, depending on the verb 'called'. Entity 2 ('Fragment-and-Compose') is the object of the verb 'called', depending directly on 'called'. There is a direct dependency between Entity 1 and Entity 2, as 'Fragment-and-Compose' names or specifies 'processing paradigm'."
    },
    {
        "raw_sentence": "KDS -LRB- Knowledge Delivery System -RRB- , which embodies this paradigm , has distinct parts devoted to creation of the propositional units , to organization of the text , to prevention of excess redundancy , to creation of combinations of units , to evaluation of these combinations as potential sentences , to selection of the best among competing combinations , and to creation of the final text .",
        "ner_pair": [
            [
                "paradigm",
                "Generic"
            ],
            [
                "KDS -LRB- Knowledge Delivery System -RRB-",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('paradigm') is the object of the relative clause, depending on 'embodies' with 'which'. Entity 2 ('KDS -LRB- Knowledge Delivery System -RRB-') is the subject, depending on 'embodies' with 'which'. There is no direct dependency between Entity 1 and Entity 2; both are related through the relative pronoun 'which' that refers back to 'KDS -LRB- Knowledge Delivery System -RRB-'.",
        "sdp_path_text": "paradigm → embodies → System",
        "sentence": "KDS (Knowledge Delivery System) embodies the paradigm.",
        "sentence_llm_dp_info": "Entity 1 ('paradigm') is the object, depending on the verb 'embodies'. Entity 2 ('KDS -LRB- Knowledge Delivery System -RRB-') is the subject, depending on the verb 'embodies'. There is a direct dependency between Entity 1 and Entity 2, as 'KDS -LRB- Knowledge Delivery System -RRB-' embodies the 'paradigm'."
    },
    {
        "raw_sentence": "The Fragment-and-Compose paradigm and the computational methods of KDS are described .",
        "ner_pair": [
            [
                "Fragment-and-Compose paradigm",
                "Method"
            ],
            [
                "computational methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Fragment-and-Compose paradigm') is part of a coordination, depending on the conjunction 'and' with 'computational methods'. Entity 2 ('computational methods') is also part of the coordination, depending on the preposition 'of' with 'KDS'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as the subjects of the verb 'are described'.",
        "sdp_path_text": "paradigm → methods",
        "sentence": "The Fragment-and-Compose paradigm and computational methods are described.",
        "sentence_llm_dp_info": "Entity 1 ('Fragment-and-Compose paradigm') is the first conjunct, depending on the conjunction 'and' with Entity 2. Entity 2 ('computational methods') is the second conjunct, also depending on the conjunction 'and' with Entity 1. Both Entity 1 and Entity 2 are subjects, depending on the verb 'are described'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'."
    },
    {
        "raw_sentence": "The Fragment-and-Compose paradigm and the computational methods of KDS are described .",
        "ner_pair": [
            [
                "Fragment-and-Compose paradigm",
                "Method"
            ],
            [
                "KDS",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('Fragment-and-Compose paradigm') is part of a coordination, depending on 'and' with 'computational methods'. Entity 2 ('KDS') is the object of the preposition 'of', depending on 'of' in the phrase 'of KDS'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the subject of the sentence that is described.",
        "sdp_path_text": "paradigm → methods → of → KDS",
        "sentence": "The Fragment-and-Compose paradigm and KDS's computational methods are described.",
        "sentence_llm_dp_info": "Entity 1 ('Fragment-and-Compose paradigm') is part of a conjunction, depending on the verb 'are described'. Entity 2 ('KDS') is part of the possessive noun phrase 'KDS's computational methods', which also depends on the verb 'are described'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of the same verb 'are described'."
    },
    {
        "raw_sentence": "The Fragment-and-Compose paradigm and the computational methods of KDS are described .",
        "ner_pair": [
            [
                "computational methods",
                "Generic"
            ],
            [
                "KDS",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('computational methods') is part of a compound noun, depending on 'of' with 'KDS'. Entity 2 ('KDS') is the head of the prepositional phrase 'of KDS', depending on 'methods'. There is a direct dependency between Entity 1 and Entity 2, where 'KDS' modifies 'computational methods' through the preposition 'of'.",
        "sdp_path_text": "methods → of → KDS",
        "sentence": "The computational methods of KDS are described.",
        "sentence_llm_dp_info": "Entity 1 ('computational methods') is the subject, depending on the verb 'described'. Entity 2 ('KDS') is the possessor, depending on 'methods' with the preposition 'of' in the phrase 'of KDS'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the possessive relationship indicated by 'of'."
    },
    {
        "raw_sentence": "This paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful .",
        "ner_pair": [
            [
                "co-occurrence similarities",
                "OtherScientificTerm"
            ],
            [
                "query terms",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('co-occurrence similarities') is the object of the preposition 'using', depending on the verb 'explores' in the phrase 'using different co-occurrence similarities'. Entity 2 ('query terms') is the subject of the relative clause 'that are useful for retrieval', depending on the verb 'are' in the clause. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger structure describing the use of similarities to separate certain types of query terms.",
        "sdp_path_text": "similarities → between → terms → for → separating → terms",
        "sentence": "Co-occurrence similarities between terms are used for separating query terms.",
        "sentence_llm_dp_info": "Entity 1 ('co-occurrence similarities') is the subject, depending on the verb 'are used'. Entity 2 ('query terms') is the object of the preposition 'for', depending on 'separating' in the phrase 'for separating query terms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'are used' and the preposition 'for'."
    },
    {
        "raw_sentence": "This paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful .",
        "ner_pair": [
            [
                "co-occurrence similarities",
                "OtherScientificTerm"
            ],
            [
                "retrieval",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('co-occurrence similarities') is the object of the preposition 'using', depending on 'using' in the phrase 'using different co-occurrence similarities'. Entity 2 ('retrieval') is part of the noun phrase 'for retrieval', functioning as a complement to the verb 'separating', indicating the purpose of the action. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where 'co-occurrence similarities' are used in the process of separating query terms for the purpose of 'retrieval'.",
        "sdp_path_text": "similarities → between → terms → for → separating → terms → are → useful → for → retrieval",
        "sentence": "Co-occurrence similarities between terms are used for separating useful terms for retrieval.",
        "sentence_llm_dp_info": "Entity 1 ('co-occurrence similarities') is the subject, depending on the verb 'are used'. Entity 2 ('retrieval') is the object of the preposition 'for', depending on 'for' in the phrase 'for retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'."
    },
    {
        "raw_sentence": "This paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful .",
        "ner_pair": [
            [
                "co-occurrence similarities",
                "OtherScientificTerm"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('co-occurrence similarities') is the object of the preposition 'using', depending on 'issue'. Entity 2 ('those') is the object of the preposition 'from', depending on 'separating'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the action of separating query terms.",
        "sdp_path_text": "similarities → between → terms → for → separating → from → those",
        "sentence": "Co-occurrence similarities between terms are used for separating useful query terms from those that are harmful.",
        "sentence_llm_dp_info": "Entity 1 ('co-occurrence similarities') is the subject, depending on the verb 'are used'. Entity 2 ('those') is the object of the relative clause, depending on 'from' in the phrase 'from those'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where 'co-occurrence similarities' are used to separate 'useful query terms' from 'those' (harmful terms)."
    },
    {
        "raw_sentence": "This paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful .",
        "ner_pair": [
            [
                "query terms",
                "Generic"
            ],
            [
                "retrieval",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('query terms') is the object of the preposition 'for', depending on 'separating' in the phrase 'for separating query terms'. Entity 2 ('retrieval') is the object of the preposition 'for', depending on 'useful' in the phrase 'useful for retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the purpose of the separation process.",
        "sdp_path_text": "terms → are → useful → for → retrieval",
        "sentence": "Query terms are useful for retrieval.",
        "sentence_llm_dp_info": "Entity 1 ('query terms') is the subject, depending on the verb 'are' with the adjective 'useful'. Entity 2 ('retrieval') is the object of the preposition 'for', depending on 'for' in the phrase 'for retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for' which indicates the purpose or use of 'query terms'."
    },
    {
        "raw_sentence": "This paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful .",
        "ner_pair": [
            [
                "those",
                "Generic"
            ],
            [
                "query terms",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('those') is the subject, depending on the verb 'are' in the clause 'those that are harmful'. Entity 2 ('query terms') is part of the noun phrase, depending on 'separating' as the object of the action 'separating query terms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same larger clause describing the separation process.",
        "sdp_path_text": "those → from → separating → terms",
        "sentence": "This paper explores separating useful query terms from those that are harmful.",
        "sentence_llm_dp_info": "Entity 1 ('those') is the subject, depending on the verb 'separating'. Entity 2 ('query terms') is the object, depending on the verb 'separating'. There is a direct dependency between Entity 1 and Entity 2, as 'those' refers back to 'query terms' in the context of the sentence."
    },
    {
        "raw_sentence": "This paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful .",
        "ner_pair": [
            [
                "retrieval",
                "Task"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('retrieval') is part of a prepositional phrase, depending on 'useful' with the preposition 'for'. Entity 2 ('those') is the subject of the relative clause, depending on 'that' which introduces the clause. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'those' refers to 'query terms' and 'retrieval' describes a condition under which these terms are evaluated.",
        "sdp_path_text": "retrieval → for → useful → are → terms → separating → from → those",
        "sentence": "This paper explores separating query terms useful for retrieval from those that are harmful.",
        "sentence_llm_dp_info": "Entity 1 ('retrieval') is the object of the preposition 'for', depending on 'useful'. Entity 2 ('those') is the subject of the relative clause, depending on 'from' in the phrase 'from those'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'those' refers back to 'query terms' that are described in relation to 'retrieval'."
    },
    {
        "raw_sentence": "The hypothesis under examination is that useful terms tend to be more similar to each other than to other query terms .",
        "ner_pair": [
            [
                "useful terms",
                "Generic"
            ],
            [
                "query terms",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('useful terms') is the subject complement, depending on 'similar' with the verb 'be'. Entity 2 ('query terms') is the object of the preposition 'to', depending on 'to' in the phrase 'to other query terms'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure involving the word 'than'.",
        "sdp_path_text": "terms → tend → be → similar → than → to → terms",
        "sentence": "Useful terms tend to be more similar to each other than to query terms.",
        "sentence_llm_dp_info": "Entity 1 ('useful terms') is the subject, depending on 'tend' as the main verb. Entity 2 ('query terms') is the object of the preposition 'to', depending on 'to' in the phrase 'than to query terms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure 'more similar to each other than to'."
    },
    {
        "raw_sentence": "Preliminary experiments with similarities computed using first-order and second-order co-occurrence seem to confirm the hypothesis .",
        "ner_pair": [
            [
                "first-order and second-order co-occurrence",
                "OtherScientificTerm"
            ],
            [
                "similarities",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('first-order and second-order co-occurrence') is the object of the preposition 'using', depending on 'using' in the phrase 'using first-order and second-order co-occurrence'. Entity 2 ('similarities') is the subject, depending on the verb 'computed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'using'.",
        "sdp_path_text": "co → using → computed → similarities",
        "sentence": "Similarities computed using first-order and second-order co-occurrence confirm the hypothesis.",
        "sentence_llm_dp_info": "Entity 1 ('first-order and second-order co-occurrence') is the object of the preposition 'using', depending on 'computed'. Entity 2 ('similarities') is the subject, depending on the verb 'computed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'using'."
    },
    {
        "raw_sentence": "We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several , previously proposed phrase-based translation models .",
        "ner_pair": [
            [
                "phrase-based translation model",
                "Method"
            ],
            [
                "decoding algorithm",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phrase-based translation model') is part of the object of the verb 'propose', coordinated with 'decoding algorithm' through the conjunction 'and'. Entity 2 ('decoding algorithm') is also part of the object of the verb 'propose', coordinated with 'phrase-based translation model'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of the verb 'propose' and are connected through the conjunction 'and'.",
        "sdp_path_text": "model → algorithm",
        "sentence": "We propose a new phrase-based translation model and decoding algorithm.",
        "sentence_llm_dp_info": "Entity 1 ('phrase-based translation model') is the object of the preposition 'a', depending on 'propose' with 'We'. Entity 2 ('decoding algorithm') is also the object of the conjunction 'and', depending on 'model' in the phrase 'model and decoding algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'."
    },
    {
        "raw_sentence": "We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several , previously proposed phrase-based translation models .",
        "ner_pair": [
            [
                "decoding algorithm",
                "Method"
            ],
            [
                "phrase-based translation models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('decoding algorithm') is part of the conjunction, coordinated with 'phrase-based translation model', and both are objects of the verb 'propose'. Entity 2 ('phrase-based translation models') is the object of the verbs 'evaluate' and 'compare', which are governed by the clause introduced by 'that'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where the algorithm and the models are part of the same proposal and the purpose of the algorithm is to evaluate and compare the models.",
        "sdp_path_text": "algorithm → model → enables → evaluate → compare → models",
        "sentence": "The decoding algorithm enables evaluating and comparing phrase-based translation models.",
        "sentence_llm_dp_info": "Entity 1 ('decoding algorithm') is the subject, depending on the verb 'enables'. Entity 2 ('phrase-based translation models') is the object, depending on 'comparing' and 'evaluating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables' which allows actions (evaluating and comparing) to be performed on Entity 2."
    },
    {
        "raw_sentence": "Within our framework , we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "phrase-based models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('framework') is the object of the preposition 'Within', depending on the preposition 'Within' in the phrase 'Within our framework'. Entity 2 ('phrase-based models') is the subject complement, depending on 'outperform' with 'word-based models'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "framework → Within → carry → understand → explain → outperform → models",
        "sentence": "Within our framework, we carry out experiments to explain why phrase-based models outperform other models.",
        "sentence_llm_dp_info": "Entity 1 ('framework') is the object of the preposition 'Within', depending on the prepositional phrase 'Within our framework'. Entity 2 ('phrase-based models') is the subject complement, depending on 'outperform' in the clause 'models outperform other models'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Within our framework , we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "word-based models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('framework') is the object of the preposition 'Within', depending on the preposition 'Within'. Entity 2 ('word-based models') is the object of the comparative clause 'outperform', depending on 'outperform' in the phrase 'why phrase-based models outperform word-based models'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "framework → Within → carry → understand → explain → outperform → models",
        "sentence": "Within our framework, we carry out experiments to explain why phrase-based models outperform word-based models.",
        "sentence_llm_dp_info": "Entity 1 ('framework') is the object of the preposition 'Within', depending on the prepositional phrase 'Within our framework'. Entity 2 ('word-based models') is the object of the comparative clause, depending on 'outperform' with 'phrase-based models'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Within our framework , we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models .",
        "ner_pair": [
            [
                "phrase-based models",
                "Method"
            ],
            [
                "word-based models",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('phrase-based models') is the subject, depending on the comparative verb 'outperform'. Entity 2 ('word-based models') is the object, also depending on the comparative verb 'outperform'. There is no direct dependency between Entity 1 and Entity 2; however, they are both involved in the comparison expressed by the verb 'outperform'.",
        "sdp_path_text": "models → outperform → models",
        "sentence": "Phrase-based models outperform word-based models.",
        "sentence_llm_dp_info": "Entity 1 ('phrase-based models') is the subject, depending on the verb 'outperform'. Entity 2 ('word-based models') is the object, depending on the verb 'outperform'. There is a direct dependency between Entity 1 and Entity 2, as 'phrase-based models' is the subject that performs the action of 'outperforming' the 'word-based models'."
    },
    {
        "raw_sentence": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations .",
        "ner_pair": [
            [
                "heuristic learning of phrase translations",
                "Method"
            ],
            [
                "means",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('heuristic learning of phrase translations') is part of a list item, depending on the conjunction 'and' within the list of 'means'. Entity 2 ('means') is the object of the preposition 'through', depending on the verb 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the list structure where Entity 1 is one of the items listed as part of the 'means'.",
        "sdp_path_text": "learning → means",
        "sentence": "Heuristic learning of phrase translations is a means to obtain high performance.",
        "sentence_llm_dp_info": "Entity 1 ('heuristic learning of phrase translations') is the subject, depending on the verb 'is'. Entity 2 ('means') is the predicate noun, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'means' directly describes what 'heuristic learning of phrase translations' is."
    },
    {
        "raw_sentence": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations .",
        "ner_pair": [
            [
                "means",
                "Generic"
            ],
            [
                "word-based alignments",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('means') is the object of the preposition 'through', depending on 'obtained'. Entity 2 ('word-based alignments') is part of the compound noun phrase, depending on 'from' in the phrase 'from word-based alignments'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'means' is described as being what 'performance can be obtained through', and 'word-based alignments' is one of the sources used in this process.",
        "sdp_path_text": "means → learning → from → alignments",
        "sentence": "The highest levels of performance can be obtained through heuristic learning from word-based alignments.",
        "sentence_llm_dp_info": "It seems there's a slight discrepancy in the provided example. The word \"means\" is not present in the given sentence. However, I will proceed with the dependency parsing analysis for the entities \"heuristic learning\" and \"word-based alignments\" as they appear to be the intended focus based on the context.\n\nSentence: The highest levels of performance can be obtained through heuristic learning from word-based alignments.\nEntity 1: heuristic learning\nEntity 2: word-based alignments\n\nAnswer:\nEntity 1 ('heuristic learning') is the object of the preposition 'through', depending on 'obtained'. Entity 2 ('word-based alignments') is the object of the preposition 'from', depending on 'from' in the phrase 'from word-based alignments'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional structure that modifies how 'performance' can be 'obtained'."
    },
    {
        "raw_sentence": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations .",
        "ner_pair": [
            [
                "lexical weighting of phrase translations",
                "Method"
            ],
            [
                "means",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('lexical weighting of phrase translations') is part of the list of methods, depending on the conjunction 'and' with 'heuristic learning of phrase translations'. Entity 2 ('means') is the object of the preposition 'through', depending on the verb 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the methods used to obtain high performance levels.",
        "sdp_path_text": "weighting → learning → means",
        "sentence": "Lexical weighting of phrase translations is a means to obtain high performance.",
        "sentence_llm_dp_info": "Entity 1 ('lexical weighting of phrase translations') is the subject, depending on the verb 'is'. Entity 2 ('means') is the predicate nominative, also depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'means' directly describes what 'lexical weighting of phrase translations' is."
    },
    {
        "raw_sentence": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations .",
        "ner_pair": [
            [
                "word-based alignments",
                "Method"
            ],
            [
                "heuristic learning of phrase translations",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word-based alignments') is the object of the preposition 'from', depending on 'heuristic learning of phrase translations'. Entity 2 ('heuristic learning of phrase translations') is part of a compound noun, depending on 'obtained' with 'can be obtained'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 serves as the source from which Entity 2 operates.",
        "sdp_path_text": "alignments → from → learning",
        "sentence": "Heuristic learning of phrase translations is based on word-based alignments.",
        "sentence_llm_dp_info": "Entity 1 ('word-based alignments') is the object, depending on the preposition 'on', which itself depends on 'based'. Entity 2 ('heuristic learning of phrase translations') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on word-based alignments'."
    },
    {
        "raw_sentence": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations .",
        "ner_pair": [
            [
                "heuristic learning of phrase translations",
                "Method"
            ],
            [
                "lexical weighting of phrase translations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('heuristic learning of phrase translations') is part of a coordination, depending on 'obtained' with 'can be'. Entity 2 ('lexical weighting of phrase translations') is also part of the same coordination, depending on 'obtained' with 'can be'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the list of means through which high performance can be obtained.",
        "sdp_path_text": "learning → weighting",
        "sentence": "Heuristic learning of phrase translations and lexical weighting of phrase translations can obtain high performance levels.",
        "sentence_llm_dp_info": "Entity 1 ('heuristic learning of phrase translations') is the subject, depending on the verb 'can obtain'. Entity 2 ('lexical weighting of phrase translations') is also a subject, depending on the same verb 'can obtain'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of the same clause, indicating that both can lead to obtaining high performance levels."
    },
    {
        "raw_sentence": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations .",
        "ner_pair": [
            [
                "word-based alignments",
                "Method"
            ],
            [
                "lexical weighting of phrase translations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('word-based alignments') is the object of the preposition 'from', depending on 'learning'. Entity 2 ('lexical weighting of phrase translations') is the object of the preposition 'and', depending on 'means'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of methods described after 'simple means'.",
        "sdp_path_text": "alignments → from → learning → weighting",
        "sentence": "Heuristic learning of word-based alignments contributes to lexical weighting of phrase translations.",
        "sentence_llm_dp_info": "Entity 1 ('word-based alignments') is the object, depending on 'learning' with the verb 'contributes'. Entity 2 ('lexical weighting of phrase translations') is the object, depending on 'contributes' with the subject 'heuristic learning of word-based alignments'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contributes'."
    },
    {
        "raw_sentence": "Color is known to be highly discriminative for many object recognition tasks , but is difficult to infer from uncontrolled images in which the illuminant is not known .",
        "ner_pair": [
            [
                "object recognition tasks",
                "Task"
            ],
            [
                "uncontrolled images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object recognition tasks') is the object of the preposition 'for', depending on 'discriminative'. Entity 2 ('uncontrolled images') is the object of the preposition 'from', depending on 'infer'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "tasks → for → discriminative → be → known → is → difficult → infer → from → images",
        "sentence": "Color is known to be highly discriminative for object recognition tasks but is difficult to infer from uncontrolled images.",
        "sentence_llm_dp_info": "Entity 1 ('object recognition tasks') is the object of the preposition 'for', depending on 'discriminative'. Entity 2 ('uncontrolled images') is the object of the preposition 'from', depending on 'infer'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Color is known to be highly discriminative for many object recognition tasks , but is difficult to infer from uncontrolled images in which the illuminant is not known .",
        "ner_pair": [
            [
                "object recognition tasks",
                "Task"
            ],
            [
                "illuminant",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('object recognition tasks') is the object of the preposition 'for', depending on 'discriminative'. Entity 2 ('illuminant') is the subject complement, depending on 'known' in the clause 'the illuminant is not known'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of color's role in recognition and inference challenges.",
        "sdp_path_text": "tasks → for → discriminative → be → known → is → difficult → infer → from → images → known → illuminant",
        "sentence": "Color is discriminative for object recognition tasks but is difficult to infer when the illuminant is unknown.",
        "sentence_llm_dp_info": "Entity 1 ('object recognition tasks') is the object of the preposition 'for', depending on 'discriminative'. Entity 2 ('illuminant') is the subject complement, depending on 'unknown'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the discussion of color's role in recognition tasks and the challenges posed by unknown lighting conditions."
    },
    {
        "raw_sentence": "Color is known to be highly discriminative for many object recognition tasks , but is difficult to infer from uncontrolled images in which the illuminant is not known .",
        "ner_pair": [
            [
                "uncontrolled images",
                "Material"
            ],
            [
                "illuminant",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('uncontrolled images') is the object of the preposition 'from', depending on the verb 'infer'. Entity 2 ('illuminant') is the subject of the clause, depending on the verb 'is' (contracted form of 'is not known'). There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the difficulty in inferring color from uncontrolled images due to the unknown status of the illuminant.",
        "sdp_path_text": "images → known → illuminant",
        "sentence": "Uncontrolled images make it difficult to infer the illuminant.",
        "sentence_llm_dp_info": "Entity 1 ('uncontrolled images') is the subject, depending on the verb 'make'. Entity 2 ('illuminant') is the object of the infinitive 'to infer', depending on 'infer' in the phrase 'to infer the illuminant'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'make' and the infinitive phrase 'to infer'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "color constancy",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'can improve'. Entity 2 ('color constancy') is the object of the preposition 'for', depending on 'for' in the phrase 'for color constancy'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.",
        "sdp_path_text": "methods → for → constancy",
        "sentence": "Traditional methods for color constancy can improve surface reflectance estimates.",
        "sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on 'can improve' as the verb. Entity 2 ('color constancy') is the object of the preposition 'for', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "surface re-flectance estimates",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'can improve'. Entity 2 ('surface re-flectance estimates') is the object, depending on 'improve' with 'methods'. There is a direct dependency between Entity 1 and Entity 2, as 'methods' directly affects 'surface re-flectance estimates' through the verb 'improve'.",
        "sdp_path_text": "methods → improve → estimates",
        "sentence": "Traditional methods improve surface reflectance estimates.",
        "sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'improve'. Entity 2 ('surface reflectance estimates') is the object, depending on the verb 'improve'. There is a direct dependency between Entity 1 and Entity 2, where 'methods' directly affects 'surface reflectance estimates' through the verb 'improve'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "uncalibrated images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'can improve'. Entity 2 ('uncalibrated images') is the object of the preposition 'from', depending on 'from' in the phrase 'from such uncalibrated images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the prepositional phrase 'from such uncalibrated images'.",
        "sdp_path_text": "methods → improve → estimates → from → images",
        "sentence": "Traditional methods improve estimates from uncalibrated images.",
        "sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'improve'. Entity 2 ('uncalibrated images') is the object of the preposition 'from', depending on 'from' in the phrase 'from uncalibrated images'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve' and the preposition 'from'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "background scene",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'can improve'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'depends' in the clause 'their output depends significantly on the background scene'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'depends' and the preposition 'on'.",
        "sdp_path_text": "methods → improve → depends → on → scene",
        "sentence": "Traditional methods for improving surface reflectance estimates depend on the background scene.",
        "sentence_llm_dp_info": "Entity 1 ('methods') is the subject, depending on the verb 'depend'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'on' in the phrase 'on the background scene'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "color constancy",
                "Task"
            ],
            [
                "surface re-flectance estimates",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('color constancy') is part of a prepositional phrase, depending on 'methods' with 'for'. Entity 2 ('surface re-flectance estimates') is the object of the verb 'improve', depending on 'improve' in the phrase 'improve surface re-flectance estimates'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve'.",
        "sdp_path_text": "constancy → for → methods → improve → estimates",
        "sentence": "Traditional methods for color constancy can improve surface reflectance estimates.",
        "sentence_llm_dp_info": "Entity 1 ('color constancy') is the object of the preposition 'for', depending on 'methods'. Entity 2 ('surface reflectance estimates') is the object, depending on 'improve' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the methods can improve."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "color constancy",
                "Task"
            ],
            [
                "uncalibrated images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('color constancy') is part of a prepositional phrase, depending on 'methods' with 'for'. Entity 2 ('uncalibrated images') is the object of the preposition 'from', depending on 'from' in the phrase 'from such uncalibrated images'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the methods and their application to the images.",
        "sdp_path_text": "constancy → for → methods → improve → estimates → from → images",
        "sentence": "Traditional methods for color constancy improve estimates from uncalibrated images.",
        "sentence_llm_dp_info": "Entity 1 ('color constancy') is the object of the preposition 'for', depending on 'methods'. Entity 2 ('uncalibrated images') is the object of the preposition 'from', depending on 'estimates'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "color constancy",
                "Task"
            ],
            [
                "background scene",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('color constancy') is part of the noun phrase 'methods for color constancy', where it is the object of the preposition 'for', depending on 'methods'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'depends'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence, particularly the clause describing the dependency of the output on the background scene.",
        "sdp_path_text": "constancy → for → methods → improve → depends → on → scene",
        "sentence": "Methods for color constancy depend on the background scene.",
        "sentence_llm_dp_info": "Entity 1 ('color constancy') is the object of the preposition 'for', depending on 'Methods'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'depend'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what methods depend on."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "uncalibrated images",
                "Material"
            ],
            [
                "surface re-flectance estimates",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('uncalibrated images') is the object, depending on the preposition 'from' which modifies 'estimates'. Entity 2 ('surface re-flectance estimates') is the object of the verb 'improve', depending on 'can improve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the preposition 'from'.",
        "sdp_path_text": "images → from → estimates",
        "sentence": "Traditional methods improve surface re-flectance estimates from uncalibrated images.",
        "sentence_llm_dp_info": "Entity 1 ('uncalibrated images') is the object of the preposition 'from', depending on 'from' in the phrase 'from uncalibrated images'. Entity 2 ('surface re-flectance estimates') is the direct object, depending on 'improve' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the preposition 'from'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "surface re-flectance estimates",
                "Method"
            ],
            [
                "background scene",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('surface re-flectance estimates') is the object of the verb 'improve', depending on 'improve' with 'can improve'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'depends' in the phrase 'depends significantly on the background scene'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'depends' and the preposition 'on'.",
        "sdp_path_text": "estimates → improve → depends → on → scene",
        "sentence": "Surface reflectance estimates depend on the background scene.",
        "sentence_llm_dp_info": "Entity 1 ('surface reflectance estimates') is the subject, depending on the verb 'depend'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'on' in the phrase 'on the background scene'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'."
    },
    {
        "raw_sentence": "Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images , but their output depends significantly on the background scene .",
        "ner_pair": [
            [
                "uncalibrated images",
                "Material"
            ],
            [
                "background scene",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('uncalibrated images') is the object of the preposition 'from', depending on 'from' in the phrase 'from such uncalibrated images'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'on' in the phrase 'on the background scene'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context described in the sentence.",
        "sdp_path_text": "images → from → estimates → improve → depends → on → scene",
        "sentence": "Estimates from uncalibrated images depend on the background scene.",
        "sentence_llm_dp_info": "Entity 1 ('uncalibrated images') is the object of the preposition 'from', depending on 'Estimates'. Entity 2 ('background scene') is the object of the preposition 'on', depending on 'depend'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what the estimates depend on."
    },
    {
        "raw_sentence": "In many recognition and retrieval applications , we have access to image sets that contain multiple views of the same object in different environments ; we show in this paper that correspondences between these images provide important constraints that can improve color constancy .",
        "ner_pair": [
            [
                "recognition and retrieval applications",
                "Task"
            ],
            [
                "color constancy",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('recognition and retrieval applications') is the subject of the clause, depending on the verb 'have' in the phrase 'we have access to'. Entity 2 ('color constancy') is the object of the verb 'improve', depending on 'can improve' in the clause 'that can improve color constancy'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where the first entity is part of the scenario that enables improvements in the second entity.",
        "sdp_path_text": "applications → In → have → show → provide → constraints → improve → constancy",
        "sentence": "Recognition and retrieval applications can improve color constancy through constraints provided by image correspondences.",
        "sentence_llm_dp_info": "Entity 1 ('recognition and retrieval applications') is the subject, depending on the verb 'can improve'. Entity 2 ('color constancy') is the object, depending on the verb 'improve'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the agent performing the action that affects Entity 2."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "multi-view color constancy problem",
                "Task"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object of the verb 'introduce', depending on 'introduce' with 'We'. Entity 2 ('method') is the subject, depending on the verb 'present' with 'and present'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.",
        "sdp_path_text": "problem → introduce → present → method",
        "sentence": "We introduce the multi-view color constancy problem and present a method.",
        "sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object of the verb 'introduce', depending on 'introduce' with 'We'. Entity 2 ('method') is the object of the verb 'present', depending on 'present' with 'We'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "multi-view color constancy problem",
                "Task"
            ],
            [
                "estimates of underlying surface re-flectance",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object of the verb 'introduce', depending on 'introduce' with 'We'. Entity 2 ('estimates of underlying surface re-flectance') is the object of the verb 'recover', depending on 'recover' which is part of the method presented. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of the research described in the sentence.",
        "sdp_path_text": "problem → introduce → present → method → recover → estimates",
        "sentence": "We introduce the multi-view color constancy problem and present a method to recover estimates of underlying surface reflectance.",
        "sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object of the verb 'introduce', depending on 'introduce' with 'We'. Entity 2 ('estimates of underlying surface reflectance') is the object of the verb 'recover', depending on 'recover' within the clause 'to recover estimates of underlying surface reflectance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence and related through the context provided by the verbs 'introduce' and 'present'."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "multi-view color constancy problem",
                "Task"
            ],
            [
                "surface properties",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object, depending on the verb 'introduce'. Entity 2 ('surface properties') is part of the compound noun 'these surface properties', which is the object of the preposition 'of', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of the sentence through the discussion of methods and estimations.",
        "sdp_path_text": "problem → introduce → present → method → recover → based → on → estimation → of → properties",
        "sentence": "We introduce the multi-view color constancy problem and present a method to recover estimates of surface properties.",
        "sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object of the verb 'introduce', depending on 'introduce' with 'We'. Entity 2 ('surface properties') is the object of the preposition 'of', depending on 'estimates'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "multi-view color constancy problem",
                "Task"
            ],
            [
                "illuminants",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object, depending on the verb 'introduce' with 'We'. Entity 2 ('illuminants') is the object of the preposition 'of', depending on 'estimation' in the phrase 'estimation of these surface properties and the illuminants'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same discourse context, where both are discussed in the scope of the introduced method.",
        "sdp_path_text": "problem → introduce → present → method → recover → based → on → estimation → of → properties → illuminants",
        "sentence": "We introduce the multi-view color constancy problem and present a method to recover estimates of illuminants.",
        "sentence_llm_dp_info": "Entity 1 ('multi-view color constancy problem') is the object, depending on the verb 'introduce' with 'We'. Entity 2 ('illuminants') is the object, depending on 'recover' in the phrase 'to recover estimates of illuminants'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "estimates of underlying surface re-flectance",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on 'present' with 'We'. Entity 2 ('estimates of underlying surface re-flectance') is the object, depending on 'recover' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recover' which indicates that the method is used to recover the estimates.",
        "sdp_path_text": "method → recover → estimates",
        "sentence": "We present a method to recover estimates of underlying surface reflectance.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the direct object, depending on the verb 'present' with 'We'. Entity 2 ('estimates of underlying surface reflectance') is the object of the preposition 'to', depending on 'to' in the phrase 'to recover estimates of underlying surface reflectance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "surface properties",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on 'present' with 'We'. Entity 2 ('surface properties') is the object, depending on 'estimation' with 'joint'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the purpose of the method.",
        "sdp_path_text": "method → recover → based → on → estimation → of → properties",
        "sentence": "We present a method to recover estimates of surface properties.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the object, depending on 'present' with 'We'. Entity 2 ('surface properties') is the object of the preposition 'of', depending on 'estimates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recover' and the prepositional phrase 'of surface properties'."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "illuminants",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'present' with 'We'. Entity 2 ('illuminants') is the object of the preposition 'of', depending on 'estimation' in the phrase 'estimation of these surface properties and the illuminants'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the purpose of the method.",
        "sdp_path_text": "method → recover → based → on → estimation → of → properties → illuminants",
        "sentence": "A method is presented to recover estimates of illuminants based on joint estimation of surface properties.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'presented'. Entity 2 ('illuminants') is the object of the preposition 'of', depending on 'estimates' in the phrase 'estimates of illuminants'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'presented' and the purpose clause 'to recover estimates of illuminants'."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "estimates of underlying surface re-flectance",
                "Task"
            ],
            [
                "surface properties",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimates of underlying surface re-flectance') is the object, depending on 'recover' with 'method'. Entity 2 ('surface properties') is the object of the preposition 'of', depending on 'estimation' in the phrase 'estimation of these surface properties'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the method's goal to recover and estimate properties and reflectance.",
        "sdp_path_text": "estimates → recover → based → on → estimation → of → properties",
        "sentence": "Estimates of underlying surface reflectance are recovered based on the estimation of surface properties.",
        "sentence_llm_dp_info": "Entity 1 ('estimates of underlying surface reflectance') is the subject, depending on the verb 'are recovered'. Entity 2 ('surface properties') is the object of the preposition 'of', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'based on the estimation of surface properties'."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "estimates of underlying surface re-flectance",
                "Task"
            ],
            [
                "illuminants",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimates of underlying surface re-flectance') is the object, depending on 'recover' which is part of the infinitive phrase 'to recover estimates of underlying surface re-flectance'. Entity 2 ('illuminants') is the object of the preposition 'of', depending on the noun phrase 'joint estimation of these surface properties and the illuminants'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the concept of joint estimation.",
        "sdp_path_text": "estimates → recover → based → on → estimation → of → properties → illuminants",
        "sentence": "We present a method to recover estimates of underlying surface re-flectance based on the estimation of illuminants.",
        "sentence_llm_dp_info": "Entity 1 ('estimates of underlying surface re-flectance') is the object of the infinitive 'to recover', depending on 'recover'. Entity 2 ('illuminants') is the object of the preposition 'of', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence."
    },
    {
        "raw_sentence": "We introduce the multi-view color constancy problem , and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images .",
        "ner_pair": [
            [
                "surface properties",
                "OtherScientificTerm"
            ],
            [
                "illuminants",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('surface properties') is part of the object, depending on 'estimation' with 'joint'. Entity 2 ('illuminants') is also part of the object, depending on 'estimation' with 'joint'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of the same joint estimation process described in the sentence.",
        "sdp_path_text": "properties → illuminants",
        "sentence": "The method recovers estimates of surface properties and illuminants.",
        "sentence_llm_dp_info": "Entity 1 ('surface properties') is part of the object complement, depending on 'recovers' with 'estimates of'. Entity 2 ('illuminants') is also part of the object complement, depending directly on 'and' which connects it to 'estimates of surface properties'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same object complement recovered by the method."
    },
    {
        "raw_sentence": "The method can exploit image correspondences obtained by various alignment techniques , and we show examples based on matching local region features .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "image correspondences",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the modal verb 'can' and the main verb 'exploit'. Entity 2 ('image correspondences') is the object, depending on 'exploit' with 'method'. There is a direct dependency between Entity 1 and Entity 2, where 'method' exploits 'image correspondences'.",
        "sdp_path_text": "method → exploit → correspondences",
        "sentence": "The method exploits image correspondences.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('image correspondences') is the object, depending on 'exploits' with 'method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' directly exploits 'image correspondences'."
    },
    {
        "raw_sentence": "The method can exploit image correspondences obtained by various alignment techniques , and we show examples based on matching local region features .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "alignment techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on 'can exploit' with 'image correspondences'. Entity 2 ('alignment techniques') is the object of the preposition 'by', depending on 'obtained' in the phrase 'obtained by various alignment techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'obtained' and the preposition 'by'.",
        "sdp_path_text": "method → exploit → correspondences → obtained → by → techniques",
        "sentence": "The method exploits correspondences obtained by alignment techniques.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('alignment techniques') is the object of the preposition 'by', depending on 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'exploits' and the prepositional phrase 'by alignment techniques'."
    },
    {
        "raw_sentence": "The method can exploit image correspondences obtained by various alignment techniques , and we show examples based on matching local region features .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "matching local region features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on 'can exploit' with 'image correspondences'. Entity 2 ('matching local region features') is the object, depending on 'based on' with 'examples'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence context, where the method's capability to exploit image correspondences is demonstrated through examples that are based on matching local region features.",
        "sdp_path_text": "method → exploit → show → examples → based → on → matching",
        "sentence": "The method exploits examples based on matching local region features.",
        "sentence_llm_dp_info": "Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('matching local region features') is the object of the preposition 'on', depending on 'based' in the phrase 'based on matching local region features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'."
    },
    {
        "raw_sentence": "The method can exploit image correspondences obtained by various alignment techniques , and we show examples based on matching local region features .",
        "ner_pair": [
            [
                "alignment techniques",
                "Method"
            ],
            [
                "image correspondences",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('alignment techniques') is the object of the preposition 'by', depending on 'obtained'. Entity 2 ('image correspondences') is the direct object, depending on the verb 'exploit'. There is a direct dependency between Entity 1 and Entity 2, as 'alignment techniques' are the means by which 'image correspondences' are obtained.",
        "sdp_path_text": "techniques → by → obtained → correspondences",
        "sentence": "Alignment techniques obtain image correspondences.",
        "sentence_llm_dp_info": "Entity 1 ('alignment techniques') is the subject, depending on the verb 'obtain'. Entity 2 ('image correspondences') is the object, depending on the verb 'obtain'. There is a direct dependency between Entity 1 and Entity 2, as 'alignment techniques' obtains 'image correspondences'."
    },
    {
        "raw_sentence": "The method can exploit image correspondences obtained by various alignment techniques , and we show examples based on matching local region features .",
        "ner_pair": [
            [
                "image correspondences",
                "OtherScientificTerm"
            ],
            [
                "matching local region features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('image correspondences') is the object of the verb 'exploit', depending on 'exploit' with 'can'. Entity 2 ('matching local region features') is the object of the preposition 'on', depending on 'on' in the phrase 'based on matching local region features'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the methods used for obtaining and showing examples.",
        "sdp_path_text": "correspondences → exploit → show → examples → based → on → matching",
        "sentence": "The method exploits image correspondences based on matching local region features.",
        "sentence_llm_dp_info": "Entity 1 ('image correspondences') is the object, depending on 'exploits' with 'The method'. Entity 2 ('matching local region features') is the object of the preposition 'on', depending on 'based' in the phrase 'based on matching local region features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'based'."
    },
    {
        "raw_sentence": "The method can exploit image correspondences obtained by various alignment techniques , and we show examples based on matching local region features .",
        "ner_pair": [
            [
                "alignment techniques",
                "Method"
            ],
            [
                "matching local region features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('alignment techniques') is the object of the preposition 'by', depending on 'obtained' in the phrase 'obtained by various alignment techniques'. Entity 2 ('matching local region features') is the object of the preposition 'on', depending on 'examples' in the phrase 'examples based on matching local region features'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of methods used for image processing.",
        "sdp_path_text": "techniques → by → obtained → correspondences → exploit → show → examples → based → on → matching",
        "sentence": "The method exploits correspondences obtained by alignment techniques based on matching local region features.",
        "sentence_llm_dp_info": "Entity 1 ('alignment techniques') is the object of the preposition 'by', depending on 'obtained'. Entity 2 ('matching local region features') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that describe the method's exploitation of correspondences."
    },
    {
        "raw_sentence": "Our results show that multi-view constraints can significantly improve estimates of both scene illuminants and object color -LRB- surface reflectance -RRB- when compared to a baseline single-view method .",
        "ner_pair": [
            [
                "multi-view constraints",
                "OtherScientificTerm"
            ],
            [
                "estimates of both scene illuminants and object color -LRB- surface reflectance -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('multi-view constraints') is the subject complement, depending on 'can' as part of the clause 'can significantly improve'. Entity 2 ('estimates of both scene illuminants and object color -LRB- surface reflectance -RRB-') is the object, depending on 'improve' with 'multi-view constraints'. There is a direct dependency between Entity 1 and Entity 2, as 'multi-view constraints' directly influences 'estimates of both scene illuminants and object color -LRB- surface reflectance -RRB-' through the verb 'improve'.",
        "sdp_path_text": "constraints → improve → estimates",
        "sentence": "Multi-view constraints can significantly improve estimates of scene illuminants and object color.",
        "sentence_llm_dp_info": "Entity 1 ('multi-view constraints') is the subject, depending on the verb 'can improve'. Entity 2 ('estimates of scene illuminants and object color') is the object, depending on the verb 'improve'. There is a direct dependency between Entity 1 and Entity 2, as 'multi-view constraints' directly influences 'estimates of scene illuminants and object color' through the verb 'improve'."
    },
    {
        "raw_sentence": "Our results show that multi-view constraints can significantly improve estimates of both scene illuminants and object color -LRB- surface reflectance -RRB- when compared to a baseline single-view method .",
        "ner_pair": [
            [
                "baseline single-view method",
                "Method"
            ],
            [
                "multi-view constraints",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('baseline single-view method') is the object of the preposition 'to', depending on 'compared' in the phrase 'when compared to a baseline single-view method'. Entity 2 ('multi-view constraints') is the subject complement, depending on 'can' in the clause 'can significantly improve estimates'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative context provided by the verb 'compared'.",
        "sdp_path_text": "method → to → compared → improve → constraints",
        "sentence": "Multi-view constraints improve estimates compared to a baseline single-view method.",
        "sentence_llm_dp_info": "Entity 1 ('baseline single-view method') is the object of the preposition 'to', depending on 'to' in the phrase 'compared to a baseline single-view method'. Entity 2 ('multi-view constraints') is the subject, depending on the verb 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparison structure 'compared to'."
    },
    {
        "raw_sentence": "Our results show that multi-view constraints can significantly improve estimates of both scene illuminants and object color -LRB- surface reflectance -RRB- when compared to a baseline single-view method .",
        "ner_pair": [
            [
                "estimates of both scene illuminants and object color -LRB- surface reflectance -RRB-",
                "Task"
            ],
            [
                "baseline single-view method",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('estimates of both scene illuminants and object color -LRB- surface reflectance -RRB-') is the object of the verb 'improve', depending on 'improve' with 'can significantly'. Entity 2 ('baseline single-view method') is the object of the preposition 'to', depending on 'compared' in the phrase 'when compared to a baseline single-view method'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure involving the verb 'compared'.",
        "sdp_path_text": "estimates → improve → compared → to → method",
        "sentence": "Multi-view constraints improve estimates of scene illuminants and object color compared to a baseline single-view method.",
        "sentence_llm_dp_info": "Entity 1 ('estimates of scene illuminants and object color') is the object of the verb 'improve', depending on 'improve' with 'Multi-view constraints'. Entity 2 ('baseline single-view method') is the object of the preposition 'to', depending on 'to' in the phrase 'compared to a baseline single-view method'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure involving 'compared to'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "concise , modular architecture",
                "Method"
            ],
            [
                "understanding",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the object, depending on the preposition 'with' as part of the phrase 'with reversible processes of...architecture'. Entity 2 ('understanding') is the object of the preposition 'of', depending on 'processes'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger structure described in the sentence.",
        "sdp_path_text": "architecture → with → processes → of → understanding",
        "sentence": "A concise, modular architecture includes processes of understanding.",
        "sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the subject, depending on the verb 'includes'. Entity 2 ('understanding') is part of the object, depending on 'processes' within the noun phrase 'processes of understanding'. There is no direct dependency between Entity 1 and Entity 2."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "concise , modular architecture",
                "Method"
            ],
            [
                "generation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is part of the list of contributions, depending on the verb 'include' in the phrase 'contributions include'. Entity 2 ('generation') is one of the objects in the prepositional phrase 'processes of understanding and generation', depending on the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence.",
        "sdp_path_text": "architecture → with → processes → of → understanding → generation",
        "sentence": "A concise, modular architecture includes processes of understanding and generation.",
        "sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the subject, depending on the verb 'includes'. Entity 2 ('generation') is part of the compound object, depending on 'processes' in the phrase 'processes of understanding and generation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the preposition 'of'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "concise , modular architecture",
                "Method"
            ],
            [
                "information-state model of reference",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is part of a list of contributions, depending on 'include' with 'contributions'. Entity 2 ('information-state model of reference') is also part of the same list, depending on 'and' which connects it to the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of contributions.",
        "sdp_path_text": "architecture → model",
        "sentence": "Our contributions include a concise, modular architecture and an information-state model of reference.",
        "sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the object, depending on the verb 'include' which is part of the clause 'Our contributions include...'. Entity 2 ('information-state model of reference') is also an object, depending on the same verb 'include'. There is no direct dependency between Entity 1 and Entity 2; both are listed as items included in the contributions."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "concise , modular architecture",
                "Method"
            ],
            [
                "semantics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is part of a list of contributions, depending on 'include' with 'contributions'. Entity 2 ('semantics') is part of another list item, depending on 'links' with 'flexible links'. There is no direct dependency between Entity 1 and Entity 2; both are elements within the larger structure of contributions described in the sentence.",
        "sdp_path_text": "architecture → model → links → between → semantics",
        "sentence": "A concise, modular architecture has links to semantics.",
        "sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the subject, depending on the verb 'has'. Entity 2 ('semantics') is the object of the preposition 'to', depending on 'links' in the phrase 'links to semantics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has' and the preposition 'to'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "concise , modular architecture",
                "Method"
            ],
            [
                "collaborative problem solving",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the object of the preposition 'with', depending on 'include' in the phrase 'include ... architecture with reversible processes'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between', depending on 'links' in the phrase 'flexible links between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "architecture → model → links → between → semantics → solving",
        "sentence": "A concise, modular architecture has links between semantics and collaborative problem solving.",
        "sentence_llm_dp_info": "Entity 1 ('concise, modular architecture') is the subject, depending on the verb 'has'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between', depending on 'links' in the phrase 'links between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has' and the prepositional phrase 'between semantics and collaborative problem solving'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "understanding",
                "Task"
            ],
            [
                "generation",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('understanding') is part of a compound noun, depending on 'processes' with the conjunction 'and'. Entity 2 ('generation') is also part of the same compound noun, depending on 'processes' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both directly connected to 'processes' through the conjunction 'and'.",
        "sdp_path_text": "understanding → generation",
        "sentence": "Our contributions include reversible processes of understanding and generation.",
        "sentence_llm_dp_info": "Entity 1 ('understanding') is part of a compound noun, depending on 'processes' with the preposition 'of'. Entity 2 ('generation') is also part of a compound noun, depending on 'processes' with the same preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both dependent on 'processes' through the preposition 'of'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "understanding",
                "Task"
            ],
            [
                "information-state model of reference",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('understanding') is part of a compound noun, depending on 'processes' as a modifier within the phrase 'reversible processes of understanding and generation'. Entity 2 ('information-state model of reference') is the object of the preposition 'of', depending on 'include' in the list of contributions. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of items included in the contributions.",
        "sdp_path_text": "understanding → of → processes → with → architecture → model",
        "sentence": "The architecture includes processes of understanding with an information-state model of reference.",
        "sentence_llm_dp_info": "Entity 1 ('understanding') is part of the object complement, depending on the preposition 'of' in the phrase 'processes of understanding'. Entity 2 ('information-state model of reference') is the object of the preposition 'with', depending on 'with' in the phrase 'with an information-state model of reference'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of the object of the verb 'includes'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "understanding",
                "Task"
            ],
            [
                "semantics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('understanding') is part of a compound noun, depending on 'processes' as a modifier. Entity 2 ('semantics') is the object of a preposition, depending on 'between' in the phrase 'between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2.",
        "sdp_path_text": "understanding → of → processes → with → architecture → model → links → between → semantics",
        "sentence": "The architecture includes processes of understanding with links to semantics.",
        "sentence_llm_dp_info": "Entity 1 ('understanding') is part of the object complement, depending on 'includes' with 'architecture'. Entity 2 ('semantics') is the object of the preposition 'to', depending on 'links' in the phrase 'links to semantics'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional structure under 'includes'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "understanding",
                "Task"
            ],
            [
                "collaborative problem solving",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('understanding') is part of a coordination, depending on 'and' within the phrase 'understanding and generation', which is the object of the preposition 'of' in 'processes of understanding and generation'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between' in the phrase 'between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2; they are connected through different parts of the sentence structure.",
        "sdp_path_text": "understanding → of → processes → with → architecture → model → links → between → semantics → solving",
        "sentence": "The architecture includes processes of understanding with links between semantics and collaborative problem solving.",
        "sentence_llm_dp_info": "Entity 1 ('understanding') is part of a noun phrase, depending on 'processes' with the preposition 'of'. Entity 2 ('collaborative problem solving') is also part of a noun phrase, depending on 'links' with the preposition 'between'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional structure linked by 'between'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "generation",
                "Task"
            ],
            [
                "information-state model of reference",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generation') is part of a compound noun, depending on 'processes' with the conjunction 'and'. Entity 2 ('information-state model of reference') is the object of the preposition 'of', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of contributions described in the sentence.",
        "sdp_path_text": "generation → understanding → of → processes → with → architecture → model",
        "sentence": "The architecture includes processes of generation and an information-state model of reference.",
        "sentence_llm_dp_info": "Entity 1 ('generation') is part of the compound noun 'processes of generation', where it is the object of the preposition 'of', depending on 'processes'. Entity 2 ('information-state model of reference') is the object of the preposition 'of', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2; both are components of the list of items included in the architecture."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "generation",
                "Task"
            ],
            [
                "semantics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generation') is part of a coordination, depending on 'and' within the phrase 'understanding and generation'. It is also part of a larger prepositional phrase 'processes of understanding and generation', where it depends on 'of'. Entity 2 ('semantics') is the object of the preposition 'between', forming the phrase 'between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2; they are both part of different clauses within the sentence.",
        "sdp_path_text": "generation → understanding → of → processes → with → architecture → model → links → between → semantics",
        "sentence": "The architecture includes processes of generation and understanding, linked to semantics.",
        "sentence_llm_dp_info": "Entity 1 ('generation') is part of a conjunction, depending on 'includes' with 'architecture'. Entity 2 ('semantics') is the object of the preposition 'to', depending on 'linked' in the phrase 'linked to semantics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'linked'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "generation",
                "Task"
            ],
            [
                "collaborative problem solving",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('generation') is part of a compound noun, depending on 'processes' with the preposition 'of' in the phrase 'processes of understanding and generation'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between', depending on 'links' in the phrase 'flexible links between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of contributions described in the sentence.",
        "sdp_path_text": "generation → understanding → of → processes → with → architecture → model → links → between → semantics → solving",
        "sentence": "The architecture includes processes of generation and links between semantics and collaborative problem solving.",
        "sentence_llm_dp_info": "Entity 1 ('generation') is part of a compound noun, depending on 'processes' with the relation 'compound'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between', depending on 'links'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence, connected through the verb 'includes' and the preposition 'between'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "information-state model of reference",
                "Method"
            ],
            [
                "semantics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information-state model of reference') is the object of the preposition 'of', depending on 'model'. It is part of a list of contributions, where 'contributions' is the subject of the verb 'include'. Entity 2 ('semantics') is the object of the preposition 'between', depending on 'links'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of contributions mentioned in the sentence.",
        "sdp_path_text": "model → links → between → semantics",
        "sentence": "An information-state model of reference has links between semantics.",
        "sentence_llm_dp_info": "Entity 1 ('information-state model of reference') is the subject, depending on the verb 'has'. Entity 2 ('semantics') is the object of the preposition 'between', depending on 'links' in the phrase 'links between semantics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'links between semantics'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "information-state model of reference",
                "Method"
            ],
            [
                "collaborative problem solving",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('information-state model of reference') is the object of the preposition 'of', depending on 'model' in the noun phrase 'an information-state model of reference'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between', depending on 'links' in the noun phrase 'flexible links between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the sentence.",
        "sdp_path_text": "model → links → between → semantics → solving",
        "sentence": "An information-state model of reference has links between semantics and collaborative problem solving.",
        "sentence_llm_dp_info": "Entity 1 ('information-state model of reference') is the subject, depending on the verb 'has'. Entity 2 ('collaborative problem solving') is the object of the preposition 'between', depending on 'between' in the phrase 'between semantics and collaborative problem solving'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'between'."
    },
    {
        "raw_sentence": "Our contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state model of reference , and flexible links between semantics and collaborative problem solving .",
        "ner_pair": [
            [
                "semantics",
                "OtherScientificTerm"
            ],
            [
                "collaborative problem solving",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "Entity 1 ('semantics') is part of a compound noun, depending on 'links' as a modifier in the phrase 'flexible links between semantics and collaborative problem solving'. Entity 2 ('collaborative problem solving') is also part of a compound noun, depending on 'links' as another modifier in the same phrase. There is no direct dependency between Entity 1 and Entity 2, but they are both dependent on 'links' in the phrase 'flexible links between semantics and collaborative problem solving'.",
        "sdp_path_text": "semantics → solving",
        "sentence": "There are flexible links between semantics and collaborative problem solving.",
        "sentence_llm_dp_info": "Entity 1 ('semantics') is the first element in a prepositional phrase, depending on 'between' with 'flexible links'. Entity 2 ('collaborative problem solving') is the second element in the same prepositional phrase, also depending on 'between' with 'flexible links'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase introduced by 'between'."
    }
]