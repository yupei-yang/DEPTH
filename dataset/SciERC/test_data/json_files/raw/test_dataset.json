[
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "Recognition of proper nouns",
                "Task"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Recognition of proper nouns') is the subject, depending on the verb 'has been studied'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "Recognition → in → text",
        "sentence": "Recognition of proper nouns is studied in Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('Recognition of proper nouns') is the subject, depending on the verb 'studied'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "Recognition of proper nouns",
                "Task"
            ],
            [
                "morphological analysis",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Recognition of proper nouns') is the subject, depending on the verb 'has been studied'. Entity 2 ('morphological analysis') is the object of the preposition 'of', depending on 'part' in the phrase 'a part of the more general problem of morphological analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the noun 'part'.\"",
        "sdp_path_text": "Recognition → studied → as → part → of → problem → of → analysis",
        "sentence": "Recognition of proper nouns has been studied as part of the problem of morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('Recognition of proper nouns') is the subject, depending on the verb 'has been studied'. Entity 2 ('morphological analysis') is the object of the preposition 'of', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as part of the problem of morphological analysis'.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "Recognition of proper nouns",
                "Task"
            ],
            [
                "Japanese text processing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Recognition of proper nouns') is the subject, depending on the verb 'has been studied'. Entity 2 ('Japanese text processing') is the object of the preposition 'of', depending on 'part' in the phrase 'part of the more general problem of Japanese text processing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as a part of the more general problem of'.\"",
        "sdp_path_text": "Recognition → studied → as → part → of → problem → in → processing",
        "sentence": "Recognition of proper nouns has been studied as part of the problem in Japanese text processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('Recognition of proper nouns') is the subject, depending on the verb 'has been studied'. Entity 2 ('Japanese text processing') is the object of the preposition 'of', depending on 'part' in the phrase 'part of the problem in Japanese text processing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as part of the problem in'.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "proper nouns",
                "OtherScientificTerm"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('proper nouns') is the object of the preposition 'of', depending on 'Recognition'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'nouns'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different parts of the sentence.\"",
        "sdp_path_text": "nouns → of → Recognition → in → text",
        "sentence": "Recognition of proper nouns in Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('proper nouns') is the object of the preposition 'of', depending on 'Recognition'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'Recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main concept of 'Recognition'.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "proper nouns",
                "OtherScientificTerm"
            ],
            [
                "morphological analysis",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('proper nouns') is the object of the preposition 'of', depending on 'Recognition'. Entity 2 ('morphological analysis') is the object of the preposition 'of', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence.\"",
        "sdp_path_text": "nouns → of → Recognition → studied → as → part → of → problem → of → analysis",
        "sentence": "Recognition of proper nouns has been studied as part of the problem of morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('proper nouns') is the object of the preposition 'of', depending on 'Recognition'. Entity 2 ('morphological analysis') is the object of the preposition 'of', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what has been studied.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "proper nouns",
                "OtherScientificTerm"
            ],
            [
                "Japanese text processing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('proper nouns') is the object of the preposition 'of', depending on 'Recognition'. Entity 2 ('Japanese text processing') is the object of the preposition 'of', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different parts of the sentence structure.\"",
        "sdp_path_text": "nouns → of → Recognition → studied → as → part → of → problem → in → processing",
        "sentence": "Recognition of proper nouns has been studied as part of Japanese text processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('proper nouns') is the object of the preposition 'of', depending on 'Recognition'. Entity 2 ('Japanese text processing') is the object of the preposition 'of', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing what has been studied.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "Japanese text",
                "Material"
            ],
            [
                "morphological analysis",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Japanese text') is the object of the preposition 'in', depending on 'nouns'. Entity 2 ('morphological analysis') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the broader context of the sentence, where Entity 1 is part of the domain being studied, and Entity 2 is part of the more general problem that includes this study.\"",
        "sdp_path_text": "text → in → Recognition → studied → as → part → of → problem → of → analysis",
        "sentence": "Japanese text has been studied as part of the problem of morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('Japanese text') is the subject, depending on the verb 'has been studied'. Entity 2 ('morphological analysis') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as part of the problem of morphological analysis'.\""
    },
    {
        "raw_sentence": "Recognition of proper nouns in Japanese text has been studied as a part of the more general problem of morphological analysis in Japanese text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .",
        "ner_pair": [
            [
                "morphological analysis",
                "Task"
            ],
            [
                "Japanese text processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphological analysis') is the object of the preposition 'of', depending on 'part'. Entity 2 ('Japanese text processing') is the subject, depending on the verb 'has been studied'. There is a direct dependency between Entity 1 and Entity 2, as 'morphological analysis' is described as a part of 'Japanese text processing'.\"",
        "sdp_path_text": "analysis → of → problem → in → processing",
        "sentence": "Morphological analysis is part of the problem in Japanese text processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphological analysis') is the subject, depending on 'is' as the main verb. Entity 2 ('Japanese text processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that provides context for the subject.\""
    },
    {
        "raw_sentence": "It has also been studied in the framework of Japanese information extraction -LRB- -LSB- 3 -RSB- -RRB- in recent years .",
        "ner_pair": [
            [
                "Japanese information extraction",
                "Task"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Japanese information extraction') is the object of the preposition 'of', depending on 'framework'. Entity 2 ('It') is the subject, depending on the verb 'has'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "extraction → of → framework → in → studied → It",
        "sentence": "It has been studied in the framework of Japanese information extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('Japanese information extraction') is the object of the preposition 'of', depending on 'framework'. Entity 2 ('It') is the subject, depending on 'has' in the passive construction 'has been studied'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the framework of'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "Multi-lingual Evaluation Task -LRB- MET -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('Multi-lingual Evaluation Task -LRB- MET -RRB-') is the object of the preposition 'to', depending on 'to' in the phrase 'to the Multi-lingual Evaluation Task -LRB- MET -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\"",
        "sdp_path_text": "approach → to → Task",
        "sentence": "Our approach considers the Multi-lingual Evaluation Task as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'considers'. Entity 2 ('Multi-lingual Evaluation Task') is the object of the preposition 'as', depending on 'as' in the phrase 'as a morphological analysis problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considers' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('Japanese text') is the object of the preposition 'for', depending on 'for' in the phrase 'for Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "approach → to → Task → for → text",
        "sentence": "Our approach to the task is for Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the preposition 'to' with 'task'. Entity 2 ('Japanese text') is the object, depending on the preposition 'for' with 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositions 'to' and 'for'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('task') is the object of the preposition 'to', depending on 'to' in the phrase 'to the Multi-lingual Evaluation Task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'is'.\"",
        "sdp_path_text": "approach → to → Task",
        "sentence": "Our approach considers the task as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'considers'. Entity 2 ('task') is the object, depending on 'considers' with 'approach'. There is a direct dependency between Entity 1 and Entity 2, as 'task' is directly considered by the 'approach'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "morphological analysis problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('morphological analysis problem') is the complement, depending on the verb 'consider'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'consider' which indicates that the approach treats the given task as a morphological analysis problem.\"",
        "sdp_path_text": "approach → is → consider → as → problem",
        "sentence": "Our approach is considered as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'considered'. Entity 2 ('morphological analysis problem') is the complement, depending on 'as' in the phrase 'as a morphological analysis problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considered' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "Japanese",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('Japanese') is an adjective modifying 'text', depending on 'text' in the phrase 'Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'approach' is described in relation to 'Japanese text'.\"",
        "sdp_path_text": "approach → to → Task → for → text → Japanese",
        "sentence": "Our approach to the task is for Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the preposition 'to' with 'task'. Entity 2 ('Japanese') is an adjective modifier, depending on 'text'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun 'text' which modifies 'approach' and is specified as 'Japanese text'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Multi-lingual Evaluation Task -LRB- MET -RRB-",
                "Task"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task -LRB- MET -RRB-') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('Japanese text') is the object of the preposition 'for', depending on 'approach'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the 'approach' through different prepositions ('to' and 'for').\"",
        "sdp_path_text": "Task → for → text",
        "sentence": "The Multi-lingual Evaluation Task (MET) is for Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task (MET)') is the subject, depending on the verb 'is'. Entity 2 ('Japanese text') is the object of the preposition 'for', depending on 'for' in the phrase 'for Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for Japanese text'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Multi-lingual Evaluation Task -LRB- MET -RRB-",
                "Task"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task -LRB- MET -RRB-') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('task') is the object of the preposition 'as', depending on 'consider'. There is no direct dependency between Entity 1 and Entity 2; they are both part of different clauses within the sentence, with Entity 1 being part of the clause describing the approach and Entity 2 being part of the clause that describes how the approach treats the task.\"",
        "sdp_path_text": "Task",
        "sentence": "The Multi-lingual Evaluation Task (MET) is considered as a morphological analysis task.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task (MET)') is the subject, depending on the verb 'is considered'. Entity 2 ('task') is the complement, depending on the verb 'is considered' through the preposition 'as'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is considered' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Multi-lingual Evaluation Task -LRB- MET -RRB-",
                "Task"
            ],
            [
                "morphological analysis problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task -LRB- MET -RRB-') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('morphological analysis problem') is the complement of the preposition 'as', depending on 'consider'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'consider' which indicates that the approach to Entity 1 is treated as Entity 2.\"",
        "sdp_path_text": "Task → to → approach → is → consider → as → problem",
        "sentence": "The Multi-lingual Evaluation Task (MET) is considered as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task (MET)') is the subject, depending on the verb 'is considered'. Entity 2 ('morphological analysis problem') is the complement, depending on the verb 'is considered' as well. There is a direct dependency between Entity 1 and Entity 2, as they are both part of the predicate 'is considered as'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Multi-lingual Evaluation Task -LRB- MET -RRB-",
                "Task"
            ],
            [
                "Japanese",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task -LRB- MET -RRB-') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('Japanese') is the modifier, depending on 'text' in the noun phrase 'Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence, where Entity 1 is the target of the approach, and Entity 2 specifies the language of the text being considered.\"",
        "sdp_path_text": "Task → for → text → Japanese",
        "sentence": "The Multi-lingual Evaluation Task is for Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-lingual Evaluation Task') is the subject, depending on 'is' as the main verb of the sentence. Entity 2 ('Japanese') is the modifier, depending on 'text' in the noun phrase 'Japanese text'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the prepositional phrase 'for Japanese text'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Japanese text",
                "Material"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Japanese text') is the object of the preposition 'for', depending on 'approach'. Entity 2 ('task') is the subject complement, depending on 'consider' with 'as a morphological analysis problem in Japanese'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the approach to the MET for analyzing Japanese text.\"",
        "sdp_path_text": "text → for → Task",
        "sentence": "Our approach considers the task for Japanese text as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('Japanese text') is the object of the preposition 'for', depending on 'task'. Entity 2 ('task') is the subject complement, depending on 'considers' with 'approach'. There is a direct dependency between Entity 1 and Entity 2, as 'Japanese text' is part of the prepositional phrase that modifies 'task'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Japanese text",
                "Material"
            ],
            [
                "morphological analysis problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Japanese text') is the object of the preposition 'for', depending on 'Task'. Entity 2 ('morphological analysis problem') is the complement of the preposition 'as', depending on 'consider'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'consider' which indicates that the 'Japanese text' is being treated as a 'morphological analysis problem'.\"",
        "sdp_path_text": "text → for → Task → to → approach → is → consider → as → problem",
        "sentence": "Our approach to the task for Japanese text is to consider it as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('Japanese text') is the object of the preposition 'for', depending on 'task'. Entity 2 ('morphological analysis problem') is the complement of the preposition 'as', depending on 'consider'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the logical structure of the sentence where the task for 'Japanese text' is considered as a 'morphological analysis problem'.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "morphological analysis problem",
                "Task"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphological analysis problem') is the complement, depending on 'consider' with 'is to consider'. Entity 2 ('task') is the object of the preposition 'as', depending on 'as' in the phrase 'as a morphological analysis problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as' which indicates that the 'task' is being considered as a 'morphological analysis problem'.\"",
        "sdp_path_text": "problem → as → consider → is → approach → to → Task",
        "sentence": "Our approach considers the task as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphological analysis problem') is the complement of the preposition 'as', depending on 'considers' with 'approach'. Entity 2 ('task') is the object of the preposition 'the', depending on 'considers' with 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considers' which treats one as the other.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "task",
                "Generic"
            ],
            [
                "Japanese",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('Japanese') is the modifier, depending on 'text' in the phrase 'Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence where 'task' is related to 'Japanese text' through the prepositional phrase 'to the Multi-lingual Evaluation Task for Japanese text'.\"",
        "sdp_path_text": "Task → for → text → Japanese",
        "sentence": "The task is considered as a morphological analysis problem for Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('task') is the subject, depending on the verb 'is considered'. Entity 2 ('Japanese') is an adjective modifier, depending on 'text' in the noun phrase 'Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun phrase 'Japanese text' which is part of the larger structure describing the nature of the task.\""
    },
    {
        "raw_sentence": "Our approach to the Multi-lingual Evaluation Task -LRB- MET -RRB- for Japanese text is to consider the given task as a morphological analysis problem in Japanese .",
        "ner_pair": [
            [
                "Japanese",
                "Material"
            ],
            [
                "morphological analysis problem",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Japanese') is the modifier, depending on 'text' with the possessive relation. Entity 2 ('morphological analysis problem') is the complement, depending on 'consider' with the preposition 'as'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where 'Japanese' modifies 'text' and 'morphological analysis problem' is what the task is considered to be.\"",
        "sdp_path_text": "Japanese → text → for → Task → to → approach → is → consider → as → problem",
        "sentence": "Our approach to the Japanese text task is to consider it as a morphological analysis problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('Japanese') is the modifier, depending on 'text' with the relation 'amod'. Entity 2 ('morphological analysis problem') is the complement, depending on 'consider' with the relation 'xcomp'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'text' and the verb 'consider'.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "morphological analyzer",
                "Method"
            ],
            [
                "recognition and classification of proper names , numerical and temporal expressions",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('recognition and classification of proper names, numerical and temporal expressions') is the object of the preposition 'for', depending on 'for' in the phrase 'for the recognition and classification of proper names, numerical and temporal expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the verb 'has done'.\"",
        "sdp_path_text": "analyzer → done → work → for → recognition",
        "sentence": "The morphological analyzer has done the work for the recognition and classification of proper names, numerical and temporal expressions.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('recognition and classification of proper names, numerical and temporal expressions') is the object of the preposition 'for', depending on 'for' in the phrase 'for the recognition and classification of proper names, numerical and temporal expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "morphological analyzer",
                "Method"
            ],
            [
                "proper names , numerical and temporal expressions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('proper names, numerical and temporal expressions') is part of the object, depending on the preposition 'of' in the phrase 'of proper names, numerical and temporal expressions'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'done' and the prepositional phrase that describes the tasks completed by the morphological analyzer.\"",
        "sdp_path_text": "analyzer → done → work → for → recognition → of → names",
        "sentence": "The morphological analyzer has done work for the recognition of proper names, numerical and temporal expressions.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('proper names, numerical and temporal expressions') is the object of the preposition 'for', depending on 'for' in the phrase 'for the recognition of proper names, numerical and temporal expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that specifies the scope of the work done by the morphological analyzer.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "morphological analyzer",
                "Method"
            ],
            [
                "Named Entity -LRB- NE -RRB- items",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('Named Entity -LRB- NE -RRB- items') is the object of the preposition 'of', depending on 'items' in the phrase 'of proper names, numerical and temporal expressions, i.e. Named Entity -LRB- NE -RRB- items'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has done' and the prepositional phrase that describes the work done by the morphological analyzer.\"",
        "sdp_path_text": "analyzer → done → work → for → recognition → of → names → items",
        "sentence": "The morphological analyzer has done the work for the recognition of Named Entity items.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('Named Entity items') is the object of the preposition 'for', depending on 'for' in the phrase 'for the recognition of Named Entity items'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has done' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "morphological analyzer",
                "Method"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('Japanese text') is the object, depending on the preposition 'in', which is part of the phrase 'in the Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions and objects described in the sentence, where the 'morphological analyzer' performs tasks on the 'Japanese text'.\"",
        "sdp_path_text": "analyzer → done → work → for → recognition → of → names → in → text",
        "sentence": "The morphological analyzer has done the work for the recognition of names in Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphological analyzer') is the subject, depending on the verb 'has done'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "recognition and classification of proper names , numerical and temporal expressions",
                "Task"
            ],
            [
                "Named Entity -LRB- NE -RRB- items",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition and classification of proper names, numerical and temporal expressions') is the object of the preposition 'for', depending on 'done' with 'work'. Entity 2 ('Named Entity (NE) items') is the appositive, depending on 'expressions' with 'i.e.'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the explanatory clause introduced by 'i.e.'.\"",
        "sdp_path_text": "recognition → of → names → items",
        "sentence": "The recognition and classification of proper names, numerical and temporal expressions are for Named Entity items.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition and classification of proper names, numerical and temporal expressions') is the subject, depending on the verb 'are'. Entity 2 ('Named Entity (NE) items') is the predicate nominative, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is what Entity 1 is described as being.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "recognition and classification of proper names , numerical and temporal expressions",
                "Task"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition and classification of proper names, numerical and temporal expressions') is the object of the preposition 'for', depending on 'work'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'items'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context provided by the sentence, where the work done by the morphological analyzer is described.\"",
        "sdp_path_text": "recognition → of → names → in → text",
        "sentence": "The recognition and classification of proper names, numerical and temporal expressions are done in Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition and classification of proper names, numerical and temporal expressions') is the subject, depending on the verb 'are done'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are done' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "Named Entity -LRB- NE -RRB- items",
                "OtherScientificTerm"
            ],
            [
                "proper names , numerical and temporal expressions",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Named Entity -LRB- NE -RRB- items') is the appositive, depending on the noun 'expressions'. Entity 2 ('proper names, numerical and temporal expressions') is the object of the preposition 'of', depending on 'classification'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where Entity 1 clarifies what Entity 2 refers to.\"",
        "sdp_path_text": "items → names",
        "sentence": "Named Entity (NE) items include proper names, numerical and temporal expressions.",
        "sentence_llm_dp_info": "\"Entity 1 ('Named Entity (NE) items') is the subject, depending on the verb 'include'. Entity 2 ('proper names, numerical and temporal expressions') is the object, depending on the verb 'include'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the list of items that Entity 1 includes.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "proper names , numerical and temporal expressions",
                "OtherScientificTerm"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('proper names, numerical and temporal expressions') is the object of the preposition 'of', depending on 'recognition and classification'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'items'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the work done by the morphological analyzer.\"",
        "sdp_path_text": "names → in → text",
        "sentence": "Proper names, numerical and temporal expressions are recognized in Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('proper names, numerical and temporal expressions') is the subject, depending on the verb 'are recognized'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e. Named Entity -LRB- NE -RRB- items in the Japanese text .",
        "ner_pair": [
            [
                "Named Entity -LRB- NE -RRB- items",
                "OtherScientificTerm"
            ],
            [
                "Japanese text",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Named Entity -LRB- NE -RRB- items') is the object of the preposition 'of', depending on 'expressions'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'items'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence where the morphological analyzer performs tasks related to these entities.\"",
        "sdp_path_text": "items → names → in → text",
        "sentence": "Named Entity items are named in Japanese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('Named Entity -LRB- NE -RRB- items') is the subject, depending on the verb 'are named'. Entity 2 ('Japanese text') is the object of the preposition 'in', depending on 'in' in the phrase 'in Japanese text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "The analyzer is called `` Amorph '' .",
        "ner_pair": [
            [
                "analyzer",
                "Generic"
            ],
            [
                "`` Amorph ''",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('analyzer') is the subject, depending on the verb 'called'. Entity 2 ('`` Amorph ''') is the complement, depending on 'called' in the phrase 'called `` Amorph '''. There is a direct dependency between Entity 1 and Entity 2, as '`` Amorph ''' is the name given to the 'analyzer'.\"",
        "sdp_path_text": "analyzer → called → Amorph",
        "sentence": "The analyzer is called 'Amorph'.",
        "sentence_llm_dp_info": "\"Entity 1 ('analyzer') is the subject, depending on the verb 'is called'. Entity 2 ('Amorph') is the object, depending on 'called' in the phrase 'is called Amorph'. There is a direct dependency between Entity 1 and Entity 2, as 'Amorph' is the name that the 'analyzer' is called.\""
    },
    {
        "raw_sentence": "Amorph recognizes NE items in two stages : dictionary lookup and rule application .",
        "ner_pair": [
            [
                "Amorph",
                "Method"
            ],
            [
                "NE items",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Amorph') is the subject, depending on the verb 'recognizes'. Entity 2 ('NE items') is the object, depending on 'recognizes' with 'Amorph'. There is a direct dependency between Entity 1 and Entity 2, as 'Amorph' directly recognizes 'NE items'.\"",
        "sdp_path_text": "Amorph → recognizes → items",
        "sentence": "Amorph recognizes NE items.",
        "sentence_llm_dp_info": "\"Entity 1 ('Amorph') is the subject, depending on the verb 'recognizes'. Entity 2 ('NE items') is the object, depending on 'recognizes' with 'Amorph'. There is a direct dependency between Entity 1 and Entity 2, as 'NE items' is the direct object of the action performed by 'Amorph'.\""
    },
    {
        "raw_sentence": "Amorph recognizes NE items in two stages : dictionary lookup and rule application .",
        "ner_pair": [
            [
                "dictionary lookup",
                "Method"
            ],
            [
                "Amorph",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup') is part of a list, depending on the conjunction 'and' with 'rule application'. Entity 2 ('Amorph') is the subject, depending on the verb 'recognizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'dictionary lookup' is one of the stages in which 'Amorph' performs its task.\"",
        "sdp_path_text": "lookup → stages → in → recognizes → Amorph",
        "sentence": "Amorph recognizes NE items through dictionary lookup.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup') is the object, depending on the preposition 'through', which modifies the verb 'recognizes'. Entity 2 ('Amorph') is the subject, depending on the verb 'recognizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recognizes' and the preposition 'through'.\""
    },
    {
        "raw_sentence": "Amorph recognizes NE items in two stages : dictionary lookup and rule application .",
        "ner_pair": [
            [
                "rule application",
                "Method"
            ],
            [
                "Amorph",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule application') is part of the compound object, depending on 'stages' with 'and'. Entity 2 ('Amorph') is the subject, depending on the verb 'recognizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'rule application' is one of the stages in which 'Amorph' operates.\"",
        "sdp_path_text": "application → lookup → stages → in → recognizes → Amorph",
        "sentence": "Amorph recognizes NE items through rule application.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule application') is the object, depending on the preposition 'through', which modifies the verb 'recognizes'. Entity 2 ('Amorph') is the subject, depending on the verb 'recognizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'through rule application'.\""
    },
    {
        "raw_sentence": "Amorph recognizes NE items in two stages : dictionary lookup and rule application .",
        "ner_pair": [
            [
                "NE items",
                "OtherScientificTerm"
            ],
            [
                "dictionary lookup",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NE items') is the object of the verb 'recognizes', depending on 'Amorph'. Entity 2 ('dictionary lookup') is part of a list of methods, depending on the verb 'recognizes' through the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described by the verb 'recognizes'.\"",
        "sdp_path_text": "items → recognizes → in → stages → lookup",
        "sentence": "NE items are recognized in stages including dictionary lookup.",
        "sentence_llm_dp_info": "\"Entity 1 ('NE items') is the subject, depending on the verb 'are recognized'. Entity 2 ('dictionary lookup') is the object of the preposition 'including', depending on 'including' in the phrase 'including dictionary lookup'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'including'.\""
    },
    {
        "raw_sentence": "Amorph recognizes NE items in two stages : dictionary lookup and rule application .",
        "ner_pair": [
            [
                "NE items",
                "OtherScientificTerm"
            ],
            [
                "rule application",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NE items') is the object, depending on 'recognizes' with 'Amorph'. Entity 2 ('rule application') is the second item in a list, depending on 'stages' with 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of the clause describing the process of recognizing NE items.\"",
        "sdp_path_text": "items → recognizes → in → stages → lookup → application",
        "sentence": "NE items are recognized through dictionary lookup and rule application.",
        "sentence_llm_dp_info": "\"Entity 1 ('NE items') is the subject, depending on the verb 'recognized'. Entity 2 ('rule application') is part of a compound predicate, depending on the conjunction 'and' which links it with 'dictionary lookup'. There is no direct dependency between Entity 1 and Entity 2, but both are involved in the process described by the verb 'recognized'.\""
    },
    {
        "raw_sentence": "Amorph recognizes NE items in two stages : dictionary lookup and rule application .",
        "ner_pair": [
            [
                "dictionary lookup",
                "Method"
            ],
            [
                "rule application",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup') is part of the list of methods, depending on the preposition 'in' which modifies 'stages'. Entity 2 ('rule application') is also part of the list of methods, depending on the conjunction 'and' which connects it to 'dictionary lookup'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same list connected by the conjunction 'and'.\"",
        "sdp_path_text": "lookup → application",
        "sentence": "Amorph recognizes NE items through dictionary lookup and rule application.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup') is part of a coordination, depending on 'through' which modifies the verb 'recognizes'. Entity 2 ('rule application') is also part of the same coordination, depending on 'and' which connects it to 'dictionary lookup'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated under the preposition 'through'.\""
    },
    {
        "raw_sentence": "First , it uses several kinds of dictionaries to segment and tag Japanese character strings .",
        "ner_pair": [
            [
                "dictionaries",
                "OtherScientificTerm"
            ],
            [
                "it",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionaries') is the object, depending on the verb 'uses'. Entity 2 ('it') is the subject, depending on the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' where 'it' is the user of 'dictionaries'.\"",
        "sdp_path_text": "dictionaries → of → kinds → uses → it",
        "sentence": "It uses dictionaries to segment and tag Japanese character strings.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionaries') is the object, depending on the verb 'uses' with 'It'. Entity 2 ('it') is the subject, depending on the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses'.\""
    },
    {
        "raw_sentence": "First , it uses several kinds of dictionaries to segment and tag Japanese character strings .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "Japanese character strings",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'uses'. Entity 2 ('Japanese character strings') is the object, depending on 'segment and tag'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the action 'to segment and tag'.\"",
        "sdp_path_text": "it → uses → segment → tag → strings",
        "sentence": "It uses dictionaries to segment and tag Japanese character strings.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'uses'. Entity 2 ('Japanese character strings') is the object, depending on 'tag' within the compound verb phrase 'segment and tag'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the actions described by the verbs 'uses' and 'tag'.\""
    },
    {
        "raw_sentence": "First , it uses several kinds of dictionaries to segment and tag Japanese character strings .",
        "ner_pair": [
            [
                "dictionaries",
                "OtherScientificTerm"
            ],
            [
                "Japanese character strings",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionaries') is the object of the preposition 'of', depending on 'kinds'. Entity 2 ('Japanese character strings') is the object, depending on 'segment and tag'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the actions performed by 'it' (the subject of the sentence).\"",
        "sdp_path_text": "dictionaries → of → kinds → uses → segment → tag → strings",
        "sentence": "Dictionaries are used to segment and tag Japanese character strings.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionaries') is the subject, depending on the verb 'are used'. Entity 2 ('Japanese character strings') is the object, depending on the verb 'segment' and 'tag'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'segment' and 'tag' which describe the actions performed on Entity 2 using Entity 1.\""
    },
    {
        "raw_sentence": "Second , based on the information resulting from the dictionary lookup stage , a set of rules is applied to the segmented strings in order to identify NE items .",
        "ner_pair": [
            [
                "dictionary lookup stage",
                "Method"
            ],
            [
                "rules",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup stage') is the object of the preposition 'from', depending on 'resulting'. Entity 2 ('rules') is the object of the preposition 'of', depending on 'set'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the process of identifying NE items.\"",
        "sdp_path_text": "stage → from → resulting → information → on → based → applied → set → of → rules",
        "sentence": "Rules are applied based on information resulting from the dictionary lookup stage.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup stage') is the subject of the participle 'resulting', which modifies 'information'. Entity 2 ('rules') is the subject, depending on the verb 'are applied'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the information flow described in the sentence, where the information from Entity 1 influences the application of Entity 2.\""
    },
    {
        "raw_sentence": "Second , based on the information resulting from the dictionary lookup stage , a set of rules is applied to the segmented strings in order to identify NE items .",
        "ner_pair": [
            [
                "dictionary lookup stage",
                "Method"
            ],
            [
                "NE items",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup stage') is the object of the preposition 'from', depending on 'resulting' in the phrase 'resulting from the dictionary lookup stage'. Entity 2 ('NE items') is the object of the infinitive 'to identify', depending on 'identify' in the phrase 'to identify NE items'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\"",
        "sdp_path_text": "stage → from → resulting → information → on → based → applied → in → order → identify → items",
        "sentence": "Information from the dictionary lookup stage is used to identify NE items.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionary lookup stage') is the object of the preposition 'from', depending on 'information'. Entity 2 ('NE items') is the object, depending on 'identify'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the information flow described in the sentence where information from Entity 1 is used to identify Entity 2.\""
    },
    {
        "raw_sentence": "Second , based on the information resulting from the dictionary lookup stage , a set of rules is applied to the segmented strings in order to identify NE items .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "NE items",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the preposition 'of', depending on 'set' in the phrase 'a set of rules'. Entity 2 ('NE items') is the object of the infinitive 'to identify', depending on 'identify' in the phrase 'to identify NE items'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\"",
        "sdp_path_text": "rules → of → set → applied → in → order → identify → items",
        "sentence": "A set of rules is applied to identify NE items.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the preposition 'of', depending on 'set'. It also depends on the verb 'applied' as the subject of the passive clause. Entity 2 ('NE items') is the object of the verb 'identify', depending on 'identify'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' and the purpose of the action, which is to 'identify NE items'.\""
    },
    {
        "raw_sentence": "We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .",
        "ner_pair": [
            [
                "priori geometric constraints",
                "OtherScientificTerm"
            ],
            [
                "3 -- D stereo reconstruction scheme",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priori geometric constraints') is the object of the preposition 'incorporate', depending on 'incorporate' in the phrase 'to incorporate a priori geometric constraints'. Entity 2 ('3 -- D stereo reconstruction scheme') is the object of the preposition 'in', depending on 'in' in the phrase 'in a 3 -- D stereo reconstruction scheme'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what is being incorporated into what.\"",
        "sdp_path_text": "constraints → incorporate → in → scheme",
        "sentence": "We propose to incorporate priori geometric constraints in a 3-D stereo reconstruction scheme.",
        "sentence_llm_dp_info": "\"Entity 1 ('priori geometric constraints') is the object of the preposition 'incorporate', depending on 'incorporate' in the phrase 'to incorporate priori geometric constraints'. Entity 2 ('3-D stereo reconstruction scheme') is the object of the preposition 'in', depending on 'in' in the phrase 'in a 3-D stereo reconstruction scheme'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger action described by the verb 'propose'.\""
    },
    {
        "raw_sentence": "We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .",
        "ner_pair": [
            [
                "priori geometric constraints",
                "OtherScientificTerm"
            ],
            [
                "image information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priori geometric constraints') is the object of the preposition 'incorporate', depending on 'incorporate' in the phrase 'to incorporate a priori geometric constraints'. Entity 2 ('image information') is the subject complement, depending on 'is' in the clause 'where image information alone is not sufficient'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "constraints → incorporate → cope → with → cases → is → information",
        "sentence": "We propose to incorporate a priori geometric constraints to cope with cases where image information is insufficient.",
        "sentence_llm_dp_info": "\"Entity 1 ('priori geometric constraints') is the object of the preposition 'a', depending on 'incorporate' in the phrase 'to incorporate a priori geometric constraints'. Entity 2 ('image information') is the subject complement, depending on 'is' in the phrase 'where image information is insufficient'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence describing the conditions under which the constraints are incorporated.\""
    },
    {
        "raw_sentence": "We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .",
        "ner_pair": [
            [
                "priori geometric constraints",
                "OtherScientificTerm"
            ],
            [
                "3 -- D shape",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priori geometric constraints') is the object of the preposition 'incorporate', depending on 'incorporate' in the phrase 'to incorporate a priori geometric constraints'. Entity 2 ('3 -- D shape') is the object of the infinitive 'recover', depending on 'recover' in the phrase 'to accurately recover 3 -- D shape'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and contribute to the overall purpose described in the sentence.\"",
        "sdp_path_text": "constraints → incorporate → cope → with → cases → is → sufficient → recover → shape",
        "sentence": "We propose to incorporate priori geometric constraints to cope with cases where image information is not sufficient to recover 3 -- D shape.",
        "sentence_llm_dp_info": "\"Entity 1 ('priori geometric constraints') is the object of the preposition 'to', depending on 'incorporate' in the phrase 'to incorporate priori geometric constraints'. Entity 2 ('3 -- D shape') is the object of the infinitive 'to recover', depending on 'recover' in the phrase 'to recover 3 -- D shape'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, connected through the verbs 'incorporate' and 'recover'.\""
    },
    {
        "raw_sentence": "We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .",
        "ner_pair": [
            [
                "3 -- D stereo reconstruction scheme",
                "Method"
            ],
            [
                "image information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('3 -- D stereo reconstruction scheme') is the object of the preposition 'in', depending on 'incorporate'. Entity 2 ('image information') is the subject, depending on 'is' in the clause 'image information alone is not sufficient'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose of incorporating constraints into the scheme to address limitations of Entity 2.\"",
        "sdp_path_text": "scheme → in → incorporate → cope → with → cases → is → information",
        "sentence": "A 3-D stereo reconstruction scheme incorporates image information to cope with cases where it is insufficient.",
        "sentence_llm_dp_info": "\"Entity 1 ('3-D stereo reconstruction scheme') is the subject, depending on the verb 'incorporates'. Entity 2 ('image information') is the direct object, depending on 'incorporates' in the phrase 'incorporates image information'. There is a direct dependency between Entity 1 and Entity 2, as 'image information' is directly incorporated by the '3-D stereo reconstruction scheme'.\""
    },
    {
        "raw_sentence": "We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .",
        "ner_pair": [
            [
                "3 -- D stereo reconstruction scheme",
                "Method"
            ],
            [
                "3 -- D shape",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('3 -- D stereo reconstruction scheme') is the object of the preposition 'in', depending on 'incorporate' with 'geometric constraints'. Entity 2 ('3 -- D shape') is the object of the preposition 'to', depending on 'recover' with 'accurately'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the purpose of incorporating geometric constraints into the reconstruction scheme.\"",
        "sdp_path_text": "scheme → in → incorporate → cope → with → cases → is → sufficient → recover → shape",
        "sentence": "A 3-D stereo reconstruction scheme incorporates geometric constraints to cope with cases insufficient for recovering 3-D shape.",
        "sentence_llm_dp_info": "\"Entity 1 ('3-D stereo reconstruction scheme') is the subject, depending on the verb 'incorporates'. Entity 2 ('3-D shape') is the object of the preposition 'for', depending on 'recovering' in the phrase 'for recovering 3-D shape'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the purpose clause 'to cope with cases insufficient for recovering 3-D shape'.\""
    },
    {
        "raw_sentence": "We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .",
        "ner_pair": [
            [
                "image information",
                "OtherScientificTerm"
            ],
            [
                "3 -- D shape",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image information') is the subject of the clause, depending on 'is' with 'not sufficient'. Entity 2 ('3 -- D shape') is the object, depending on 'recover' with 'accurately'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence, where the insufficiency of Entity 1 to accurately recover Entity 2 is described.\"",
        "sdp_path_text": "information → is → sufficient → recover → shape",
        "sentence": "Image information is not sufficient to accurately recover 3--D shape.",
        "sentence_llm_dp_info": "\"Entity 1 ('image information') is the subject, depending on the verb 'is' in the phrase 'is not sufficient'. Entity 2 ('3--D shape') is the object, depending on 'recover' in the phrase 'to accurately recover 3--D shape'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recover' and the adverb 'accurately'.\""
    },
    {
        "raw_sentence": "Our approach is based on the iterative deformation of a 3 -- D surface mesh to minimize an objective function .",
        "ner_pair": [
            [
                "iterative deformation of a 3 -- D surface mesh",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('iterative deformation of a 3 -- D surface mesh') is the object of the preposition 'on', depending on 'based' in the phrase 'based on'. Entity 2 ('approach') is the subject, depending on the verb 'is' in the phrase 'is based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' which links 'approach' to 'iterative deformation of a 3 -- D surface mesh'.\"",
        "sdp_path_text": "deformation → on → based → approach",
        "sentence": "Our approach is based on the iterative deformation of a 3-D surface mesh.",
        "sentence_llm_dp_info": "\"Entity 1 ('iterative deformation of a 3-D surface mesh') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the iterative deformation of a 3-D surface mesh'. Entity 2 ('approach') is the subject, depending on the verb 'is' in the phrase 'Our approach is based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' and the verb 'based'.\""
    },
    {
        "raw_sentence": "Our approach is based on the iterative deformation of a 3 -- D surface mesh to minimize an objective function .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "objective function",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is' with 'based'. Entity 2 ('objective function') is the object, depending on 'minimize' with 'to minimize'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'to minimize an objective function'.\"",
        "sdp_path_text": "approach → based → on → deformation → minimize → function",
        "sentence": "Our approach is based on deforming a surface mesh to minimize the objective function.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is' with 'based'. Entity 2 ('objective function') is the object, depending on 'minimize' with 'to minimize'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to minimize the objective function'.\""
    },
    {
        "raw_sentence": "Our approach is based on the iterative deformation of a 3 -- D surface mesh to minimize an objective function .",
        "ner_pair": [
            [
                "iterative deformation of a 3 -- D surface mesh",
                "Method"
            ],
            [
                "objective function",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('iterative deformation of a 3 -- D surface mesh') is the object of the preposition 'on', depending on 'based' in the phrase 'based on'. Entity 2 ('objective function') is the object of the verb 'minimize', depending on 'minimize' in the phrase 'to minimize an objective function'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the purpose of the approach.\"",
        "sdp_path_text": "deformation → minimize → function",
        "sentence": "Iterative deformation of a 3-D surface mesh minimizes the objective function.",
        "sentence_llm_dp_info": "\"Entity 1 ('iterative deformation of a 3-D surface mesh') is the subject, depending on the verb 'minimizes'. Entity 2 ('objective function') is the object, depending on the verb 'minimizes'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 performs the action that affects Entity 2.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "anisotropic meshing",
                "Method"
            ],
            [
                "non-quadratic approach",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of a compound object, depending on 'combining' with 'with'. Entity 2 ('non-quadratic approach') is also part of the compound object, depending on 'with' in the phrase 'with a non-quadratic approach'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of the compound object being combined.\"",
        "sdp_path_text": "meshing → combining → with → approach",
        "sentence": "Combining anisotropic meshing with a non-quadratic approach enables satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of a compound subject, depending on the conjunction 'with' that links it to 'non-quadratic approach'. Entity 2 ('non-quadratic approach') is also part of the compound subject, linked to 'anisotropic meshing' through the conjunction 'with'. Both together depend on the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'with'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "anisotropic meshing",
                "Method"
            ],
            [
                "regularization",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of a compound subject, depending on 'combining' with 'with'. Entity 2 ('regularization') is the object of the preposition 'to', depending on 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of the method described in the sentence, which is combined to enable satisfactory reconstruction results.\"",
        "sdp_path_text": "meshing → combining → with → approach → to → regularization",
        "sentence": "Combining anisotropic meshing with a non-quadratic approach to regularization enables satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of a compound subject, depending on 'Combining' with the conjunction 'with'. Entity 2 ('regularization') is the object of the preposition 'to', depending on 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the subject that enables the satisfactory reconstruction results.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "anisotropic meshing",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of the conjunction, depending on 'combining' with 'with'. Entity 2 ('reconstruction') is the object, depending on 'obtain' with 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'enables' which leads to the action of obtaining 'reconstruction results'.\"",
        "sdp_path_text": "meshing → combining → enables → obtain → results → reconstruction",
        "sentence": "Combining anisotropic meshing enables satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is the object of the verb 'Combining', which acts as the subject of the sentence. Entity 2 ('reconstruction') is part of the noun phrase 'reconstruction results', which is the object of the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables' that indicates the relationship where 'anisotropic meshing' contributes to enabling 'reconstruction results'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "anisotropic meshing",
                "Method"
            ],
            [
                "triangulations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of a coordination, depending on 'combining' with 'a non-quadratic approach'. Entity 2 ('triangulations') is the object of the preposition 'using', depending on 'using' in the phrase 'using triangulations with few vertices'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described in the sentence.\"",
        "sdp_path_text": "meshing → combining → enables → obtain → using → triangulations",
        "sentence": "Combining anisotropic meshing enables obtaining satisfactory results using triangulations.",
        "sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is the object of the verb 'Combining', indicating it is being combined. Entity 2 ('triangulations') is the object of the preposition 'using', depending on 'using' in the phrase 'using triangulations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the process that leads to 'obtaining satisfactory results'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "anisotropic meshing",
                "Method"
            ],
            [
                "vertices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is part of a compound subject, depending on 'combining' with 'with a non-quadratic approach'. Entity 2 ('vertices') is the object of the preposition 'with', depending on 'triangulations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of obtaining satisfactory reconstruction results.\"",
        "sdp_path_text": "meshing → combining → enables → obtain → using → triangulations → with → vertices",
        "sentence": "Combining anisotropic meshing enables obtaining satisfactory results using triangulations with few vertices.",
        "sentence_llm_dp_info": "\"Entity 1 ('anisotropic meshing') is the object of the verb 'Combining', which is the subject of the sentence. Entity 2 ('vertices') is part of a prepositional phrase, acting as the object of the preposition 'with', modifying 'triangulations'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the method that combines anisotropic meshing to achieve results with triangulations that have few vertices.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "non-quadratic approach",
                "Method"
            ],
            [
                "regularization",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is the object of the preposition 'to', depending on 'with' in the phrase 'with a non-quadratic approach to regularization'. Entity 2 ('regularization') is the object of the preposition 'to', depending on 'approach' in the same phrase 'a non-quadratic approach to regularization'. There is a direct dependency between Entity 1 and Entity 2, as 'regularization' is directly linked to 'non-quadratic approach' through the preposition 'to'.\"",
        "sdp_path_text": "approach → to → regularization",
        "sentence": "A non-quadratic approach to regularization enables satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is the subject, depending on the verb 'enables'. Entity 2 ('regularization') is the object of the preposition 'to', depending on 'to' in the phrase 'to regularization'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "non-quadratic approach",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is the object of the preposition 'with', depending on 'combining'. Entity 2 ('reconstruction') is part of the compound noun 'reconstruction results', depending on 'obtain'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the logical flow of the sentence where 'non-quadratic approach' contributes to enabling the 'reconstruction results'.\"",
        "sdp_path_text": "approach → with → combining → enables → obtain → results → reconstruction",
        "sentence": "A non-quadratic approach combined with anisotropic meshing enables satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is the subject, depending on 'enables' as the verb. Entity 2 ('reconstruction') is part of the compound noun 'reconstruction results', which is the object of the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables' and the compound noun 'reconstruction results'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "non-quadratic approach",
                "Method"
            ],
            [
                "triangulations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is part of the object of the preposition 'with', depending on 'combining'. Entity 2 ('triangulations') is the object of the preposition 'using', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the overall meaning of the sentence by being part of different clauses.\"",
        "sdp_path_text": "approach → with → combining → enables → obtain → using → triangulations",
        "sentence": "A non-quadratic approach combined with anisotropic meshing enables obtaining results using triangulations.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is part of a compound noun, depending on 'combined' with 'with'. Entity 2 ('triangulations') is the object of the preposition 'using', depending on 'using' in the phrase 'using triangulations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause that describes how the approach and meshing enable the obtaining of results.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "non-quadratic approach",
                "Method"
            ],
            [
                "vertices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is part of the prepositional phrase 'with a non-quadratic approach to regularization', where it serves as the object of the preposition 'with', depending on 'combining'. Entity 2 ('vertices') is the object of the preposition 'with' in the phrase 'with few vertices', depending on 'triangulations'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that contribute to the overall meaning of the sentence.\"",
        "sdp_path_text": "approach → with → combining → enables → obtain → using → triangulations → with → vertices",
        "sentence": "A non-quadratic approach combined with anisotropic meshing enables obtaining satisfactory results using triangulations with few vertices.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-quadratic approach') is part of the subject, depending on 'enables' as a nominal subject. Entity 2 ('vertices') is part of the object complement, depending on 'triangulations' in the prepositional phrase 'with few vertices'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "regularization",
                "OtherScientificTerm"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regularization') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('reconstruction') is the object of the verb 'obtain', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contribute to the overall meaning of the sentence.\"",
        "sdp_path_text": "regularization → to → approach → with → combining → enables → obtain → results → reconstruction",
        "sentence": "Combining anisotropic meshing with a non-quadratic approach to regularization enables satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('regularization') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('reconstruction') is the object of the noun 'results', depending on 'results' in the phrase 'reconstruction results'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the effect of combining anisotropic meshing with a non-quadratic approach.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "regularization",
                "OtherScientificTerm"
            ],
            [
                "triangulations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regularization') is part of the prepositional phrase 'to regularization', which modifies 'approach'. Entity 2 ('triangulations') is the object of the preposition 'using', depending on 'using' in the phrase 'using triangulations'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "regularization → to → approach → with → combining → enables → obtain → using → triangulations",
        "sentence": "Combining a non-quadratic approach to regularization enables obtaining results using triangulations.",
        "sentence_llm_dp_info": "\"Entity 1 ('regularization') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('triangulations') is the object of the preposition 'using', depending on 'obtaining'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "regularization",
                "OtherScientificTerm"
            ],
            [
                "vertices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regularization') is part of the prepositional phrase 'to regularization', which modifies 'approach'. Entity 1 depends on 'approach' through the preposition 'to'. Entity 2 ('vertices') is the object of the preposition 'with', modifying the noun 'triangulations'. Entity 2 depends on 'triangulations' through the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "regularization → to → approach → with → combining → enables → obtain → using → triangulations → with → vertices",
        "sentence": "Combining a non-quadratic approach to regularization enables obtaining satisfactory results using triangulations with few vertices.",
        "sentence_llm_dp_info": "\"Entity 1 ('regularization') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('vertices') is part of a prepositional phrase, depending on 'triangulations'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "triangulations",
                "OtherScientificTerm"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulations') is the object of the preposition 'using', depending on 'using' in the phrase 'using triangulations'. Entity 2 ('reconstruction') is part of the noun phrase 'reconstruction results', which is the object of the verb 'obtain'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'triangulations' is used as a tool or method to achieve 'reconstruction results'.\"",
        "sdp_path_text": "triangulations → using → obtain → results → reconstruction",
        "sentence": "Triangulations with few vertices enable satisfactory reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulations') is the subject, depending on the verb 'enable'. Entity 2 ('reconstruction') is part of the noun phrase 'reconstruction results', which is the object of the verb 'enable'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enable' and the noun phrase 'reconstruction results'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "reconstruction",
                "Task"
            ],
            [
                "vertices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the noun phrase 'satisfactory reconstruction results', acting as the object of the verb 'obtain'. Entity 2 ('vertices') is the object of the preposition 'with', specifying a characteristic of the triangulations used in the process. There is no direct dependency between Entity 1 and Entity 2; both are part of the clause describing the outcome of the method discussed.\"",
        "sdp_path_text": "reconstruction → results → obtain → using → triangulations → with → vertices",
        "sentence": "{\n  \"Simplified sentence\": \"Combining anisotropic meshing with a non-quadratic approach to regularization enables satisfactory reconstruction results using triangulations with few vertices.\"\n} \n\nHowever, to strictly adhere to the instructions and focus on the SDP while removing extraneous information, a more concise version would be:\n\n{\n  \"Simplified sentence\": \"Satisfactory reconstruction results are obtained using triangulations with few vertices.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the compound noun 'reconstruction results', which is the subject of the passive clause, depending on the verb 'are obtained'. Entity 2 ('vertices') is the object of the preposition 'with', depending on 'with' in the phrase 'with few vertices'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'reconstruction results' are described as being obtained 'using triangulations with few vertices'.\""
    },
    {
        "raw_sentence": "We show that combining anisotropic meshing with a non-quadratic approach to regularization enables us to obtain satisfactory reconstruction results using triangulations with few vertices .",
        "ner_pair": [
            [
                "triangulations",
                "OtherScientificTerm"
            ],
            [
                "vertices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulations') is the object of the preposition 'using', depending on 'using' in the phrase 'using triangulations'. Entity 2 ('vertices') is the object of the preposition 'with', depending on 'with' in the phrase 'with few vertices'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase 'using triangulations with few vertices'.\"",
        "sdp_path_text": "triangulations → with → vertices",
        "sentence": "Triangulations use few vertices.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulations') is the subject, depending on the verb 'use'. Entity 2 ('vertices') is the object, depending on 'use' with 'few'. There is a direct dependency between Entity 1 and Entity 2, as 'vertices' is the direct object of the action 'use' performed by 'triangulations'.\""
    },
    {
        "raw_sentence": "Structural or numerical constraints can then be added locally to the reconstruction process through a constrained optimization scheme .",
        "ner_pair": [
            [
                "Structural or numerical constraints",
                "OtherScientificTerm"
            ],
            [
                "reconstruction process",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Structural or numerical constraints') is the subject, depending on the verb 'can be added'. Entity 2 ('reconstruction process') is the object of the preposition 'to', depending on 'to' in the phrase 'to the reconstruction process'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' and the verb 'added'.\"",
        "sdp_path_text": "constraints → added → to → process",
        "sentence": "Structural or numerical constraints can be added to the reconstruction process.",
        "sentence_llm_dp_info": "\"Entity 1 ('Structural or numerical constraints') is the subject, depending on the verb 'can be added'. Entity 2 ('reconstruction process') is the object of the preposition 'to', depending on 'to' in the phrase 'to the reconstruction process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "Structural or numerical constraints can then be added locally to the reconstruction process through a constrained optimization scheme .",
        "ner_pair": [
            [
                "constrained optimization scheme",
                "Method"
            ],
            [
                "Structural or numerical constraints",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('constrained optimization scheme') is the object, depending on the preposition 'through', which itself depends on the verb 'be added'. Entity 2 ('Structural or numerical constraints') is the subject, depending on the verb 'can be added'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'through a constrained optimization scheme'.\"",
        "sdp_path_text": "scheme → through → added → constraints",
        "sentence": "Structural or numerical constraints can be added through a constrained optimization scheme.",
        "sentence_llm_dp_info": "\"Entity 1 ('constrained optimization scheme') is the object, depending on the verb 'be' (can be). Entity 2 ('Structural or numerical constraints') is the subject, depending on the verb 'can be added'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'be added' which indicates that Entity 2 can be added through Entity 1.\""
    },
    {
        "raw_sentence": "Structural or numerical constraints can then be added locally to the reconstruction process through a constrained optimization scheme .",
        "ner_pair": [
            [
                "reconstruction process",
                "Method"
            ],
            [
                "constrained optimization scheme",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction process') is the object of the preposition 'to', depending on 'added' in the phrase 'added locally to the reconstruction process'. Entity 2 ('constrained optimization scheme') is the object of the preposition 'through', depending on 'added' in the phrase 'through a constrained optimization scheme'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'constraints' can be added to the 'reconstruction process' through the 'constrained optimization scheme'.\"",
        "sdp_path_text": "process → to → added → through → scheme",
        "sentence": "Constraints can be added to the reconstruction process through a constrained optimization scheme.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction process') is the object of the preposition 'to', depending on 'added' in the phrase 'added to the reconstruction process'. Entity 2 ('constrained optimization scheme') is the subject complement, depending on 'through' in the phrase 'through a constrained optimization scheme'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'added' and the preposition 'through'.\""
    },
    {
        "raw_sentence": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .",
        "ner_pair": [
            [
                "They",
                "Generic"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('They') is the subject, depending on the verb 'improve'. Entity 2 ('reconstruction') is part of the compound noun 'reconstruction results', which is the object of the verb 'improve'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'improve' and the compound noun 'reconstruction results'.\"",
        "sdp_path_text": "They → improve → results → reconstruction",
        "sentence": "They improve reconstruction results.",
        "sentence_llm_dp_info": "\"Entity 1 ('They') is the subject, depending on the verb 'improve'. Entity 2 ('reconstruction') is part of the compound noun 'reconstruction results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the noun 'results'.\""
    },
    {
        "raw_sentence": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .",
        "ner_pair": [
            [
                "They",
                "Generic"
            ],
            [
                "priori knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('They') is the subject, depending on the verb 'improve'. Entity 2 ('priori knowledge') is part of a noun phrase functioning as the complement of the preposition 'with', depending on 'with' in the phrase 'with a priori knowledge'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where 'They' performs actions that involve 'priori knowledge'.\"",
        "sdp_path_text": "They → improve → enforce → consistency → with → knowledge",
        "sentence": "They improve results and enforce consistency with priori knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('They') is the subject, depending on the verb 'improve'. Entity 2 ('priori knowledge') is the object of the preposition 'with', depending on 'with' in the phrase 'with priori knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .",
        "ner_pair": [
            [
                "They",
                "Generic"
            ],
            [
                "object shape",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('They') is the subject, depending on the verb 'improve'. Entity 2 ('object shape') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause that describes how 'They' improve results and enforce consistency with knowledge about 'object shape'.\"",
        "sdp_path_text": "They → improve → enforce → consistency → with → knowledge → about → shape",
        "sentence": "They improve results and enforce consistency with knowledge about object shape.",
        "sentence_llm_dp_info": "\"Entity 1 ('They') is the subject, depending on the verb 'improve'. Entity 2 ('object shape') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve' and the prepositional phrase 'with knowledge about object shape'.\""
    },
    {
        "raw_sentence": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .",
        "ner_pair": [
            [
                "reconstruction",
                "Task"
            ],
            [
                "priori knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the noun phrase 'reconstruction results', acting as the object of the verb 'improve'. Entity 2 ('priori knowledge') is the object of the preposition 'with', specifying the type of knowledge used to enforce consistency. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'enforce' and the preposition 'with' that connects them to the concept of consistency.\"",
        "sdp_path_text": "reconstruction → results → improve → enforce → consistency → with → knowledge",
        "sentence": "They improve reconstruction results and enforce consistency with priori knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the compound noun 'reconstruction results', which is the object of the verb 'improve'. Entity 2 ('priori knowledge') is the object of the preposition 'with', indicating the means or the standard by which consistency is enforced. There is no direct dependency between Entity 1 and Entity 2; they are both related to different parts of the sentence structure.\""
    },
    {
        "raw_sentence": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .",
        "ner_pair": [
            [
                "reconstruction",
                "Task"
            ],
            [
                "object shape",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the compound noun 'reconstruction results', where it depends on 'results' as a modifier. Entity 2 ('object shape') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, particularly through the phrase 'a priori knowledge about object shape' which influences the consistency enforced on the 'reconstruction results'.\"",
        "sdp_path_text": "reconstruction → results → improve → enforce → consistency → with → knowledge → about → shape",
        "sentence": "They improve reconstruction results and enforce consistency with knowledge about object shape.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the compound noun 'reconstruction results', which is the object of the verb 'improve'. Entity 2 ('object shape') is the object of the preposition 'about', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the improvements and enforcement actions described in the sentence.\""
    },
    {
        "raw_sentence": "They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .",
        "ner_pair": [
            [
                "object shape",
                "OtherScientificTerm"
            ],
            [
                "priori knowledge",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object shape') is the object of the preposition 'about', depending on 'knowledge'. Entity 2 ('priori knowledge') is the noun modifier, depending on 'with' in the phrase 'with a priori knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'about' where 'object shape' modifies 'priori knowledge'.\"",
        "sdp_path_text": "shape → about → knowledge",
        "sentence": "They enforce consistency with priori knowledge about object shape.",
        "sentence_llm_dp_info": "\"Entity 1 ('object shape') is the object of the preposition 'about', depending on 'priori knowledge'. Entity 2 ('priori knowledge') is the complement of the preposition 'with', depending on 'enforce consistency'. There is a direct dependency between Entity 1 and Entity 2, as 'object shape' is part of the prepositional phrase that modifies 'priori knowledge'.\""
    },
    {
        "raw_sentence": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3 -- D reconstruction .",
        "ner_pair": [
            [
                "modeling properties",
                "OtherScientificTerm"
            ],
            [
                "differential features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('modeling properties') is part of a compound noun phrase, depending on 'description' with the conjunction 'and'. Entity 2 ('differential features') is the subject, depending on the verb 'make'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the noun phrase that serves as the subject of the sentence, connected through the conjunction 'and'.\"",
        "sdp_path_text": "properties → description → of → features",
        "sentence": "The modeling properties and strong description of differential features make them useful tools.",
        "sentence_llm_dp_info": "\"Entity 1 ('modeling properties') is part of a conjunction, depending on 'and' with 'strong description'. Entity 2 ('differential features') is the object of the preposition 'of', depending on 'description'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that serves as the subject of the verb 'make'.\""
    },
    {
        "raw_sentence": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3 -- D reconstruction .",
        "ner_pair": [
            [
                "modeling properties",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('modeling properties') is part of a compound noun, depending on 'description' with the conjunction 'and'. Entity 2 ('them') is a pronoun, depending on 'make' as its object. There is a direct dependency between Entity 1 and Entity 2, where 'them' refers back to the compound noun including 'modeling properties'.\"",
        "sdp_path_text": "properties → description → make → tools → them",
        "sentence": "The modeling properties make them useful tools.",
        "sentence_llm_dp_info": "\"Entity 1 ('modeling properties') is the subject, depending on the verb 'make'. Entity 2 ('them') is the object, depending on 'make' with 'modeling properties'. There is a direct dependency between Entity 1 and Entity 2, as 'them' is directly affected by the action of 'make' performed by 'modeling properties'.\""
    },
    {
        "raw_sentence": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3 -- D reconstruction .",
        "ner_pair": [
            [
                "modeling properties",
                "OtherScientificTerm"
            ],
            [
                "3 -- D reconstruction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('modeling properties') is part of the compound subject, depending on the conjunction 'and' with 'description'. It is also modified by the adjective 'strong'. Entity 2 ('3 -- D reconstruction') is the object of the preposition 'for', depending on 'for' in the phrase 'for 3 -- D reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'make' and the prepositional phrase 'as constraints for 3 -- D reconstruction'.\"",
        "sdp_path_text": "properties → description → make → tools → used → as → constraints → for → reconstruction",
        "sentence": "Modeling properties make differential features useful tools for 3-D reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('modeling properties') is the subject, depending on the verb 'make'. Entity 2 ('3-D reconstruction') is the object of the preposition 'for', depending on 'for' in the phrase 'for 3-D reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'make' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3 -- D reconstruction .",
        "ner_pair": [
            [
                "differential features",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('differential features') is the subject, depending on the verb 'make'. Entity 2 ('them') is the object, referring back to 'differential features' and depending on the verb 'make'. There is a direct dependency between Entity 1 and Entity 2, where 'them' is a pronoun referring to 'differential features' and both are part of the clause describing what makes these features useful.\"",
        "sdp_path_text": "features → of → description → make → tools → them",
        "sentence": "Differential features make them useful tools.",
        "sentence_llm_dp_info": "\"Entity 1 ('differential features') is the subject, depending on the verb 'make'. Entity 2 ('them') is the object, depending on 'make' in the phrase 'make them'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'make'.\""
    },
    {
        "raw_sentence": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3 -- D reconstruction .",
        "ner_pair": [
            [
                "differential features",
                "OtherScientificTerm"
            ],
            [
                "3 -- D reconstruction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('differential features') is the subject, depending on the verb 'make'. Entity 2 ('3 -- D reconstruction') is the object of the preposition 'for', depending on 'constraints'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'tools' and the prepositional phrase 'as constraints for 3 -- D reconstruction'.\"",
        "sdp_path_text": "features → of → description → make → tools → used → as → constraints → for → reconstruction",
        "sentence": "Differential features are useful tools used as constraints for 3-D reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('differential features') is the subject, depending on 'are' as the main verb. Entity 2 ('3-D reconstruction') is the object, depending on 'for' which indicates the purpose or beneficiary of the action described by the verb 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the preposition 'for', indicating that differential features are used as constraints for the 3-D reconstruction process.\""
    },
    {
        "raw_sentence": "The strong description and modeling properties of differential features make them useful tools that can be efficiently used as constraints for 3 -- D reconstruction .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "3 -- D reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on the verb 'make' with 'properties'. Entity 2 ('3 -- D reconstruction') is the object of the preposition 'for', depending on 'for' in the phrase 'for 3 -- D reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the preposition 'for'.\"",
        "sdp_path_text": "them → tools → used → as → constraints → for → reconstruction",
        "sentence": "Differential features are useful tools that can be used as constraints for 3-D reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'used' with 'can be used'. Entity 2 ('3-D reconstruction') is the object of the preposition 'for', depending on 'for' in the phrase 'for 3-D reconstruction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This work proposes a new research direction to address the lack of structures in traditional n-gram models .",
        "ner_pair": [
            [
                "lack of structures",
                "OtherScientificTerm"
            ],
            [
                "n-gram models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lack of structures') is the object of the preposition 'of', depending on 'address' in the phrase 'to address the lack of structures'. Entity 2 ('n-gram models') is the object of the preposition 'in', depending on 'structures' in the phrase 'lack of structures in traditional n-gram models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "lack → in → models",
        "sentence": "The work addresses the lack of structures in n-gram models.",
        "sentence_llm_dp_info": "\"Entity 1 ('lack of structures') is the object of the preposition 'of', depending on 'addresses' with 'The work'. Entity 2 ('n-gram models') is the object of the preposition 'in', depending on 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'of structures' and 'in n-gram models'.\""
    },
    {
        "raw_sentence": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus .",
        "ner_pair": [
            [
                "weakly supervised dependency parser",
                "Task"
            ],
            [
                "speech syntax",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('weakly supervised dependency parser') is the subject complement, depending on 'based' with 'It'. Entity 2 ('speech syntax') is the object, depending on 'model' with 'can'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'can model'.\"",
        "sdp_path_text": "parser → model → syntax",
        "sentence": "A weakly supervised dependency parser models speech syntax.",
        "sentence_llm_dp_info": "\"Entity 1 ('weakly supervised dependency parser') is the subject, depending on the verb 'models'. Entity 2 ('speech syntax') is the object, depending on 'models' with 'weakly supervised dependency parser'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is modeling Entity 2.\""
    },
    {
        "raw_sentence": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus .",
        "ner_pair": [
            [
                "weakly supervised dependency parser",
                "Task"
            ],
            [
                "annotated training corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('weakly supervised dependency parser') is the subject complement, depending on 'based' with 'is based on'. Entity 2 ('annotated training corpus') is the object of the preposition 'on', depending on 'relying' in the phrase 'relying on any annotated training corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the negation 'without' which indicates that Entity 1 does not depend on Entity 2.\"",
        "sdp_path_text": "parser → model → without → relying → on → corpus",
        "sentence": "A weakly supervised dependency parser models speech syntax without relying on an annotated training corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('weakly supervised dependency parser') is the subject, depending on the verb 'models'. Entity 2 ('annotated training corpus') is the object of the preposition 'on', depending on 'relying' in the phrase 'without relying on an annotated training corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'without relying on'.\""
    },
    {
        "raw_sentence": "It is based on a weakly supervised dependency parser that can model speech syntax without relying on any annotated training corpus .",
        "ner_pair": [
            [
                "speech syntax",
                "OtherScientificTerm"
            ],
            [
                "annotated training corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech syntax') is the object, depending on 'model' with 'can'. Entity 2 ('annotated training corpus') is the object, depending on 'relying' with 'without'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "syntax → model → without → relying → on → corpus",
        "sentence": "Speech syntax can be modeled without relying on an annotated training corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech syntax') is the subject, depending on the verb 'can be modeled'. Entity 2 ('annotated training corpus') is the object of the preposition 'on', depending on 'relying'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'without relying on'.\""
    },
    {
        "raw_sentence": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge .",
        "ner_pair": [
            [
                "Labeled data",
                "OtherScientificTerm"
            ],
            [
                "hand-crafted rules",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Labeled data') is the subject, depending on the verb 'replaced'. Entity 2 ('hand-crafted rules') is the object, depending on 'by' in the phrase 'by a few hand-crafted rules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'replaced' and the preposition 'by'.\"",
        "sdp_path_text": "data → replaced → by → rules",
        "sentence": "Labeled data is replaced by hand-crafted rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('Labeled data') is the subject, depending on the passive verb 'is replaced'. Entity 2 ('hand-crafted rules') is the object, depending on 'replaced' in the phrase 'replaced by hand-crafted rules'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the agent that replaces Entity 1.\""
    },
    {
        "raw_sentence": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge .",
        "ner_pair": [
            [
                "Labeled data",
                "OtherScientificTerm"
            ],
            [
                "syntactic knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Labeled data') is the subject, depending on the verb 'replaced'. Entity 2 ('syntactic knowledge') is the object, depending on 'encode' with 'rules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'replaced' and the clause that follows.\"",
        "sdp_path_text": "data → replaced → by → rules → encode → knowledge",
        "sentence": "Labeled data is replaced by rules that encode syntactic knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('Labeled data') is the subject, depending on the verb 'replaced'. Entity 2 ('syntactic knowledge') is the object of the preposition 'by', depending on 'encode' in the phrase 'that encode syntactic knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'replaced' and the relative clause 'that encode syntactic knowledge'.\""
    },
    {
        "raw_sentence": "Labeled data is replaced by a few hand-crafted rules that encode basic syntactic knowledge .",
        "ner_pair": [
            [
                "hand-crafted rules",
                "OtherScientificTerm"
            ],
            [
                "syntactic knowledge",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hand-crafted rules') is the object, depending on 'replaced' with 'data'. Entity 2 ('syntactic knowledge') is the object, depending on 'encode' with 'rules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'encode'.\"",
        "sdp_path_text": "rules → encode → knowledge",
        "sentence": "Hand-crafted rules encode syntactic knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('hand-crafted rules') is the subject, depending on the verb 'encode'. Entity 2 ('syntactic knowledge') is the object, depending on 'encode' with 'hand-crafted rules'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 encodes Entity 2.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "Bayesian inference",
                "Method"
            ],
            [
                "rules",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('rules') is the object, depending on 'samples' with 'Bayesian inference'. There is a direct dependency between Entity 1 and Entity 2, as 'Bayesian inference' is the agent performing the action of sampling 'rules'.\"",
        "sdp_path_text": "inference → samples → rules",
        "sentence": "Bayesian inference samples rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('rules') is the object, depending on 'samples' with 'Bayesian inference'. There is a direct dependency between Entity 1 and Entity 2, where 'Bayesian inference' is sampling 'rules'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "Bayesian inference",
                "Method"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('them') is the object, depending on 'combining' with 'rules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of sampling and combining rules.\"",
        "sdp_path_text": "inference → samples → disambiguating → combining → them",
        "sentence": "Bayesian inference samples and combines rules to disambiguate them.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('them') is the object, depending on the verb 'disambiguate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'samples' and 'disambiguate' in the sentence.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "Bayesian inference",
                "Method"
            ],
            [
                "complex tree structures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('complex tree structures') is the object, depending on 'create' with 'combining them'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through a series of actions described in the sentence, where 'Bayesian inference' leads to the creation of 'complex tree structures'.\"",
        "sdp_path_text": "inference → samples → disambiguating → combining → create → structures",
        "sentence": "Bayesian inference creates complex tree structures by sampling and combining rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'creates'. Entity 2 ('complex tree structures') is the direct object, depending on the verb 'creates'. There is a direct dependency between Entity 1 and Entity 2, as 'Bayesian inference' is the agent that performs the action of creating 'complex tree structures'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "Bayesian inference",
                "Method"
            ],
            [
                "discriminative model 's posterior",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('discriminative model's posterior') is the object of the preposition 'on', depending on 'maximize' in the clause 'that maximize a discriminative model's posterior on a target unlabeled corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'maximize' and the preposition 'on'.\"",
        "sdp_path_text": "inference → samples → disambiguating → combining → create → structures → maximize → posterior",
        "sentence": "Bayesian inference maximizes a discriminative model's posterior by sampling and combining rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'maximizes'. Entity 2 ('discriminative model's posterior') is the object, depending on 'maximizes' with 'Bayesian inference'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 performs the action of maximizing Entity 2.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "Bayesian inference",
                "Method"
            ],
            [
                "unlabeled corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'posterior'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the series of actions and objects described in the sentence, where 'Bayesian inference' influences the creation of tree structures that affect the 'posterior' on the 'unlabeled corpus'.\"",
        "sdp_path_text": "inference → samples → disambiguating → combining → create → structures → maximize → on → corpus",
        "sentence": "Bayesian inference samples rules to maximize a model's posterior on an unlabeled corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference') is the subject, depending on the verb 'samples'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'posterior'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions described in the sentence, where 'Bayesian inference' influences the 'posterior' which is evaluated 'on an unlabeled corpus'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the object, depending on the verb 'samples' with 'Bayesian inference'. Entity 2 ('them') is the object, depending on the verbs 'disambiguating' and 'combining' with 'Bayesian inference'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers back to 'rules' and is used in the actions of disambiguation and combination.\"",
        "sdp_path_text": "rules → samples → disambiguating → combining → them",
        "sentence": "Bayesian inference samples rules, disambiguating and combining them.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the object, depending on the verb 'samples' with 'Bayesian inference'. Entity 2 ('them') is the object, depending on the verbs 'disambiguating' and 'combining' with 'Bayesian inference'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers back to 'rules'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "complex tree structures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the verb 'samples', depending on 'Bayesian inference'. Entity 2 ('complex tree structures') is the object of the verb 'create', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a sequence of actions where 'rules' are sampled and then used to 'create complex tree structures'.\"",
        "sdp_path_text": "rules → samples → disambiguating → combining → create → structures",
        "sentence": "Bayesian inference samples rules, disambiguates and combines them to create complex tree structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the verb 'samples', depending on 'Bayesian inference'. It also appears as the object of the verbs 'disambiguates' and 'combines'. Entity 2 ('complex tree structures') is the object of the infinitive 'to create', depending on 'combines'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs that describe actions performed on or with 'rules' to achieve the creation of 'complex tree structures'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "discriminative model 's posterior",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the verb 'samples', depending on 'inference'. Entity 2 ('discriminative model's posterior') is the object of the verb 'maximize', depending on 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'rules' are used to 'create complex tree structures' that aim to 'maximize' the 'discriminative model's posterior'.\"",
        "sdp_path_text": "rules → samples → disambiguating → combining → create → structures → maximize → posterior",
        "sentence": "Bayesian inference samples rules to maximize a discriminative model's posterior.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the object, depending on the verb 'samples' with 'Bayesian inference'. Entity 2 ('discriminative model's posterior') is the object, depending on the verb 'maximize'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'to maximize' which indicates the purpose of sampling the rules.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "unlabeled corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the verb 'samples', depending on 'inference'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'posterior'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'rules' are sampled to maximize the posterior on the 'unlabeled corpus'.\"",
        "sdp_path_text": "rules → samples → disambiguating → combining → create → structures → maximize → on → corpus",
        "sentence": "Bayesian inference samples rules to create structures that maximize the posterior on an unlabeled corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the verb 'samples', depending on 'Bayesian inference'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'posterior'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "complex tree structures",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'combining' with 'disambiguating and combining them'. Entity 2 ('complex tree structures') is the object, depending on 'create' with 'combining them to create'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'create' and the conjunction 'and'.\"",
        "sdp_path_text": "them → combining → create → structures",
        "sentence": "Combining them creates complex tree structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'combines' with 'Combining'. Entity 2 ('complex tree structures') is the subject complement, depending on 'creates' with 'Combining'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the action described by the verb 'creates'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "discriminative model 's posterior",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'combining' with 'and'. Entity 2 ('discriminative model's posterior') is the object, depending on 'maximize' with 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'them' refers to 'rules' that are used to 'create complex tree structures' which aim to 'maximize a discriminative model's posterior'.\"",
        "sdp_path_text": "them → combining → create → structures → maximize → posterior",
        "sentence": "Combining them creates structures that maximize the discriminative model's posterior.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'combines', depending on 'combines'. Entity 2 ('discriminative model's posterior') is the object of the verb 'maximize', depending on 'maximize'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where 'them' contributes to the action leading to the maximization of the 'discriminative model's posterior'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "unlabeled corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'combining', depending on 'combining' in the phrase 'combining them'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'on' in the phrase 'on a target unlabeled corpus'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "them → combining → create → structures → maximize → on → corpus",
        "sentence": "Combining them creates structures that maximize the model's posterior on an unlabeled corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'Combining', depending on 'Combining'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'on' in the phrase 'on an unlabeled corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the effect of combining 'them'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "complex tree structures",
                "OtherScientificTerm"
            ],
            [
                "discriminative model 's posterior",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('complex tree structures') is the object, depending on 'create' which is part of the clause 'combining them to create'. Entity 2 ('discriminative model's posterior') is the object of the preposition 'on', depending on 'maximize' in the phrase 'that maximize a discriminative model's posterior on a target unlabeled corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same relative clause introduced by 'that'.\"",
        "sdp_path_text": "structures → maximize → posterior",
        "sentence": "Complex tree structures maximize a discriminative model's posterior.",
        "sentence_llm_dp_info": "\"Entity 1 ('complex tree structures') is the subject, depending on the verb 'maximize'. Entity 2 ('discriminative model's posterior') is the object, depending on 'maximize' with 'complex tree structures'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the agent performing the action that affects Entity 2.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "complex tree structures",
                "OtherScientificTerm"
            ],
            [
                "unlabeled corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('complex tree structures') is the object, depending on the verb 'create'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'posterior'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the action of creating structures that maximize the posterior on the corpus.\"",
        "sdp_path_text": "structures → maximize → on → corpus",
        "sentence": "Complex tree structures maximize a discriminative model's posterior on an unlabeled corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('complex tree structures') is the subject, depending on the verb 'maximize'. Entity 2 ('unlabeled corpus') is the object of the preposition 'on', depending on 'posterior'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'maximize' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Bayesian inference then samples the rules , disambiguating and combining them to create complex tree structures that maximize a discriminative model 's posterior on a target unlabeled corpus .",
        "ner_pair": [
            [
                "unlabeled corpus",
                "Material"
            ],
            [
                "discriminative model 's posterior",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlabeled corpus') is the object, depending on 'posterior' with the possessive form 'model's'. Entity 2 ('discriminative model's posterior') is the object of the relative clause, depending on 'maximize' with 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'maximize' which indicates that the complex tree structures are created to maximize the posterior on the 'unlabeled corpus'.\"",
        "sdp_path_text": "corpus → on → maximize → posterior",
        "sentence": "Bayesian inference maximizes a discriminative model's posterior on an unlabeled corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlabeled corpus') is the object, depending on the preposition 'on' with 'posterior'. Entity 2 ('discriminative model's posterior') is the object, depending on the verb 'maximizes' with 'Bayesian inference'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'maximizes' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "This posterior encodes sparse se-lectional preferences between a head word and its dependents .",
        "ner_pair": [
            [
                "posterior",
                "Generic"
            ],
            [
                "sparse se-lectional preferences",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('posterior') is the subject, depending on the verb 'encodes'. Entity 2 ('sparse se-lectional preferences') is the object, depending on 'encodes' with 'posterior'. There is a direct dependency between Entity 1 and Entity 2, where 'posterior' directly governs 'sparse se-lectional preferences' as its object.\"",
        "sdp_path_text": "posterior → encodes → preferences",
        "sentence": "The posterior encodes sparse selectional preferences.",
        "sentence_llm_dp_info": "\"Entity 1 ('posterior') is the subject, depending on the verb 'encodes'. Entity 2 ('sparse selectional preferences') is the object, depending on 'encodes' with 'posterior'. There is a direct dependency between Entity 1 and Entity 2, where 'posterior' encodes 'sparse selectional preferences'.\""
    },
    {
        "raw_sentence": "The model is evaluated on English and Czech newspaper texts , and is then validated on French broadcast news transcriptions .",
        "ner_pair": [
            [
                "English and Czech newspaper texts",
                "Material"
            ],
            [
                "model",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English and Czech newspaper texts') is the object, depending on the preposition 'on' which is part of the phrase 'on English and Czech newspaper texts', modifying the verb 'evaluated'. Entity 2 ('model') is the subject, depending on the verb 'is evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on English and Czech newspaper texts' which modifies the verb 'evaluated'.\"",
        "sdp_path_text": "texts → on → evaluated → model",
        "sentence": "The model is evaluated on English and Czech newspaper texts.",
        "sentence_llm_dp_info": "\"Entity 1 ('English and Czech newspaper texts') is the object, depending on the preposition 'on', which itself depends on the verb 'evaluated'. Entity 2 ('model') is the subject, depending on the verb 'is evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' in the phrase 'on English and Czech newspaper texts'.\""
    },
    {
        "raw_sentence": "The model is evaluated on English and Czech newspaper texts , and is then validated on French broadcast news transcriptions .",
        "ner_pair": [
            [
                "French broadcast news transcriptions",
                "Material"
            ],
            [
                "model",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('French broadcast news transcriptions') is the object of the preposition 'on', depending on 'validated'. Entity 2 ('model') is the subject, depending on 'is' in the verb phrase 'is evaluated' and 'is validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'validated'.\"",
        "sdp_path_text": "transcriptions → on → validated → evaluated → model",
        "sentence": "The model is validated on French broadcast news transcriptions.",
        "sentence_llm_dp_info": "\"Entity 1 ('French broadcast news transcriptions') is the object, depending on the preposition 'on', which modifies 'validated'. Entity 2 ('model') is the subject, depending on the verb 'is validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' in the phrase 'on French broadcast news transcriptions'.\""
    },
    {
        "raw_sentence": "The model is evaluated on English and Czech newspaper texts , and is then validated on French broadcast news transcriptions .",
        "ner_pair": [
            [
                "English and Czech newspaper texts",
                "Material"
            ],
            [
                "French broadcast news transcriptions",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English and Czech newspaper texts') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('French broadcast news transcriptions') is also the object of the preposition 'on', depending on 'validated'. There is no direct dependency between Entity 1 and Entity 2; both are objects of different clauses within the same sentence.\"",
        "sdp_path_text": "texts → on → evaluated → validated → on → transcriptions",
        "sentence": "The model is evaluated on English and Czech newspaper texts and validated on French broadcast news transcriptions.",
        "sentence_llm_dp_info": "\"Entity 1 ('English and Czech newspaper texts') is the object of the preposition 'on', depending on 'evaluated' with 'The model'. Entity 2 ('French broadcast news transcriptions') is also the object of the preposition 'on', depending on 'validated' with 'The model'. There is no direct dependency between Entity 1 and Entity 2; both are objects of different clauses in the sentence.\""
    },
    {
        "raw_sentence": "Listen-Communicate-Show -LRB- LCS -RRB- is a new paradigm for human interaction with data sources .",
        "ner_pair": [
            [
                "Listen-Communicate-Show -LRB- LCS -RRB-",
                "Task"
            ],
            [
                "human interaction with data sources",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Listen-Communicate-Show -LRB- LCS -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('human interaction with data sources') is the complement, depending on the verb 'is' as well, where it functions as the predicate nominative. There is no direct dependency between Entity 1 and Entity 2; both are related through the copular verb 'is'.\"",
        "sdp_path_text": "Show → is → paradigm → for → interaction",
        "sentence": "Listen-Communicate-Show (LCS) is a paradigm for human interaction with data sources.",
        "sentence_llm_dp_info": "\"Entity 1 ('Listen-Communicate-Show -LRB- LCS -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('human interaction with data sources') is the complement, depending on the verb 'is' as well. There is a direct dependency between Entity 1 and Entity 2, as both are part of the same predicate structure, where 'LCS' is described as being 'a paradigm for human interaction with data sources'.\""
    },
    {
        "raw_sentence": "We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and information sources .",
        "ner_pair": [
            [
                "intelligent mobile agents",
                "Method"
            ],
            [
                "spoken language understanding system",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intelligent mobile agents') is the object of the relative clause, depending on 'that' which introduces the relative clause modifying 'agents'. Entity 2 ('spoken language understanding system') is the object of the preposition 'with', depending on 'integrate' in the phrase 'integrate...with'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the integration process described in the sentence.\"",
        "sdp_path_text": "agents → with → integrate → system",
        "sentence": "Intelligent mobile agents are integrated with a spoken language understanding system.",
        "sentence_llm_dp_info": "\"Entity 1 ('intelligent mobile agents') is the subject, depending on the verb 'are integrated'. Entity 2 ('spoken language understanding system') is the object, depending on 'with' in the phrase 'with a spoken language understanding system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which indicates the integration relationship.\""
    },
    {
        "raw_sentence": "We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and information sources .",
        "ner_pair": [
            [
                "spoken language understanding system",
                "Method"
            ],
            [
                "information sources",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spoken language understanding system') is the object of the verb 'integrate', depending on 'We'. Entity 2 ('information sources') is the object of the preposition 'between', depending on 'between' in the phrase 'between users and information sources'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the function of the intelligent mobile agents.\"",
        "sdp_path_text": "system → integrate → with → agents → mediate → between → users → sources",
        "sentence": "The spoken language understanding system is integrated with agents that mediate between users and information sources.",
        "sentence_llm_dp_info": "\"Entity 1 ('spoken language understanding system') is the subject, depending on 'is' as the main verb. Entity 2 ('information sources') is the object of the preposition 'between', depending on 'between' in the phrase 'between users and information sources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'between users and information sources' which describes the role of the agents.\""
    },
    {
        "raw_sentence": "We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and information sources .",
        "ner_pair": [
            [
                "intelligent mobile agents",
                "Method"
            ],
            [
                "information sources",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intelligent mobile agents') is the object of the preposition 'with', depending on 'integrate'. Entity 2 ('information sources') is the object of the preposition 'between', depending on 'mediate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the role of the agents in mediating interactions.\"",
        "sdp_path_text": "agents → mediate → between → users → sources",
        "sentence": "Intelligent mobile agents mediate between users and information sources.",
        "sentence_llm_dp_info": "\"Entity 1 ('intelligent mobile agents') is the subject, depending on the verb 'mediate'. Entity 2 ('information sources') is the object of the preposition 'between', depending on 'between' in the phrase 'between users and information sources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'between'.\""
    },
    {
        "raw_sentence": "We have built and will demonstrate an application of this approach called LCS-Marine .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "LCS-Marine",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'application'. Entity 2 ('LCS-Marine') is the object complement, depending on 'called' which modifies 'application'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'application' and the verb 'called'.\"",
        "sdp_path_text": "approach → of → application → called → LCS",
        "sentence": "The approach is applied in an application called LCS-Marine.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'applied'. Entity 2 ('LCS-Marine') is the object of the preposition 'in', depending on 'in' in the phrase 'in an application called LCS-Marine'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "A domain independent model is proposed for the automated interpretation of nominal compounds in English .",
        "ner_pair": [
            [
                "domain independent model",
                "Method"
            ],
            [
                "automated interpretation of nominal compounds",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent model') is the subject, depending on the verb 'proposed'. Entity 2 ('automated interpretation of nominal compounds') is the object of the preposition 'for', depending on 'for' in the phrase 'for the automated interpretation of nominal compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "model → proposed → for → interpretation",
        "sentence": "A domain independent model is proposed for the automated interpretation of nominal compounds.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent model') is the subject, depending on the verb 'proposed'. Entity 2 ('automated interpretation of nominal compounds') is the object of the preposition 'for', depending on 'for' in the phrase 'for the automated interpretation of nominal compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A domain independent model is proposed for the automated interpretation of nominal compounds in English .",
        "ner_pair": [
            [
                "domain independent model",
                "Method"
            ],
            [
                "nominal compounds",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent model') is the subject, depending on the verb 'proposed'. Entity 2 ('nominal compounds') is the object of the preposition 'of', depending on 'interpretation' in the phrase 'interpretation of nominal compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the verb 'interpretation'.\"",
        "sdp_path_text": "model → proposed → for → interpretation → of → compounds",
        "sentence": "A domain independent model is proposed for the interpretation of nominal compounds.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent model') is the subject, depending on the verb 'proposed'. Entity 2 ('nominal compounds') is the object of the preposition 'of', depending on 'interpretation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' in the phrase 'interpretation of nominal compounds'.\""
    },
    {
        "raw_sentence": "A domain independent model is proposed for the automated interpretation of nominal compounds in English .",
        "ner_pair": [
            [
                "domain independent model",
                "Method"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent model') is the subject, depending on the verb 'proposed'. Entity 2 ('English') is the object of the preposition 'in', depending on 'in' in the phrase 'in English'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "model → proposed → for → interpretation → in → English",
        "sentence": "A domain independent model is proposed for interpreting nominal compounds in English.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent model') is the subject, depending on the verb 'proposed'. Entity 2 ('English') is the object of the preposition 'in', depending on 'in' in the phrase 'in English'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in English'.\""
    },
    {
        "raw_sentence": "A domain independent model is proposed for the automated interpretation of nominal compounds in English .",
        "ner_pair": [
            [
                "automated interpretation of nominal compounds",
                "Task"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automated interpretation of nominal compounds') is the object of the preposition 'for', depending on 'proposed'. Entity 2 ('English') is the object of the preposition 'in', depending on 'nominal compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrases 'for the automated interpretation of nominal compounds' and 'in English'.\"",
        "sdp_path_text": "interpretation → in → English",
        "sentence": "An automated interpretation of nominal compounds is proposed for English.",
        "sentence_llm_dp_info": "\"Entity 1 ('automated interpretation of nominal compounds') is the subject, depending on the verb 'proposed'. Entity 2 ('English') is the object of the preposition 'for', depending on 'for' in the phrase 'for English'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A domain independent model is proposed for the automated interpretation of nominal compounds in English .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "nominal compounds",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'in', depending on 'in' in the phrase 'in English'. Entity 2 ('nominal compounds') is the object of the preposition 'of', depending on 'interpretation' in the phrase 'interpretation of nominal compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase describing the scope of the interpretation.\"",
        "sdp_path_text": "English → in → interpretation → of → compounds",
        "sentence": "A model is proposed for the interpretation of nominal compounds in English.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'in', depending on 'in' in the phrase 'in English'. Entity 2 ('nominal compounds') is the object of the preposition 'of', depending on 'interpretation' in the phrase 'interpretation of nominal compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional structure that modifies the noun 'interpretation'.\""
    },
    {
        "raw_sentence": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "productive rules of interpretation",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is' in the phrase 'This model is'. Entity 2 ('productive rules of interpretation') is the object of the preposition 'for', depending on 'account' in the phrase 'to account for productive rules of interpretation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to account for'.\"",
        "sdp_path_text": "model → meant → account → for → rules",
        "sentence": "This model is meant to account for productive rules of interpretation.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is'. Entity 2 ('productive rules of interpretation') is the object of the preposition 'for', depending on 'account' in the phrase 'to account for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'account' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "morpho-syntactic and semantic characteristics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is' (meant). Entity 2 ('morpho-syntactic and semantic characteristics') is the object, depending on the verb 'inferred'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from the morpho-syntactic and semantic characteristics'.\"",
        "sdp_path_text": "model → meant → account → for → rules → inferred → from → characteristics",
        "sentence": "The model is meant to account for rules inferred from the morpho-syntactic and semantic characteristics.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is'. Entity 2 ('morpho-syntactic and semantic characteristics') is the object of the preposition 'from', depending on 'inferred'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'inferred' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "nominal constituents",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is' and modified by 'This'. Entity 2 ('nominal constituents') is the object of the preposition 'of', depending on 'characteristics'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause describing the purpose of the model, which involves the characteristics of the nominal constituents.\"",
        "sdp_path_text": "model → meant → account → for → rules → inferred → from → characteristics → of → constituents",
        "sentence": "The model is meant to account for rules inferred from the characteristics of nominal constituents.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is'. Entity 2 ('nominal constituents') is the object of the preposition 'of', depending on 'characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from the characteristics of nominal constituents'.\""
    },
    {
        "raw_sentence": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents .",
        "ner_pair": [
            [
                "morpho-syntactic and semantic characteristics",
                "OtherScientificTerm"
            ],
            [
                "productive rules of interpretation",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morpho-syntactic and semantic characteristics') is the object of the preposition 'from', depending on 'inferred'. Entity 2 ('productive rules of interpretation') is the object of the preposition 'for', depending on 'account'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'inferred' and the preposition 'from'.\"",
        "sdp_path_text": "characteristics → from → inferred → rules",
        "sentence": "Productive rules of interpretation are inferred from morpho-syntactic and semantic characteristics.",
        "sentence_llm_dp_info": "\"Entity 1 ('morpho-syntactic and semantic characteristics') is the object, depending on the preposition 'from', which itself depends on the verb 'inferred'. Entity 2 ('productive rules of interpretation') is the subject, depending on the verb 'inferred'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'inferred' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents .",
        "ner_pair": [
            [
                "productive rules of interpretation",
                "OtherScientificTerm"
            ],
            [
                "nominal constituents",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('productive rules of interpretation') is the object of the preposition 'for', depending on 'account'. Entity 2 ('nominal constituents') is the object of the preposition 'of', depending on 'characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the model accounts for.\"",
        "sdp_path_text": "rules → inferred → from → characteristics → of → constituents",
        "sentence": "Productive rules of interpretation are inferred from the characteristics of nominal constituents.",
        "sentence_llm_dp_info": "\"Entity 1 ('productive rules of interpretation') is the subject, depending on the verb 'inferred'. Entity 2 ('nominal constituents') is the object of the preposition 'of', depending on 'characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'inferred' and the prepositional phrase 'from the characteristics of nominal constituents'.\""
    },
    {
        "raw_sentence": "This model is meant to account for productive rules of interpretation which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents .",
        "ner_pair": [
            [
                "morpho-syntactic and semantic characteristics",
                "OtherScientificTerm"
            ],
            [
                "nominal constituents",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morpho-syntactic and semantic characteristics') is the object of the preposition 'from', depending on 'inferred'. Entity 2 ('nominal constituents') is the object of the preposition 'of', depending on 'characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the verb 'inferred'.\"",
        "sdp_path_text": "characteristics → of → constituents",
        "sentence": "The characteristics are of the nominal constituents.",
        "sentence_llm_dp_info": "\"Entity 1 ('morpho-syntactic and semantic characteristics') is the subject complement, depending on the copula 'are'. Entity 2 ('nominal constituents') is the object of the preposition 'of', depending on 'of' in the phrase 'of the nominal constituents'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "In particular , we make extensive use of Pustejovsky 's principles concerning the predicative information associated with nominals .",
        "ner_pair": [
            [
                "Pustejovsky 's principles",
                "Method"
            ],
            [
                "predicative information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pustejovsky's principles') is the object of the preposition 'of', depending on 'use'. Entity 2 ('predicative information') is the subject complement, depending on 'associated' with 'nominals'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what is used extensively and what is associated with nominals.\"",
        "sdp_path_text": "principles → concerning → information",
        "sentence": "Pustejovsky's principles concern predicative information.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pustejovsky's principles') is the subject, depending on the verb 'concern'. Entity 2 ('predicative information') is the object, depending on 'concern' with 'Pustejovsky's principles'. There is a direct dependency between Entity 1 and Entity 2, as 'Pustejovsky's principles' directly concerns 'predicative information'.\""
    },
    {
        "raw_sentence": "In particular , we make extensive use of Pustejovsky 's principles concerning the predicative information associated with nominals .",
        "ner_pair": [
            [
                "Pustejovsky 's principles",
                "Method"
            ],
            [
                "nominals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pustejovsky's principles') is the object of the preposition 'of', depending on 'use'. Entity 2 ('nominals') is the object of the preposition 'with', depending on 'associated'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is used and how it relates to nominals.\"",
        "sdp_path_text": "principles → concerning → information → associated → with → nominals",
        "sentence": "Pustejovsky's principles concern the predicative information associated with nominals.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pustejovsky's principles') is the subject, depending on the verb 'concern'. Entity 2 ('nominals') is the object of the preposition 'with', depending on 'with' in the phrase 'with nominals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'concern' and the prepositional phrase 'with nominals'.\""
    },
    {
        "raw_sentence": "In particular , we make extensive use of Pustejovsky 's principles concerning the predicative information associated with nominals .",
        "ner_pair": [
            [
                "nominals",
                "OtherScientificTerm"
            ],
            [
                "predicative information",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nominals') is the object of the preposition 'with', depending on 'with' in the phrase 'with nominals'. Entity 2 ('predicative information') is the object of the preposition 'concerning', depending on 'concerning' in the phrase 'concerning the predicative information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'make' and the prepositions 'concerning' and 'with'.\"",
        "sdp_path_text": "nominals → with → associated → information",
        "sentence": "Nominals are associated with predicative information.",
        "sentence_llm_dp_info": "\"Entity 1 ('nominals') is the subject, depending on the verb 'are associated'. Entity 2 ('predicative information') is the object, depending on the verb 'are associated'. There is a direct dependency between Entity 1 and Entity 2, as they are directly linked by the verb 'are associated'.\""
    },
    {
        "raw_sentence": "We argue that it is necessary to draw a line between generalizable semantic principles and domain-specific semantic information .",
        "ner_pair": [
            [
                "generalizable semantic principles",
                "OtherScientificTerm"
            ],
            [
                "domain-specific semantic information",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generalizable semantic principles') is the object of the preposition 'between', depending on 'draw a line between'. Entity 2 ('domain-specific semantic information') is also the object of the preposition 'between', depending on 'draw a line between'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same prepositional phrase 'between generalizable semantic principles and domain-specific semantic information'.\"",
        "sdp_path_text": "principles → information",
        "sentence": "We argue for distinguishing between generalizable semantic principles and domain-specific semantic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('generalizable semantic principles') is the object of the preposition 'between', depending on 'distinguishing'. Entity 2 ('domain-specific semantic information') is also the object of the preposition 'between', depending on 'distinguishing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'between generalizable semantic principles and domain-specific semantic information'.\""
    },
    {
        "raw_sentence": "We explain this distinction and we show how this model may be applied to the interpretation of compounds in real texts , provided that complementary semantic information are retrieved .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "interpretation of compounds",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject complement, depending on 'show' with 'we'. Entity 2 ('interpretation of compounds') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied to the interpretation of compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'applied'.\"",
        "sdp_path_text": "model → applied → to → interpretation",
        "sentence": "The model may be applied to the interpretation of compounds.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'applied'. Entity 2 ('interpretation of compounds') is the object of the preposition 'to', depending on 'to' in the phrase 'to the interpretation of compounds'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "We explain this distinction and we show how this model may be applied to the interpretation of compounds in real texts , provided that complementary semantic information are retrieved .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "semantic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the clause, depending on 'show' with 'we'. Entity 2 ('semantic information') is the subject complement, depending on 'retrieved' with 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence, contributing to the overall meaning of the clause.\"",
        "sdp_path_text": "model → applied → provided → retrieved → information",
        "sentence": "The model may be applied to retrieve semantic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'applied'. Entity 2 ('semantic information') is the object of the preposition 'to', depending on 'retrieve' in the phrase 'to retrieve semantic information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'retrieve' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We explain this distinction and we show how this model may be applied to the interpretation of compounds in real texts , provided that complementary semantic information are retrieved .",
        "ner_pair": [
            [
                "interpretation of compounds",
                "Task"
            ],
            [
                "semantic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('interpretation of compounds') is the object of the preposition 'to', depending on 'applied' with 'model'. Entity 2 ('semantic information') is the subject complement, depending on 'retrieved' with 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the application of the model and the conditions for its successful use.\"",
        "sdp_path_text": "interpretation → to → applied → provided → retrieved → information",
        "sentence": "The interpretation of compounds can be applied provided that semantic information is retrieved.",
        "sentence_llm_dp_info": "\"Entity 1 ('interpretation of compounds') is the subject, depending on the verb 'can be applied'. Entity 2 ('semantic information') is the subject complement, depending on the verb 'is retrieved'. There is no direct dependency between Entity 1 and Entity 2, but both are related to conditions for application and retrieval, respectively.\""
    },
    {
        "raw_sentence": "We present a new method for detecting interest points using histogram information .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "detecting interest points",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'present' with 'We'. Entity 2 ('detecting interest points') is the complement of the preposition 'for', depending on 'for' in the phrase 'for detecting interest points'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "method → for → detecting",
        "sentence": "We present a new method for detecting interest points.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the direct object, depending on the verb 'present'. Entity 2 ('detecting interest points') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting interest points'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present a new method for detecting interest points using histogram information .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "histogram information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on the verb 'present'. Entity 2 ('histogram information') is the object of the preposition 'using', depending on 'using' in the phrase 'using histogram information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the method and how it uses histogram information.\"",
        "sdp_path_text": "method → for → detecting → using → information",
        "sentence": "{\n  \"Simplified sentence\": \"We present a new method for detecting interest points using histogram information.\"\n} \n\nHowever, to better follow the instructions and remove unnecessary details while retaining the core relationship:\n\n{\n  \"Simplified sentence\": \"The method uses histogram information for detecting.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'uses'. Entity 2 ('histogram information') is the object, depending on 'uses' in the phrase 'uses histogram information'. There is a direct dependency between Entity 1 and Entity 2, as 'method' directly uses 'histogram information'.\""
    },
    {
        "raw_sentence": "We present a new method for detecting interest points using histogram information .",
        "ner_pair": [
            [
                "histogram information",
                "OtherScientificTerm"
            ],
            [
                "detecting interest points",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('histogram information') is the object, depending on the preposition 'using', which modifies the verb 'detecting'. Entity 2 ('detecting interest points') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting interest points'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'using' that indicates the method or tool used for the action described by Entity 2.\"",
        "sdp_path_text": "information → using → detecting",
        "sentence": "Histogram information is used for detecting interest points.",
        "sentence_llm_dp_info": "\"Entity 1 ('histogram information') is the subject, depending on the verb 'used'. Entity 2 ('detecting interest points') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting interest points'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .",
        "ner_pair": [
            [
                "pixel-wise differences in image intensity",
                "Metric"
            ],
            [
                "interest point detectors",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pixel-wise differences in image intensity') is the object of the preposition 'in', depending on 'measure' from the clause describing the existing 'interest point detectors'. Entity 2 ('interest point detectors') is the subject, depending on the verb 'measure'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the clause where 'interest point detectors' measure 'pixel-wise differences in image intensity'.\"",
        "sdp_path_text": "differences → measure → detectors",
        "sentence": "Interest point detectors measure pixel-wise differences in image intensity.",
        "sentence_llm_dp_info": "\"Entity 1 ('pixel-wise differences in image intensity') is the object, depending on 'measure' with 'interest point detectors'. Entity 2 ('interest point detectors') is the subject, depending on the verb 'measure'. There is a direct dependency between Entity 1 and Entity 2, as 'interest point detectors' measures 'pixel-wise differences in image intensity'.\""
    },
    {
        "raw_sentence": "Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .",
        "ner_pair": [
            [
                "interest point detectors",
                "Method"
            ],
            [
                "histogram-based representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('interest point detectors') is the subject of the clause 'which measure pixel-wise differences in image intensity', depending on the relative pronoun 'which'. Entity 2 ('histogram-based representations') is the object of the preposition 'incorporate', depending on the verb 'incorporate' in the clause 'our detectors incorporate histogram-based representations'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different aspects of the comparison being made in the sentence.\"",
        "sdp_path_text": "detectors → Unlike → incorporate → representations",
        "sentence": "Our interest point detectors incorporate histogram-based representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('interest point detectors') is the subject, depending on the verb 'incorporate'. Entity 2 ('histogram-based representations') is the object, depending on 'incorporate' with 'interest point detectors'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly incorporated by Entity 1.\""
    },
    {
        "raw_sentence": "Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .",
        "ner_pair": [
            [
                "pixel-wise differences in image intensity",
                "Metric"
            ],
            [
                "detectors",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pixel-wise differences in image intensity') is the object of the verb 'measure', depending on 'measure' in the clause 'which measure pixel-wise differences in image intensity'. Entity 2 ('detectors') is the subject, depending on 'incorporate' with 'our detectors'. There is no direct dependency between Entity 1 and Entity 2, but they are part of contrasting clauses within the same sentence.\"",
        "sdp_path_text": "differences → measure → detectors",
        "sentence": "Detectors measure pixel-wise differences in image intensity.",
        "sentence_llm_dp_info": "\"Entity 1 ('pixel-wise differences in image intensity') is the object, depending on the verb 'measure'. Entity 2 ('detectors') is the subject, depending on the verb 'measure'. There is a direct dependency between Entity 1 and Entity 2, as 'detectors' measures 'pixel-wise differences in image intensity'.\""
    },
    {
        "raw_sentence": "Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .",
        "ner_pair": [
            [
                "pixel-wise differences in image intensity",
                "Metric"
            ],
            [
                "histogram-based representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pixel-wise differences in image intensity') is the object of the preposition 'in', depending on 'measure' with 'which'. Entity 2 ('histogram-based representations') is the object of the preposition 'incorporate', depending on 'detectors' with 'our'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different aspects of the comparison between existing and our detectors.\"",
        "sdp_path_text": "differences → measure → detectors → Unlike → incorporate → representations",
        "sentence": "Unlike detectors measuring pixel-wise differences in image intensity, our detectors incorporate histogram-based representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('pixel-wise differences in image intensity') is the object of the preposition 'in', depending on 'measuring' which modifies 'detectors'. Entity 2 ('histogram-based representations') is the object of the verb 'incorporate', depending on 'detectors'. There is no direct dependency between Entity 1 and Entity 2; both are related to different types of 'detectors' in the sentence.\""
    },
    {
        "raw_sentence": "Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .",
        "ner_pair": [
            [
                "histogram-based representations",
                "Method"
            ],
            [
                "detectors",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('histogram-based representations') is the object of the verb 'incorporate', depending on 'detectors'. Entity 2 ('detectors') is the subject, depending on 'incorporate' with 'histogram-based representations'. There is a direct dependency between Entity 1 and Entity 2, as 'detectors' incorporates 'histogram-based representations'.\"",
        "sdp_path_text": "representations → incorporate → Unlike → detectors",
        "sentence": "Detectors incorporate histogram-based representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('histogram-based representations') is the object, depending on the verb 'incorporate'. Entity 2 ('detectors') is the subject, depending on the verb 'incorporate'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is incorporated by Entity 2.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "detectors",
                "Generic"
            ],
            [
                "large-scale structures",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on 'are' as its verb. Entity 2 ('large-scale structures') is part of the object complement, depending on 'capture' which is part of the verb phrase 'are able to capture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture'.\"",
        "sdp_path_text": "detectors → are → able → capture → structures",
        "sentence": "The proposed detectors are able to capture large-scale structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'are' and modified by the adjective 'proposed'. Entity 2 ('large-scale structures') is the object, depending on the verb 'capture' which is part of the phrase 'to capture large-scale structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capture'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "detectors",
                "Generic"
            ],
            [
                "distinctive textured patterns",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on 'are' (the copula verb). Entity 2 ('distinctive textured patterns') is part of a compound object, depending on 'capture' with 'and'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'capture' which has 'large-scale structures' and 'distinctive textured patterns' as its objects.\"",
        "sdp_path_text": "detectors → are → able → capture → structures → patterns",
        "sentence": "The proposed detectors are able to capture distinctive textured patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'are' and modified by the adjective 'proposed'. Entity 2 ('distinctive textured patterns') is the object, depending on the verb 'capture'. There is a direct dependency between Entity 1 and Entity 2, as 'detectors' are the agents that can 'capture' the 'distinctive textured patterns'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "detectors",
                "Generic"
            ],
            [
                "rotation",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'are' and modified by 'proposed'. Entity 2 ('rotation') is part of a prepositional phrase, depending on 'invariance' with 'to'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'invariance' which describes a property of the 'detectors'.\"",
        "sdp_path_text": "detectors → are → exhibit → invariance → to → rotation",
        "sentence": "The proposed detectors exhibit invariance to rotation.",
        "sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'exhibit'. Entity 2 ('rotation') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exhibit' and the prepositional phrase 'to rotation'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "detectors",
                "Generic"
            ],
            [
                "illumination variation",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on 'are' (the copula verb) and 'able' (part of the predicate). Entity 2 ('illumination variation') is part of a list of objects, depending on 'invariance' through the preposition 'to'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "detectors → are → exhibit → invariance → to → rotation → variation",
        "sentence": "The detectors exhibit invariance to illumination variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'exhibit'. Entity 2 ('illumination variation') is the object of the preposition 'to', depending on 'to' in the phrase 'to illumination variation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "detectors",
                "Generic"
            ],
            [
                "blur",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'are' and modified by 'proposed'. Entity 2 ('blur') is the object of the preposition 'to', part of a list of conditions that the 'detectors' exhibit invariance to. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exhibit' and the preposition 'to'.\"",
        "sdp_path_text": "detectors → are → exhibit → invariance → to → rotation → variation → blur",
        "sentence": "The proposed detectors exhibit invariance to blur.",
        "sentence_llm_dp_info": "\"Entity 1 ('detectors') is the subject, depending on the verb 'exhibit'. Entity 2 ('blur') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'invariance' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "large-scale structures",
                "OtherScientificTerm"
            ],
            [
                "distinctive textured patterns",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is the object of the verb 'capture', depending on 'detectors'. Entity 2 ('distinctive textured patterns') is also the object of the verb 'capture', depending on 'detectors'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'capture'.\"",
        "sdp_path_text": "structures → patterns",
        "sentence": "The proposed detectors capture large-scale structures and distinctive textured patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is a conjunct, depending on 'capture' with 'detectors'. Entity 2 ('distinctive textured patterns') is also a conjunct, depending on 'capture' with 'detectors'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'capture'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "large-scale structures",
                "OtherScientificTerm"
            ],
            [
                "rotation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is the object of the verb 'capture', depending on 'capture' in the clause 'to capture large-scale structures'. Entity 2 ('rotation') is part of a list of objects, depending on the preposition 'to' in the phrase 'invariance to rotation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "structures → capture → able → are → exhibit → invariance → to → rotation",
        "sentence": "The proposed detectors capture large-scale structures and exhibit invariance to rotation.",
        "sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is the object, depending on 'capture' with 'detectors'. Entity 2 ('rotation') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the actions performed by 'detectors'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "large-scale structures",
                "OtherScientificTerm"
            ],
            [
                "illumination variation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is part of the object complement, depending on 'capture' with 'detectors'. Entity 2 ('illumination variation') is part of the object complement, depending on 'invariance' with 'exhibit'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the capabilities of the 'detectors'.\"",
        "sdp_path_text": "structures → capture → able → are → exhibit → invariance → to → rotation → variation",
        "sentence": "The proposed detectors are able to capture large-scale structures and exhibit invariance to illumination variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is the object, depending on 'capture' with 'detectors'. Entity 2 ('illumination variation') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "large-scale structures",
                "OtherScientificTerm"
            ],
            [
                "blur",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is part of the object complement, depending on 'capture' with 'detectors'. Entity 2 ('blur') is part of a list of items, depending on 'invariance' with 'exhibit'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "structures → capture → able → are → exhibit → invariance → to → rotation → variation → blur",
        "sentence": "The proposed detectors are able to capture large-scale structures and exhibit invariance to blur.",
        "sentence_llm_dp_info": "\"Entity 1 ('large-scale structures') is the object of the verb 'capture', depending on 'capture' with 'detectors'. Entity 2 ('blur') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "distinctive textured patterns",
                "OtherScientificTerm"
            ],
            [
                "rotation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distinctive textured patterns') is the object of the verb 'capture', depending on 'capture' with 'detectors'. Entity 2 ('rotation') is part of a list of objects of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "patterns → structures → capture → able → are → exhibit → invariance → to → rotation",
        "sentence": "Distinctive textured patterns exhibit strong invariance to rotation.",
        "sentence_llm_dp_info": "\"Entity 1 ('distinctive textured patterns') is the subject, depending on the verb 'exhibit'. Entity 2 ('rotation') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'to rotation' which modifies 'invariance'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "distinctive textured patterns",
                "OtherScientificTerm"
            ],
            [
                "illumination variation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distinctive textured patterns') is the object of the verb 'capture', depending on 'capture' with 'detectors'. Entity 2 ('illumination variation') is part of a list of objects, depending on 'invariance' with 'exhibit'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the capabilities of the 'detectors' described in the sentence.\"",
        "sdp_path_text": "patterns → structures → capture → able → are → exhibit → invariance → to → rotation → variation",
        "sentence": "The proposed detectors are able to capture distinctive textured patterns and exhibit invariance to illumination variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('distinctive textured patterns') is the object of the verb 'capture', depending on 'capture' which is part of the clause 'are able to capture'. Entity 2 ('illumination variation') is the object of the preposition 'to', depending on 'invariance' in the phrase 'invariance to illumination variation'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the capabilities of the 'proposed detectors'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "distinctive textured patterns",
                "OtherScientificTerm"
            ],
            [
                "blur",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distinctive textured patterns') is the object of the verb 'capture', depending on 'and' which connects it with 'large-scale structures'. Entity 2 ('blur') is part of a list of conditions, depending on 'invariance' with the preposition 'to'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "patterns → structures → capture → able → are → exhibit → invariance → to → rotation → variation → blur",
        "sentence": "Distinctive textured patterns exhibit invariance to blur.",
        "sentence_llm_dp_info": "\"Entity 1 ('distinctive textured patterns') is the subject, depending on the verb 'exhibit'. Entity 2 ('blur') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'exhibit invariance to'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "rotation",
                "OtherScientificTerm"
            ],
            [
                "illumination variation",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rotation') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('illumination variation') is also the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of objects that the proposed detectors exhibit strong invariance to.\"",
        "sdp_path_text": "rotation → variation",
        "sentence": "The proposed detectors exhibit strong invariance to rotation and illumination variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('rotation') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('illumination variation') is also the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; both are related to 'invariance' through the preposition 'to'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "rotation",
                "OtherScientificTerm"
            ],
            [
                "blur",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rotation') is part of a prepositional phrase, depending on 'invariance' with the preposition 'to'. Entity 2 ('blur') is also part of a prepositional phrase, depending on 'invariance' with the preposition 'to'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list of elements that 'invariance' is invariant to.\"",
        "sdp_path_text": "rotation → variation → blur",
        "sentence": "The detectors exhibit strong invariance to rotation variation and blur.",
        "sentence_llm_dp_info": "\"Entity 1 ('rotation') is part of the compound noun 'rotation variation', which is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('blur') is a coordinate object, also depending on 'invariance' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of the preposition 'to' and are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "The proposed detectors are able to capture large-scale structures and distinctive textured patterns , and exhibit strong invariance to rotation , illumination variation , and blur .",
        "ner_pair": [
            [
                "illumination variation",
                "OtherScientificTerm"
            ],
            [
                "blur",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination variation') is part of a coordination, depending on the conjunction 'and' with 'rotation' and 'blur'. Entity 2 ('blur') is also part of a coordination, depending on the conjunction 'and' with 'rotation' and 'illumination variation'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the list of conditions for which the detectors exhibit strong invariance.\"",
        "sdp_path_text": "variation → blur",
        "sentence": "The proposed detectors exhibit strong invariance to illumination variation and blur.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination variation') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('blur') is also the object of the preposition 'and', depending on 'illumination variation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of objects that the proposed detectors exhibit invariance to.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "histogram-based interest point detectors",
                "Method"
            ],
            [
                "matching textured scenes",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('histogram-based interest point detectors') is the subject, depending on 'perform' as the main verb. Entity 2 ('matching textured scenes') is part of the prepositional phrase 'for the tasks of matching textured scenes', functioning as an object of the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the context provided by the verb 'perform' and the prepositional phrase that specifies the task.\"",
        "sdp_path_text": "detectors → perform → for → tasks → of → matching",
        "sentence": "Histogram-based interest point detectors perform well for matching textured scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('histogram-based interest point detectors') is the subject, depending on the verb 'perform'. Entity 2 ('matching textured scenes') is the object of the preposition 'for', depending on 'for' in the phrase 'for matching textured scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose or function of Entity 1.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "histogram-based interest point detectors",
                "Method"
            ],
            [
                "blur and illumination changes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('histogram-based interest point detectors') is the subject, depending on 'perform' with 'perform particularly well'. Entity 2 ('blur and illumination changes') is part of a prepositional phrase, depending on 'under' which modifies the conditions under which the detectors perform well. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the preposition 'under' indicating the conditions under which Entity 1 performs well.\"",
        "sdp_path_text": "detectors → perform → for → tasks → of → matching → under → changes",
        "sentence": "Histogram-based interest point detectors perform well for matching under blur and illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('histogram-based interest point detectors') is the subject, depending on the verb 'perform'. Entity 2 ('blur and illumination changes') is the object of the preposition 'under', depending on 'under' in the phrase 'under blur and illumination changes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'under'.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "repeatability",
                "Metric"
            ],
            [
                "histogram-based interest point detectors",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('repeatability') is part of a coordination, depending on 'and' with 'distinctiveness', and together they form the object of the preposition 'in terms of'. Entity 2 ('histogram-based interest point detectors') is the subject, depending on 'perform' with 'perform particularly well'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where the performance of Entity 2 is described in terms of Entity 1.\"",
        "sdp_path_text": "repeatability → of → terms → in → matching → of → tasks → for → perform → detectors",
        "sentence": "Histogram-based interest point detectors perform well in terms of repeatability for matching tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('repeatability') is the object of the preposition 'in', depending on 'perform well'. Entity 2 ('histogram-based interest point detectors') is the subject, depending on the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'perform well in terms of'.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "distinctiveness",
                "Metric"
            ],
            [
                "histogram-based interest point detectors",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distinctiveness') is part of a coordinated list, depending on 'in terms of' which modifies the performance of the 'detectors'. Entity 2 ('histogram-based interest point detectors') is the subject of the clause, depending on 'perform' as the main verb. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure describing the performance of the detectors in various aspects, including distinctiveness.\"",
        "sdp_path_text": "distinctiveness → repeatability → of → terms → in → matching → of → tasks → for → perform → detectors",
        "sentence": "The histogram-based interest point detectors perform well in terms of distinctiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('distinctiveness') is the object of the preposition 'of', depending on 'in terms of'. Entity 2 ('histogram-based interest point detectors') is the subject, depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in terms of'.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "matching textured scenes",
                "Task"
            ],
            [
                "blur and illumination changes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matching textured scenes') is the object of the preposition 'for', depending on 'perform'. Entity 2 ('blur and illumination changes') is the object of the preposition 'under', depending on 'scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a larger prepositional phrase that modifies the performance of the detectors.\"",
        "sdp_path_text": "matching → under → changes",
        "sentence": "Matching textured scenes performs well under blur and illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('matching textured scenes') is the subject, depending on the verb 'performs'. Entity 2 ('blur and illumination changes') is the object of the preposition 'under', depending on 'under' in the phrase 'under blur and illumination changes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'under'.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "matching textured scenes",
                "Task"
            ],
            [
                "repeatability",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matching textured scenes') is part of the prepositional phrase, depending on 'tasks' with 'for'. Entity 2 ('repeatability') is the object of the preposition 'of', depending on 'terms' in the phrase 'in terms of'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the overall context of the sentence, which discusses the performance of interest point detectors in specific tasks.\"",
        "sdp_path_text": "matching → in → terms → of → repeatability",
        "sentence": "Matching textured scenes performs well in terms of repeatability.",
        "sentence_llm_dp_info": "\"Entity 1 ('matching textured scenes') is the subject, depending on the verb 'performs'. Entity 2 ('repeatability') is the object of the preposition 'of', depending on 'terms' in the phrase 'in terms of repeatability'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in terms of'.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "matching textured scenes",
                "Task"
            ],
            [
                "distinctiveness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matching textured scenes') is the object of the preposition 'for', depending on 'perform' in the clause 'perform particularly well for the tasks of matching textured scenes'. Entity 2 ('distinctiveness') is part of a compound object, depending on 'in' in the phrase 'in terms of repeatability and distinctiveness'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the performance evaluation described in the sentence.\"",
        "sdp_path_text": "matching → in → terms → of → repeatability → distinctiveness",
        "sentence": "Matching textured scenes performs well in terms of distinctiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('matching textured scenes') is the subject, depending on the verb 'performs'. Entity 2 ('distinctiveness') is the object of the preposition 'of', depending on 'terms' in the phrase 'in terms of distinctiveness'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in terms of'.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "blur and illumination changes",
                "OtherScientificTerm"
            ],
            [
                "repeatability",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('blur and illumination changes') is part of a prepositional phrase, depending on 'under' which modifies 'tasks'. Entity 2 ('repeatability') is an element in a list, depending on 'in terms of' which modifies the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2; both are related to different aspects of the sentence structure, with Entity 1 describing conditions under which the tasks are performed, and Entity 2 being one of the criteria by which performance is measured.\"",
        "sdp_path_text": "changes → under → matching → in → terms → of → repeatability",
        "sentence": "The proposed detectors perform well for matching scenes under blur and illumination changes in terms of repeatability.",
        "sentence_llm_dp_info": "\"Entity 1 ('blur and illumination changes') is the object of the preposition 'under', depending on 'perform'. Entity 2 ('repeatability') is the object of the preposition 'in terms of', depending on 'well'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the conditions under which the performance is evaluated.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "blur and illumination changes",
                "OtherScientificTerm"
            ],
            [
                "distinctiveness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('blur and illumination changes') is the object of the preposition 'under', depending on 'matching textured scenes'. Entity 2 ('distinctiveness') is part of a compound noun, depending on 'in terms of'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context describing the conditions and criteria for the performance of the interest point detectors.\"",
        "sdp_path_text": "changes → under → matching → in → terms → of → repeatability → distinctiveness",
        "sentence": "The proposed detectors perform well in matching scenes under blur and illumination changes, in terms of distinctiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('blur and illumination changes') is the object of the preposition 'under', depending on 'matching'. Entity 2 ('distinctiveness') is the object of the preposition 'in terms of', depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the conditions under which the performance of the proposed detectors is described.\""
    },
    {
        "raw_sentence": "The experimental results show that the proposed histogram-based interest point detectors perform particularly well for the tasks of matching textured scenes under blur and illumination changes , in terms of repeatability and distinctiveness .",
        "ner_pair": [
            [
                "repeatability",
                "Metric"
            ],
            [
                "distinctiveness",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('repeatability') is part of a coordinated structure, depending on 'in' with 'in terms of'. Entity 2 ('distinctiveness') is also part of a coordinated structure, depending on 'and' with 'repeatability'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as the objects of the preposition 'in'.\"",
        "sdp_path_text": "repeatability → distinctiveness",
        "sentence": "The proposed detectors perform well in terms of repeatability and distinctiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('repeatability') is part of a conjunction, depending on 'terms' with 'in terms of'. Entity 2 ('distinctiveness') is also part of a conjunction, depending on 'terms' with 'in terms of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same prepositional phrase 'in terms of repeatability and distinctiveness'.\""
    },
    {
        "raw_sentence": "An extension of our method to space-time interest point detection for action classification is also presented .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "space-time interest point detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'of', depending on 'extension'. Entity 2 ('space-time interest point detection') is the complement of the preposition 'to', depending on 'to' in the phrase 'to space-time interest point detection'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what the extension is applied to and its purpose.\"",
        "sdp_path_text": "method → of → extension → to → detection",
        "sentence": "An extension of the method is presented for space-time interest point detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'of', depending on 'extension'. Entity 2 ('space-time interest point detection') is the object of the preposition 'for', depending on 'presented'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause through different prepositions.\""
    },
    {
        "raw_sentence": "An extension of our method to space-time interest point detection for action classification is also presented .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "action classification",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is part of the noun phrase 'extension of our method', where it depends on 'extension' as the object of the preposition 'of'. Entity 2 ('action classification') is the object of the preposition 'for', indicating the purpose, and it depends on 'for'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrases 'of our method' and 'for action classification'.\"",
        "sdp_path_text": "method → of → extension → to → detection → for → classification",
        "sentence": "An extension of the method is presented for action classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'of', depending on 'extension'. Entity 2 ('action classification') is the object of the preposition 'for', depending on 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is presented.\""
    },
    {
        "raw_sentence": "An extension of our method to space-time interest point detection for action classification is also presented .",
        "ner_pair": [
            [
                "space-time interest point detection",
                "Task"
            ],
            [
                "action classification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('space-time interest point detection') is the object of the preposition 'to', depending on 'extension'. Entity 2 ('action classification') is the object of the preposition 'for', depending on 'detection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'to space-time interest point detection' and 'for action classification'.\"",
        "sdp_path_text": "detection → for → classification",
        "sentence": "Space-time interest point detection is used for action classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('space-time interest point detection') is the subject, depending on the verb 'is used'. Entity 2 ('action classification') is the object of the preposition 'for', depending on 'for' in the phrase 'for action classification'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We have implemented a restricted domain parser called Plume .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "restricted domain parser",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object, depending on 'called' with 'parser'. Entity 2 ('restricted domain parser') is the subject complement, depending on 'implemented' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'called'.\"",
        "sdp_path_text": "Plume → called → parser",
        "sentence": "Plume is a restricted domain parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is'. Entity 2 ('restricted domain parser') is the predicate nominative, depending on 'is' in the phrase 'is a restricted domain parser'. There is a direct dependency between Entity 1 and Entity 2, as 'restricted domain parser' directly describes what 'Plume' is.\""
    },
    {
        "raw_sentence": "Building on previous work at Carnegie-Mellon University e.g. -LSB- 4 , 5 , 8 -RSB- , Plume 's approach to parsing is based on semantic caseframe instantiation .",
        "ner_pair": [
            [
                "Plume 's approach",
                "Method"
            ],
            [
                "parsing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume's approach') is the subject, depending on the preposition 'to' with 'parsing'. Entity 2 ('parsing') is the object of the preposition 'to', depending on 'to' in the phrase 'to parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\"",
        "sdp_path_text": "approach → to → parsing",
        "sentence": "Plume's approach is based on parsing.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume's approach') is the subject, depending on the verb 'is'. Entity 2 ('parsing') is the complement, depending on 'based' with 'is based on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'is based on'.\""
    },
    {
        "raw_sentence": "Building on previous work at Carnegie-Mellon University e.g. -LSB- 4 , 5 , 8 -RSB- , Plume 's approach to parsing is based on semantic caseframe instantiation .",
        "ner_pair": [
            [
                "semantic caseframe instantiation",
                "OtherScientificTerm"
            ],
            [
                "Plume 's approach",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic caseframe instantiation') is the object, depending on 'based' which modifies 'approach'. Entity 2 ('Plume's approach') is the subject, depending on 'is' as the main verb of the clause. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the basis or foundation for Entity 2.\"",
        "sdp_path_text": "instantiation → on → based → approach",
        "sentence": "Plume's approach to parsing is based on semantic caseframe instantiation.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic caseframe instantiation') is the complement, depending on 'based' with 'is based on'. Entity 2 ('Plume's approach') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is based on'.\""
    },
    {
        "raw_sentence": "Building on previous work at Carnegie-Mellon University e.g. -LSB- 4 , 5 , 8 -RSB- , Plume 's approach to parsing is based on semantic caseframe instantiation .",
        "ner_pair": [
            [
                "parsing",
                "Task"
            ],
            [
                "semantic caseframe instantiation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parsing') is part of a prepositional phrase, depending on 'approach' with the preposition 'to'. Entity 2 ('semantic caseframe instantiation') is the complement of the preposition 'on', depending on 'based' in the phrase 'based on semantic caseframe instantiation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' and the verb 'based'.\"",
        "sdp_path_text": "parsing → to → approach → based → on → instantiation",
        "sentence": "Plume's approach to parsing is based on semantic caseframe instantiation.",
        "sentence_llm_dp_info": "\"Entity 1 ('parsing') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('semantic caseframe instantiation') is the complement, depending on 'based' with 'is based on'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing 'Plume's approach'.\""
    },
    {
        "raw_sentence": "This has the advantages of efficiency on grammatical input , and robustness in the face of ungrammatical input .",
        "ner_pair": [
            [
                "grammatical input",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grammatical input') is the object of the preposition 'on', depending on 'advantages'. Entity 2 ('robustness') is the subject complement, depending on 'has' with 'This'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the advantages and characteristics of 'This'.\"",
        "sdp_path_text": "input → on → efficiency → robustness",
        "sentence": "Efficiency on grammatical input contributes to robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('grammatical input') is the object of the preposition 'on', depending on 'efficiency'. Entity 2 ('robustness') is the object of the preposition 'to', depending on 'contributes'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure that describes how efficiency affects robustness.\""
    },
    {
        "raw_sentence": "This has the advantages of efficiency on grammatical input , and robustness in the face of ungrammatical input .",
        "ner_pair": [
            [
                "ungrammatical input",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ungrammatical input') is the object of the preposition 'of', depending on 'robustness'. Entity 2 ('robustness') is part of a compound noun, depending on 'and' which connects it with 'advantages'. There is a direct dependency between Entity 1 and Entity 2, where 'ungrammatical input' modifies 'robustness' through the prepositional phrase 'in the face of ungrammatical input'.\"",
        "sdp_path_text": "input → of → face → in → robustness",
        "sentence": "Robustness is maintained in the face of ungrammatical input.",
        "sentence_llm_dp_info": "\"Entity 1 ('ungrammatical input') is the object, depending on 'in' with 'face'. Entity 2 ('robustness') is the subject, depending on the verb 'is maintained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the face of'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "declarative and imperative utterances",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is' in the clause 'is well adapted'. Entity 2 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted' in the phrase 'well adapted to'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' which indicates that 'Plume' is adapted to handle 'declarative and imperative utterances'.\"",
        "sdp_path_text": "Plume → adapted → to → utterances",
        "sentence": "Plume is adapted to declarative and imperative utterances.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'adapted'. Entity 2 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'to' in the phrase 'to declarative and imperative utterances'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is' in 'is well adapted'. Entity 2 ('it') is the subject, depending on the verb 'handles'. There is no direct dependency between Entity 1 and Entity 2; however, 'it' likely refers back to 'Plume' in the context of the sentence.\"",
        "sdp_path_text": "Plume → adapted → handles → it",
        "sentence": "Plume handles utterances in an adapted manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('it') does not appear in the sentence, so there is no dependency for Entity 2. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "passives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is' and also on the verb 'handles'. Entity 2 ('passives') is part of a list of objects, depending on the verb 'handles'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handles' which indicates that Plume processes passives among other linguistic structures.\"",
        "sdp_path_text": "Plume → adapted → handles → passives",
        "sentence": "Plume handles passives in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('passives') is the object, depending on the verb 'handles'. There is a direct dependency between Entity 1 and Entity 2, as 'passives' is directly handled by 'Plume'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('relative clauses') is part of a list of objects, depending on the verb 'handles'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handles' which governs the list including Entity 2.\"",
        "sdp_path_text": "Plume → adapted → handles → passives → clauses",
        "sentence": "Plume handles relative clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('relative clauses') is the object, depending on the verb 'handles'. There is a direct dependency between Entity 1 and Entity 2, where 'Plume' is handling 'relative clauses'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('interrogatives') is the object, depending on 'handles' with 'Plume'. There is a direct dependency between Entity 1 and Entity 2, as 'Plume' is the agent that 'handles' 'interrogatives'.\"",
        "sdp_path_text": "Plume → adapted → handles → passives → clauses → interrogatives",
        "sentence": "Plume handles interrogatives in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('interrogatives') is the object, depending on 'handles'. There is a direct dependency between Entity 1 and Entity 2, where 'Plume' is handling 'interrogatives'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "patchy syntactic coverage",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('patchy syntactic coverage') is the object, depending on 'leading to'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the series of actions described, where 'Plume' handling certain linguistic features leads to 'patchy syntactic coverage'.\"",
        "sdp_path_text": "Plume → adapted → handles → leading → to → coverage",
        "sentence": "Plume handles certain linguistic structures leading to patchy syntactic coverage.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'handles'. Entity 2 ('patchy syntactic coverage') is the object, depending on 'leading to' which modifies 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions and outcomes described in the sentence.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "declarative and imperative utterances",
                "Material"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted' in the phrase 'well adapted to'. Entity 2 ('it') is the subject, depending on 'handles' in the clause 'it handles passives, relative clauses and interrogatives'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence, where 'it' refers to 'Plume', which is adapted to handle Entity 1.\"",
        "sdp_path_text": "utterances → to → adapted → handles → it",
        "sentence": "It handles declarative and imperative utterances well.",
        "sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object, depending on the verb 'handles'. Entity 2 ('it') is the subject, depending on the verb 'handles'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handles'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "declarative and imperative utterances",
                "Material"
            ],
            [
                "passives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted'. Entity 2 ('passives') is part of a list, depending on the verb 'handles'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "utterances → to → adapted → handles → passives",
        "sentence": "Plume is adapted to declarative and imperative utterances but handles passives in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted'. Entity 2 ('passives') is the subject complement, depending on 'handles' with the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the system 'Plume' through different verbs ('adapted' and 'handles').\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "declarative and imperative utterances",
                "Material"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted' in the phrase 'adapted to simple declarative and imperative utterances'. Entity 2 ('relative clauses') is part of a list of objects, depending on 'handles' in the phrase 'it handles passives, relative clauses and interrogatives'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "utterances → to → adapted → handles → passives → clauses",
        "sentence": "Plume is adapted to declarative and imperative utterances but handles relative clauses in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted'. Entity 2 ('relative clauses') is the object of the preposition 'in', depending on 'handles'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "declarative and imperative utterances",
                "Material"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted'. Entity 2 ('interrogatives') is part of a list, depending on 'handles' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the capabilities of 'Plume'.\"",
        "sdp_path_text": "utterances → to → adapted → handles → passives → clauses → interrogatives",
        "sentence": "Plume handles declarative and imperative utterances as well as interrogatives.",
        "sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is part of a coordination, depending on the conjunction 'as well as' with 'interrogatives'. Entity 2 ('interrogatives') is also part of the same coordination, depending on the conjunction 'as well as' with 'declarative and imperative utterances'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'as well as'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "declarative and imperative utterances",
                "Material"
            ],
            [
                "patchy syntactic coverage",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted' in the phrase 'well adapted to'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on 'leading to' in the phrase 'leading to patchy syntactic coverage'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "utterances → to → adapted → handles → leading → to → coverage",
        "sentence": "While adapted to declarative and imperative utterances, handling leads to patchy syntactic coverage.",
        "sentence_llm_dp_info": "\"Entity 1 ('declarative and imperative utterances') is the object of the preposition 'to', depending on 'adapted'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on 'leads to'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the outcome and adaptation context of the handling process.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "passives",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('passives') is the first item in a list of objects, depending on 'handles' in the phrase 'handles passives, relative clauses and interrogatives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handles'.\"",
        "sdp_path_text": "it → handles → passives",
        "sentence": "It handles passives.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('passives') is the object, depending on 'handles'. There is a direct dependency between Entity 1 and Entity 2, as 'passives' is the direct object of the verb 'handles'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('relative clauses') is part of a conjunction, depending on 'and' which connects it with 'passives' and 'interrogatives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handles' which governs the entire list including Entity 2.\"",
        "sdp_path_text": "it → handles → passives → clauses",
        "sentence": "It handles relative clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('relative clauses') is the object, depending on 'handles'. There is a direct dependency between Entity 1 and Entity 2, where 'it' is the agent performing the action of handling 'relative clauses'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('interrogatives') is part of a compound noun phrase, depending on 'and' which connects it with 'passives' and 'relative clauses'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'handles' which governs the list including Entity 2.\"",
        "sdp_path_text": "it → handles → passives → clauses → interrogatives",
        "sentence": "It handles interrogatives among other complex structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('interrogatives') is the object, depending on 'handles' with 'it'. There is a direct dependency between Entity 1 and Entity 2, as 'it' is the agent that performs the action of handling 'interrogatives'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "patchy syntactic coverage",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('patchy syntactic coverage') is the object, depending on 'leading to' which is part of the verbal phrase describing the result of handling certain linguistic structures. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of actions described in the sentence, where 'it' (referring to Plume) leads to 'patchy syntactic coverage' through its handling of linguistic structures.\"",
        "sdp_path_text": "it → handles → leading → to → coverage",
        "sentence": "It handles certain structures leading to patchy syntactic coverage.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'handles'. Entity 2 ('patchy syntactic coverage') is the object of the preposition 'to', depending on 'leading' in the phrase 'leading to patchy syntactic coverage'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'handles' and the phrase 'leading to'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "passives",
                "OtherScientificTerm"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('passives') is part of a coordinated list, depending on the verb 'handles' with 'it'. Entity 2 ('relative clauses') is also part of the same coordinated list, depending on the conjunction 'and' with 'passives'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'handles'.\"",
        "sdp_path_text": "passives → clauses",
        "sentence": "Plume handles passives and relative clauses in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('passives') is a conjunct, depending on 'handles' with 'Plume'. Entity 2 ('relative clauses') is also a conjunct, depending on 'handles' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated elements in the same list, connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "passives",
                "OtherScientificTerm"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('passives') is part of a coordination, depending on 'handles' with 'it'. Entity 2 ('interrogatives') is also part of a coordination, depending on 'handles' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated objects of the verb 'handles'.\"",
        "sdp_path_text": "passives → clauses → interrogatives",
        "sentence": "Plume handles passives, relative clauses, and interrogatives in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('passives') is one of the objects in a coordination, depending on 'handles' with 'Plume'. Entity 2 ('interrogatives') is another object in the same coordination, also depending on 'handles' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same coordination structure.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "passives",
                "OtherScientificTerm"
            ],
            [
                "patchy syntactic coverage",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('passives') is part of a list, depending on the verb 'handles' with 'it'. Entity 2 ('patchy syntactic coverage') is the object, depending on 'leading to' with 'manner'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handles' and the phrase 'leading to'.\"",
        "sdp_path_text": "passives → handles → leading → to → coverage",
        "sentence": "Handling passives leads to patchy syntactic coverage.",
        "sentence_llm_dp_info": "\"Entity 1 ('passives') is the object of the preposition 'to', depending on 'leads'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on 'leads'. There is a direct dependency between Entity 1 and Entity 2, as 'leads' directly connects 'passives' to 'patchy syntactic coverage'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relative clauses') is part of a coordinated list, depending on the conjunction 'and' with 'passives'. Entity 2 ('interrogatives') is also part of the same coordinated list, depending on the conjunction 'and' with 'relative clauses'. Both Entity 1 and Entity 2 are objects of the verb 'handles'. There is no direct dependency between Entity 1 and Entity 2, but they are both directly dependent on the verb 'handles'.\"",
        "sdp_path_text": "clauses → interrogatives",
        "sentence": "Relative clauses and interrogatives are handled in an ad hoc manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('relative clauses') is a conjunct, depending on 'are' with the coordination 'and'. Entity 2 ('interrogatives') is a conjunct, also depending on 'are' with the coordination 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as subjects of the sentence.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            [
                "patchy syntactic coverage",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relative clauses') is part of a list of items, depending on the verb 'handles' with 'it'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on the verb 'leading to'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the limitations of how 'Plume' handles certain grammatical structures.\"",
        "sdp_path_text": "clauses → passives → handles → leading → to → coverage",
        "sentence": "Relative clauses are handled in an ad hoc manner, leading to patchy syntactic coverage.",
        "sentence_llm_dp_info": "\"Entity 1 ('relative clauses') is the subject, depending on 'handled'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on 'leading to'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the causal relationship expressed by 'leading to'.\""
    },
    {
        "raw_sentence": "While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage .",
        "ner_pair": [
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            [
                "patchy syntactic coverage",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('interrogatives') is part of a list of items, depending on 'handles' with 'it'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on 'leading to' with 'manner'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the handling capabilities and outcomes of 'Plume'.\"",
        "sdp_path_text": "interrogatives → clauses → passives → handles → leading → to → coverage",
        "sentence": "Interrogatives are handled in an ad hoc manner, leading to patchy syntactic coverage.",
        "sentence_llm_dp_info": "\"Entity 1 ('interrogatives') is the subject, depending on the verb 'handled'. Entity 2 ('patchy syntactic coverage') is the subject complement, depending on the verb 'leading'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by the verb 'leading'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object of the preposition 'as', depending on 'outlines' with 'This paper'. Entity 2 ('it') is a pronoun, depending on 'exists' as the subject. There is no direct dependency between Entity 1 and Entity 2; however, they are semantically related through the reference of 'it' to 'Plume'.\"",
        "sdp_path_text": "Plume → outlines → exists → it",
        "sentence": "This paper outlines Plume as it currently exists.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the complement, depending on 'outlines' with 'This paper'. Entity 2 ('it') is the subject, depending on 'exists' with the verb 'exists'. There is no direct dependency between Entity 1 and Entity 2, but 'it' likely refers back to 'Plume' in the context of the sentence.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "passives",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object of the preposition 'as' and the object of the preposition 'for', depending on 'outlines' and 'design' respectively. Entity 2 ('passives') is part of a list of objects, depending on 'handle' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' which indicates that 'Plume' is designed to manage 'passives' among other linguistic structures.\"",
        "sdp_path_text": "Plume → outlines → describes → design → for → extending → handle → passives",
        "sentence": "Plume is designed to handle passives.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is designed'. Entity 2 ('passives') is the object of the verb 'handle', depending on 'to handle' in the phrase 'to handle passives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to handle passives'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object of the preposition 'as' and also the object of the preposition 'for' in the phrase 'for extending Plume'. Entity 2 ('relative clauses') is part of a list of objects, depending on 'handle' in the phrase 'to handle passives, relative clauses, and interrogatives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' which is part of the larger clause describing the design for extending Plume.\"",
        "sdp_path_text": "Plume → outlines → describes → design → for → extending → handle → passives → clauses",
        "sentence": "Plume is designed to handle relative clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is designed'. Entity 2 ('relative clauses') is the object of the preposition 'to', depending on 'handle' in the phrase 'to handle relative clauses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object of the preposition 'as' and the object of the preposition 'for', appearing in the phrases 'as it currently exists' and 'for extending Plume'. Entity 2 ('interrogatives') is part of a list of objects, depending on 'handle' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' which is part of the description of the design for extending Plume.\"",
        "sdp_path_text": "Plume → outlines → describes → design → for → extending → handle → passives → clauses → interrogatives",
        "sentence": "Plume is designed to handle passives, relative clauses, and interrogatives.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is designed'. Entity 2 ('interrogatives') is part of a coordination, depending on 'handle' with 'passives' and 'relative clauses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' and the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "Plume",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the preposition 'as', depending on 'outlines' with 'This paper'. Entity 2 ('Plume') is the subject complement, depending on 'outlines' with 'This paper'. There is a direct dependency between Entity 1 and Entity 2, as 'it' refers back to 'Plume' in the context of the sentence.\"",
        "sdp_path_text": "it → exists → outlines → Plume",
        "sentence": "This paper outlines Plume as it currently exists.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the preposition 'as', depending on 'as' in the phrase 'as it'. Entity 2 ('Plume') is the subject complement, depending on the verb 'outlines'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'as it currently exists' where 'it' refers back to 'Plume'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "passives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the preposition 'as', depending on 'outlines' with 'This paper'. Entity 2 ('passives') is one of the objects in a list, depending on 'handle' in the phrase 'to handle passives'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "it → exists → outlines → describes → design → for → extending → handle → passives",
        "sentence": "It outlines and describes the design for extending to handle passives.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verbs 'outlines' and 'describes'. Entity 2 ('passives') is the object of the preposition 'to', depending on 'handle' in the phrase 'to handle passives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'outlines' and 'describes' and the prepositional phrase 'to handle passives'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject complement, depending on 'exists' with 'as'. Entity 2 ('relative clauses') is part of a list of objects, depending on 'handle' in the phrase 'to handle passives, relative clauses, and interrogatives'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "it → exists → outlines → describes → design → for → extending → handle → passives → clauses",
        "sentence": "It outlines and describes the design for extending to handle relative clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verbs 'outlines' and 'describes'. Entity 2 ('relative clauses') is the object of the preposition 'to', depending on 'to' in the phrase 'to handle relative clauses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'outlines' and 'describes' and the purpose clause 'for extending to handle relative clauses'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the preposition 'as', depending on 'outlines' with 'This paper'. Entity 2 ('interrogatives') is part of a list of objects, depending on 'handle' in the phrase 'to handle passives, relative clauses, and interrogatives'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "it → exists → outlines → describes → design → for → extending → handle → passives → clauses → interrogatives",
        "sentence": "It outlines and describes the design for extending to handle interrogatives.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verbs 'outlines' and 'describes'. Entity 2 ('interrogatives') is the object of the preposition 'for', depending on 'handle' in the phrase 'for extending to handle interrogatives'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "passives",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object of the preposition 'as' in the clause 'Plume as it currently exists', and it also serves as the object of the preposition 'for' in the phrase 'for extending Plume'. Entity 2 ('passives') is part of a list of objects, depending on 'handle' in the phrase 'to handle passives, relative clauses, and interrogatives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' which is part of the purpose clause 'for extending Plume to handle...'.\"",
        "sdp_path_text": "Plume → outlines → describes → design → for → extending → handle → passives",
        "sentence": "Plume is designed to handle passives.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is designed'. Entity 2 ('passives') is the object of the verb 'handle', depending on 'handle' in the phrase 'to handle passives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' which is part of the purpose clause 'designed to handle passives'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject of the clause 'Plume as it currently exists', depending on 'outlines' with 'This paper'. Entity 2 ('relative clauses') is part of a list of objects, depending on 'handle' in the phrase 'to handle passives, relative clauses, and interrogatives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' which is part of the description of the design for extending Plume.\"",
        "sdp_path_text": "Plume → outlines → describes → design → for → extending → handle → passives → clauses",
        "sentence": "Plume is designed to handle relative clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is designed'. Entity 2 ('relative clauses') is the object of the verb 'handle', depending on 'to handle'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to handle relative clauses'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "Plume",
                "Method"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Plume') is the object of the preposition 'as', depending on 'outlines' with 'This paper'. It also appears as the object of the preposition 'for' in the phrase 'for extending Plume'. Entity 2 ('interrogatives') is part of a list of objects, depending on 'handle' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'handle' which is part of the clause describing the design for extending Plume.\"",
        "sdp_path_text": "Plume → outlines → describes → design → for → extending → handle → passives → clauses → interrogatives",
        "sentence": "Plume is designed to handle passives, relative clauses, and interrogatives.",
        "sentence_llm_dp_info": "\"Entity 1 ('Plume') is the subject, depending on the verb 'is designed'. Entity 2 ('interrogatives') is part of a list, depending on the conjunction 'and' which connects it to 'passives' and 'relative clauses', all of which are objects of the verb 'handle'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'handle' and the design purpose of 'Plume'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "passives",
                "OtherScientificTerm"
            ],
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('passives') is an element of a list, depending on the verb 'handle' in the phrase 'to handle passives'. Entity 2 ('relative clauses') is also an element of the same list, depending on the conjunction 'and' which connects it to 'passives'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of items that 'Plume' is being extended to handle.\"",
        "sdp_path_text": "passives → clauses",
        "sentence": "Plume will handle passives and relative clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('passives') is the object of the conjunction 'and', depending on 'handle' with 'Plume'. Entity 2 ('relative clauses') is also the object of the conjunction 'and', depending on 'handle' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated objects of the verb 'handle'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "passives",
                "OtherScientificTerm"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('passives') is one of the objects in a list, depending on the preposition 'for' which is part of the phrase 'for extending Plume to handle'. Entity 2 ('interrogatives') is another object in the same list, also depending on the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list of objects.\"",
        "sdp_path_text": "passives → clauses → interrogatives",
        "sentence": "Plume will handle passives, relative clauses, and interrogatives.",
        "sentence_llm_dp_info": "\"Entity 1 ('passives') is a member of a coordination, depending on 'handle' with 'will'. Entity 2 ('interrogatives') is also a member of a coordination, depending on 'handle' with 'will'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same coordination, linked through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This paper outlines Plume as it currently exists and describes our detailed design for extending Plume to handle passives , relative clauses , and interrogatives in a general manner .",
        "ner_pair": [
            [
                "relative clauses",
                "OtherScientificTerm"
            ],
            [
                "interrogatives",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relative clauses') is part of a list, depending on the verb 'handle'. Entity 2 ('interrogatives') is also part of the same list, depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both listed as items that Plume will be extended to handle.\"",
        "sdp_path_text": "clauses → interrogatives",
        "sentence": "Plume will handle relative clauses and interrogatives in a general manner.",
        "sentence_llm_dp_info": "\"Entity 1 ('relative clauses') is the first object, depending on 'handle' with 'Plume'. Entity 2 ('interrogatives') is the second object, also depending on 'handle' with 'Plume'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'handle'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "unlexicalized parser",
                "Method"
            ],
            [
                "German",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlexicalized parser') is the object, depending on 'present' with 'we'. Entity 2 ('German') is the complementizer, depending on 'for' in the phrase 'for German'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "parser → for → German",
        "sentence": "An unlexicalized parser is presented for German.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlexicalized parser') is the subject, depending on the verb 'presented'. Entity 2 ('German') is the object of the preposition 'for', depending on 'for' in the phrase 'for German'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of a conjunction, depending on 'employs' with 'unlexicalized parser'. Entity 2 ('unlexicalized parser') is the direct object, depending on the verb 'present'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'employs'.\"",
        "sdp_path_text": "smoothing → analysis → employs → parser",
        "sentence": "The unlexicalized parser employs smoothing for analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object, depending on the verb 'employs'. Entity 2 ('unlexicalized parser') is the subject, depending on the verb 'employs'. There is a direct dependency between Entity 1 and Entity 2, where 'unlexicalized parser' employs 'smoothing'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "suffix analysis",
                "Method"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('suffix analysis') is part of a list of methods, depending on the conjunction 'and' with 'smoothing'. Entity 2 ('unlexicalized parser') is the object of the preposition 'for', depending on 'present' in the phrase 'present an unlexicalized parser for German'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the overall structure describing the features and performance of the parser.\"",
        "sdp_path_text": "analysis → employs → parser",
        "sentence": "The unlexicalized parser employs suffix analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('suffix analysis') is the object, depending on the verb 'employs'. Entity 2 ('unlexicalized parser') is the subject, also depending on the verb 'employs'. There is a direct dependency between Entity 1 and Entity 2, where 'unlexicalized parser' employs 'suffix analysis'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "labelled bracket F-score",
                "Metric"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('labelled bracket F-score') is the object, depending on the verb 'achieve' with 'which' (referring to 'unlexicalized parser'). Entity 2 ('unlexicalized parser') is the object, depending on the verb 'present' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the relative clause 'which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2'.\"",
        "sdp_path_text": "score → achieve → employs → parser",
        "sentence": "The unlexicalized parser achieves a labelled bracket F-score.",
        "sentence_llm_dp_info": "\"Entity 1 ('labelled bracket F-score') is the object, depending on 'achieves' with 'unlexicalized parser'. Entity 2 ('unlexicalized parser') is the subject, depending on the verb 'achieves'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is the agent performing the action that results in Entity 1.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "NEGRA corpus",
                "Material"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NEGRA corpus') is the object, depending on 'results' with 'reported'. Entity 2 ('unlexicalized parser') is the object, depending on 'present' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same discourse context, where the performance of the parser is compared against previous results on the corpus.\"",
        "sdp_path_text": "corpus → on → results → than → higher → 76.2 → of → score → achieve → employs → parser",
        "sentence": "The unlexicalized parser achieves a higher score on the NEGRA corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('NEGRA corpus') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NEGRA corpus'. Entity 2 ('unlexicalized parser') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on the NEGRA corpus' which modifies the verb 'achieves'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "German",
                "Material"
            ],
            [
                "smoothing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('smoothing') is part of a coordination, depending on 'employs' with 'parser'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "German → for → parser → employs → analysis → smoothing",
        "sentence": "A parser for German employs smoothing.",
        "sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('smoothing') is the object, depending on the verb 'employs'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the parser does and for which language.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "German",
                "Material"
            ],
            [
                "suffix analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('suffix analysis') is part of a conjunction, depending on 'employs' with 'smoothing and suffix analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the parser being described in the sentence.\"",
        "sdp_path_text": "German → for → parser → employs → analysis",
        "sentence": "A parser for German employs suffix analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('suffix analysis') is the object, depending on 'employs' with 'parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main subject 'parser'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "German",
                "Material"
            ],
            [
                "labelled bracket F-score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('labelled bracket F-score') is the object of the relative clause 'which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the parser's capabilities and performance.\"",
        "sdp_path_text": "German → for → parser → employs → achieve → score",
        "sentence": "A parser for German achieves a labelled bracket F-score.",
        "sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('labelled bracket F-score') is the object, depending on 'achieves' with 'parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the subject 'parser'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "German",
                "Material"
            ],
            [
                "NEGRA corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "German → for → parser → employs → achieve → score → of → 76.2 → higher → than → results → on → corpus",
        "sentence": "A parser for German achieves a higher score than results on the NEGRA corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('German') is the object of the preposition 'for', depending on 'parser'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "suffix analysis",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object of the preposition 'and', depending on 'employs' with 'parser'. Entity 2 ('suffix analysis') is also the object of the preposition 'and', depending on 'employs' with 'parser'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list under the verb 'employs'.\"",
        "sdp_path_text": "smoothing → analysis",
        "sentence": "The parser employs smoothing and suffix analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object of the conjunction 'and', depending on 'employs' with 'The parser'. Entity 2 ('suffix analysis') is also an object, depending on the conjunction 'and' with 'smoothing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' under the verb 'employs'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "labelled bracket F-score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of a conjunction, depending on 'employs' with 'parser'. Entity 2 ('labelled bracket F-score') is the object, depending on 'achieve' with 'parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the actions performed by the parser described in the sentence.\"",
        "sdp_path_text": "smoothing → analysis → employs → achieve → score",
        "sentence": "Smoothing and suffix analysis are employed to achieve a labelled bracket F-score.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of a coordination, depending on the verb 'are employed'. Entity 2 ('labelled bracket F-score') is the object, depending on the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieve' which indicates the purpose of employing the techniques mentioned.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "NEGRA corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of a conjunction, depending on 'employs' with 'parser'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "smoothing → analysis → employs → achieve → score → of → 76.2 → higher → than → results → on → corpus",
        "sentence": "Smoothing analysis helps achieve a higher score on the NEGRA corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of the compound noun 'smoothing analysis', which is the subject, depending on the verb 'helps'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NEGRA corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'smoothing analysis' (which includes Entity 1) influences the score on 'NEGRA corpus' (Entity 2).\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "suffix analysis",
                "Method"
            ],
            [
                "labelled bracket F-score",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('suffix analysis') is part of a coordination, depending on 'employs' with 'smoothing'. Entity 2 ('labelled bracket F-score') is the object of the preposition 'of', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'achieve' through the structure of the sentence.\"",
        "sdp_path_text": "analysis → employs → achieve → score",
        "sentence": "Suffix analysis is employed to achieve a labelled bracket F-score.",
        "sentence_llm_dp_info": "\"Entity 1 ('suffix analysis') is the subject, depending on the verb 'is employed'. Entity 2 ('labelled bracket F-score') is the object, depending on 'achieve' with 'employed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to achieve'.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "suffix analysis",
                "Method"
            ],
            [
                "NEGRA corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('suffix analysis') is part of the list of methods used, depending on 'employs' with 'parser'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the performance and methods described in the sentence.\"",
        "sdp_path_text": "analysis → employs → achieve → score → of → 76.2 → higher → than → results → on → corpus",
        "sentence": "Suffix analysis is employed to achieve a higher score than previously reported results on the NEGRA corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('suffix analysis') is the subject, depending on the verb 'is employed'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NEGRA corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose of the employment of suffix analysis, which is to achieve a higher score on the NEGRA corpus.\""
    },
    {
        "raw_sentence": "In this paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than previously reported results on the NEGRA corpus .",
        "ner_pair": [
            [
                "labelled bracket F-score",
                "Metric"
            ],
            [
                "NEGRA corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('labelled bracket F-score') is the object, depending on the verb 'achieve' with 'which'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the performance of the parser.\"",
        "sdp_path_text": "score → of → 76.2 → higher → than → results → on → corpus",
        "sentence": "The labelled bracket F-score of 76.2 is higher than results on the NEGRA corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('labelled bracket F-score') is the subject, depending on the verb 'is'. Entity 2 ('NEGRA corpus') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparison structure involving 'higher than'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "model",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the subject complement, depending on the preposition 'of' in the phrase 'of the model'. Entity 2 ('model') is the object of the preposition 'of', depending on 'accuracy'. There is a direct dependency between Entity 1 and Entity 2, as 'model' specifies what the 'accuracy' pertains to.\"",
        "sdp_path_text": "accuracy → of → model",
        "sentence": "The model has high accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'has' with 'model'. Entity 2 ('model') is the subject, depending on the verb 'has'. There is a direct dependency between Entity 1 and Entity 2, where 'model' is the subject and 'accuracy' is the object of the verb 'has'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "smoothing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object of the preposition 'of', depending on 'model'. Entity 2 ('smoothing') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different aspects of the sentence structure.\"",
        "sdp_path_text": "accuracy → to → addition → In → allows → use → of → smoothing",
        "sentence": "The use of smoothing allows for better examination of its impact on accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'impact' with 'its'. Entity 2 ('smoothing') is the subject, depending on 'allows' with 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'impact on accuracy'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object of the preposition 'of', depending on 'model'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of discussing aspects of a model and its components.\"",
        "sdp_path_text": "accuracy → to → addition → In → allows → use → in → parser",
        "sentence": "The accuracy of the model allows us to better examine the interplay between smoothing and parsing results in an unlexicalized parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the subject, depending on 'allows' with 'The accuracy of the model'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'in' in the phrase 'in an unlexicalized parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allows' and the prepositional phrase 'in an unlexicalized parser'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "smoothing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object of the preposition 'of', depending on 'model'. Entity 2 ('smoothing') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of discussing aspects of the model and its performance.\"",
        "sdp_path_text": "accuracy → to → addition → In → allows → use → of → smoothing",
        "sentence": "The use of smoothing allows for better examination of its impact on accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'impact' with 'its'. Entity 2 ('smoothing') is the subject, depending on 'allows' with 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'impact on accuracy'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "parsing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object of the preposition 'of', depending on 'model'. Entity 2 ('parsing') is part of the compound noun 'parsing results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2; however, they are both related to the topic of the sentence, which discusses aspects of a model's performance and the examination of techniques affecting its outcomes.\"",
        "sdp_path_text": "accuracy → to → addition → In → allows → examine → interplay → between → results → smoothing → parsing",
        "sentence": "The accuracy of the model allows us to examine the interplay between smoothing and parsing results.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the subject, depending on the verb 'allows'. Entity 2 ('parsing') is part of the compound noun 'parsing results', which is the object of the preposition 'between'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence, specifically via the verb 'allows' and the prepositional phrase 'between smoothing and parsing results'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "smoothing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is part of a prepositional phrase, depending on 'of' in 'the high accuracy of the model'. Entity 2 ('smoothing') is the object of the preposition 'of', depending on 'use' in 'the use of smoothing'. There is no direct dependency between Entity 1 and Entity 2, but both are related to aspects of the sentence that describe components or techniques used in the context of the model and its performance.\"",
        "sdp_path_text": "model → of → accuracy → to → addition → In → allows → use → of → smoothing",
        "sentence": "The model's accuracy is improved by the use of smoothing.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is part of the possessive noun phrase 'model's accuracy', depending on 'accuracy' as its modifier. Entity 2 ('smoothing') is the object of the preposition 'of', depending on 'use' in the phrase 'use of smoothing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improved' and the prepositional phrase 'by the use of smoothing'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is part of a prepositional phrase, depending on 'of' with 'accuracy'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both mentioned in the context of discussing aspects of parsing and smoothing techniques.\"",
        "sdp_path_text": "model → of → accuracy → to → addition → In → allows → use → in → parser",
        "sentence": "The model's accuracy allows the use of an unlexicalized parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is part of the possessive noun phrase 'model's accuracy', where 'accuracy' depends on 'model' through the possessive case. Entity 2 ('unlexicalized parser') is the object of the preposition 'of', depending on 'use' in the phrase 'use of an unlexicalized parser'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'allows' and the noun 'use'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "smoothing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is part of the prepositional phrase 'of the model', depending on 'accuracy' with the preposition 'of'. Entity 2 ('smoothing') is the object of the preposition 'of' in the phrase 'use of smoothing', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both discussed in the context of the sentence, with 'smoothing' being mentioned in relation to its impact on 'parsing results'.\"",
        "sdp_path_text": "model → of → accuracy → to → addition → In → allows → use → of → smoothing",
        "sentence": "The model's accuracy is improved by the use of smoothing.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is part of the possessive noun phrase 'model's accuracy', depending on 'accuracy' as its modifier. Entity 2 ('smoothing') is the object of the preposition 'of', depending on 'use' in the phrase 'use of smoothing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improved' and the prepositional phrase 'by the use of smoothing'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "parsing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'of', depending on 'accuracy'. Entity 2 ('parsing') is part of a compound noun, depending on 'results' in the phrase 'parsing results'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in describing aspects of the system being discussed.\"",
        "sdp_path_text": "model → of → accuracy → to → addition → In → allows → examine → interplay → between → results → smoothing → parsing",
        "sentence": "The model allows us to examine the interplay between smoothing and parsing results.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'allows'. Entity 2 ('parsing') is part of a compound noun, depending on 'interplay' with 'and' in the phrase 'interplay between smoothing and parsing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allows' and the prepositional phrase 'between smoothing and parsing'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of the noun phrase, depending on 'use' with the preposition 'of' in the phrase 'use of smoothing'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'in' in the phrase 'in an unlexicalized parser'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the conditions that allow for better examination of the interplay between them.\"",
        "sdp_path_text": "smoothing → of → use → in → parser",
        "sentence": "The use of smoothing in an unlexicalized parser allows better examination of the interplay between smoothing and parsing results.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object of the preposition 'of', depending on 'use'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the noun 'use' which serves as the subject of the clause.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "parsing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of the noun phrase 'the use of smoothing', where it is the object of the preposition 'of', depending on 'use'. Entity 2 ('parsing') is part of the noun phrase 'parsing results', where it modifies 'results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both mentioned within the context of examining their interplay.\"",
        "sdp_path_text": "smoothing → of → use → allows → examine → interplay → between → results → smoothing → parsing",
        "sentence": "The use of smoothing allows us to examine the interplay between smoothing and parsing results.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object of the preposition 'of', depending on 'use'. Entity 2 ('parsing') is part of the compound noun 'parsing results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both mentioned in the context of examining their interplay.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "unlexicalized parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object of the preposition 'of', depending on 'use'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify 'use'.\"",
        "sdp_path_text": "smoothing → of → use → in → parser",
        "sentence": "The use of smoothing in an unlexicalized parser allows better examination of their interplay.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is the object of the preposition 'of', depending on 'use'. Entity 2 ('unlexicalized parser') is the object of the preposition 'in', depending on 'of smoothing in'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase 'of smoothing in an unlexicalized parser'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "unlexicalized parser",
                "Method"
            ],
            [
                "parsing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlexicalized parser') is the object of the preposition 'in', depending on 'use'. Entity 2 ('parsing') is part of the compound noun 'parsing results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of examining the interplay, which is described in the sentence.\"",
        "sdp_path_text": "parser → in → use → allows → examine → interplay → between → results → smoothing → parsing",
        "sentence": "The use of smoothing in an unlexicalized parser allows examining the interplay between smoothing and parsing results.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlexicalized parser') is the object of the preposition 'in', depending on 'use'. Entity 2 ('parsing') is part of the compound noun 'parsing results', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'smoothing' and its effects on 'parsing results'.\""
    },
    {
        "raw_sentence": "In addition to the high accuracy of the model , the use of smoothing in an unlexicalized parser allows us to better examine the interplay between smoothing and parsing results .",
        "ner_pair": [
            [
                "smoothing",
                "Method"
            ],
            [
                "parsing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of a prepositional phrase, depending on 'use' with 'of'. Entity 2 ('parsing') is part of a compound noun, depending on 'interplay' with 'between'. There is no direct dependency between Entity 1 and Entity 2, but they are both mentioned in the context of examining their interaction.\"",
        "sdp_path_text": "smoothing → of → use → allows → examine → interplay → between → results → smoothing → parsing",
        "sentence": "The use of smoothing allows us to examine the interplay between smoothing and parsing results.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothing') is part of a noun phrase, depending on 'use' with the preposition 'of'. Entity 2 ('parsing') is part of a compound noun, depending on 'results' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger noun phrase 'the interplay between smoothing and parsing results'.\""
    },
    {
        "raw_sentence": "This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts .",
        "ner_pair": [
            [
                "unsupervised learning approach",
                "Method"
            ],
            [
                "relations between named entities",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unsupervised learning approach') is the subject, depending on the verb 'presents' with 'This paper'. Entity 2 ('relations between named entities') is the object of the infinitive 'to disambiguate', depending on 'disambiguate' in the phrase 'to disambiguate various relations between named entities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to disambiguate'.\"",
        "sdp_path_text": "approach → disambiguate → relations",
        "sentence": "An unsupervised learning approach disambiguates relations between named entities.",
        "sentence_llm_dp_info": "\"Entity 1 ('unsupervised learning approach') is the subject, depending on the verb 'disambiguates'. Entity 2 ('relations between named entities') is the object, depending on the verb 'disambiguates'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 performs the action (disambiguates) on Entity 2.\""
    },
    {
        "raw_sentence": "This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts .",
        "ner_pair": [
            [
                "lexical and syntactic features",
                "OtherScientificTerm"
            ],
            [
                "unsupervised learning approach",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical and syntactic features') is the object of the preposition 'of', depending on 'use'. Entity 2 ('unsupervised learning approach') is the object of the verb 'presents', depending on 'presents' in the phrase 'presents an unsupervised learning approach'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'use' which describes how the features are utilized in the approach.\"",
        "sdp_path_text": "features → of → use → by → disambiguate → approach",
        "sentence": "Lexical and syntactic features are used by the unsupervised learning approach to disambiguate relations.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical and syntactic features') is the subject, depending on the passive verb 'are used'. Entity 2 ('unsupervised learning approach') is the agent of the passive construction, depending on 'by' in the phrase 'by the unsupervised learning approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction where Entity 2 is the agent performing the action on Entity 1.\""
    },
    {
        "raw_sentence": "This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts .",
        "ner_pair": [
            [
                "relations between named entities",
                "OtherScientificTerm"
            ],
            [
                "lexical and syntactic features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relations between named entities') is the object of the preposition 'to', depending on 'disambiguate'. Entity 2 ('lexical and syntactic features') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the purpose and method of the unsupervised learning approach.\"",
        "sdp_path_text": "relations → disambiguate → by → use → of → features",
        "sentence": "This paper presents an approach to disambiguate relations between named entities using lexical and syntactic features.",
        "sentence_llm_dp_info": "\"Entity 1 ('relations between named entities') is the object of the preposition 'to', depending on 'approach'. Entity 2 ('lexical and syntactic features') is the object of the preposition 'using', depending on 'using'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the approach presented in the paper.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the object of the preposition 'of', depending on 'Laplacian'. Entity 2 ('It') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the process described in the sentence where 'It' (the subject) performs actions that involve 'eigenvectors'.\"",
        "sdp_path_text": "eigenvectors → calculating → by → works → It",
        "sentence": "It works by calculating eigenvectors.",
        "sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the object, depending on the verb 'calculating'. Entity 2 ('It') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'calculating' which describes the action performed on 'eigenvectors' by 'It'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "adjacency graph 's Laplacian",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'works'. Entity 2 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors of an adjacency graph's Laplacian'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'works' and the prepositional phrase that modifies the action.\"",
        "sdp_path_text": "It → works → by → calculating → eigenvectors → of → Laplacian",
        "sentence": "It works by calculating eigenvectors of the adjacency graph's Laplacian.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'works'. Entity 2 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors of the adjacency graph's Laplacian'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "submanifold",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'works'. Entity 2 ('submanifold') is the object of the preposition 'of', depending on 'recover' in the phrase 'to recover a submanifold of data'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the series of actions described in the sentence, where 'It' performs operations that lead to the recovery of the 'submanifold'.\"",
        "sdp_path_text": "It → works → by → calculating → recover → submanifold",
        "sentence": "It works by calculating to recover a submanifold.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'works'. Entity 2 ('submanifold') is the object of the verb 'recover', which is part of the infinitive phrase 'to recover a submanifold'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions described by the verbs 'works' and 'recover'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "high dimensionality space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'works'. Entity 2 ('high dimensionality space') is the object of the preposition 'from', depending on 'from' in the phrase 'from a high dimensionality space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of actions described in the sentence.\"",
        "sdp_path_text": "It → works → by → calculating → recover → from → space",
        "sentence": "It works by calculating to recover from a high dimensionality space.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'works'. Entity 2 ('high dimensionality space') is the object of the preposition 'from', depending on 'from' in the phrase 'from a high dimensionality space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'from a high dimensionality space' which modifies the verb 'recover'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "cluster number estimation",
                "Task"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cluster number estimation') is the object, depending on 'performing' which is part of the verb phrase 'performing cluster number estimation'. Entity 2 ('It') is the subject, depending on 'works' as the main verb of the sentence. There is no direct dependency between Entity 1 and Entity 2; they are connected through the sequence of actions described in the sentence, where 'It' initiates the process that ultimately leads to the 'cluster number estimation'.\"",
        "sdp_path_text": "estimation → performing → calculating → by → works → It",
        "sentence": "It works by performing cluster number estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('cluster number estimation') is the object, depending on 'performing' with 'by'. Entity 2 ('It') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'works' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the object of the preposition 'of', depending on 'Laplacian'. Entity 2 ('It') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'It' refers to the process or system that uses the 'eigenvectors' for its operation.\"",
        "sdp_path_text": "eigenvectors → calculating → by → works → It",
        "sentence": "It works by calculating eigenvectors.",
        "sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the object, depending on 'calculating' with 'by'. Entity 2 ('It') is the subject, depending on the verb 'works'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' which describes how 'It' works.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "adjacency graph 's Laplacian",
                "OtherScientificTerm"
            ],
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors of an adjacency graph's Laplacian'. Entity 2 ('eigenvectors') is the direct object, depending on 'calculating' in the phrase 'calculating eigenvectors'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is calculated from Entity 1.\"",
        "sdp_path_text": "Laplacian → of → eigenvectors",
        "sentence": "It works by calculating eigenvectors of the adjacency graph's Laplacian.",
        "sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the possessive noun, depending on 'of' with 'eigenvectors'. Entity 2 ('eigenvectors') is the object of the verb 'calculating', depending on 'by' in the phrase 'by calculating eigenvectors'. There is a direct dependency between Entity 1 and Entity 2, where 'Laplacian' modifies 'eigenvectors' through the preposition 'of'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            [
                "submanifold",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors'. Entity 2 ('submanifold') is the object of the preposition 'of', depending on 'recover' in the phrase 'recover a submanifold'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described in the sentence, with 'eigenvectors' being used to 'recover' the 'submanifold'.\"",
        "sdp_path_text": "eigenvectors → calculating → recover → submanifold",
        "sentence": "Eigenvectors are calculated to recover a submanifold of data.",
        "sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the subject, depending on the verb 'calculated'. Entity 2 ('submanifold') is the object of the preposition 'of', depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'calculated' and the purpose clause 'to recover a submanifold of data'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            [
                "high dimensionality space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors'. Entity 2 ('high dimensionality space') is the object of the preposition 'from', depending on 'recover' in the phrase 'recover a submanifold of data from a high dimensionality space'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the process described in the sentence, where Entity 1 is used to recover a submanifold from Entity 2.\"",
        "sdp_path_text": "eigenvectors → calculating → recover → from → space",
        "sentence": "Eigenvectors are calculated to recover data from a high dimensionality space.",
        "sentence_llm_dp_info": "\"Entity 1 ('eigenvectors') is the subject, depending on the verb 'calculated'. Entity 2 ('high dimensionality space') is the object of the preposition 'from', depending on 'from' in the phrase 'from a high dimensionality space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' which indicates the source or origin of the action performed on the eigenvectors.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "cluster number estimation",
                "Task"
            ],
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cluster number estimation') is the object of the verb 'performing', depending on 'performing'. Entity 2 ('eigenvectors') is the object of the preposition 'on', depending on 'on' in the phrase 'on the eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of performing cluster number estimation on the eigenvectors.\"",
        "sdp_path_text": "estimation → performing → calculating → eigenvectors",
        "sentence": "Cluster number estimation is performed on the eigenvectors calculated from the adjacency graph's Laplacian.",
        "sentence_llm_dp_info": "\"Entity 1 ('cluster number estimation') is the subject, depending on the verb 'is performed'. Entity 2 ('eigenvectors') is the object of the preposition 'on', depending on 'performed' in the phrase 'is performed on the eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "adjacency graph 's Laplacian",
                "OtherScientificTerm"
            ],
            [
                "submanifold",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating'. Entity 2 ('submanifold') is the object of the preposition 'a', depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where the action of 'recovering' the submanifold involves 'calculating eigenvectors' of the 'adjacency graph’s Laplacian'.\"",
        "sdp_path_text": "Laplacian → of → eigenvectors → calculating → recover → submanifold",
        "sentence": "It works by calculating eigenvectors of the adjacency graph's Laplacian to recover a submanifold.",
        "sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors of the adjacency graph's Laplacian'. Entity 2 ('submanifold') is the object, depending on 'recover' in the phrase 'to recover a submanifold'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Laplacian' is used in the process that leads to the recovery of the 'submanifold'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "adjacency graph 's Laplacian",
                "OtherScientificTerm"
            ],
            [
                "high dimensionality space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating' in the phrase 'calculating eigenvectors of an adjacency graph’s Laplacian'. Entity 2 ('high dimensionality space') is the object of the preposition 'from', depending on 'recover' in the phrase 'recover a submanifold of data from a high dimensionality space'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the process described in the sentence.\"",
        "sdp_path_text": "Laplacian → of → eigenvectors → calculating → recover → from → space",
        "sentence": "The Laplacian of an adjacency graph helps recover data from a high dimensionality space.",
        "sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the subject, depending on the verb 'helps'. Entity 2 ('high dimensionality space') is the object of the preposition 'from', depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of 'recovering' data.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "adjacency graph 's Laplacian",
                "OtherScientificTerm"
            ],
            [
                "cluster number estimation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating'. Entity 2 ('cluster number estimation') is the object of the preposition 'on', depending on 'performing'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the process described in the sentence, linked through the main actions of 'calculating' and 'performing'.\"",
        "sdp_path_text": "Laplacian → of → eigenvectors → calculating → performing → estimation",
        "sentence": "It calculates eigenvectors of the adjacency graph's Laplacian and performs cluster number estimation on them.",
        "sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'eigenvectors'. Entity 2 ('cluster number estimation') is the subject, depending on the verb 'performs'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "adjacency graph 's Laplacian",
                "OtherScientificTerm"
            ],
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the object of the preposition 'of', depending on 'calculating'. Entity 2 ('eigenvectors') is the direct object, depending on 'calculating'. There is a direct dependency between Entity 1 and Entity 2, as 'eigenvectors' are calculated 'of' the 'adjacency graph's Laplacian'.\"",
        "sdp_path_text": "Laplacian → of → eigenvectors",
        "sentence": "It calculates eigenvectors of the adjacency graph's Laplacian.",
        "sentence_llm_dp_info": "\"Entity 1 ('adjacency graph's Laplacian') is the possessive noun phrase, depending on 'of' with 'eigenvectors'. Entity 2 ('eigenvectors') is the object, depending on the verb 'calculates'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 modifies Entity 2 through the preposition 'of'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "high dimensionality space",
                "OtherScientificTerm"
            ],
            [
                "submanifold",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high dimensionality space') is the object of the preposition 'from', depending on 'recover'. Entity 2 ('submanifold') is the direct object, depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recover', where 'submanifold' is what is recovered from the 'high dimensionality space'.\"",
        "sdp_path_text": "space → from → recover → submanifold",
        "sentence": "It recovers a submanifold from a high dimensionality space.",
        "sentence_llm_dp_info": "\"Entity 1 ('high dimensionality space') is the object of the preposition 'from', depending on 'recovers'. Entity 2 ('submanifold') is the direct object, depending on the verb 'recovers'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'recovers'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "submanifold",
                "OtherScientificTerm"
            ],
            [
                "cluster number estimation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('submanifold') is the object of the preposition 'of', depending on 'recover' in the phrase 'to recover a submanifold of data'. Entity 2 ('cluster number estimation') is the object of the preposition 'on', depending on 'performing' in the phrase 'performing cluster number estimation on the eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the process described in the sentence, linked through the actions of 'recovering' and 'performing'.\"",
        "sdp_path_text": "submanifold → recover → calculating → performing → estimation",
        "sentence": "It recovers a submanifold and performs cluster number estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('submanifold') is the object of the verb 'recovers', depending on 'recovers'. Entity 2 ('cluster number estimation') is the object of the verb 'performs', depending on 'performs'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different verbs in the same sentence.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "submanifold",
                "OtherScientificTerm"
            ],
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('submanifold') is the object of the preposition 'of', depending on 'recover' with the phrase 'to recover a submanifold of data'. Entity 2 ('eigenvectors') is the object of the preposition 'on', depending on 'performing' with the phrase 'performing cluster number estimation on the eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the process described in the sentence, with 'eigenvectors' being used in the final step and 'submanifold' being an intermediate result.\"",
        "sdp_path_text": "submanifold → recover → calculating → eigenvectors",
        "sentence": "It recovers a submanifold from data using eigenvectors.",
        "sentence_llm_dp_info": "\"Entity 1 ('submanifold') is the direct object, depending on the verb 'recovers'. Entity 2 ('eigenvectors') is the object of the preposition 'using', depending on 'using' in the phrase 'using eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'submanifold' is recovered and 'eigenvectors' are used in the process.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "high dimensionality space",
                "OtherScientificTerm"
            ],
            [
                "cluster number estimation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high dimensionality space') is the object of the preposition 'from', depending on 'recover'. Entity 2 ('cluster number estimation') is the object of the verb 'performing', depending on 'then performing'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence, where the recovery from the high dimensionality space precedes the cluster number estimation.\"",
        "sdp_path_text": "space → from → recover → calculating → performing → estimation",
        "sentence": "It recovers data from a high dimensionality space and performs cluster number estimation on the recovered data.",
        "sentence_llm_dp_info": "\"Entity 1 ('high dimensionality space') is the object of the preposition 'from', depending on 'recovers' in the phrase 'recovers data from a high dimensionality space'. Entity 2 ('cluster number estimation') is the object of the preposition 'on', depending on 'performs' in the phrase 'performs cluster number estimation on the recovered data'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence involving the recovery and estimation actions.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "high dimensionality space",
                "OtherScientificTerm"
            ],
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high dimensionality space') is the object of the preposition 'from', depending on 'recover'. Entity 2 ('eigenvectors') is the object of the preposition 'on', depending on 'performing'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence, where 'eigenvectors' are used to recover data from the 'high dimensionality space'.\"",
        "sdp_path_text": "space → from → recover → calculating → eigenvectors",
        "sentence": "It recovers eigenvectors from a high dimensionality space.",
        "sentence_llm_dp_info": "\"Entity 1 ('high dimensionality space') is the object of the preposition 'from', depending on 'recovers'. Entity 2 ('eigenvectors') is the direct object, depending on the verb 'recovers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recovers'.\""
    },
    {
        "raw_sentence": "It works by calculating eigenvectors of an adjacency graph 's Laplacian to recover a submanifold of data from a high dimensionality space and then performing cluster number estimation on the eigenvectors .",
        "ner_pair": [
            [
                "cluster number estimation",
                "Task"
            ],
            [
                "eigenvectors",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cluster number estimation') is the object, depending on the verb 'performing'. Entity 2 ('eigenvectors') is the object, depending on the preposition 'on' within the phrase 'on the eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of 'performing' which operates 'on the eigenvectors'.\"",
        "sdp_path_text": "estimation → performing → calculating → eigenvectors",
        "sentence": "Cluster number estimation is performed on the eigenvectors calculated from the adjacency graph's Laplacian.",
        "sentence_llm_dp_info": "\"Entity 1 ('cluster number estimation') is the subject, depending on the verb 'is performed'. Entity 2 ('eigenvectors') is the object of the preposition 'on', depending on 'performed' in the phrase 'is performed on the eigenvectors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is performed' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Experiment results on ACE corpora show that this spectral clustering based approach outperforms the other clustering methods .",
        "ner_pair": [
            [
                "ACE corpora",
                "Material"
            ],
            [
                "spectral clustering based approach",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE corpora') is the object of the preposition 'on', depending on 'results'. Entity 2 ('spectral clustering based approach') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'ACE corpora' provides context for the experiment, and 'spectral clustering based approach' is the method being evaluated.\"",
        "sdp_path_text": "corpora → on → results → show → outperforms → approach",
        "sentence": "Results on ACE corpora show that the spectral clustering based approach outperforms other methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE corpora') is the object of the preposition 'on', depending on 'Results'. Entity 2 ('spectral clustering based approach') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the performance of Entity 2 is evaluated based on results from Entity 1.\""
    },
    {
        "raw_sentence": "Experiment results on ACE corpora show that this spectral clustering based approach outperforms the other clustering methods .",
        "ner_pair": [
            [
                "ACE corpora",
                "Material"
            ],
            [
                "clustering methods",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE corpora') is the object of the preposition 'on', depending on 'results'. Entity 2 ('clustering methods') is the object of the preposition 'the', depending on 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'ACE corpora' serves as the context for the experiment and 'clustering methods' is compared against the approach discussed.\"",
        "sdp_path_text": "corpora → on → results → show → outperforms → methods",
        "sentence": "Experiment results on ACE corpora show that the spectral clustering approach outperforms other clustering methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE corpora') is the object of the preposition 'on', depending on 'results'. Entity 2 ('clustering methods') is the object of the preposition 'other', depending on 'outperforms'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Experiment results on ACE corpora show that this spectral clustering based approach outperforms the other clustering methods .",
        "ner_pair": [
            [
                "spectral clustering based approach",
                "Method"
            ],
            [
                "clustering methods",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spectral clustering based approach') is the subject complement, depending on 'show' with 'results'. Entity 2 ('clustering methods') is the object, depending on 'outperforms' with 'approach'. There is a direct dependency between Entity 1 and Entity 2, as 'approach' outperforms 'methods'.\"",
        "sdp_path_text": "approach → outperforms → methods",
        "sentence": "The spectral clustering based approach outperforms other clustering methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('spectral clustering based approach') is the subject, depending on the verb 'outperforms'. Entity 2 ('clustering methods') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is performing the action (outperforming) on Entity 2.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "mathematical formalism",
                "Method"
            ],
            [
                "structures",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the object, depending on the verb 'proposes'. Entity 2 ('structures') is the object of the preposition 'of', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for the combination of various structures'.\"",
        "sdp_path_text": "formalism → for → combination → of → structures",
        "sentence": "A mathematical formalism is proposed for the combination of various structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the subject, depending on the verb 'proposed'. Entity 2 ('structures') is the object of the preposition 'of', depending on 'combination' in the phrase 'for the combination of various structures'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for the combination of various structures'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "mathematical formalism",
                "Method"
            ],
            [
                "strings",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the object of the preposition 'for', depending on 'proposes' with 'This paper'. Entity 2 ('strings') is part of a list of objects, depending on the preposition 'of' within the phrase 'combination of various structures'. There is no direct dependency between Entity 1 and Entity 2; both are related to the concept of 'combination' and 'structures'.\"",
        "sdp_path_text": "formalism → for → combination → of → structures → strings",
        "sentence": "A mathematical formalism is proposed for the combination of structures including strings.",
        "sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the subject, depending on the verb 'proposed'. Entity 2 ('strings') is part of a prepositional phrase, depending on 'including' which modifies 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that describes what the formalism includes.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "mathematical formalism",
                "Method"
            ],
            [
                "trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the object, depending on 'proposes' with 'This paper'. Entity 2 ('trees') is part of a list, depending on 'structures' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence.\"",
        "sdp_path_text": "formalism → for → combination → of → structures → strings → trees",
        "sentence": "A mathematical formalism is proposed for the combination of structures including trees.",
        "sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the subject, depending on the verb 'proposed'. Entity 2 ('trees') is part of the object complement, depending on 'including' within the prepositional phrase 'including trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that modifies the noun 'structures'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "mathematical formalism",
                "Method"
            ],
            [
                "dags",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the object of the verb 'proposes', depending on 'proposes' with 'This paper'. Entity 2 ('dags') is part of a list of objects, depending on the preposition 'of' within the prepositional phrase 'of them'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger structure described in the sentence.\"",
        "sdp_path_text": "formalism → for → combination → of → structures → strings → trees → dags",
        "sentence": "A mathematical formalism is proposed for the combination of structures including dags.",
        "sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the subject, depending on the verb 'proposed'. Entity 2 ('dags') is part of a prepositional phrase, depending on 'including'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'including' which modifies the noun 'structures'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "mathematical formalism",
                "Method"
            ],
            [
                "graphs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the object of the verb 'proposes', depending on 'proposes' with 'This paper'. Entity 2 ('graphs') is one of the items in a list, depending on the preposition 'of' in the phrase 'of them'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing what the formalism is for.\"",
        "sdp_path_text": "formalism → for → combination → of → structures → strings → trees → dags → graphs",
        "sentence": "A mathematical formalism is proposed for the combination of structures including graphs.",
        "sentence_llm_dp_info": "\"Entity 1 ('mathematical formalism') is the subject, depending on the verb 'proposed'. Entity 2 ('graphs') is part of the object complement, depending on the preposition 'including' within the phrase 'including graphs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'including' which modifies the noun 'structures'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "strings",
                "OtherScientificTerm"
            ],
            [
                "structures",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('strings') is one of the items in a list, depending on the preposition 'of' with 'them'. Entity 2 ('structures') is the object of the preposition 'of', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase where 'structures' is modified by the list that includes 'strings'.\"",
        "sdp_path_text": "strings → structures",
        "sentence": "Strings are among the structures combined in this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('strings') is the subject complement, depending on the verb 'are'. Entity 2 ('structures') is the object of the preposition 'among', depending on 'among' in the phrase 'among the structures'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'among the structures'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "trees",
                "OtherScientificTerm"
            ],
            [
                "structures",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trees') is part of a list, depending on the preposition 'of' with 'structures'. Entity 2 ('structures') is the object of the preposition 'of', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of various structures'.\"",
        "sdp_path_text": "trees → strings → structures",
        "sentence": "Trees are among the structures considered in this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('trees') is the subject, depending on the verb 'are'. Entity 2 ('structures') is the noun complement, depending on the verb 'considered'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the clause that describes what is considered in this formalism.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "dags",
                "OtherScientificTerm"
            ],
            [
                "structures",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dags') is part of a list, depending on the preposition 'of' within the prepositional phrase 'of them'. Entity 2 ('structures') is the object of the preposition 'of', depending on 'combination' in the phrase 'for the combination of various structures'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase and list structure.\"",
        "sdp_path_text": "dags → trees → strings → structures",
        "sentence": "Dags, trees, and strings are structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('dags') is a subject, depending on the verb 'are'. Entity 2 ('structures') is the predicate nominative, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as they are connected through the verb 'are' indicating that 'dags' are a type of 'structures'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "graphs",
                "OtherScientificTerm"
            ],
            [
                "structures",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graphs') is part of the list of examples, depending on the preposition 'of' within the prepositional phrase 'of them'. Entity 2 ('structures') is the object of the preposition 'of', depending on 'combination' in the phrase 'for the combination of various structures'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence.\"",
        "sdp_path_text": "graphs → dags → trees → strings → structures",
        "sentence": "Graphs are among the structures considered in this paper.",
        "sentence_llm_dp_info": "\"Entity 1 ('graphs') is the subject, depending on the verb 'are'. Entity 2 ('structures') is the object of the preposition 'among', depending on 'considered' in the phrase 'considered in this paper'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'among' and the verb 'considered'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "structures",
                "Generic"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('structures') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('them') is the object of the preposition 'of', depending on 'products'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of items that can be combined using the generic mathematical formalism described in the sentence.\"",
        "sdp_path_text": "structures → of → combination → for → formalism → mathematical",
        "sentence": "A mathematical formalism is proposed for the combination of various structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('structures') is the object of the preposition 'of', depending on 'formalism'. Entity 2 ('them') does not appear in the sentence provided, so it cannot be analyzed for dependencies within this context. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "strings",
                "OtherScientificTerm"
            ],
            [
                "trees",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('strings') is one of the items in a list, depending on the preposition 'of' in the phrase 'of various structures'. Entity 2 ('trees') is also an item in the same list, depending on the same preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list of structures.\"",
        "sdp_path_text": "strings → trees",
        "sentence": "The paper proposes a formalism for combining structures like strings and trees.",
        "sentence_llm_dp_info": "\"Entity 1 ('strings') is part of the compound noun, depending on 'like' with 'structures'. Entity 2 ('trees') is also part of the compound noun, depending on 'like' with 'structures'. There is no direct dependency between Entity 1 and Entity 2, but they are both listed as examples of structures being combined, connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "strings",
                "OtherScientificTerm"
            ],
            [
                "dags",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('strings') is one of the items in a list, depending on the preposition 'of' within the phrase 'of various structures'. Entity 2 ('dags') is also one of the items in the same list, depending on the same preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items that are the objects of the preposition 'of'.\"",
        "sdp_path_text": "strings → trees → dags",
        "sentence": "This paper proposes a formalism for combining strings, trees, and dags.",
        "sentence_llm_dp_info": "\"Entity 1 ('strings') is part of a conjunction, depending on the preposition 'for' in the phrase 'for combining strings, trees, and dags'. Entity 2 ('dags') is also part of the same conjunction, depending on the preposition 'for' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list being combined.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "strings",
                "OtherScientificTerm"
            ],
            [
                "graphs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('strings') is a member of the list, depending on 'combination' through the preposition 'of'. Entity 2 ('graphs') is also a member of the list, depending on 'combination' through the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list described by the prepositional phrase 'of various structures'.\"",
        "sdp_path_text": "strings → trees → dags → graphs",
        "sentence": "This paper proposes a formalism for the combination of strings, trees, dags, and graphs.",
        "sentence_llm_dp_info": "\"Entity 1 ('strings') is part of a coordinated list, depending on 'combination' through the conjunction 'and'. Entity 2 ('graphs') is also part of the same coordinated list, depending on 'combination' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list that depends on 'combination'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "strings",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('strings') is one of the items in a list, depending on the preposition 'of' with 'structures'. Entity 2 ('them') is the object of the preposition 'of', depending on 'products'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of structures being referred to by 'them'.\"",
        "sdp_path_text": "strings → structures → of → combination → for → formalism → mathematical",
        "sentence": "A mathematical formalism is proposed for the combination of structures including strings and other forms.",
        "sentence_llm_dp_info": "\"Entity 1 ('strings') is part of a list, depending on the preposition 'including' which modifies 'structures'. Entity 2 ('them') is a pronoun, depending on 'structures' as its antecedent. There is no direct dependency between Entity 1 and Entity 2, but both are related to 'structures' through the preposition 'including' and the pronoun 'them'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "trees",
                "OtherScientificTerm"
            ],
            [
                "dags",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trees') is part of a list, depending on the preposition 'of' in the phrase 'of various structures'. Entity 2 ('dags') is also part of the same list, depending on the conjunction 'and' which connects it to 'trees'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of structures described in the sentence.\"",
        "sdp_path_text": "trees → dags",
        "sentence": "Trees and dags are among the structures combined in this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('trees') is the subject, depending on the verb 'are'. Entity 2 ('dags') is also a subject, coordinated with 'trees' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in a coordinated structure.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "trees",
                "OtherScientificTerm"
            ],
            [
                "graphs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trees') is a member of a list, depending on 'structures' with the preposition 'of'. Entity 2 ('graphs') is also a member of the same list, depending on 'structures' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list that is the object of the preposition 'of'.\"",
        "sdp_path_text": "trees → dags → graphs",
        "sentence": "Trees and graphs are among the structures combined in this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('trees') is the subject, depending on the verb 'are'. Entity 2 ('graphs') is coordinated with 'trees', depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through coordination.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "trees",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trees') is part of a list, depending on the preposition 'of' within the phrase 'of various structures'. Entity 2 ('them') is the object of the preposition 'of' in the phrase 'products of them', referring back to the list of structures. There is no direct dependency between Entity 1 and Entity 2; both are related to the concept of 'structures' in the sentence.\"",
        "sdp_path_text": "trees → strings → structures → of → combination → for → formalism → mathematical",
        "sentence": "The formalism is for the combination of structures including trees and other elements.",
        "sentence_llm_dp_info": "\"Entity 1 ('trees') is part of a coordination, depending on 'including' with 'structures'. Entity 2 ('them') is the object of the preposition 'of', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "dags",
                "OtherScientificTerm"
            ],
            [
                "graphs",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dags') is part of a list, depending on the preposition 'of' within the phrase 'of various structures'. Entity 2 ('graphs') is also part of the same list, depending on the same preposition 'of' within the phrase 'of various structures'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list connected through the conjunction 'and'.\"",
        "sdp_path_text": "dags → graphs",
        "sentence": "This paper proposes a formalism for the combination of dags and graphs.",
        "sentence_llm_dp_info": "\"Entity 1 ('dags') is the object of the preposition 'of', depending on 'combination'. Entity 2 ('graphs') is also the object of the preposition 'of', depending on 'combination'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'of' in the phrase 'combination of dags and graphs'.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "dags",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dags') is part of a list, depending on the preposition 'of' within the phrase 'of various structures'. Entity 2 ('them') is the object of the preposition 'of', referring back to the list including 'dags'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same list and 'them' refers back to the items listed, including 'dags'.\"",
        "sdp_path_text": "dags → trees → strings → structures → of → combination → for → formalism → mathematical",
        "sentence": "This paper proposes a mathematical formalism for the combination of structures including dags.",
        "sentence_llm_dp_info": "\"Entity 1 ('dags') is the object of the preposition 'including', depending on 'including' in the phrase 'including dags'. Entity 2 ('them') is not present in the given sentence, so it cannot be analyzed for dependencies within this context. There is no direct dependency between Entity 1 and Entity 2, as 'them' does not appear in the sentence.\""
    },
    {
        "raw_sentence": "This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .",
        "ner_pair": [
            [
                "graphs",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graphs') is part of a list, depending on the preposition 'of' within the prepositional phrase 'of various structures'. Entity 2 ('them') is the object of the preposition 'of' in the phrase 'of them', which modifies 'products'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of structures being combined.\"",
        "sdp_path_text": "graphs → dags → trees → strings → structures → of → combination → for → formalism → mathematical",
        "sentence": "The formalism combines various structures including graphs.",
        "sentence_llm_dp_info": "\"Entity 1 ('graphs') is part of the object of the preposition 'including', depending on 'including' in the phrase 'including graphs'. Entity 2 ('them') is the object of the verb 'combines', depending on 'combines' in the phrase 'combines them'. There is no direct dependency between Entity 1 and Entity 2; however, they are both related to the verb 'combines' through different dependency paths.\""
    },
    {
        "raw_sentence": "The polarization of the objects of the elementary structures controls the saturation of the final structure .",
        "ner_pair": [
            [
                "polarization",
                "OtherScientificTerm"
            ],
            [
                "elementary structures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('polarization') is the subject, depending on the verb 'controls'. Entity 2 ('elementary structures') is the object of the preposition 'of', depending on 'objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun phrase 'the objects of the elementary structures' which is part of the subject of the sentence.\"",
        "sdp_path_text": "polarization → of → objects → of → structures",
        "sentence": "{\n  \"Simplified sentence\": \"The polarization of the objects of the elementary structures controls the final structure.\"\n}\n\nHowever, to better align with the SDP and maintain the focus on the relationship between \"polarization\" and \"elementary structures,\" a more precise simplification would be:\n\n{\n  \"Simplified sentence\": \"The polarization of the elementary structures controls the final structure.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('polarization') is the subject of the clause, depending on the verb 'controls'. Entity 2 ('elementary structures') is the object of the preposition 'of', depending on 'polarization' in the phrase 'polarization of the elementary structures'. There is a direct dependency between Entity 1 and Entity 2, as 'elementary structures' modifies 'polarization'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "formalism",
                "Generic"
            ],
            [
                "rewriting systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'is' and modified by the adjectives 'elementary' and 'powerful'. Entity 2 ('rewriting systems') is part of a list of examples, depending on the preposition 'such as' which modifies the noun 'grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where 'formalism' can simulate various 'grammar formalisms', including 'rewriting systems'.\"",
        "sdp_path_text": "formalism → is → elementary → powerful → simulate → formalisms → as → rewriting",
        "sentence": "This formalism is powerful enough to simulate rewriting systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'is'. Entity 2 ('rewriting systems') is the object of the verb 'simulate', depending on 'simulate' in the phrase 'to simulate rewriting systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'simulate'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "formalism",
                "Generic"
            ],
            [
                "dependency grammars",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the copula 'is' and modified by the adjectives 'elementary' and 'powerful'. Entity 2 ('dependency grammars') is part of a list of examples, depending on the preposition 'such as' which modifies 'grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where 'formalism' is described as being able to simulate various grammar formalisms, including 'dependency grammars'.\"",
        "sdp_path_text": "formalism → is → elementary → powerful → simulate → formalisms → as → rewriting → systems → grammars",
        "sentence": "This formalism is powerful enough to simulate dependency grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'is'. Entity 2 ('dependency grammars') is the object of the verb 'simulate', depending on 'simulate' in the phrase 'to simulate dependency grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'simulate'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "formalism",
                "Generic"
            ],
            [
                "TAG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'is'. Entity 2 ('TAG') is part of a list of examples, depending on the preposition 'such as' which modifies 'grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence, where 'formalism' is described as being able to simulate various grammar formalisms, including 'TAG'.\"",
        "sdp_path_text": "formalism → is → elementary → powerful → simulate → formalisms → as → rewriting → systems → grammars → TAG",
        "sentence": "This formalism is powerful enough to simulate grammar formalisms, including TAG.",
        "sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on 'is' with 'powerful'. Entity 2 ('TAG') is the object of the preposition 'including', depending on 'including' in the phrase 'including TAG'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'including'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "formalism",
                "Generic"
            ],
            [
                "HPSG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'is'. Entity 2 ('HPSG') is part of a list of objects, depending on 'simulate' through the prepositional phrase 'such as rewriting systems, dependency grammars, TAG, HPSG and LFG'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'simulate' and the prepositional phrase that lists various grammar formalisms.\"",
        "sdp_path_text": "formalism → is → elementary → powerful → simulate → formalisms → as → rewriting → systems → grammars → TAG → HPSG",
        "sentence": "This formalism can simulate HPSG.",
        "sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'can simulate'. Entity 2 ('HPSG') is the object, depending on the verb 'simulate'. There is a direct dependency between Entity 1 and Entity 2, as 'formalism' is the subject that performs the action of simulating 'HPSG'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "formalism",
                "Generic"
            ],
            [
                "LFG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the copula 'is' in the clause 'This formalism is both elementary and powerful'. Entity 2 ('LFG') is part of a list, depending on 'such as' which introduces examples of 'grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where 'formalism' is described as capable of simulating various grammar formalisms, including 'LFG'.\"",
        "sdp_path_text": "formalism → is → elementary → powerful → simulate → formalisms → as → rewriting → systems → grammars → TAG → HPSG → LFG",
        "sentence": "This formalism is powerful enough to simulate LFG.",
        "sentence_llm_dp_info": "\"Entity 1 ('formalism') is the subject, depending on the verb 'is' in the phrase 'is powerful'. Entity 2 ('LFG') is the object of the verb 'simulate', depending on 'simulate' in the phrase 'to simulate LFG'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'simulate'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "rewriting systems",
                "Method"
            ],
            [
                "grammar formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a list, depending on the conjunction 'such as', which modifies 'grammar formalisms'. Entity 2 ('grammar formalisms') is the object of the preposition 'to', depending on 'simulate' in the phrase 'to strongly simulate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase and the list structure.\"",
        "sdp_path_text": "rewriting → as → formalisms",
        "sentence": "Rewriting systems are among the grammar formalisms this formalism can simulate.",
        "sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is the subject, depending on the verb 'are'. Entity 2 ('grammar formalisms') is part of the noun phrase functioning as a complement to the preposition 'among', depending on 'among' in the phrase 'among the grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'among'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "dependency grammars",
                "Method"
            ],
            [
                "grammar formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is part of a list, depending on the preposition 'such as', which itself depends on 'formalisms'. Entity 2 ('grammar formalisms') is the object of the preposition 'to', depending on 'simulate' in the phrase 'to strongly simulate many grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'such as' which lists examples of 'grammar formalisms'.\"",
        "sdp_path_text": "grammars → systems → rewriting → as → formalisms",
        "sentence": "Dependency grammars are among the grammar formalisms that this formalism can simulate.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is the subject, depending on the verb 'are'. Entity 2 ('grammar formalisms') is the object of the preposition 'among', depending on 'among' in the phrase 'among the grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'among the grammar formalisms'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "TAG",
                "OtherScientificTerm"
            ],
            [
                "grammar formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAG') is part of a list, depending on 'such as' which modifies 'grammar formalisms'. Entity 2 ('grammar formalisms') is the object of the preposition 'simulate', depending on 'simulate' in the phrase 'to strongly simulate many grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'such as' which lists examples of 'grammar formalisms'.\"",
        "sdp_path_text": "TAG → grammars → systems → rewriting → as → formalisms",
        "sentence": "TAG is one of the grammar formalisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAG') is the subject, depending on the verb 'is'. Entity 2 ('grammar formalisms') is the complement, depending on the preposition 'of' in the phrase 'one of the grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the grammar formalisms'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "HPSG",
                "OtherScientificTerm"
            ],
            [
                "grammar formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('HPSG') is part of a list, depending on the conjunction 'and' within the phrase 'such as rewriting systems, dependency grammars, TAG, HPSG and LFG'. Entity 2 ('grammar formalisms') is the object of the preposition 'to', depending on 'simulate' in the phrase 'to strongly simulate many grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase and the list that includes Entity 1.\"",
        "sdp_path_text": "HPSG → TAG → grammars → systems → rewriting → as → formalisms",
        "sentence": "HPSG is among the grammar formalisms that this formalism can simulate.",
        "sentence_llm_dp_info": "\"Entity 1 ('HPSG') is the subject, depending on the verb 'is'. Entity 2 ('grammar formalisms') is the object of the preposition 'among', depending on 'among' in the phrase 'among the grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'among the grammar formalisms'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "LFG",
                "OtherScientificTerm"
            ],
            [
                "grammar formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LFG') is part of a list, depending on the conjunction 'and' within the phrase 'such as rewriting systems, dependency grammars, TAG, HPSG and LFG', which modifies 'grammar formalisms'. Entity 2 ('grammar formalisms') is the object of the preposition 'to', depending on 'simulate' in the phrase 'to strongly simulate many grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase and the list structure.\"",
        "sdp_path_text": "LFG → HPSG → TAG → grammars → systems → rewriting → as → formalisms",
        "sentence": "LFG is one of the grammar formalisms, including rewriting systems, dependency grammars, TAG, and HPSG.",
        "sentence_llm_dp_info": "\"Entity 1 ('LFG') is the subject, depending on the copula 'is' and part of the noun phrase 'one of the grammar formalisms'. Entity 2 ('grammar formalisms') is the object of the preposition 'of', depending on 'one'. There is a direct dependency between Entity 1 and Entity 2, as 'LFG' is described as being 'one of the grammar formalisms'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "rewriting systems",
                "Method"
            ],
            [
                "dependency grammars",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a list, depending on the preposition 'such as', which modifies 'grammar formalisms'. Entity 2 ('dependency grammars') is also part of the same list, depending on the same preposition 'such as', which modifies 'grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2; they are both listed as examples of 'grammar formalisms'.\"",
        "sdp_path_text": "rewriting → systems → grammars",
        "sentence": "Rewriting systems and dependency grammars are simulated by this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is the subject, depending on the verb 'are' in the clause 'rewriting systems and dependency grammars are simulated'. Entity 2 ('dependency grammars') is also a subject, conjoined with 'rewriting systems' and depending on the same verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in a coordinated structure.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "rewriting systems",
                "Method"
            ],
            [
                "TAG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a list, depending on the verb 'simulate' through the preposition 'such as'. Entity 2 ('TAG') is also part of the same list, depending on the same verb 'simulate' through the conjunction 'and' and the preposition 'such as'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a list that serves as an example of what can be simulated.\"",
        "sdp_path_text": "rewriting → systems → grammars → TAG",
        "sentence": "Rewriting systems and TAG are among the grammar formalisms this formalism can simulate.",
        "sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a coordinated noun phrase, depending on 'are' with the verb 'are'. Entity 2 ('TAG') is also part of the same coordinated noun phrase, depending on 'and' with 'rewriting systems'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger noun phrase that serves as the subject of the sentence.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "rewriting systems",
                "Method"
            ],
            [
                "HPSG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a list, depending on 'simulate' through the preposition 'such as'. Entity 2 ('HPSG') is also part of the same list, depending on 'simulate' through the preposition 'such as'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a list that serves as the object of the preposition 'such as'.\"",
        "sdp_path_text": "rewriting → systems → grammars → TAG → HPSG",
        "sentence": "Rewriting systems, dependency grammars, TAG, and HPSG are simulated by this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a coordinated subject, depending on the verb 'are simulated'. Entity 2 ('HPSG') is also part of the same coordinated subject, depending on the coordinating conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger coordinated structure that depends on the verb 'are simulated'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "rewriting systems",
                "Method"
            ],
            [
                "LFG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a conjunct list, depending on the preposition 'such as', which modifies 'grammar formalisms'. Entity 2 ('LFG') is also part of the same conjunct list, depending on the coordinating conjunction 'and' with 'HPSG', and together they depend on 'such as'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of examples for 'grammar formalisms'.\"",
        "sdp_path_text": "rewriting → systems → grammars → TAG → HPSG → LFG",
        "sentence": "Rewriting systems, dependency grammars, TAG, HPSG, and LFG are simulated by this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('rewriting systems') is part of a coordinated list of subjects, depending on the verb 'are' and modified by the conjunction 'and'. Entity 2 ('LFG') is also part of the same coordinated list of subjects, directly connected to the previous items through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger coordinated structure that serves as the subject of the sentence.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "dependency grammars",
                "Method"
            ],
            [
                "TAG",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is part of a list, depending on the preposition 'such as', which modifies 'grammar formalisms'. Entity 2 ('TAG') is also part of the same list, depending on the conjunction 'and' and the preposition 'such as', which modifies 'grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2; they are both elements in a list of examples.\"",
        "sdp_path_text": "grammars → TAG",
        "sentence": "Dependency grammars and TAG are among the grammar formalisms this formalism can simulate.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is part of a conjunction, depending on 'are' with 'and'. Entity 2 ('TAG') is also part of the same conjunction, depending on 'are' with 'and'. Both entities are subjects in the clause 'dependency grammars and TAG are among the grammar formalisms'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "dependency grammars",
                "Method"
            ],
            [
                "HPSG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is part of a list, depending on 'simulate' through the prepositional phrase 'such as'. Entity 2 ('HPSG') is also part of the same list, depending on 'simulate' through the same prepositional phrase 'such as'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of the list introduced by 'such as'.\"",
        "sdp_path_text": "grammars → TAG → HPSG",
        "sentence": "Dependency grammars and HPSG are among the grammar formalisms this formalism can simulate.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is the subject, depending on the verb 'are'. Entity 2 ('HPSG') is a coordinate subject, also depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same subject coordinated by 'and'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "dependency grammars",
                "Method"
            ],
            [
                "LFG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is a conjunct, depending on 'and' which connects it with other items in the list, and the entire list depends on 'simulate' as the object of the verb. Entity 2 ('LFG') is also a conjunct, depending on 'and' which connects it with other items in the list, and the entire list depends on 'simulate' as the object of the verb. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same conjunctive list.\"",
        "sdp_path_text": "grammars → TAG → HPSG → LFG",
        "sentence": "Dependency grammars, TAG, HPSG, and LFG are simulated by this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency grammars') is part of a coordinated subject, depending on the verb 'are simulated'. Entity 2 ('LFG') is also part of the coordinated subject, depending on the conjunction 'and' which links it with the other subjects. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same subject group linked by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "TAG",
                "OtherScientificTerm"
            ],
            [
                "HPSG",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAG') is part of a list, depending on 'simulate' through the conjunction 'and'. Entity 2 ('HPSG') is also part of the same list, depending on 'simulate' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both listed as examples of grammar formalisms that can be simulated.\"",
        "sdp_path_text": "TAG → HPSG",
        "sentence": "This formalism can simulate grammar formalisms such as TAG and HPSG.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAG') is the object of the preposition 'such as', depending on 'formalisms'. Entity 2 ('HPSG') is also the object of the preposition 'such as', depending on 'formalisms'. There is no direct dependency between Entity 1 and Entity 2; both are listed as examples of 'grammar formalisms'.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "TAG",
                "OtherScientificTerm"
            ],
            [
                "LFG",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAG') is part of a coordinated list, depending on 'simulate' through the preposition 'such as'. Entity 2 ('LFG') is also part of the same coordinated list, depending on 'simulate' through the preposition 'such as'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of examples.\"",
        "sdp_path_text": "TAG → HPSG → LFG",
        "sentence": "TAG, HPSG, and LFG are simulated by this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAG') is part of a coordination, depending on 'are' with the verb 'simulated'. Entity 2 ('LFG') is also part of the same coordination, depending on 'and' which connects it with 'HPSG'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated subjects in the sentence.\""
    },
    {
        "raw_sentence": "This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms , such as rewriting systems , dependency grammars , TAG , HPSG and LFG .",
        "ner_pair": [
            [
                "HPSG",
                "OtherScientificTerm"
            ],
            [
                "LFG",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('HPSG') is part of a conjunction, depending on 'and' with 'LFG'. Entity 2 ('LFG') is also part of a conjunction, depending on 'and' with 'HPSG'. Both entities are listed as examples of 'grammar formalisms' and depend on the preposition 'such as'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and' within the list of examples.\"",
        "sdp_path_text": "HPSG → LFG",
        "sentence": "HPSG and LFG are among the grammar formalisms simulated by this formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('HPSG') is the first item in a conjunction, depending on 'are' as a conjunct. Entity 2 ('LFG') is the second item in a conjunction, also depending on 'are' as a conjunct. There is no direct dependency between Entity 1 and Entity 2; both are part of the same conjunction and depend on the verb 'are'.\""
    },
    {
        "raw_sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions , suitable for efficient implementation of kernels in image processing .",
        "ner_pair": [
            [
                "mixed-signal paradigm",
                "Method"
            ],
            [
                "high-resolution parallel inner-product computation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixed-signal paradigm') is the subject, depending on the verb 'presented'. Entity 2 ('high-resolution parallel inner-product computation') is the object of the preposition 'for', depending on 'for' in the phrase 'for high-resolution parallel inner-product computation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "paradigm → presented → for → computation",
        "sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixed-signal paradigm') is the subject, depending on the verb 'presented'. Entity 2 ('high-resolution parallel inner-product computation') is the object of the preposition 'for', depending on 'for' in the phrase 'for high-resolution parallel inner-product computation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions , suitable for efficient implementation of kernels in image processing .",
        "ner_pair": [
            [
                "mixed-signal paradigm",
                "Method"
            ],
            [
                "kernels",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixed-signal paradigm') is the subject, depending on the verb 'presented'. Entity 2 ('kernels') is the object of the preposition 'of', depending on 'implementation' in the phrase 'implementation of kernels'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence, where the 'mixed-signal paradigm' is described as being suitable for the 'efficient implementation of kernels'.\"",
        "sdp_path_text": "paradigm → suitable → for → implementation → of → kernels",
        "sentence": "A mixed-signal paradigm is suitable for the implementation of kernels.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixed-signal paradigm') is the subject, depending on the verb 'is' (suitable). Entity 2 ('kernels') is the object of the preposition 'of', depending on 'implementation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'for the implementation of'.\""
    },
    {
        "raw_sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions , suitable for efficient implementation of kernels in image processing .",
        "ner_pair": [
            [
                "mixed-signal paradigm",
                "Method"
            ],
            [
                "image processing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixed-signal paradigm') is the subject, depending on the verb 'presented'. Entity 2 ('image processing') is the object of the preposition 'for', depending on 'suitable' in the phrase 'suitable for efficient implementation of kernels in image processing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for efficient implementation of kernels in image processing'.\"",
        "sdp_path_text": "paradigm → suitable → for → implementation → in → processing",
        "sentence": "A mixed-signal paradigm is suitable for implementation in image processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixed-signal paradigm') is the subject, depending on the verb 'is' (suitable). Entity 2 ('image processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in image processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in image processing'.\""
    },
    {
        "raw_sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions , suitable for efficient implementation of kernels in image processing .",
        "ner_pair": [
            [
                "high-resolution parallel inner-product computation",
                "Task"
            ],
            [
                "kernels",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high-resolution parallel inner-product computation') is the object of the preposition 'for', depending on 'presented'. Entity 2 ('kernels') is the object of the preposition 'of', depending on 'implementation'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the purpose and suitability of the presented paradigm.\"",
        "sdp_path_text": "computation → for → presented → paradigm → suitable → for → implementation → of → kernels",
        "sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation suitable for implementation of kernels.",
        "sentence_llm_dp_info": "\"Entity 1 ('high-resolution parallel inner-product computation') is the object of the preposition 'for', depending on 'presented'. Entity 2 ('kernels') is the object of the preposition 'for', depending on 'suitable'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the purpose or application described in the sentence.\""
    },
    {
        "raw_sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions , suitable for efficient implementation of kernels in image processing .",
        "ner_pair": [
            [
                "high-resolution parallel inner-product computation",
                "Task"
            ],
            [
                "image processing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high-resolution parallel inner-product computation') is the object of the preposition 'for', depending on 'presented'. Entity 2 ('image processing') is part of the noun phrase 'kernels in image processing', where it serves as the object of the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause through the verb 'presented' and the context of the sentence.\"",
        "sdp_path_text": "computation → for → presented → paradigm → suitable → for → implementation → in → processing",
        "sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation, suitable for image processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('high-resolution parallel inner-product computation') is the object of the preposition 'for', depending on 'presented'. Entity 2 ('image processing') is the object of the preposition 'for', depending on 'suitable'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different prepositions that describe the purpose or suitability of the mixed-signal paradigm.\""
    },
    {
        "raw_sentence": "A mixed-signal paradigm is presented for high-resolution parallel inner-product computation in very high dimensions , suitable for efficient implementation of kernels in image processing .",
        "ner_pair": [
            [
                "kernels",
                "Method"
            ],
            [
                "image processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('kernels') is the object, depending on 'implementation' with 'efficient'. Entity 2 ('image processing') is the object of the preposition 'of', depending on 'of' in the phrase 'of image processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for efficient implementation of kernels in image processing'.\"",
        "sdp_path_text": "kernels → of → implementation → in → processing",
        "sentence": "Kernels are implemented in image processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('kernels') is the subject, depending on the verb 'implemented'. Entity 2 ('image processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in image processing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "At the core of the externally digital architecture is a high-density , low-power analog array performing binary-binary partial matrix-vector multiplication .",
        "ner_pair": [
            [
                "high-density , low-power analog array",
                "OtherScientificTerm"
            ],
            [
                "externally digital architecture",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high-density, low-power analog array') is the subject, depending on the verb 'is' in the clause 'is performing binary-binary partial matrix-vector multiplication'. Entity 2 ('externally digital architecture') is the object of the preposition 'of', depending on 'core' in the phrase 'at the core of the externally digital architecture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase and the copular verb 'is'.\"",
        "sdp_path_text": "array → is → At → core → of → architecture",
        "sentence": "A high-density, low-power analog array is at the core of the externally digital architecture.",
        "sentence_llm_dp_info": "\"Entity 1 ('high-density, low-power analog array') is the subject, depending on 'is' as the main verb of the clause. Entity 2 ('externally digital architecture') is the object of the preposition 'of', depending on 'of' in the phrase 'of the externally digital architecture'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that describes the location or part of Entity 2 where Entity 1 is found.\""
    },
    {
        "raw_sentence": "At the core of the externally digital architecture is a high-density , low-power analog array performing binary-binary partial matrix-vector multiplication .",
        "ner_pair": [
            [
                "externally digital architecture",
                "Method"
            ],
            [
                "binary-binary partial matrix-vector multiplication",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('externally digital architecture') is the subject complement, depending on the verb 'is'. Entity 2 ('binary-binary partial matrix-vector multiplication') is the object, depending on 'performing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' and the participle 'performing' which describes the function of the 'analog array' at the core of the 'externally digital architecture'.\"",
        "sdp_path_text": "architecture → of → core → At → is → array → performing → multiplication",
        "sentence": "The externally digital architecture includes an array performing binary-binary partial matrix-vector multiplication.",
        "sentence_llm_dp_info": "\"Entity 1 ('externally digital architecture') is the subject, depending on the verb 'includes'. Entity 2 ('binary-binary partial matrix-vector multiplication') is the object, depending on 'performing' with 'array'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the noun 'array' which performs the action described by Entity 2.\""
    },
    {
        "raw_sentence": "At the core of the externally digital architecture is a high-density , low-power analog array performing binary-binary partial matrix-vector multiplication .",
        "ner_pair": [
            [
                "binary-binary partial matrix-vector multiplication",
                "Method"
            ],
            [
                "high-density , low-power analog array",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('binary-binary partial matrix-vector multiplication') is the object, depending on the verb 'performing'. Entity 2 ('high-density, low-power analog array') is the subject, depending on the verb 'is' in the phrase 'is a high-density, low-power analog array'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'performing' where Entity 2 performs the action described by Entity 1.\"",
        "sdp_path_text": "multiplication → performing → array",
        "sentence": "A high-density, low-power analog array performs binary-binary partial matrix-vector multiplication.",
        "sentence_llm_dp_info": "\"Entity 1 ('binary-binary partial matrix-vector multiplication') is the object, depending on the verb 'performs'. Entity 2 ('high-density, low-power analog array') is the subject, depending on the verb 'performs'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 performs the action (verb 'performs') on Entity 1.\""
    },
    {
        "raw_sentence": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion , owing to random statistics in the analog summation of binary products .",
        "ner_pair": [
            [
                "Full digital resolution",
                "Metric"
            ],
            [
                "low-resolution analog-to-digital conversion",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Full digital resolution') is the subject, depending on the verb 'maintained'. Entity 2 ('low-resolution analog-to-digital conversion') is the object of the preposition 'with', depending on 'with' in the phrase 'with low-resolution analog-to-digital conversion'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\"",
        "sdp_path_text": "resolution → maintained → with → conversion",
        "sentence": "Full digital resolution is maintained with low-resolution analog-to-digital conversion.",
        "sentence_llm_dp_info": "\"Entity 1 ('Full digital resolution') is the subject, depending on the verb 'maintained'. Entity 2 ('low-resolution analog-to-digital conversion') is the object of the preposition 'with', depending on 'with' in the phrase 'with low-resolution analog-to-digital conversion'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which indicates that the maintenance of full digital resolution is achieved alongside or through the use of low-resolution analog-to-digital conversion.\""
    },
    {
        "raw_sentence": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion , owing to random statistics in the analog summation of binary products .",
        "ner_pair": [
            [
                "Full digital resolution",
                "Metric"
            ],
            [
                "random statistics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Full digital resolution') is the subject, depending on the verb 'maintained'. Entity 2 ('random statistics') is the object of the preposition 'to', depending on 'owing' in the phrase 'owing to random statistics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the causal relationship expressed by 'owing to'.\"",
        "sdp_path_text": "resolution → maintained → owing → to → statistics",
        "sentence": "Full digital resolution is maintained owing to random statistics.",
        "sentence_llm_dp_info": "\"Entity 1 ('Full digital resolution') is the subject, depending on the verb 'maintained'. Entity 2 ('random statistics') is the object of the preposition 'to', depending on 'owing' in the phrase 'owing to random statistics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'owing to'.\""
    },
    {
        "raw_sentence": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion , owing to random statistics in the analog summation of binary products .",
        "ner_pair": [
            [
                "Full digital resolution",
                "Metric"
            ],
            [
                "analog summation of binary products",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Full digital resolution') is the subject, depending on the verb 'maintained'. Entity 2 ('analog summation of binary products') is the object of the preposition 'in', depending on 'owing to' in the phrase 'owing to random statistics in the analog summation of binary products'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the causal relationship expressed by 'owing to'.\"",
        "sdp_path_text": "resolution → maintained → owing → to → statistics → in → summation",
        "sentence": "Full digital resolution is maintained owing to statistics in the analog summation of binary products.",
        "sentence_llm_dp_info": "\"Entity 1 ('Full digital resolution') is the subject, depending on the verb 'maintained'. Entity 2 ('analog summation of binary products') is the object of the preposition 'in', depending on 'owing to' in the phrase 'owing to statistics in the analog summation of binary products'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by 'owing to'.\""
    },
    {
        "raw_sentence": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion , owing to random statistics in the analog summation of binary products .",
        "ner_pair": [
            [
                "low-resolution analog-to-digital conversion",
                "Method"
            ],
            [
                "random statistics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low-resolution analog-to-digital conversion') is the object of the preposition 'with', depending on 'maintained'. Entity 2 ('random statistics') is the object of the preposition 'to', depending on 'owing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause explaining why full digital resolution is maintained.\"",
        "sdp_path_text": "conversion → with → maintained → owing → to → statistics",
        "sentence": "Low-resolution analog-to-digital conversion maintains full digital resolution owing to random statistics.",
        "sentence_llm_dp_info": "\"Entity 1 ('low-resolution analog-to-digital conversion') is the subject, depending on the verb 'maintains'. Entity 2 ('random statistics') is the object of the preposition 'to', depending on 'owing' in the phrase 'owing to random statistics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'owing to'.\""
    },
    {
        "raw_sentence": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion , owing to random statistics in the analog summation of binary products .",
        "ner_pair": [
            [
                "low-resolution analog-to-digital conversion",
                "Method"
            ],
            [
                "analog summation of binary products",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low-resolution analog-to-digital conversion') is the object of the preposition 'with', depending on the verb 'maintained'. Entity 2 ('analog summation of binary products') is the object of the preposition 'in', depending on the prepositional phrase 'owing to random statistics'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause that explains how full digital resolution is maintained despite the use of low-resolution conversion, due to the randomness in the analog summation process.\"",
        "sdp_path_text": "conversion → with → maintained → owing → to → statistics → in → summation",
        "sentence": "Low-resolution analog-to-digital conversion maintains full digital resolution owing to random statistics in the analog summation of binary products.",
        "sentence_llm_dp_info": "\"Entity 1 ('low-resolution analog-to-digital conversion') is the subject, depending on the verb 'maintains'. Entity 2 ('analog summation of binary products') is the object of the preposition 'in', depending on 'owing to' in the phrase 'owing to random statistics in the analog summation of binary products'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'owing to random statistics in the analog summation of binary products'.\""
    },
    {
        "raw_sentence": "Full digital resolution is maintained even with low-resolution analog-to-digital conversion , owing to random statistics in the analog summation of binary products .",
        "ner_pair": [
            [
                "random statistics",
                "OtherScientificTerm"
            ],
            [
                "analog summation of binary products",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('random statistics') is the subject complement, depending on 'owing' which indicates the reason. Entity 2 ('analog summation of binary products') is the object of the preposition 'in', depending on 'in' in the phrase 'in the analog summation of binary products'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same explanatory clause introduced by 'owing to'.\"",
        "sdp_path_text": "statistics → in → summation",
        "sentence": "Random statistics are involved in the analog summation of binary products.",
        "sentence_llm_dp_info": "\"Entity 1 ('random statistics') is the subject, depending on the verb 'are involved'. Entity 2 ('analog summation of binary products') is the object of the preposition 'in', depending on 'involved' in the phrase 'involved in the analog summation of binary products'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs .",
        "ner_pair": [
            [
                "random modulation scheme",
                "Method"
            ],
            [
                "near-Bernoulli statistics",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('random modulation scheme') is the subject, depending on the verb 'produces'. Entity 2 ('near-Bernoulli statistics') is the direct object, depending on the verb 'produces'. There is a direct dependency between Entity 1 and Entity 2, where 'random modulation scheme' produces 'near-Bernoulli statistics'.\"",
        "sdp_path_text": "scheme → produces → statistics",
        "sentence": "A random modulation scheme produces near-Bernoulli statistics.",
        "sentence_llm_dp_info": "\"Entity 1 ('random modulation scheme') is the subject, depending on the verb 'produces'. Entity 2 ('near-Bernoulli statistics') is the object, depending on the verb 'produces'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the producer and Entity 2 is the product.\""
    },
    {
        "raw_sentence": "A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs .",
        "ner_pair": [
            [
                "highly correlated inputs",
                "Material"
            ],
            [
                "random modulation scheme",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('highly correlated inputs') is the object, depending on the preposition 'for', which itself depends on the adjective 'near-Bernoulli'. Entity 2 ('random modulation scheme') is the subject, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the prepositional phrase 'for highly correlated inputs'.\"",
        "sdp_path_text": "inputs → for → produces → scheme",
        "sentence": "A random modulation scheme produces results for highly correlated inputs.",
        "sentence_llm_dp_info": "\"Entity 1 ('highly correlated inputs') is the object of the preposition 'for', depending on 'produces' in the phrase 'produces results for highly correlated inputs'. Entity 2 ('random modulation scheme') is the subject, depending on the verb 'produces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "A random modulation scheme produces near-Bernoulli statistics even for highly correlated inputs .",
        "ner_pair": [
            [
                "near-Bernoulli statistics",
                "OtherScientificTerm"
            ],
            [
                "highly correlated inputs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('near-Bernoulli statistics') is the object, depending on 'produces' with 'scheme'. Entity 2 ('highly correlated inputs') is the object of the preposition 'for', depending on 'for' in the phrase 'for highly correlated inputs'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the effect of the 'random modulation scheme'.\"",
        "sdp_path_text": "statistics → produces → for → inputs",
        "sentence": "A random modulation scheme produces near-Bernoulli statistics for highly correlated inputs.",
        "sentence_llm_dp_info": "\"Entity 1 ('near-Bernoulli statistics') is the object, depending on the verb 'produces' with 'scheme'. Entity 2 ('highly correlated inputs') is the object of the preposition 'for', depending on 'for' in the phrase 'for highly correlated inputs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produces' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "The approach is validated with real image data , and with experimental results from a CID/DRAM analog array prototype in 0.5 cents m CMOS .",
        "ner_pair": [
            [
                "real image data",
                "Material"
            ],
            [
                "approach",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('real image data') is the object of the preposition 'with', depending on 'validated'. Entity 2 ('approach') is the subject, depending on the verb 'is' in 'is validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which links 'real image data' to the action of validating the 'approach'.\"",
        "sdp_path_text": "data → with → validated → approach",
        "sentence": "The approach is validated with real image data.",
        "sentence_llm_dp_info": "\"Entity 1 ('real image data') is the object, depending on the preposition 'with' which modifies 'validated'. Entity 2 ('approach') is the subject, depending on the verb 'is validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' indicating that the 'real image data' is used in the validation of the 'approach'.\""
    },
    {
        "raw_sentence": "The approach is validated with real image data , and with experimental results from a CID/DRAM analog array prototype in 0.5 cents m CMOS .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "CID/DRAM analog array prototype",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'validated'. Entity 2 ('CID/DRAM analog array prototype') is the object of the preposition 'from', depending on 'from' in the phrase 'from a CID/DRAM analog array prototype'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the validation process described in the sentence.\"",
        "sdp_path_text": "approach → validated → with → with → results → from → prototype",
        "sentence": "The approach is validated with results from the CID/DRAM analog array prototype.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'validated'. Entity 2 ('CID/DRAM analog array prototype') is the noun modifier, depending on 'results'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'with results from the CID/DRAM analog array prototype'.\""
    },
    {
        "raw_sentence": "The approach is validated with real image data , and with experimental results from a CID/DRAM analog array prototype in 0.5 cents m CMOS .",
        "ner_pair": [
            [
                "real image data",
                "Material"
            ],
            [
                "CID/DRAM analog array prototype",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('real image data') is the object of the preposition 'with', depending on 'validated'. Entity 2 ('CID/DRAM analog array prototype') is also the object of the preposition 'with', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2; both are part of the validation process described in the sentence.\"",
        "sdp_path_text": "data → with → with → results → from → prototype",
        "sentence": "The approach is validated with real image data and results from a CID/DRAM analog array prototype.",
        "sentence_llm_dp_info": "\"Entity 1 ('real image data') is the object of the preposition 'with', depending on 'validated'. Entity 2 ('CID/DRAM analog array prototype') is the object of the preposition 'from', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the validation context described in the sentence.\""
    },
    {
        "raw_sentence": "In this paper we specialize the projective unifocal , bifo-cal , and trifocal tensors to the affine case , and show how the tensors obtained relate to the registered tensors encountered in previous work .",
        "ner_pair": [
            [
                "projective unifocal , bifo-cal , and trifocal tensors",
                "Method"
            ],
            [
                "affine case",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('projective unifocal, bifo-cal, and trifocal tensors') is the object of the verb 'specialize', depending on 'specialize' with 'we'. Entity 2 ('affine case') is the object of the preposition 'to', depending on 'to' in the phrase 'to the affine case'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'specialize' and the preposition 'to'.\"",
        "sdp_path_text": "tensors → to → case",
        "sentence": "The projective unifocal, bifocal, and trifocal tensors are specialized to the affine case.",
        "sentence_llm_dp_info": "\"Entity 1 ('projective unifocal, bifocal, and trifocal tensors') is the subject, depending on the verb 'are specialized'. Entity 2 ('affine case') is the object of the preposition 'to', depending on 'to' in the phrase 'to the affine case'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are specialized' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "In this paper we specialize the projective unifocal , bifo-cal , and trifocal tensors to the affine case , and show how the tensors obtained relate to the registered tensors encountered in previous work .",
        "ner_pair": [
            [
                "projective unifocal , bifo-cal , and trifocal tensors",
                "Method"
            ],
            [
                "registered tensors",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('projective unifocal, bifo-cal, and trifocal tensors') is the subject, depending on the verb 'specialize' with 'we'. Entity 2 ('registered tensors') is the object, depending on the verb 'relate' with 'tensors obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verbs 'specialize' and 'relate' in the context of the sentence.\"",
        "sdp_path_text": "tensors → specialize → show → relate → to → tensors",
        "sentence": "The projective unifocal, bifocal, and trifocal tensors are specialized and shown to relate to the registered tensors.",
        "sentence_llm_dp_info": "\"Entity 1 ('projective unifocal, bifocal, and trifocal tensors') is the subject, depending on the verb 'are'. Entity 2 ('registered tensors') is the object of the verb 'relate', depending on 'relate' in the phrase 'to relate to the registered tensors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'relate'.\""
    },
    {
        "raw_sentence": "In this paper we specialize the projective unifocal , bifo-cal , and trifocal tensors to the affine case , and show how the tensors obtained relate to the registered tensors encountered in previous work .",
        "ner_pair": [
            [
                "affine case",
                "OtherScientificTerm"
            ],
            [
                "tensors",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine case') is the object of the preposition 'to', depending on 'specialize' with 'tensors'. Entity 2 ('tensors') is the direct object, depending on 'specialize' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'specialize' where 'tensors' are specialized to the 'affine case'.\"",
        "sdp_path_text": "case → to → tensors",
        "sentence": "The affine case relates to the tensors.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine case') is the subject, depending on the verb 'relates'. Entity 2 ('tensors') is the object, depending on the verb 'relates'. There is a direct dependency between Entity 1 and Entity 2, as 'tensors' is directly related to 'affine case' through the verb 'relates'.\""
    },
    {
        "raw_sentence": "In this paper we specialize the projective unifocal , bifo-cal , and trifocal tensors to the affine case , and show how the tensors obtained relate to the registered tensors encountered in previous work .",
        "ner_pair": [
            [
                "affine case",
                "OtherScientificTerm"
            ],
            [
                "registered tensors",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine case') is the object of the preposition 'to', depending on 'specialize' with 'tensors'. Entity 2 ('registered tensors') is the object of the preposition 'to', depending on 'relate' with 'obtained tensors'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the sentence where tensors are being specialized and related to different concepts.\"",
        "sdp_path_text": "case → to → tensors → specialize → show → relate → to → tensors",
        "sentence": "In the affine case, tensors relate to registered tensors.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine case') is the subject complement, depending on 'In' which marks the location or condition. Entity 2 ('registered tensors') is the object of the preposition 'to', depending on 'relate'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'relate'.\""
    },
    {
        "raw_sentence": "In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor , together with a simple geometric interpretation .",
        "ner_pair": [
            [
                "affine cameras",
                "Method"
            ],
            [
                "trifocal tensor",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine cameras') is the object of the preposition 'of', depending on 'case'. Entity 2 ('trifocal tensor') is the object of the preposition 'of', depending on 'components'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the context described in the sentence, where constraints are given for the components of the trifocal tensor in the case of affine cameras.\"",
        "sdp_path_text": "cameras → of → case → In → give → constraints → on → components → of → tensor",
        "sentence": "Constraints on the components of the trifocal tensor are given for the case of affine cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine cameras') is the object of the preposition 'for', depending on 'for' in the phrase 'for the case of affine cameras'. Entity 2 ('trifocal tensor') is part of a compound noun, depending on 'components' in the phrase 'components of the trifocal tensor'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence, where constraints on the components of the trifocal tensor are specified for the case involving affine cameras.\""
    },
    {
        "raw_sentence": "In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor , together with a simple geometric interpretation .",
        "ner_pair": [
            [
                "affine cameras",
                "Method"
            ],
            [
                "geometric interpretation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine cameras') is part of a prepositional phrase, depending on 'case' with 'of'. Entity 2 ('geometric interpretation') is the object of the preposition 'with', depending on 'with' in the phrase 'with a simple geometric interpretation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "cameras → of → case → In → give → with → interpretation",
        "sentence": "In the case of affine cameras, we give a geometric interpretation.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine cameras') is the object of the preposition 'of', depending on 'case'. Entity 2 ('geometric interpretation') is the direct object, depending on the verb 'give'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence structure.\""
    },
    {
        "raw_sentence": "In the simpler case of affine cameras we give neccessary and sufficient constraints on the components of the trifocal tensor , together with a simple geometric interpretation .",
        "ner_pair": [
            [
                "trifocal tensor",
                "Method"
            ],
            [
                "geometric interpretation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trifocal tensor') is the object of the preposition 'of', depending on 'components'. Entity 2 ('geometric interpretation') is the object of the preposition 'with', depending on 'together'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is given along with the constraints.\"",
        "sdp_path_text": "tensor → of → components → on → constraints → give → with → interpretation",
        "sentence": "Constraints on the components of the trifocal tensor are given with a geometric interpretation.",
        "sentence_llm_dp_info": "\"Entity 1 ('trifocal tensor') is part of a noun phrase, depending on 'of' in 'components of the trifocal tensor'. Entity 2 ('geometric interpretation') is the object of the preposition 'with', depending on 'with' in the phrase 'with a geometric interpretation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sentence structure, where 'trifocal tensor' is part of the subject and 'geometric interpretation' is an additional detail provided about the main clause.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "point correspondences",
                "OtherScientificTerm"
            ],
            [
                "estimation of the tensors",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('estimation of the tensors') is the subject, depending on 'achieved' with 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is part of the prepositional phrase that modifies Entity 2.\"",
        "sdp_path_text": "correspondences → from → tensors → of → estimation",
        "sentence": "The estimation of the tensors is achieved from point correspondences.",
        "sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object, depending on the preposition 'from', which modifies the verb 'achieved'. Entity 2 ('estimation of the tensors') is the subject, depending on the verb 'is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' and the verb 'is achieved'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "estimation of the tensors",
                "Task"
            ],
            [
                "factorization",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimation of the tensors') is the subject, depending on the verb 'achieved'. Entity 2 ('factorization') is the object of the preposition 'through', depending on 'through' in the phrase 'through factorization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'through' which indicates the method by which the 'estimation of the tensors' is 'achieved'.\"",
        "sdp_path_text": "estimation → achieved → through → factorization",
        "sentence": "The estimation of the tensors is achieved through factorization.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimation of the tensors') is the subject, depending on the verb 'achieved'. Entity 2 ('factorization') is the object of the preposition 'through', depending on 'achieved' in the phrase 'through factorization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the preposition 'through'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "estimation of the tensors",
                "Task"
            ],
            [
                "line correspondences",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimation of the tensors') is the object of the preposition 'of', depending on 'from' in the phrase 'from point correspondences'. It is also part of the clause 'the estimation of the tensors from point correspondences is achieved through factorization'. Entity 2 ('line correspondences') is the object of the preposition 'from', depending on 'from' in the phrase 'from line correspondences'. There is no direct dependency between Entity 1 and Entity 2; both are related to the process of estimation but from different types of correspondences.\"",
        "sdp_path_text": "estimation → achieved → show → discuss → estimation → from → correspondences",
        "sentence": "The estimation of the tensors is discussed in relation to line correspondences.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimation of the tensors') is the subject, depending on the verb 'discussed'. Entity 2 ('line correspondences') is the object of the preposition 'to', depending on 'relation' in the phrase 'in relation to line correspondences'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in relation to'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "tensors",
                "Generic"
            ],
            [
                "point correspondences",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tensors') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same nominal clause 'the estimation of the tensors from point correspondences'.\"",
        "sdp_path_text": "tensors → from → correspondences",
        "sentence": "The estimation of tensors is achieved from point correspondences.",
        "sentence_llm_dp_info": "\"Entity 1 ('tensors') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('point correspondences') is the object of the preposition 'from', depending on 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the sentence.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "factorization",
                "Method"
            ],
            [
                "tensors",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('factorization') is the object of the preposition 'through', depending on the verb 'achieved'. Entity 2 ('tensors') is the object of the preposition 'of', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the process of achieving the estimation of the tensors.\"",
        "sdp_path_text": "factorization → through → achieved → estimation → of → tensors",
        "sentence": "Factorization achieves the estimation of tensors.",
        "sentence_llm_dp_info": "\"Entity 1 ('factorization') is the subject, depending on the verb 'achieves'. Entity 2 ('tensors') is the object of the preposition 'of', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieves' and the prepositional phrase 'of tensors'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "tensors",
                "Generic"
            ],
            [
                "estimation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tensors') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('estimation') is the subject, depending on the verb 'is' in the clause 'the estimation is achieved'. There is a direct dependency between Entity 1 and Entity 2, as 'tensors' is part of the phrase 'the estimation of the tensors'.\"",
        "sdp_path_text": "tensors → of → estimation",
        "sentence": "The estimation of tensors is achieved through factorization.",
        "sentence_llm_dp_info": "\"Entity 1 ('tensors') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('estimation') is the subject, depending on the verb 'is achieved'. There is a direct dependency between Entity 1 and Entity 2, as 'tensors' is part of the noun phrase that modifies 'estimation'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "tensors",
                "Generic"
            ],
            [
                "line correspondences",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tensors') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('line correspondences') is the object of the preposition 'from', depending on 'the estimation from line correspondences'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the discussion about different aspects of the estimation process.\"",
        "sdp_path_text": "tensors → of → estimation → achieved → show → discuss → estimation → from → correspondences",
        "sentence": "The estimation of tensors from line correspondences is discussed.",
        "sentence_llm_dp_info": "\"Entity 1 ('tensors') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('line correspondences') is the object of the preposition 'from', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the noun 'estimation'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "point correspondences",
                "OtherScientificTerm"
            ],
            [
                "factorization",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('factorization') is the object of the preposition 'through', depending on 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the process of achieving the estimation.\"",
        "sdp_path_text": "correspondences → from → tensors → of → estimation → achieved → through → factorization",
        "sentence": "The estimation of tensors from point correspondences is achieved through factorization.",
        "sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('factorization') is the object of the preposition 'through', depending on 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the sentence, with Entity 1 being the source of data for the 'estimation' and Entity 2 being the method used to achieve it.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "point correspondences",
                "OtherScientificTerm"
            ],
            [
                "estimation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('estimation') is the subject, depending on the verb 'achieved'. There is a direct dependency between Entity 1 and Entity 2, where 'point correspondences' is part of the prepositional phrase that modifies 'estimation'.\"",
        "sdp_path_text": "correspondences → from → tensors → of → estimation",
        "sentence": "The estimation of tensors is achieved from point correspondences.",
        "sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object, depending on the preposition 'from', which itself depends on the verb 'achieved'. Entity 2 ('estimation') is part of the compound subject, depending on the verb 'is' in the clause 'estimation of tensors is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "point correspondences",
                "OtherScientificTerm"
            ],
            [
                "line correspondences",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('line correspondences') is also the object of the preposition 'from', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the same verb 'estimation' through the preposition 'from'.\"",
        "sdp_path_text": "correspondences → from → tensors → of → estimation → achieved → show → discuss → estimation → from → correspondences",
        "sentence": "We show how estimation from point correspondences and line correspondences is achieved.",
        "sentence_llm_dp_info": "\"Entity 1 ('point correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('line correspondences') is also the object of the preposition 'from', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same preposition 'from' in the context of 'estimation'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "factorization",
                "Method"
            ],
            [
                "estimation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('factorization') is the object of the preposition 'through', depending on 'achieved'. Entity 2 ('estimation') is the subject, depending on 'is' with 'achieved'. There is a direct dependency between Entity 1 and Entity 2, as 'factorization' is part of the method through which the 'estimation' is achieved.\"",
        "sdp_path_text": "factorization → through → achieved → estimation",
        "sentence": "Factorization is used to achieve estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('factorization') is the subject, depending on the verb 'is used'. Entity 2 ('estimation') is the object, depending on 'achieve' with 'to achieve estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to achieve estimation'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "factorization",
                "Method"
            ],
            [
                "line correspondences",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('factorization') is the object of the preposition 'through', depending on the verb 'achieved'. Entity 2 ('line correspondences') is the object of the preposition 'from', depending on the verb 'discuss'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "factorization → through → achieved → show → discuss → estimation → from → correspondences",
        "sentence": "Factorization is discussed in relation to the estimation from line correspondences.",
        "sentence_llm_dp_info": "\"Entity 1 ('factorization') is the subject, depending on the verb 'discussed'. Entity 2 ('line correspondences') is the object of the preposition 'from', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the discussion of 'estimation from line correspondences'.\""
    },
    {
        "raw_sentence": "Finally , we show how the estimation of the tensors from point correspondences is achieved through factorization , and discuss the estimation from line correspondences .",
        "ner_pair": [
            [
                "line correspondences",
                "OtherScientificTerm"
            ],
            [
                "estimation",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('line correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('estimation') is the subject, depending on 'discuss' with 'we'. There is a direct dependency between Entity 1 and Entity 2, where 'estimation' is modified by 'from line correspondences'.\"",
        "sdp_path_text": "correspondences → from → estimation → discuss → show → achieved → estimation",
        "sentence": "The estimation from line correspondences is discussed.",
        "sentence_llm_dp_info": "\"Entity 1 ('line correspondences') is the object of the preposition 'from', depending on 'estimation'. Entity 2 ('estimation') is the subject, depending on the verb 'discussed'. There is a direct dependency between Entity 1 and Entity 2, as 'line correspondences' modifies 'estimation' through the preposition 'from'.\""
    },
    {
        "raw_sentence": "In Thai language , it frequently happens that there is fluctuation in the choice of classifier for a given concrete noun , both from the point of view of the whole speech community and individual speakers .",
        "ner_pair": [
            [
                "Thai language",
                "Material"
            ],
            [
                "classifier",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Thai language') is the subject, depending on the preposition 'in' with 'In'. Entity 2 ('classifier') is the object of the preposition 'of', depending on 'choice'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'fluctuation in the choice of classifier for a given concrete noun'.\"",
        "sdp_path_text": "language → In → happens → is → fluctuation → in → choice → of → classifier",
        "sentence": "In Thai language, fluctuation happens in the choice of classifier.",
        "sentence_llm_dp_info": "\"Entity 1 ('Thai language') is the object of the preposition 'In', depending on the preposition 'In'. Entity 2 ('classifier') is the object of the preposition 'of', depending on 'choice'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the sentence structure, where the choice of classifier is described as fluctuating within the Thai language.\""
    },
    {
        "raw_sentence": "As far as we can do in the rule-based approach is to give a default rule to pick up a corresponding classifier of each noun .",
        "ner_pair": [
            [
                "rule-based approach",
                "Method"
            ],
            [
                "classifier",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based approach') is the object of the preposition 'in', depending on 'do'. Entity 2 ('classifier') is the object of the preposition 'of', depending on 'pick up' in the phrase 'to pick up a corresponding classifier'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where the action of picking up a classifier is described within the context of what can be done in the rule-based approach.\"",
        "sdp_path_text": "approach → in → do → far → is → give → rule → pick → classifier",
        "sentence": "The rule-based approach gives a rule to pick a classifier for each noun.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based approach') is the subject, depending on the verb 'gives'. Entity 2 ('classifier') is the object, depending on the verb 'pick' with 'rule'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'gives' and 'pick'.\""
    },
    {
        "raw_sentence": "We propose a corpus-based method -LRB- Biber ,1993 ; Nagao ,1993 ; Smadja ,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase .",
        "ner_pair": [
            [
                "corpus-based method",
                "Method"
            ],
            [
                "Noun Classifier Associations -LRB- NCA -RRB-",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpus-based method') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('Noun Classifier Associations (NCA)') is the object of the relative clause 'which generates', depending on 'generates' in the clause. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause that describes the function of the 'corpus-based method'.\"",
        "sdp_path_text": "method → generates → Associations",
        "sentence": "The corpus-based method generates Noun Classifier Associations (NCA).",
        "sentence_llm_dp_info": "\"Entity 1 ('corpus-based method') is the subject, depending on the verb 'generates'. Entity 2 ('Noun Classifier Associations (NCA)') is the object, depending directly on 'generates'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the agent that performs the action of generating Entity 2.\""
    },
    {
        "raw_sentence": "We propose a corpus-based method -LRB- Biber ,1993 ; Nagao ,1993 ; Smadja ,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase .",
        "ner_pair": [
            [
                "corpus-based method",
                "Method"
            ],
            [
                "classifier assignment",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpus-based method') is the object, depending on the verb 'propose' with 'We'. Entity 2 ('classifier assignment') is part of the compound noun phrase within the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the purpose clause introduced by 'to overcome'.\"",
        "sdp_path_text": "method → generates → overcome → problems → in → assignment",
        "sentence": "The corpus-based method generates NCA to overcome problems in classifier assignment.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpus-based method') is the subject, depending on the verb 'generates'. Entity 2 ('classifier assignment') is the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'overcome' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "We propose a corpus-based method -LRB- Biber ,1993 ; Nagao ,1993 ; Smadja ,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase .",
        "ner_pair": [
            [
                "corpus-based method",
                "Method"
            ],
            [
                "semantic construction of noun phrase",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpus-based method') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('semantic construction of noun phrase') is part of a compound object, depending on 'overcome' with 'problems'. There is no direct dependency between Entity 1 and Entity 2; they are both related to different parts of the sentence's structure, with Entity 1 being proposed and Entity 2 being one of the issues that the proposal aims to address.\"",
        "sdp_path_text": "method → generates → overcome → problems → in → assignment → construction",
        "sentence": "The corpus-based method generates Noun Classifier Associations to address issues in the semantic construction of noun phrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpus-based method') is the subject, depending on the verb 'generates'. Entity 2 ('semantic construction of noun phrase') is the object of the preposition 'in', depending on 'issues'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause introduced by 'to address issues in'.\""
    },
    {
        "raw_sentence": "We propose a corpus-based method -LRB- Biber ,1993 ; Nagao ,1993 ; Smadja ,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase .",
        "ner_pair": [
            [
                "Noun Classifier Associations -LRB- NCA -RRB-",
                "Method"
            ],
            [
                "classifier assignment",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Noun Classifier Associations -LRB- NCA -RRB-') is the object of the relative clause, depending on 'generates' with 'method'. Entity 2 ('classifier assignment') is part of a compound noun, depending on 'problems' in the phrase 'problems in classifier assignment'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of the method's purpose to address issues related to noun phrases.\"",
        "sdp_path_text": "Associations → generates → overcome → problems → in → assignment",
        "sentence": "Noun Classifier Associations (NCA) are generated to overcome problems in classifier assignment.",
        "sentence_llm_dp_info": "\"Entity 1 ('Noun Classifier Associations (NCA)') is the subject, depending on the verb 'generated'. Entity 2 ('classifier assignment') is the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'to overcome problems in classifier assignment'.\""
    },
    {
        "raw_sentence": "We propose a corpus-based method -LRB- Biber ,1993 ; Nagao ,1993 ; Smadja ,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase .",
        "ner_pair": [
            [
                "Noun Classifier Associations -LRB- NCA -RRB-",
                "Method"
            ],
            [
                "semantic construction of noun phrase",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Noun Classifier Associations -LRB- NCA -RRB-') is the object of the relative clause, depending on 'generates' with 'method'. Entity 2 ('semantic construction of noun phrase') is the object of the preposition 'of', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of overcoming issues in classifier assignment and semantic construction.\"",
        "sdp_path_text": "Associations → generates → overcome → problems → in → assignment → construction",
        "sentence": "Noun Classifier Associations (NCA) are generated to overcome problems in the semantic construction of noun phrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('Noun Classifier Associations (NCA)') is the subject, depending on the verb 'are generated'. Entity 2 ('semantic construction of noun phrase') is the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'to overcome problems in the semantic construction of noun phrases'.\""
    },
    {
        "raw_sentence": "We propose a corpus-based method -LRB- Biber ,1993 ; Nagao ,1993 ; Smadja ,1993 -RRB- which generates Noun Classifier Associations -LRB- NCA -RRB- to overcome the problems in classifier assignment and semantic construction of noun phrase .",
        "ner_pair": [
            [
                "classifier assignment",
                "Task"
            ],
            [
                "semantic construction of noun phrase",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classifier assignment') is part of the object complement, depending on the preposition 'in' within the phrase 'problems in classifier assignment'. Entity 2 ('semantic construction of noun phrase') is also part of the object complement, depending on the preposition 'in' within the phrase 'problems in semantic construction of noun phrase'. There is no direct dependency between Entity 1 and Entity 2, but both are connected through the preposition 'in' to the noun 'problems'.\"",
        "sdp_path_text": "assignment → construction",
        "sentence": "The method aims to overcome problems in classifier assignment and semantic construction of noun phrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('classifier assignment') is part of the object of the preposition 'in', depending on 'problems'. Entity 2 ('semantic construction of noun phrases') is also part of the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2; both are components of the same prepositional phrase 'in classifier assignment and semantic construction of noun phrases'.\""
    },
    {
        "raw_sentence": "The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences .",
        "ner_pair": [
            [
                "concept hierarchy constraints",
                "OtherScientificTerm"
            ],
            [
                "NCA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('concept hierarchy constraints') is the object of the preposition 'under', depending on 'recomposed'. Entity 2 ('NCA') is the subject, depending on 'is' in the clause 'The NCA is created'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'under'.\"",
        "sdp_path_text": "constraints → under → recomposed → created → NCA",
        "sentence": "The NCA is created and recomposed under concept hierarchy constraints.",
        "sentence_llm_dp_info": "\"Entity 1 ('concept hierarchy constraints') is the object of the preposition 'under', depending on 'under' in the phrase 'under concept hierarchy constraints'. Entity 2 ('NCA') is the subject, depending on the verbs 'is created' and 'recomposed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'under'.\""
    },
    {
        "raw_sentence": "The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences .",
        "ner_pair": [
            [
                "frequency of occurrences",
                "OtherScientificTerm"
            ],
            [
                "NCA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('frequency of occurrences') is the object, depending on the preposition 'and', which is part of the list of items that describe how the NCA is recomposed. Entity 2 ('NCA') is the subject, depending on the verb 'is' in the main clause 'The NCA is created'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the recomposition process described in the sentence.\"",
        "sdp_path_text": "frequency → constraints → under → recomposed → created → NCA",
        "sentence": "The NCA is created and recomposed under constraints of frequency of occurrences.",
        "sentence_llm_dp_info": "\"Entity 1 ('frequency of occurrences') is the object of the preposition 'of', depending on 'constraints'. Entity 2 ('NCA') is the subject, depending on the verbs 'created' and 'recomposed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'under constraints of frequency of occurrences'.\""
    },
    {
        "raw_sentence": "The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences .",
        "ner_pair": [
            [
                "concept hierarchy constraints",
                "OtherScientificTerm"
            ],
            [
                "frequency of occurrences",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('concept hierarchy constraints') is part of a compound noun, depending on 'under' with 'recomposed'. Entity 2 ('frequency of occurrences') is also part of a compound noun, depending on 'and' which links it to 'concept hierarchy constraints'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\"",
        "sdp_path_text": "constraints → frequency",
        "sentence": "The NCA is recomposed under concept hierarchy constraints and frequency of occurrences.",
        "sentence_llm_dp_info": "\"Entity 1 ('concept hierarchy constraints') is the object of the preposition 'under', depending on 'recomposed'. Entity 2 ('frequency of occurrences') is also the object of the preposition 'under', depending on 'recomposed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase modifying 'recomposed'.\""
    },
    {
        "raw_sentence": "The perception of transparent objects from images is known to be a very hard problem in vision .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "perception of transparent objects",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'from', depending on 'perception'. Entity 2 ('perception of transparent objects') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'images' modifies 'perception' through the preposition 'from'.\"",
        "sdp_path_text": "images → from → perception",
        "sentence": "The perception of transparent objects from images is known to be a hard problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'from', depending on 'perception'. Entity 2 ('perception of transparent objects') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'images' modifies 'perception' through the prepositional phrase 'from images'.\""
    },
    {
        "raw_sentence": "We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "transparent object",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'behave' and modified by the relative clause 'that are imaged through a transparent object'. Entity 2 ('transparent object') is the object of the preposition 'through', depending on 'imaged' in the phrase 'imaged through a transparent object'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'through a transparent object' which modifies 'features'.\"",
        "sdp_path_text": "features → imaged → through → object",
        "sentence": "Features imaged through a transparent object behave differently.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'behave'. Entity 2 ('transparent object') is the object of the preposition 'through', depending on 'imaged' in the phrase 'imaged through a transparent object'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'imaged' and the preposition 'through'.\""
    },
    {
        "raw_sentence": "We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene .",
        "ner_pair": [
            [
                "those",
                "Generic"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('those') is the subject, depending on 'behave' as the main verb. Entity 2 ('features') is the subject, depending on 'imaged' as part of the relative clause modifying 'features'. There is no direct dependency between Entity 1 and Entity 2; however, they are semantically related as 'those' refers back to 'features' in the context of the sentence.\"",
        "sdp_path_text": "those → from → differently → behave → features",
        "sentence": "Those behave differently from features.",
        "sentence_llm_dp_info": "\"Entity 1 ('those') is the subject, depending on the verb 'behave'. Entity 2 ('features') is the object of the preposition 'from', depending on 'from' in the phrase 'from features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We show how features that are imaged through a transparent object behave differently from those that are rigidly attached to the scene .",
        "ner_pair": [
            [
                "transparent object",
                "OtherScientificTerm"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transparent object') is the object of the preposition 'through', depending on 'imaged'. Entity 2 ('those') is the subject of the clause 'those that are rigidly attached to the scene', depending on 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing different behaviors of features.\"",
        "sdp_path_text": "object → through → imaged → features → behave → differently → from → those",
        "sentence": "Features imaged through a transparent object behave differently from those attached to the scene.",
        "sentence_llm_dp_info": "\"Entity 1 ('transparent object') is the object of the preposition 'through', depending on 'imaged'. Entity 2 ('those') is the subject of the clause 'those attached to the scene', depending on 'behave'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same semantic context where 'those' refers to features that are compared to features imaged through a 'transparent object'.\""
    },
    {
        "raw_sentence": "We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion .",
        "ner_pair": [
            [
                "model-based approach",
                "Method"
            ],
            [
                "shapes and the poses of transparent objects",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model-based approach') is the subject complement, depending on the verb 'present' with 'We'. Entity 2 ('shapes and the poses of transparent objects') is the object, depending on 'recover' in the phrase 'to recover the shapes and the poses of transparent objects'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure of the sentence, where 'model-based approach' is what is being presented, and 'shapes and the poses of transparent objects' is what the approach aims to recover.\"",
        "sdp_path_text": "approach → recover → shapes",
        "sentence": "The model-based approach recovers the shapes and poses of transparent objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('model-based approach') is the subject, depending on the verb 'recovers'. Entity 2 ('shapes and poses of transparent objects') is the direct object, depending on 'recovers' in the phrase 'recovers the shapes and poses of transparent objects'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 performs the action (recovers) on Entity 2.\""
    },
    {
        "raw_sentence": "We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion .",
        "ner_pair": [
            [
                "model-based approach",
                "Method"
            ],
            [
                "known motion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model-based approach') is the object of the preposition 'to', depending on 'present' with 'We'. Entity 2 ('known motion') is the object of the preposition 'from', depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'model-based approach' is used to achieve the recovery of shapes and poses from 'known motion'.\"",
        "sdp_path_text": "approach → recover → from → motion",
        "sentence": "A model-based approach recovers shapes and poses from known motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('model-based approach') is the subject, depending on the verb 'recovers'. Entity 2 ('known motion') is the object of the preposition 'from', depending on 'from' in the phrase 'from known motion'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recovers' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "We present a novel model-based approach to recover the shapes and the poses of transparent objects from known motion .",
        "ner_pair": [
            [
                "known motion",
                "OtherScientificTerm"
            ],
            [
                "shapes and the poses of transparent objects",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('known motion') is the object of the preposition 'from', depending on 'recover'. Entity 2 ('shapes and the poses of transparent objects') is the direct object, depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recover'.\"",
        "sdp_path_text": "motion → from → recover → shapes",
        "sentence": "Known motion is used to recover the shapes and poses of transparent objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('known motion') is the subject, depending on the verb 'used'. Entity 2 ('shapes and the poses of transparent objects') is the object, depending on the verb 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recover' which indicates that 'known motion' is used in the process of recovering 'shapes and the poses of transparent objects'.\""
    },
    {
        "raw_sentence": "The objects can be complex in that they may be composed of multiple layers with different refractive indices .",
        "ner_pair": [
            [
                "objects",
                "Generic"
            ],
            [
                "they",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('objects') is the subject, depending on the verb 'can be'. Entity 2 ('they') is a pronoun, referring back to 'objects' and serving as the subject of the clause 'they may be composed of multiple layers'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 2 refers back to Entity 1, creating an anaphoric reference.\"",
        "sdp_path_text": "objects → be → composed → they",
        "sentence": "Objects can be composed of multiple layers.",
        "sentence_llm_dp_info": "\"Entity 1 ('objects') is the subject, depending on the verb 'can be composed'. Entity 2 ('they') does not appear in the sentence provided. Therefore, there is no dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence.\""
    },
    {
        "raw_sentence": "The objects can be complex in that they may be composed of multiple layers with different refractive indices .",
        "ner_pair": [
            [
                "objects",
                "Generic"
            ],
            [
                "multiple layers",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('objects') is the subject, depending on the verb 'can be'. Entity 2 ('multiple layers') is the object of the preposition 'of', depending on 'composed' in the phrase 'composed of multiple layers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'composed'.\"",
        "sdp_path_text": "objects → be → composed → of → layers",
        "sentence": "Objects can be composed of multiple layers.",
        "sentence_llm_dp_info": "\"Entity 1 ('objects') is the subject, depending on the verb 'can be composed'. Entity 2 ('multiple layers') is the object, depending on 'composed' with 'of' in the phrase 'composed of multiple layers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'composed' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "The objects can be complex in that they may be composed of multiple layers with different refractive indices .",
        "ner_pair": [
            [
                "objects",
                "Generic"
            ],
            [
                "refractive indices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('objects') is the subject, depending on the verb 'can be'. Entity 2 ('refractive indices') is the object of the preposition 'with', depending on 'with' in the phrase 'with different refractive indices'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'with different refractive indices'.\"",
        "sdp_path_text": "objects → be → composed → of → layers → with → indices",
        "sentence": "Objects can be composed of layers with refractive indices.",
        "sentence_llm_dp_info": "\"Entity 1 ('objects') is the subject, depending on the modal verb 'can' and followed by the verb 'be'. Entity 2 ('refractive indices') is the object of the preposition 'of', depending on 'layers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of layers with refractive indices'.\""
    },
    {
        "raw_sentence": "The objects can be complex in that they may be composed of multiple layers with different refractive indices .",
        "ner_pair": [
            [
                "multiple layers",
                "OtherScientificTerm"
            ],
            [
                "they",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple layers') is the object of the preposition 'of', depending on 'composed'. Entity 2 ('they') is the subject, depending on the verb 'can be'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the clause where 'they' refers back to 'objects' which can be 'composed of multiple layers'.\"",
        "sdp_path_text": "layers → of → composed → they",
        "sentence": "They can be composed of multiple layers.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple layers') is the object, depending on the preposition 'of' with 'composed'. Entity 2 ('they') is the subject, depending on the auxiliary verb 'can' with 'be'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'composed' which indicates that 'they' can consist of 'multiple layers'.\""
    },
    {
        "raw_sentence": "The objects can be complex in that they may be composed of multiple layers with different refractive indices .",
        "ner_pair": [
            [
                "they",
                "Generic"
            ],
            [
                "refractive indices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('they') is the subject, depending on the verb 'be' (can be). Entity 2 ('refractive indices') is the object, depending on the preposition 'of' in the phrase 'with different refractive indices'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the composition of the objects.\"",
        "sdp_path_text": "they → composed → of → layers → with → indices",
        "sentence": "They are composed of layers with refractive indices.",
        "sentence_llm_dp_info": "\"Entity 1 ('they') is the subject, depending on the verb 'composed'. Entity 2 ('refractive indices') is the object of the preposition 'with', depending on 'layers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'composed' and the prepositional phrase 'with refractive indices'.\""
    },
    {
        "raw_sentence": "The objects can be complex in that they may be composed of multiple layers with different refractive indices .",
        "ner_pair": [
            [
                "refractive indices",
                "OtherScientificTerm"
            ],
            [
                "multiple layers",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('refractive indices') is the object, depending on the adjective 'different' which modifies it. Entity 2 ('multiple layers') is the object of the preposition 'of', depending on 'composed'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'multiple layers' are described as having 'different refractive indices'.\"",
        "sdp_path_text": "indices → with → layers",
        "sentence": "Refractive indices are associated with multiple layers.",
        "sentence_llm_dp_info": "\"Entity 1 ('refractive indices') is the subject, depending on the verb 'are associated'. Entity 2 ('multiple layers') is the object, depending on the verb 'are associated'. There is a direct dependency between Entity 1 and Entity 2, as they are directly linked through the verb 'are associated'.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "real scenes",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object, depending on the verb 'applied'. Entity 2 ('real scenes') is the object of the preposition 'to', depending on 'to' in the phrase 'to real scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' in the context of the application action described by the verb 'applied'.\"",
        "sdp_path_text": "it → applied → to → scenes",
        "sentence": "It has been applied to real scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has been applied'. Entity 2 ('real scenes') is the object of the preposition 'to', depending on 'to' in the phrase 'to real scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has been applied' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "transparent objects",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the verb 'applied', depending on 'have applied' with 'We'. Entity 2 ('transparent objects') is the object of the verb 'include', depending on 'include' within the relative clause 'that include transparent objects'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related through the scene to which 'it' is applied and which includes 'transparent objects'.\"",
        "sdp_path_text": "it → applied → to → scenes → include → objects",
        "sentence": "It has been applied to scenes including transparent objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has been applied'. Entity 2 ('transparent objects') is the object of the preposition 'including', depending on 'including' in the phrase 'including transparent objects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'including transparent objects'.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "shapes of the objects",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the verb 'applied', depending on 'have applied' with 'We'. Entity 2 ('shapes of the objects') is the object of the verb 'recovered', depending on 'recovered' with 'and'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and related through the verbs 'applied' and 'recovered'.\"",
        "sdp_path_text": "it → applied → recovered → shapes",
        "sentence": "It was applied to recover the shapes of the objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'was applied'. Entity 2 ('shapes of the objects') is the object of the verb 'recover', depending on 'recover' in the phrase 'to recover the shapes of the objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'was applied' and the purpose clause 'to recover the shapes of the objects'.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object of the verb 'applied', depending on 'have applied' with 'We'. Entity 2 ('accuracy') is the object of the preposition 'with', depending on 'with' in the phrase 'with high accuracy'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "it → applied → recovered → with → accuracy",
        "sentence": "It has been applied to recover shapes with high accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has been applied'. Entity 2 ('accuracy') is the object, depending on the adjective 'high' and the preposition 'with' in the phrase 'with high accuracy'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "transparent objects",
                "OtherScientificTerm"
            ],
            [
                "real scenes",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transparent objects') is the object, depending on 'include' with 'scenes'. Entity 2 ('real scenes') is the object of the preposition 'to', depending on 'applied' in the phrase 'applied it to real scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'that include transparent objects'.\"",
        "sdp_path_text": "objects → include → scenes",
        "sentence": "Real scenes include transparent objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('transparent objects') is the object, depending on the verb 'include'. Entity 2 ('real scenes') is the subject, depending on the verb 'include'. There is a direct dependency between Entity 1 and Entity 2, as 'transparent objects' is included in 'real scenes'.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "real scenes",
                "Material"
            ],
            [
                "shapes of the objects",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('real scenes') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('shapes of the objects') is the object of the verb 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the process described in the sentence.\"",
        "sdp_path_text": "scenes → to → applied → recovered → shapes",
        "sentence": "We have applied it to real scenes and recovered the shapes of the objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('real scenes') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('shapes of the objects') is the object of the verb 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the actions described in the sentence, with 'real scenes' being the target of the application and 'shapes of the objects' being the result of the recovery process.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "real scenes",
                "Material"
            ],
            [
                "accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('real scenes') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('accuracy') is the object of the preposition 'with', depending on 'recovered'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "scenes → to → applied → recovered → with → accuracy",
        "sentence": "We have applied it to real scenes and recovered the shapes with high accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('real scenes') is the object of the preposition 'to', depending on 'applied'. Entity 2 ('accuracy') is part of the noun phrase 'high accuracy', acting as the object complement of the verb 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the actions described in the sentence through different verbs ('applied' and 'recovered').\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "transparent objects",
                "OtherScientificTerm"
            ],
            [
                "shapes of the objects",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transparent objects') is the object of the relative clause, depending on 'include' with 'scenes'. Entity 2 ('shapes of the objects') is the object, depending on 'recovered' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the actions performed on or related to the objects.\"",
        "sdp_path_text": "objects → include → scenes → to → applied → recovered → shapes",
        "sentence": "Shapes of transparent objects were recovered from scenes that include them.",
        "sentence_llm_dp_info": "\"Entity 1 ('transparent objects') is the object of the preposition 'of', depending on 'shapes'. Entity 2 ('shapes of the objects') is the subject, depending on the verb 'were recovered'. There is a direct dependency between Entity 1 and Entity 2, as 'shapes' (Entity 2) modifies 'objects' (Entity 1) through the prepositional phrase 'of the objects'.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "transparent objects",
                "OtherScientificTerm"
            ],
            [
                "accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transparent objects') is the object of the relative clause, depending on 'include' with 'scenes'. Entity 2 ('accuracy') is the object complement, depending on 'recovered' with 'shapes'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the application and results of the action.\"",
        "sdp_path_text": "objects → include → scenes → to → applied → recovered → with → accuracy",
        "sentence": "The shapes of transparent objects were recovered with high accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('transparent objects') is the object of the preposition 'of', depending on 'shapes'. Entity 2 ('accuracy') is the object of the preposition 'with', depending on 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where 'shapes' of Entity 1 are described as being 'recovered' 'with' high Entity 2.\""
    },
    {
        "raw_sentence": "We have applied it to real scenes that include transparent objects and recovered the shapes of the objects with high accuracy .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "shapes of the objects",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on the adjective 'high' and the preposition 'with', which modifies the verb 'recovered'. Entity 2 ('shapes of the objects') is the direct object, depending on the verb 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'recovered'.\"",
        "sdp_path_text": "accuracy → with → recovered → shapes",
        "sentence": "The shapes of the objects were recovered with high accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object complement, depending on 'recovered' with 'high'. Entity 2 ('shapes of the objects') is the subject, depending on 'were' with 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the predicate 'were recovered with high accuracy'.\""
    },
    {
        "raw_sentence": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .",
        "ner_pair": [
            [
                "probabilistic framework",
                "Method"
            ],
            [
                "visual models of 3D object categories",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('probabilistic framework') is the object of the preposition 'for', depending on 'propose'. Entity 2 ('visual models of 3D object categories') is the object of the preposition 'of', depending on 'learning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'framework' is used for 'learning' 'visual models'.\"",
        "sdp_path_text": "framework → for → learning → models",
        "sentence": "We propose a probabilistic framework for learning visual models of 3D object categories.",
        "sentence_llm_dp_info": "\"Entity 1 ('probabilistic framework') is the object, depending on 'propose' with 'We'. Entity 2 ('visual models of 3D object categories') is the object of the preposition 'of', depending on 'learning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'framework' is proposed for 'learning' about 'visual models of 3D object categories'.\""
    },
    {
        "raw_sentence": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .",
        "ner_pair": [
            [
                "appearance information",
                "OtherScientificTerm"
            ],
            [
                "probabilistic framework",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('appearance information') is the object of the preposition 'and', depending on 'combining'. Entity 2 ('probabilistic framework') is the object of the preposition 'for', depending on 'framework' in the phrase 'for learning visual models of 3D object categories'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what the framework combines.\"",
        "sdp_path_text": "information → combining → by → learning → for → framework",
        "sentence": "We propose a probabilistic framework for learning visual models by combining appearance information.",
        "sentence_llm_dp_info": "\"Entity 1 ('appearance information') is the object, depending on the verb 'combining'. Entity 2 ('probabilistic framework') is the object of the preposition 'for', depending on 'for' in the phrase 'for learning visual models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the action of proposing a method for learning visual models.\""
    },
    {
        "raw_sentence": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .",
        "ner_pair": [
            [
                "geometric constraints",
                "OtherScientificTerm"
            ],
            [
                "probabilistic framework",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric constraints') is the object of the preposition 'and', depending on 'information' in the phrase 'appearance information and geometric constraints'. Entity 2 ('probabilistic framework') is the object of the preposition 'for', depending on 'framework' in the phrase 'a novel probabilistic framework'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the components used in the learning process.\"",
        "sdp_path_text": "constraints → information → combining → by → learning → for → framework",
        "sentence": "We propose a probabilistic framework for learning visual models by combining geometric constraints.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric constraints') is the object of the preposition 'combining', depending on 'combining' in the phrase 'combining geometric constraints'. Entity 2 ('probabilistic framework') is the direct object, depending on the verb 'propose' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combining' which modifies the action of proposing the framework.\""
    },
    {
        "raw_sentence": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .",
        "ner_pair": [
            [
                "visual models of 3D object categories",
                "Task"
            ],
            [
                "appearance information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual models of 3D object categories') is the object of the preposition 'of', depending on 'learning' in the phrase 'learning visual models of 3D object categories'. Entity 2 ('appearance information') is the subject complement, depending on 'combining' in the phrase 'combining appearance information and geometric constraints'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the components combined in the framework.\"",
        "sdp_path_text": "models → learning → by → combining → information",
        "sentence": "Visual models of 3D object categories are learned by combining appearance information.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual models of 3D object categories') is the subject, depending on the verb 'learned'. Entity 2 ('appearance information') is the object, depending on the preposition 'combining' in the phrase 'by combining appearance information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'learned' and the prepositional phrase 'by combining appearance information'.\""
    },
    {
        "raw_sentence": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .",
        "ner_pair": [
            [
                "visual models of 3D object categories",
                "Task"
            ],
            [
                "geometric constraints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual models of 3D object categories') is the object of the preposition 'of', depending on 'learning'. Entity 2 ('geometric constraints') is the object, depending on 'combining' with 'appearance information'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what is being combined in the framework.\"",
        "sdp_path_text": "models → learning → by → combining → information → constraints",
        "sentence": "Visual models of 3D object categories are learned by combining information and geometric constraints.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual models of 3D object categories') is the subject, depending on the verb 'learned'. Entity 2 ('geometric constraints') is the object of the preposition 'and', depending on 'combining' in the phrase 'combining information and geometric constraints'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'visual models of 3D object categories' are described as being learned through the combination of 'information and geometric constraints'.\""
    },
    {
        "raw_sentence": "We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .",
        "ner_pair": [
            [
                "appearance information",
                "OtherScientificTerm"
            ],
            [
                "geometric constraints",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('appearance information') is the object of the preposition 'and', depending on 'combining' in the phrase 'combining appearance information and geometric constraints'. Entity 2 ('geometric constraints') is also the object of the preposition 'and', depending on 'combining' in the same phrase. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the coordinated structure introduced by 'and'.\"",
        "sdp_path_text": "information → constraints",
        "sentence": "{\n  \"Simplified sentence\": \"We propose a framework for learning visual models of 3D object categories by combining appearance information and geometric constraints.\"\n} \n\nHowever, to strictly adhere to the instructions and focus only on the relationship highlighted by the SDP while ensuring conciseness:\n\n{\n  \"Simplified sentence\": \"Appearance information and geometric constraints are combined.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('appearance information') is the subject, depending on the verb 'combined'. Entity 2 ('geometric constraints') is also a subject, conjoined with 'appearance information' and depending on the same verb 'combined'. There is no direct dependency between Entity 1 and Entity 2; however, they are both subjects of the same verb, indicating a parallel relationship in the context of being combined.\""
    },
    {
        "raw_sentence": "A generative framework is used for learning a model that captures the relative position of parts within each of the discretized viewpoints .",
        "ner_pair": [
            [
                "generative framework",
                "Method"
            ],
            [
                "model",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generative framework') is the subject, depending on the verb 'used'. Entity 2 ('model') is the object of the relative clause, depending on 'that' which modifies 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the relative clause 'that captures the relative position of parts within each of the discretized viewpoints'.\"",
        "sdp_path_text": "framework → used → for → learning → model",
        "sentence": "A generative framework is used for learning a model.",
        "sentence_llm_dp_info": "\"Entity 1 ('generative framework') is the subject, depending on the verb 'used'. Entity 2 ('model') is the object, depending on the verb 'learning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used for learning'.\""
    },
    {
        "raw_sentence": "A generative framework is used for learning a model that captures the relative position of parts within each of the discretized viewpoints .",
        "ner_pair": [
            [
                "generative framework",
                "Method"
            ],
            [
                "discretized viewpoints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generative framework') is the subject, depending on the verb 'is used'. Entity 2 ('discretized viewpoints') is the object of the preposition 'within', depending on 'parts'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, with the relationship mediated through the structure of the sentence involving 'model' and 'parts'.\"",
        "sdp_path_text": "framework → used → for → learning → model → captures → position → within → each → of → viewpoints",
        "sentence": "A generative framework is used for learning a model that captures the position within discretized viewpoints.",
        "sentence_llm_dp_info": "\"Entity 1 ('generative framework') is the subject, depending on the verb 'used'. Entity 2 ('discretized viewpoints') is the object of the preposition 'within', depending on 'position'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing what the model captures.\""
    },
    {
        "raw_sentence": "A generative framework is used for learning a model that captures the relative position of parts within each of the discretized viewpoints .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "discretized viewpoints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the relative clause, depending on 'learning' with 'a model'. Entity 2 ('discretized viewpoints') is the object of the preposition 'of', depending on 'each' in the phrase 'each of the discretized viewpoints'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the aspects of the model being learned.\"",
        "sdp_path_text": "model → captures → position → within → each → of → viewpoints",
        "sentence": "A model captures the position within discretized viewpoints.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'captures'. Entity 2 ('discretized viewpoints') is the object of the preposition 'within', depending on 'within' in the phrase 'within discretized viewpoints'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'within discretized viewpoints' which modifies the object 'position'.\""
    },
    {
        "raw_sentence": "Contrary to most of the existing mixture of viewpoints models , our model establishes explicit correspondences of parts across different viewpoints of the object class .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "viewpoints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on 'establishes' as its verb. Entity 2 ('viewpoints') is part of the prepositional phrase 'of the object class', where it depends on 'parts' as the object of the preposition 'across'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the structure of the sentence, specifically through the action 'establishes explicit correspondences' that relates the 'model' to 'parts across different viewpoints'.\"",
        "sdp_path_text": "models → mixture → of → viewpoints",
        "sentence": "Our model establishes correspondences across different viewpoints.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'establishes'. Entity 2 ('viewpoints') is the object of the preposition 'across', depending on 'across' in the phrase 'across different viewpoints'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'across'.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "image",
                "Material"
            ],
            [
                "detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given a new image'. Entity 2 ('detection') is part of the compound subject, depending on 'are' in the clause 'detection and classification are achieved'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "image → Given → achieved → detection",
        "sentence": "Detection is achieved given a new image.",
        "sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'given', depending on 'given' in the phrase 'given a new image'. Entity 2 ('detection') is the subject, depending on the verb 'is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'given a new image' which modifies the context in which 'detection' is achieved.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "image",
                "Material"
            ],
            [
                "classification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given a new image'. Entity 2 ('classification') is part of a compound predicate, depending on 'are' in the phrase 'detection and classification are achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context where 'detection and classification' are described as being 'achieved' in relation to the 'image'.\"",
        "sdp_path_text": "image → Given → achieved → detection → classification",
        "sentence": "Given a new image, classification is achieved.",
        "sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given a new image'. Entity 2 ('classification') is the subject, depending on the verb 'is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the presence of the 'image' leads to the 'classification' being achieved.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "image",
                "Material"
            ],
            [
                "position",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on the prepositional phrase 'Given a new image'. Entity 2 ('position') is part of the object complement, depending on 'determining' with the phrase 'the position and viewpoint of the model'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the process described in the sentence.\"",
        "sdp_path_text": "image → Given → achieved → by → determining → position",
        "sentence": "Given an image, the position is determined to achieve detection and classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given an image'. Entity 2 ('position') is the subject, depending on the verb 'is determined'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the sentence structure.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "image",
                "Material"
            ],
            [
                "viewpoint",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given a new image'. Entity 2 ('viewpoint') is part of the compound object, depending on 'determining' in the phrase 'determining the position and viewpoint'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "image → Given → achieved → by → determining → position → viewpoint",
        "sentence": "Detection and classification of a new image are achieved by determining the position and viewpoint.",
        "sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'of', depending on 'classification'. Entity 2 ('viewpoint') is part of the conjunction, depending on 'determining' with 'position'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "image",
                "Material"
            ],
            [
                "recognition scores",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on the preposition 'Given' in the phrase 'Given a new image'. Entity 2 ('recognition scores') is the object, depending on 'maximize' in the clause 'that maximize recognition scores'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the process described in the sentence.\"",
        "sdp_path_text": "image → Given → achieved → by → determining → position → maximize → scores",
        "sentence": "Given an image, recognition scores are maximized by determining the position and viewpoint of the model.",
        "sentence_llm_dp_info": "\"Entity 1 ('image') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given an image'. Entity 2 ('recognition scores') is the subject, depending on the verb 'are maximized'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related in the same clause where the maximization of recognition scores involves the given image.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "detection",
                "Task"
            ],
            [
                "classification",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection') is part of a coordination, depending on the conjunction 'and' with 'classification'. Entity 2 ('classification') is also part of the coordination, depending on the same conjunction 'and' with 'detection'. Both 'detection' and 'classification' are the subjects of the verb 'are achieved'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\"",
        "sdp_path_text": "detection → classification",
        "sentence": "Detection and classification are achieved.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection') is part of a coordination, depending on the conjunction 'and' with 'classification'. Entity 2 ('classification') is also part of the same coordination, depending on the conjunction 'and' with 'detection'. Both 'detection' and 'classification' are subjects, depending on the verb 'are achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as subjects of the sentence.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "position",
                "OtherScientificTerm"
            ],
            [
                "detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('position') is part of the compound noun 'position and viewpoint', which is the object of the verb 'determining'. Entity 2 ('detection') is part of the compound noun 'detection and classification', which is the subject of the verb 'are achieved'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "position → determining → by → achieved → detection",
        "sentence": "Detection is achieved by determining the position.",
        "sentence_llm_dp_info": "\"Entity 1 ('position') is the object, depending on 'determining' with 'the position'. Entity 2 ('detection') is the subject, depending on 'achieved' with 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'determining' which is part of the process that achieves the detection.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "viewpoint",
                "OtherScientificTerm"
            ],
            [
                "detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('viewpoint') is part of a compound noun, depending on 'determining' with the phrase 'the position and viewpoint of the model'. Entity 2 ('detection') is part of a coordination, depending on 'are' as a subject in the clause 'detection and classification are achieved'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "viewpoint → position → determining → by → achieved → detection",
        "sentence": "Detection is achieved by determining the position and viewpoint.",
        "sentence_llm_dp_info": "\"Entity 1 ('viewpoint') is part of the object complement, depending on 'determining' in the phrase 'determining the position and viewpoint'. Entity 2 ('detection') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'determining' which describes how 'detection' is achieved.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "detection",
                "Task"
            ],
            [
                "recognition scores",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection') is part of a coordination, depending on the conjunction 'and' with 'classification', which together form the subject of the clause, depending on 'are' in 'are achieved'. Entity 2 ('recognition scores') is the object of the preposition 'of', depending on 'maximize' in the phrase 'that maximize recognition scores'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where both are part of the process described.\"",
        "sdp_path_text": "detection → achieved → by → determining → position → maximize → scores",
        "sentence": "Detection is achieved by determining the position that maximizes recognition scores.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection') is the subject, depending on the verb 'is achieved'. Entity 2 ('recognition scores') is the object of the relative clause, depending on 'maximizes' with 'position'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause that describes how detection is achieved.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "position",
                "OtherScientificTerm"
            ],
            [
                "classification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('position') is part of a coordination, depending on 'determining' with the conjunction 'and' connecting it to 'viewpoint'. Entity 2 ('classification') is the second element in a compound predicate, depending on 'are' as part of the passive construction 'are achieved'. There is no direct dependency between Entity 1 and Entity 2; they are connected through their roles in the overall process described in the sentence.\"",
        "sdp_path_text": "position → determining → by → achieved → detection → classification",
        "sentence": "Classification is achieved by determining the position.",
        "sentence_llm_dp_info": "\"Entity 1 ('position') is the object, depending on the verb 'determining'. Entity 2 ('classification') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'determining' which contributes to the achievement of 'classification'.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "viewpoint",
                "OtherScientificTerm"
            ],
            [
                "classification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('viewpoint') is part of a coordinated noun phrase, depending on 'and' with 'position'. It is also an object of the preposition 'of', which modifies 'model'. Entity 2 ('classification') is part of a coordinated verb phrase, depending on 'and' with 'detection'. Both 'detection' and 'classification' are subjects, depending on the verb 'are' in the phrase 'are achieved'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "viewpoint → position → determining → by → achieved → detection → classification",
        "sentence": "Classification is achieved by determining the viewpoint and position.",
        "sentence_llm_dp_info": "\"Entity 1 ('viewpoint') is the object of the preposition 'the', depending on 'determining' in the phrase 'determining the viewpoint'. Entity 2 ('classification') is the subject, depending on the verb 'is achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described by the verb 'determining'.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "classification",
                "Task"
            ],
            [
                "recognition scores",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classification') is part of a coordination, depending on 'and' with 'detection'. Entity 2 ('recognition scores') is the object of the preposition 'of', depending on 'maximize'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'maximize' and the preposition 'of'.\"",
        "sdp_path_text": "classification → detection → achieved → by → determining → position → maximize → scores",
        "sentence": "Classification and detection are achieved by maximizing recognition scores.",
        "sentence_llm_dp_info": "\"Entity 1 ('classification') is part of a coordination, depending on 'are' as a subject. Entity 2 ('recognition scores') is the object of the preposition 'by', depending on 'maximizing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'achieved' and the prepositional phrase 'by maximizing recognition scores'.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "position",
                "OtherScientificTerm"
            ],
            [
                "viewpoint",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('position') is part of the conjunction, depending on 'determining' with the phrase 'the position and viewpoint of the model'. Entity 2 ('viewpoint') is also part of the conjunction, depending on 'determining' with the same phrase 'the position and viewpoint of the model'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the same conjunctive structure.\"",
        "sdp_path_text": "position → viewpoint",
        "sentence": "Detection and classification are achieved by determining the position and viewpoint.",
        "sentence_llm_dp_info": "\"Entity 1 ('position') is the object of the preposition 'the', depending on 'determining'. Entity 2 ('viewpoint') is also the object of the preposition 'the', depending on 'determining'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same preposition 'the' within the context of 'determining'.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "position",
                "OtherScientificTerm"
            ],
            [
                "recognition scores",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('position') is part of the compound noun 'position and viewpoint', which is the object of the preposition 'of', depending on 'determining'. Entity 2 ('recognition scores') is the object of the preposition 'of', depending on 'maximize'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is being determined to achieve detection and classification.\"",
        "sdp_path_text": "position → maximize → scores",
        "sentence": "The position maximizes recognition scores.",
        "sentence_llm_dp_info": "\"Entity 1 ('position') is the subject, depending on the verb 'maximizes'. Entity 2 ('recognition scores') is the object, depending on the verb 'maximizes'. There is a direct dependency between Entity 1 and Entity 2, as 'position' is the agent that performs the action of maximizing 'recognition scores'.\""
    },
    {
        "raw_sentence": "Given a new image , detection and classification are achieved by determining the position and viewpoint of the model that maximize recognition scores of the candidate objects .",
        "ner_pair": [
            [
                "viewpoint",
                "OtherScientificTerm"
            ],
            [
                "recognition scores",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('viewpoint') is part of the conjunction 'position and viewpoint', which is the object of the preposition 'of', depending on 'determining'. Entity 2 ('recognition scores') is the object of the preposition 'of', depending on 'maximize'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is determined to achieve detection and classification.\"",
        "sdp_path_text": "viewpoint → position → maximize → scores",
        "sentence": "The viewpoint and position maximize recognition scores.",
        "sentence_llm_dp_info": "\"Entity 1 ('viewpoint') is part of a coordination with 'position', together forming the subject, depending on the verb 'maximize'. Entity 2 ('recognition scores') is the object, depending on the verb 'maximize'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the action described by the verb 'maximize'.\""
    },
    {
        "raw_sentence": "Our approach is among the first to propose a generative proba-bilistic framework for 3D object categorization .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "generative proba-bilistic framework",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('generative proba-bilistic framework') is the object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'propose' which indicates that the approach is proposing the framework.\"",
        "sdp_path_text": "approach → is → among → first → propose → framework",
        "sentence": "Our approach is among the first to propose a generative probabilistic framework.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('generative probabilistic framework') is the object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'propose' which is part of the clause 'to propose a generative probabilistic framework'.\""
    },
    {
        "raw_sentence": "Our approach is among the first to propose a generative proba-bilistic framework for 3D object categorization .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "3D object categorization",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('3D object categorization') is the object of the preposition 'for', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'propose' and the preposition 'for'.\"",
        "sdp_path_text": "approach → is → among → first → propose → framework → for → categorization",
        "sentence": "Our approach is among the first to propose a framework for 3D object categorization.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('3D object categorization') is the object of the preposition 'for', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'propose' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our approach is among the first to propose a generative proba-bilistic framework for 3D object categorization .",
        "ner_pair": [
            [
                "generative proba-bilistic framework",
                "Method"
            ],
            [
                "3D object categorization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generative proba-bilistic framework') is the object, depending on 'propose' with 'approach'. Entity 2 ('3D object categorization') is the complement, depending on 'for' in the phrase 'for 3D object categorization'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "framework → for → categorization",
        "sentence": "Our approach proposes a generative probabilistic framework for 3D object categorization.",
        "sentence_llm_dp_info": "\"Entity 1 ('generative probabilistic framework') is the object, depending on the verb 'proposes'. Entity 2 ('3D object categorization') is the complement of the preposition 'for', depending on 'for' in the phrase 'for 3D object categorization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "detection task",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'on', depending on 'test' with 'We'. Entity 2 ('detection task') is the first object in a compound object, depending on 'on' in the phrase 'on the detection task'. There is no direct dependency between Entity 1 and Entity 2; they are part of the same clause where 'algorithm' is tested on multiple tasks including the 'detection task'.\"",
        "sdp_path_text": "algorithm → test → on → task",
        "sentence": "We test our algorithm on the detection task.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'on', depending on 'test' with 'We'. Entity 2 ('detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the detection task'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'on the detection task'.\""
    },
    {
        "raw_sentence": "We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "viewpoint classification task",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'on', depending on 'test' with 'We'. Entity 2 ('viewpoint classification task') is the second object of the conjunction 'and', depending on 'task' in the phrase 'the detection task and the viewpoint classification task'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'algorithm' is tested on both tasks.\"",
        "sdp_path_text": "algorithm → test → on → task → task",
        "sentence": "We test our algorithm on the viewpoint classification task.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'on', depending on 'test' with 'We'. Entity 2 ('viewpoint classification task') is also the object of the preposition 'on', depending directly on 'on' in the phrase 'on the viewpoint classification task'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase governed by 'on'.\""
    },
    {
        "raw_sentence": "We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .",
        "ner_pair": [
            [
                "PASCAL VOC 2006 datasets",
                "Material"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PASCAL VOC 2006 datasets') is the object of the preposition 'from', depending on 'category'. Entity 2 ('algorithm') is the object of the preposition 'on', depending on 'test'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where the algorithm is tested on tasks using categories from the datasets.\"",
        "sdp_path_text": "datasets → from → category → using → by → test → algorithm",
        "sentence": "The algorithm is tested using the PASCAL VOC 2006 datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('PASCAL VOC 2006 datasets') is the object of the preposition 'using', depending on 'tested'. Entity 2 ('algorithm') is the subject, depending on the verb 'is tested'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'using'.\""
    },
    {
        "raw_sentence": "We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .",
        "ner_pair": [
            [
                "detection task",
                "Task"
            ],
            [
                "viewpoint classification task",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection task') is the object of the preposition 'on', depending on 'test'. Entity 2 ('viewpoint classification task') is also the object of the preposition 'and', depending on 'detection task'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'on' and 'and' respectively, indicating that the algorithm is tested on both tasks.\"",
        "sdp_path_text": "task → task",
        "sentence": "We test our algorithm on the detection task and the viewpoint classification task.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection task') is the object of the preposition 'on', depending on 'test'. Entity 2 ('viewpoint classification task') is also the object of the preposition 'on', depending on 'test'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'on' in the sentence.\""
    },
    {
        "raw_sentence": "We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .",
        "ner_pair": [
            [
                "detection task",
                "Task"
            ],
            [
                "PASCAL VOC 2006 datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection task') is the object of the preposition 'on', depending on 'test'. Entity 2 ('PASCAL VOC 2006 datasets') is the object of the preposition 'from', depending on 'category'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verb 'test' and the prepositions 'on' and 'from'.\"",
        "sdp_path_text": "task → on → test → by → using → category → from → datasets",
        "sentence": "We test the detection task using the PASCAL VOC 2006 datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection task') is the object of the preposition 'the', depending on 'test' with 'We'. Entity 2 ('PASCAL VOC 2006 datasets') is the object of the preposition 'using', depending on 'using' in the phrase 'using the PASCAL VOC 2006 datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'test'.\""
    },
    {
        "raw_sentence": "We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .",
        "ner_pair": [
            [
                "viewpoint classification task",
                "Task"
            ],
            [
                "PASCAL VOC 2006 datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('viewpoint classification task') is the object of the preposition 'on', depending on 'test' with 'We'. Entity 2 ('PASCAL VOC 2006 datasets') is part of a compound noun, depending on 'category' with 'from'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "task → task → on → test → by → using → category → from → datasets",
        "sentence": "We test the viewpoint classification task using the PASCAL VOC 2006 datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('viewpoint classification task') is the object of the verb 'test', depending on 'test' with 'We'. Entity 2 ('PASCAL VOC 2006 datasets') is the object of the preposition 'using', depending on 'using' in the phrase 'using the PASCAL VOC 2006 datasets'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We show promising results in both the detection and viewpoint classification tasks on these two challenging datasets .",
        "ner_pair": [
            [
                "datasets",
                "Generic"
            ],
            [
                "detection and viewpoint classification tasks",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('datasets') is the object of the preposition 'on', depending on 'on' in the phrase 'on these two challenging datasets'. Entity 2 ('detection and viewpoint classification tasks') is the object of the preposition 'in', depending on 'in' in the phrase 'in both the detection and viewpoint classification tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the context in which 'promising results' are shown.\"",
        "sdp_path_text": "datasets → on → tasks",
        "sentence": "Promising results are shown on datasets for detection and viewpoint classification tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('datasets') is the object of the preposition 'on', depending on 'shown' in the phrase 'shown on datasets'. Entity 2 ('detection and viewpoint classification tasks') is the object of the preposition 'for', depending on 'datasets' in the phrase 'datasets for detection and viewpoint classification tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars -LRB- LFG -RRB- to the domain of sentence condensation .",
        "ner_pair": [
            [
                "ambiguity packing and stochastic disambiguation techniques",
                "Method"
            ],
            [
                "Lexical-Functional Grammars -LRB- LFG -RRB-",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ambiguity packing and stochastic disambiguation techniques') is the object of the preposition 'of', depending on 'application'. Entity 2 ('Lexical-Functional Grammars -LRB- LFG -RRB-') is the object of the preposition 'for', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger noun phrase that serves as the object of the verb 'present'.\"",
        "sdp_path_text": "packing → of → application → for → -RRB-",
        "sentence": "Ambiguity packing and stochastic disambiguation techniques are applied for Lexical-Functional Grammars (LFG).",
        "sentence_llm_dp_info": "\"Entity 1 ('ambiguity packing and stochastic disambiguation techniques') is the subject, depending on the verb 'are applied'. Entity 2 ('Lexical-Functional Grammars (LFG)') is the object of the preposition 'for', depending on 'for' in the phrase 'for Lexical-Functional Grammars (LFG)'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are applied' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars -LRB- LFG -RRB- to the domain of sentence condensation .",
        "ner_pair": [
            [
                "ambiguity packing and stochastic disambiguation techniques",
                "Method"
            ],
            [
                "sentence condensation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ambiguity packing and stochastic disambiguation techniques') is the object of the preposition 'of', depending on 'application'. Entity 2 ('sentence condensation') is the object of the preposition 'to', depending on 'to' in the phrase 'to the domain of sentence condensation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the application and its target domain.\"",
        "sdp_path_text": "packing → of → application → present → to → domain → of → condensation",
        "sentence": "We present an application of ambiguity packing and stochastic disambiguation techniques to the domain of sentence condensation.",
        "sentence_llm_dp_info": "\"Entity 1 ('ambiguity packing and stochastic disambiguation techniques') is the object of the preposition 'of', depending on 'application'. Entity 2 ('sentence condensation') is the object of the preposition 'to', depending on 'to' in the phrase 'to the domain of sentence condensation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing the application's domain and methods.\""
    },
    {
        "raw_sentence": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars -LRB- LFG -RRB- to the domain of sentence condensation .",
        "ner_pair": [
            [
                "Lexical-Functional Grammars -LRB- LFG -RRB-",
                "Method"
            ],
            [
                "sentence condensation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Lexical-Functional Grammars -LRB- LFG -RRB-') is the object of the preposition 'for', depending on 'for' in the phrase 'for Lexical-Functional Grammars -LRB- LFG -RRB-'. Entity 2 ('sentence condensation') is the object of the preposition 'to', depending on 'to' in the phrase 'to the domain of sentence condensation'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger prepositional phrases that modify the main clause.\"",
        "sdp_path_text": "-RRB- → for → application → present → to → domain → of → condensation",
        "sentence": "We present an application of Lexical-Functional Grammars (LFG) for sentence condensation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Lexical-Functional Grammars (LFG)') is the object of the preposition 'of', depending on 'application'. Entity 2 ('sentence condensation') is the object of the preposition 'for', depending on 'for' in the phrase 'for sentence condensation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying 'application'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object of the preposition 'for', depending on 'incorporates' which is part of the verb phrase 'incorporates...for LFG'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the prepositional phrase 'for LFG'.\"",
        "sdp_path_text": "parser → incorporates → system",
        "sentence": "The system incorporates a linguistic parser/generator.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object, depending on the verb 'incorporates'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, where 'system' is the subject that performs the action of incorporating 'linguistic parser/generator'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "LFG",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('LFG') is the object of the preposition 'for', depending on 'parser/generator'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun phrase 'a linguistic parser/generator for LFG' where 'LFG' specifies the type of parser/generator that the system incorporates.\"",
        "sdp_path_text": "system → incorporates → parser → generator → for → LFG",
        "sentence": "Our system incorporates a linguistic parser/generator for LFG.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('LFG') is the object of the preposition 'for', depending on 'for' in the phrase 'for LFG'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporates' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "transfer component",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the object of the preposition 'for', depending on 'incorporates' with 'system'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' where 'system' is the subject and 'transfer component' is part of the list of objects being incorporated.\"",
        "sdp_path_text": "component → generator → parser → incorporates → system",
        "sentence": "The system incorporates a transfer component.",
        "sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the object, depending on the verb 'incorporates'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, where 'system' incorporates 'transfer component'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "parse reduction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('parse reduction') is part of a complex noun phrase, acting as the object of the preposition 'for', which modifies 'transfer component'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'system' incorporates components that operate on 'parse reduction'.\"",
        "sdp_path_text": "system → incorporates → parser → generator → component → for → reduction",
        "sentence": "Our system incorporates a component for parse reduction.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('parse reduction') is the object, depending on the preposition 'for', which is part of the prepositional phrase 'for parse reduction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('packed parse forests') is the object of the preposition 'on', depending on 'operating' in the phrase 'operating on packed parse forests'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporates' and the prepositional phrase describing one of the components of the system.\"",
        "sdp_path_text": "system → incorporates → parser → generator → component → operating → on → forests",
        "sentence": "Our system incorporates a component operating on packed parse forests.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('packed parse forests') is the object of the preposition 'on', depending on 'operating' in the phrase 'operating on packed parse forests'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the prepositional phrase 'operating on'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "maximum-entropy model",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('maximum-entropy model') is the object, depending on the conjunction 'and', which links it to other components of the larger structure. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'system' is the entity that incorporates multiple components, including the 'maximum-entropy model'.\"",
        "sdp_path_text": "model → component → generator → parser → incorporates → system",
        "sentence": "The system incorporates a maximum-entropy model.",
        "sentence_llm_dp_info": "\"Entity 1 ('maximum-entropy model') is the object, depending on the verb 'incorporates'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is the subject that performs the action of incorporating Entity 1.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('stochastic output selection') is the object, depending on the preposition 'for' within the phrase 'for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of components that the system incorporates.\"",
        "sdp_path_text": "system → incorporates → parser → generator → component → model → for → selection",
        "sentence": "Our system incorporates a model for stochastic output selection.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporates' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "LFG",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object of the preposition 'for', depending on 'incorporates' with 'Our system'. Entity 2 ('LFG') is the object of the preposition 'for', depending directly on 'linguistic parser/generator'. There is a direct dependency between Entity 1 and Entity 2, where 'LFG' specifies the type or domain of the 'linguistic parser/generator'.\"",
        "sdp_path_text": "parser → generator → for → LFG",
        "sentence": "The system incorporates a linguistic parser/generator for LFG.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object, depending on 'incorporates' with 'The system'. Entity 2 ('LFG') is the complement, depending on the preposition 'for' with 'linguistic parser/generator'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "transfer component",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is part of the list item, depending on 'incorporates' with 'system'. Entity 2 ('transfer component') is another part of the list item, also depending on 'incorporates' with 'system'. There is no direct dependency between Entity 1 and Entity 2; both are elements of what the system incorporates.\"",
        "sdp_path_text": "parser → generator → component",
        "sentence": "The system incorporates a linguistic parser/generator and a transfer component.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object of the preposition 'a', depending on 'incorporates' in the phrase 'incorporates a linguistic parser/generator'. Entity 2 ('transfer component') is also an object of the preposition 'a', depending on 'incorporates' in the phrase 'incorporates a transfer component'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of items being incorporated by the system.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "parse reduction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object of the preposition 'for', depending on 'incorporates' with 'Our system'. Entity 2 ('parse reduction') is the object of the preposition 'for', depending on 'component' with 'transfer component'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure described by the sentence, which outlines different components incorporated into the system.\"",
        "sdp_path_text": "parser → generator → component → for → reduction",
        "sentence": "The linguistic parser/generator includes a component for parse reduction.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the subject, depending on the verb 'includes'. Entity 2 ('parse reduction') is the object of the preposition 'for', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'component' which is part of the structure that Entity 1 includes.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the object of the preposition 'for', depending on 'incorporates' in the phrase 'incorporates a linguistic parser/generator for LFG'. Entity 2 ('packed parse forests') is the object of the preposition 'on', depending on 'operating' in the phrase 'operating on packed parse forests'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "parser → generator → component → operating → on → forests",
        "sentence": "The linguistic parser/generator operates on packed parse forests.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the subject, depending on the verb 'operates'. Entity 2 ('packed parse forests') is the object, depending on 'on' in the phrase 'on packed parse forests'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "maximum-entropy model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is part of a list, depending on 'incorporates' with 'system'. Entity 2 ('maximum-entropy model') is also part of the same list, depending on 'incorporates' with 'system'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list that the system incorporates.\"",
        "sdp_path_text": "parser → generator → component → model",
        "sentence": "The system includes a linguistic parser/generator and a maximum-entropy model.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is part of a compound noun, depending on 'includes' with 'The system'. Entity 2 ('maximum-entropy model') is also part of a compound noun, depending on 'and' which connects it to 'linguistic parser/generator'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "linguistic parser/generator",
                "Method"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is part of a compound noun, depending on 'incorporates' with 'Our system'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2; both are components of the system described in the sentence, linked through the conjunction 'and'.\"",
        "sdp_path_text": "parser → generator → component → model → for → selection",
        "sentence": "The linguistic parser/generator includes a model for stochastic output selection.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic parser/generator') is the subject, depending on the verb 'includes'. Entity 2 ('stochastic output selection') is the object, depending on 'model' in the phrase 'a model for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "LFG",
                "Method"
            ],
            [
                "transfer component",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'parser/generator'. Entity 2 ('transfer component') is the subject, depending on 'incorporates' with 'system'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "LFG → for → generator → component",
        "sentence": "The system incorporates a linguistic generator for LFG and a transfer component.",
        "sentence_llm_dp_info": "\"Entity 1 ('LFG') is part of the prepositional phrase 'for LFG', which modifies 'linguistic generator'. Entity 2 ('transfer component') is the second object of the verb 'incorporates', depending directly on 'incorporates'. There is no direct dependency between Entity 1 and Entity 2; both are components that the system incorporates, but they are mentioned in separate clauses.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "LFG",
                "Method"
            ],
            [
                "parse reduction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'parser/generator'. Entity 2 ('parse reduction') is the object of the verb 'operating', depending on 'transfer component'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "LFG → for → generator → component → for → reduction",
        "sentence": "Our system includes a generator for LFG and a component for parse reduction.",
        "sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'generator'. Entity 2 ('parse reduction') is the object of the preposition 'for', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of prepositions that modify different parts of the sentence (generator and component).\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "LFG",
                "Method"
            ],
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'parser/generator'. Entity 2 ('packed parse forests') is the object of the preposition 'on', depending on 'operating'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "LFG → for → generator → component → operating → on → forests",
        "sentence": "The system includes a generator for LFG that operates on packed parse forests.",
        "sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'generator'. Entity 2 ('packed parse forests') is the object of the preposition 'on', depending on 'operates'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the components and operations of the system.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "LFG",
                "Method"
            ],
            [
                "maximum-entropy model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'parser/generator'. Entity 2 ('maximum-entropy model') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of components incorporated by the system, connected through the conjunction 'and'.\"",
        "sdp_path_text": "LFG → for → generator → component → model",
        "sentence": "The system incorporates a generator for LFG and a maximum-entropy model.",
        "sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'generator'. Entity 2 ('maximum-entropy model') is the second object of the conjunction 'and', depending on 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of items that the system incorporates.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "LFG",
                "Method"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'parser/generator'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "LFG → for → generator → component → model → for → selection",
        "sentence": "Our system uses a linguistic generator for LFG and a maximum-entropy model for stochastic output selection.",
        "sentence_llm_dp_info": "\"Entity 1 ('LFG') is the object of the preposition 'for', depending on 'generator'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "transfer component",
                "Method"
            ],
            [
                "parse reduction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the object of the preposition 'for', depending on 'incorporates' with 'Our system'. Entity 2 ('parse reduction') is the object of the preposition 'for', depending on 'operating' with 'transfer component'. There is a direct dependency between Entity 1 and Entity 2, as 'parse reduction' specifies the operation performed by the 'transfer component'.\"",
        "sdp_path_text": "component → for → reduction",
        "sentence": "The transfer component operates for parse reduction.",
        "sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the subject, depending on the verb 'operates'. Entity 2 ('parse reduction') is the object of the preposition 'for', depending on 'for' in the phrase 'for parse reduction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "transfer component",
                "Method"
            ],
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the subject of the clause, depending on the verb 'operating' which indicates its function. Entity 2 ('packed parse forests') is the object of the preposition 'on', indicating what the 'transfer component' operates on. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' which shows that Entity 2 is the target of the operation performed by Entity 1.\"",
        "sdp_path_text": "component → operating → on → forests",
        "sentence": "The transfer component operates on packed parse forests.",
        "sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the subject, depending on the verb 'operates'. Entity 2 ('packed parse forests') is the object, depending on 'on' in the phrase 'on packed parse forests'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "transfer component",
                "Method"
            ],
            [
                "maximum-entropy model",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the subject of the verb 'operating', depending on 'for' in the phrase 'for parse reduction'. Entity 2 ('maximum-entropy model') is the subject of the verb 'for', depending on 'for' in the phrase 'for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of components incorporated by the system, connected through the conjunction 'and'.\"",
        "sdp_path_text": "component → model",
        "sentence": "The system includes a transfer component and a maximum-entropy model.",
        "sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the object of the conjunction 'and', depending on 'includes' with 'The system'. Entity 2 ('maximum-entropy model') is also the object of the conjunction 'and', depending on 'includes' with 'The system'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list coordinated by 'and'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "transfer component",
                "Method"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the subject of the clause, depending on 'incorporates' with 'system'. It also has a modifier 'for parse reduction operating on packed parse forests'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, both being incorporated into the system described.\"",
        "sdp_path_text": "component → model → for → selection",
        "sentence": "The transfer component uses a maximum-entropy model for stochastic output selection.",
        "sentence_llm_dp_info": "\"Entity 1 ('transfer component') is the subject, depending on the verb 'uses'. Entity 2 ('stochastic output selection') is the object, depending on 'for' in the phrase 'for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            [
                "parse reduction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('packed parse forests') is the object of the preposition 'on', depending on 'operating'. Entity 2 ('parse reduction') is the object of the preposition 'for', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'operating on packed parse forests' which modifies 'parse reduction'.\"",
        "sdp_path_text": "forests → on → operating → component → for → reduction",
        "sentence": "A component operates on packed parse forests for parse reduction.",
        "sentence_llm_dp_info": "\"Entity 1 ('packed parse forests') is the object of the preposition 'on', depending on 'operates' with 'A component'. Entity 2 ('parse reduction') is the object, depending on 'for' in the phrase 'for parse reduction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger action described by the verb 'operates'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "parse reduction",
                "Task"
            ],
            [
                "maximum-entropy model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parse reduction') is the object of the preposition 'for', depending on 'component'. Entity 2 ('maximum-entropy model') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of components incorporated into the system.\"",
        "sdp_path_text": "reduction → for → component → model",
        "sentence": "The system incorporates a component for parse reduction and a maximum-entropy model.",
        "sentence_llm_dp_info": "\"Entity 1 ('parse reduction') is the object of the preposition 'for', depending on 'component'. Entity 2 ('maximum-entropy model') is the object of the preposition 'and', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of components incorporated by the system.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "parse reduction",
                "Task"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parse reduction') is the object of the preposition 'for', depending on 'component'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure described in the sentence, being objects of different prepositional phrases.\"",
        "sdp_path_text": "reduction → for → component → model → for → selection",
        "sentence": "The system includes a component for parse reduction and a model for stochastic output selection.",
        "sentence_llm_dp_info": "\"Entity 1 ('parse reduction') is the object of the preposition 'for', depending on 'component'. Entity 2 ('stochastic output selection') is also the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but both are related to their respective nouns ('component' and 'model') through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            [
                "maximum-entropy model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('packed parse forests') is the object of the preposition 'on', depending on 'operating' in the phrase 'operating on packed parse forests'. Entity 2 ('maximum-entropy model') is the object of the preposition 'for', depending on 'for' in the phrase 'for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "forests → on → operating → component → model",
        "sentence": "The system includes a component operating on packed parse forests and a maximum-entropy model.",
        "sentence_llm_dp_info": "\"Entity 1 ('packed parse forests') is the object of the preposition 'on', depending on 'operating' in the phrase 'operating on packed parse forests'. Entity 2 ('maximum-entropy model') is the object of the preposition 'and', depending on 'includes' in the phrase 'includes ... and a maximum-entropy model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of components included in the system.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "packed parse forests",
                "OtherScientificTerm"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('packed parse forests') is the object of the preposition 'on', depending on 'operating' in the phrase 'operating on packed parse forests'. Entity 2 ('stochastic output selection') is the object of the preposition 'for', depending on 'model' in the phrase 'model for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "forests → on → operating → component → model → for → selection",
        "sentence": "A component operates on packed parse forests, and a model selects stochastic output.",
        "sentence_llm_dp_info": "\"Entity 1 ('packed parse forests') is the object, depending on the verb 'operates' with 'component'. Entity 2 ('stochastic output selection') is the object, depending on the verb 'selects' with 'model'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .",
        "ner_pair": [
            [
                "maximum-entropy model",
                "Method"
            ],
            [
                "stochastic output selection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('maximum-entropy model') is the subject, depending on 'incorporates' with 'Our system'. Entity 2 ('stochastic output selection') is the object, depending on 'for' in the phrase 'for stochastic output selection'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a list of components incorporated by the system.\"",
        "sdp_path_text": "model → for → selection",
        "sentence": "The maximum-entropy model is used for stochastic output selection.",
        "sentence_llm_dp_info": "\"Entity 1 ('maximum-entropy model') is the subject, depending on the verb 'is used'. Entity 2 ('stochastic output selection') is the object, depending on the preposition 'for', which itself depends on 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is used' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Furthermore , we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems .",
        "ner_pair": [
            [
                "parser evaluation methods",
                "Method"
            ],
            [
                "summarization quality",
                "Metric"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parser evaluation methods') is the object of the preposition 'of', depending on 'use'. Entity 2 ('summarization quality') is the object of the preposition 'of', depending on 'evaluating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being proposed for automatic evaluation.\"",
        "sdp_path_text": "methods → of → use → for → evaluating → quality",
        "sentence": "Parser evaluation methods are used for evaluating summarization quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('parser evaluation methods') is the subject, depending on the verb 'are used'. Entity 2 ('summarization quality') is the object of the preposition 'for', depending on 'for' in the phrase 'for evaluating summarization quality'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for evaluating'.\""
    },
    {
        "raw_sentence": "Furthermore , we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems .",
        "ner_pair": [
            [
                "parser evaluation methods",
                "Method"
            ],
            [
                "sentence condensation systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parser evaluation methods') is the object of the preposition 'of', depending on 'use'. Entity 2 ('sentence condensation systems') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the evaluation methods and the systems being evaluated.\"",
        "sdp_path_text": "methods → of → use → for → evaluating → quality → of → systems",
        "sentence": "We propose the use of parser evaluation methods for evaluating the quality of sentence condensation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('parser evaluation methods') is the object of the preposition 'of', depending on 'use'. Entity 2 ('sentence condensation systems') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where 'methods' are used for evaluating the 'quality' of 'systems'.\""
    },
    {
        "raw_sentence": "Furthermore , we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems .",
        "ner_pair": [
            [
                "summarization quality",
                "Metric"
            ],
            [
                "sentence condensation systems",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the object of the preposition 'of', depending on 'evaluating'. Entity 2 ('sentence condensation systems') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger phrase 'the summarization quality of sentence condensation systems'.\"",
        "sdp_path_text": "quality → of → systems",
        "sentence": "We propose using standard parser evaluation methods to evaluate the summarization quality of sentence condensation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the object of the preposition 'of', depending on 'evaluate'. Entity 2 ('sentence condensation systems') is the object of the preposition 'of', also depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and are related through the verb 'evaluate'.\""
    },
    {
        "raw_sentence": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings .",
        "ner_pair": [
            [
                "summarization quality",
                "Metric"
            ],
            [
                "automatic parse-based evaluation",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the object of the preposition 'of', depending on 'evaluation'. Entity 2 ('automatic parse-based evaluation') is part of a noun phrase, depending on 'correlation' with the preposition 'between'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the correlation established in the sentence.\"",
        "sdp_path_text": "quality → of → evaluation → shows → correlation → between → evaluation",
        "sentence": "Summarization quality shows a correlation with automatic parse-based evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the verb 'shows'. Entity 2 ('automatic parse-based evaluation') is the object of the preposition 'with', depending on 'correlation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'shows' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings .",
        "ner_pair": [
            [
                "summarization quality",
                "Metric"
            ],
            [
                "manual evaluation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the object of the preposition 'of', depending on 'evaluation'. Entity 2 ('manual evaluation') is part of the prepositional phrase 'of a manual evaluation', acting as an object of the preposition 'of', which modifies 'correlation'. There is no direct dependency between Entity 1 and Entity 2; both are related through the noun 'correlation' and the preposition 'of'.\"",
        "sdp_path_text": "quality → of → evaluation → shows → correlation → between → evaluation → evaluation",
        "sentence": "Summarization quality shows a correlation with manual evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the verb 'shows'. Entity 2 ('manual evaluation') is the object of the preposition 'with', depending on 'correlation' in the phrase 'correlation with manual evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'shows' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings .",
        "ner_pair": [
            [
                "automatic parse-based evaluation",
                "Method"
            ],
            [
                "manual evaluation",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatic parse-based evaluation') is the subject, depending on the verb 'shows' as part of the clause describing what is shown to have a close correlation. Entity 2 ('manual evaluation') is the object of the preposition 'and', forming a compound object with 'automatic parse-based evaluation' in the context of the correlation being described. There is no direct dependency between Entity 1 and Entity 2; they are both part of the compound object showing a correlation.\"",
        "sdp_path_text": "evaluation → evaluation",
        "sentence": "An experimental evaluation shows a close correlation between automatic parse-based evaluation and manual evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatic parse-based evaluation') is part of the prepositional phrase 'between automatic parse-based evaluation and manual evaluation', depending on 'between'. Entity 2 ('manual evaluation') is also part of the same prepositional phrase, depending on 'and'. There is no direct dependency between Entity 1 and Entity 2; both are components of the prepositional phrase that modifies 'correlation'.\""
    },
    {
        "raw_sentence": "Overall summarization quality of the proposed system is state-of-the-art , with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator .",
        "ner_pair": [
            [
                "summarization quality",
                "Metric"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the verb 'is' which indicates its state or condition. Entity 2 ('system') is the object of the preposition 'of', depending on 'quality' in the phrase 'quality of the proposed system'. There is a direct dependency between Entity 1 and Entity 2, as 'system' modifies 'quality' to specify whose quality is being discussed.\"",
        "sdp_path_text": "quality → of → system",
        "sentence": "Summarization quality of the system is state-of-the-art.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the verb 'is'. Entity 2 ('system') is the object of the preposition 'of', depending on 'quality' in the phrase 'quality of the system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "Overall summarization quality of the proposed system is state-of-the-art , with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator .",
        "ner_pair": [
            [
                "summarization quality",
                "Metric"
            ],
            [
                "grammaticality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the copula 'is' with the complement 'state-of-the-art'. Entity 2 ('grammaticality') is the subject of the clause 'grammaticality of the system output', depending on the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.\"",
        "sdp_path_text": "quality → is → with → grammaticality",
        "sentence": "Summarization quality is guaranteed to have grammaticality.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the verb 'is' with 'guaranteed'. Entity 2 ('grammaticality') is the complement, depending on 'have' which is part of the verb phrase 'is guaranteed to have'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'is guaranteed to have'.\""
    },
    {
        "raw_sentence": "Overall summarization quality of the proposed system is state-of-the-art , with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator .",
        "ner_pair": [
            [
                "summarization quality",
                "Metric"
            ],
            [
                "constraint-based parser/generator",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the copula 'is' with 'state-of-the-art'. Entity 2 ('constraint-based parser/generator') is the object, depending on 'use' with 'due to the use of a constraint-based parser/generator'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the clause that explains the reason for the quality being state-of-the-art.\"",
        "sdp_path_text": "quality → is → with → grammaticality → due → use → of → parser",
        "sentence": "Summarization quality is state-of-the-art with grammaticality due to the use of a constraint-based parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization quality') is the subject, depending on the copula 'is' with 'state-of-the-art'. Entity 2 ('constraint-based parser') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by 'due to'.\""
    },
    {
        "raw_sentence": "Overall summarization quality of the proposed system is state-of-the-art , with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator .",
        "ner_pair": [
            [
                "grammaticality",
                "Metric"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grammaticality') is the object, depending on 'guaranteed' with 'of the system output'. Entity 2 ('system') is the object of the preposition 'of', depending on 'quality' in the phrase 'quality of the proposed system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence, where 'system' is part of the clause that modifies 'output' which is related to 'grammaticality'.\"",
        "sdp_path_text": "grammaticality → with → is → quality → of → system",
        "sentence": "The grammaticality of the system's output is guaranteed.",
        "sentence_llm_dp_info": "\"Entity 1 ('grammaticality') is the subject, depending on the verb 'is'. Entity 2 ('system') is part of the possessive noun phrase 'the system's', modifying 'output'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the possessive structure and the copula 'is'.\""
    },
    {
        "raw_sentence": "Overall summarization quality of the proposed system is state-of-the-art , with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator .",
        "ner_pair": [
            [
                "constraint-based parser/generator",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('constraint-based parser/generator') is the object, depending on 'use' with 'the use of a constraint-based parser/generator'. Entity 2 ('system') is the subject, depending on 'quality' with 'summarization quality of the proposed system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause that describes the reason for the system's performance, specifically the use of the constraint-based parser/generator.\"",
        "sdp_path_text": "parser → of → use → due → grammaticality → with → is → quality → of → system",
        "sentence": "The system's quality is state-of-the-art, with grammaticality due to the use of a constraint-based parser/generator.",
        "sentence_llm_dp_info": "\"Entity 1 ('constraint-based parser/generator') is the object of the preposition 'of', depending on 'use'. Entity 2 ('system') is the subject, depending on the copula 'is' with 'quality'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'due to the use of a constraint-based parser/generator'.\""
    },
    {
        "raw_sentence": "Overall summarization quality of the proposed system is state-of-the-art , with guaranteed grammaticality of the system output due to the use of a constraint-based parser/generator .",
        "ner_pair": [
            [
                "grammaticality",
                "Metric"
            ],
            [
                "constraint-based parser/generator",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grammaticality') is the subject of the clause 'grammaticality is guaranteed', depending on the verb 'guaranteed'. Entity 2 ('constraint-based parser/generator') is the object of the preposition 'of', depending on the noun 'use' in the phrase 'use of a constraint-based parser/generator'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the causal relationship expressed by the phrase 'due to the use of'.\"",
        "sdp_path_text": "grammaticality → due → use → of → parser",
        "sentence": "Grammaticality of the system output is due to the use of a constraint-based parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('grammaticality') is the subject, depending on the verb 'is'. Entity 2 ('constraint-based parser') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship expressed by the phrase 'is due to'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "robust principal component analysis -LRB- robust PCA -RRB- problem",
                "Method"
            ],
            [
                "machine learning applications",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis -LRB- robust PCA -RRB- problem') is the subject, depending on the verb 'has been considered'. Entity 2 ('machine learning applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in many machine learning applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "problem → considered → in → applications",
        "sentence": "The robust principal component analysis problem has been considered in machine learning applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis -LRB- robust PCA -RRB- problem') is the subject, depending on the verb 'has been considered'. Entity 2 ('machine learning applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in machine learning applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "robust principal component analysis -LRB- robust PCA -RRB- problem",
                "Method"
            ],
            [
                "data matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis -LRB- robust PCA -RRB- problem') is the subject, depending on the verb 'has been considered'. Entity 2 ('data matrix') is the object, depending on 'decompose' within the clause 'the goal is to decompose the data matrix'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related as Entity 2 is the target of the action (decomposition) that is relevant to the consideration of Entity 1.\"",
        "sdp_path_text": "problem → considered → in → applications → is → decompose → matrix",
        "sentence": "The robust PCA problem is considered to decompose the data matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis (robust PCA) problem') is the subject, depending on the verb 'is considered'. Entity 2 ('data matrix') is the object of the verb 'decompose', which is part of the infinitive phrase 'to decompose the data matrix'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to decompose the data matrix'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "robust principal component analysis -LRB- robust PCA -RRB- problem",
                "Method"
            ],
            [
                "low rank part",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis -LRB- robust PCA -RRB- problem') is the subject, depending on the verb 'has been considered'. Entity 2 ('low rank part') is part of the object of the preposition 'to', depending on 'decompose' in the clause 'to decompose the data matrix to a low rank part'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'considered' and the subsequent clause describing the goal of the decomposition.\"",
        "sdp_path_text": "problem → considered → in → applications → is → decompose → to → part",
        "sentence": "The robust PCA problem is considered to decompose data into a low rank part.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis -LRB- robust PCA -RRB- problem') is the subject, depending on 'is considered'. Entity 2 ('low rank part') is the object of the preposition 'into', depending on 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'decompose' and the preposition 'into'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "robust principal component analysis -LRB- robust PCA -RRB- problem",
                "Method"
            ],
            [
                "sparse residual",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis -LRB- robust PCA -RRB- problem') is the subject, depending on the verb 'has been considered'. Entity 2 ('sparse residual') is part of the object complement, depending on 'plus' in the phrase 'a low rank part plus a sparse residual'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of the sentence where the 'problem' involves decomposing a matrix into parts, one of which is the 'sparse residual'.\"",
        "sdp_path_text": "problem → considered → in → applications → is → decompose → to → part → residual",
        "sentence": "The robust PCA problem is considered to decompose the data matrix into a low rank part and a sparse residual.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust principal component analysis (robust PCA) problem') is the subject, depending on the verb 'is considered'. Entity 2 ('sparse residual') is the object of the preposition 'into', which is part of the phrase 'into a low rank part and a sparse residual', depending on 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'decompose' and the preposition 'into'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "machine learning applications",
                "Task"
            ],
            [
                "data matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning applications') is the object of the preposition 'in', depending on 'considered'. Entity 2 ('data matrix') is the subject of the clause, depending on 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence, where 'machine learning applications' consider the problem involving the 'data matrix'.\"",
        "sdp_path_text": "applications → is → decompose → matrix",
        "sentence": "Machine learning applications aim to decompose the data matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning applications') is the subject, depending on the verb 'aim'. Entity 2 ('data matrix') is the object of the verb 'decompose', which is part of the infinitive phrase 'to decompose the data matrix'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aim' and the infinitive phrase 'to decompose'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "machine learning applications",
                "Task"
            ],
            [
                "low rank part",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning applications') is the object of the preposition 'in', depending on 'considered'. Entity 2 ('low rank part') is the object complement, depending on 'decompose' in the clause 'the goal is to decompose the data matrix to a low rank part'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the process described in the sentence.\"",
        "sdp_path_text": "applications → is → decompose → to → part",
        "sentence": "Machine learning applications aim to decompose data into a low rank part.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning applications') is the subject, depending on the verb 'aim'. Entity 2 ('low rank part') is the object of the preposition 'into', depending on 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aim' and the phrase 'to decompose data into a low rank part'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "machine learning applications",
                "Task"
            ],
            [
                "sparse residual",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning applications') is the object of the preposition 'in', depending on 'considered'. Entity 2 ('sparse residual') is part of a compound noun, depending on 'plus' in the phrase 'a low rank part plus a sparse residual'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "applications → is → decompose → to → part → residual",
        "sentence": "Machine learning applications aim to decompose data into a low rank part and a sparse residual.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning applications') is the subject, depending on the verb 'aim'. Entity 2 ('sparse residual') is part of the object complement, depending on 'and' in the phrase 'a low rank part and a sparse residual'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure where 'applications' aim to decompose 'data' into components including 'a sparse residual'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "low rank part",
                "OtherScientificTerm"
            ],
            [
                "data matrix",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank part') is the object of the preposition 'to', depending on 'decompose' in the clause 'the goal is to decompose the data matrix to a low rank part'. Entity 2 ('data matrix') is the object, depending on 'decompose' with 'the goal is to decompose the data matrix'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'decompose'.\"",
        "sdp_path_text": "part → to → decompose → matrix",
        "sentence": "The goal is to decompose the data matrix to a low rank part.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank part') is the object, depending on the preposition 'to' in the phrase 'to a low rank part'. Entity 2 ('data matrix') is the object of the verb 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'decompose' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "sparse residual",
                "OtherScientificTerm"
            ],
            [
                "data matrix",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sparse residual') is the object, depending on the verb 'plus' within the clause 'to a low rank part plus a sparse residual'. Entity 2 ('data matrix') is the object, depending on the verb 'decompose' in the clause 'the goal is to decompose the data matrix'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where 'sparse residual' is part of the outcome of the action performed on 'data matrix'.\"",
        "sdp_path_text": "residual → part → to → decompose → matrix",
        "sentence": "The goal is to decompose the data matrix into a low rank part and a sparse residual.",
        "sentence_llm_dp_info": "\"Entity 1 ('sparse residual') is the second object of the verb 'decompose', depending on 'into'. Entity 2 ('data matrix') is the object of the preposition 'the', depending on 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'decompose'.\""
    },
    {
        "raw_sentence": "The robust principal component analysis -LRB- robust PCA -RRB- problem has been considered in many machine learning applications , where the goal is to decompose the data matrix to a low rank part plus a sparse residual .",
        "ner_pair": [
            [
                "low rank part",
                "OtherScientificTerm"
            ],
            [
                "sparse residual",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank part') is the object complement, depending on 'decompose' with the verb 'is'. Entity 2 ('sparse residual') is also an object complement, depending on 'plus' which connects it to 'low rank part'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'plus' within the same clause.\"",
        "sdp_path_text": "part → residual",
        "sentence": "The goal is to decompose the data matrix into a low rank part and a sparse residual.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank part') is the object of the preposition 'into', depending on 'decompose'. Entity 2 ('sparse residual') is also the object of the preposition 'into', depending on 'decompose'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'into'.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "low rank plus sparse structure",
                "OtherScientificTerm"
            ],
            [
                "approaches",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'considering', depending on 'considering' in the phrase 'considering the low rank plus sparse structure'. Entity 2 ('approaches') is the subject, depending on 'developed' in the phrase 'approaches are developed'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'considering' which indicates that the 'structure' is considered in the development of the 'approaches'.\"",
        "sdp_path_text": "rank → considering → by → developed → approaches",
        "sentence": "Approaches are developed by considering the low rank plus sparse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'considering', depending on 'considering' in the phrase 'by considering'. Entity 2 ('approaches') is the subject, depending on the verb 'developed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'by considering the low rank plus sparse structure'.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "side information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on 'developed' as the verb. Entity 2 ('side information') is the object, depending on 'given' as part of the passive construction 'may also be given'. There is no direct dependency between Entity 1 and Entity 2; they are both part of different clauses within the same complex sentence.\"",
        "sdp_path_text": "approaches → developed → given → information",
        "sentence": "Current approaches are developed considering side information.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'developed'. Entity 2 ('side information') is the object of the preposition 'considering', depending on 'considering' in the phrase 'considering side information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'considering'.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "information",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on 'developed' with 'are'. Entity 2 ('information') is the object, depending on 'given' with 'may also be'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context discussing methods and data in applications.\"",
        "sdp_path_text": "approaches → developed → given → information",
        "sentence": "Current approaches are developed with given information.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'developed'. Entity 2 ('information') is the object of the preposition 'with', depending on 'with' in the phrase 'with given information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'are developed'. Entity 2 ('robust PCA') is the object of the clause, depending on 'help' in the phrase 'could such information help robust PCA'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence, particularly the discussion around the development of approaches and their potential impact on robust PCA.\"",
        "sdp_path_text": "approaches → developed → given → is → help → PCA",
        "sentence": "Current approaches, developed with given information, help robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'help'. Entity 2 ('robust PCA') is the object, depending on the verb 'help'. There is a direct dependency between Entity 1 and Entity 2, as 'approaches' directly helps 'robust PCA'.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "low rank plus sparse structure",
                "OtherScientificTerm"
            ],
            [
                "side information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'considering', depending on 'considering' in the phrase 'only considering the low rank plus sparse structure'. Entity 2 ('side information') is the subject complement, depending on 'may be given' with 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context describing different types of information that can be considered in the application of robust PCA.\"",
        "sdp_path_text": "rank → considering → by → developed → given → information",
        "sentence": "While current approaches consider the low rank plus sparse structure, side information may also be given.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the verb 'consider', depending on 'approaches'. Entity 2 ('side information') is the subject of the modal verb 'may', depending on 'be given'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context described in the sentence.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "low rank plus sparse structure",
                "OtherScientificTerm"
            ],
            [
                "information",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'considering', depending on 'considering' in the phrase 'only considering the low rank plus sparse structure'. Entity 2 ('information') is the subject complement, depending on 'be given' in the clause 'side information of row and/or column entities may also be given'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the same sentence.\"",
        "sdp_path_text": "rank → considering → by → developed → given → information",
        "sentence": "Current approaches consider the low rank plus sparse structure, and side information may also be given.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'the', depending on 'consider' with 'approaches'. Entity 2 ('information') is the subject, depending on 'may' with 'be given'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "low rank plus sparse structure",
                "OtherScientificTerm"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'considering', depending on 'considering' in the phrase 'considering the low rank plus sparse structure'. Entity 2 ('robust PCA') is the object of the preposition 'help', depending on 'help' in the phrase 'help robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the broader context of the sentence which discusses the consideration of different structures and the potential impact on a specific technique.\"",
        "sdp_path_text": "rank → considering → by → developed → given → is → help → PCA",
        "sentence": "Considering the low rank plus sparse structure helps robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank plus sparse structure') is the object of the preposition 'the', depending on 'Considering'. Entity 2 ('robust PCA') is the object, depending on 'helps'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps', which indicates that considering Entity 1 helps Entity 2.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject complement, depending on 'given' with 'may also be'. Entity 2 ('robust PCA') is the object, depending on 'help' with 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause that discusses the potential impact of side information on robust PCA.\"",
        "sdp_path_text": "information → given → is → help → PCA",
        "sentence": "Side information may help robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'may help'. Entity 2 ('robust PCA') is the object, depending on the verb 'may help'. There is a direct dependency between Entity 1 and Entity 2, as 'side information' is the subject that may help 'robust PCA'.\""
    },
    {
        "raw_sentence": "While current approaches are developed by only considering the low rank plus sparse structure , in many applications , side information of row and/or column entities may also be given , and it is still unclear to what extent could such information help robust PCA .",
        "ner_pair": [
            [
                "information",
                "Generic"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('information') is the subject, depending on 'given' as the verb. Entity 2 ('robust PCA') is the object of the clause, depending on 'help' as the verb. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the clause that discusses the potential impact of Entity 1 on Entity 2.\"",
        "sdp_path_text": "information → given → is → help → PCA",
        "sentence": "Information given can help robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('information') is the subject, depending on the verb 'given'. Entity 2 ('robust PCA') is the object of the verb 'help', depending on 'help' in the phrase 'help robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'help'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object of the preposition 'with', depending on 'problem'. Entity 2 ('robust PCA') is part of the noun phrase 'the problem of robust PCA', serving as the complement of the preposition 'of', which depends on 'problem'. There is no direct dependency between Entity 1 and Entity 2; both are related to the noun 'problem'.\"",
        "sdp_path_text": "information → with → problem → of → PCA",
        "sentence": "Side information is used in the problem of robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'used'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'in' in the phrase 'in the problem of robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the problem of'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "robust PCA",
                "Method"
            ],
            [
                "prior structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is part of the noun phrase 'the problem of robust PCA', which is the object of the verb 'study'. Entity 2 ('prior structure') is part of the compound noun phrase 'both prior structure and features of entities', which is the subject of the relative clause 'are exploited for recovery'. There is no direct dependency between Entity 1 and Entity 2; they are both elements within the larger context of the problem being studied and the information used for recovery.\"",
        "sdp_path_text": "PCA → of → problem → exploited → structure",
        "sentence": "Robust PCA exploits prior structure for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the subject, depending on the verb 'exploits'. Entity 2 ('prior structure') is the object, depending on 'exploits' with 'robust PCA'. There is a direct dependency between Entity 1 and Entity 2, as 'prior structure' is directly used by 'robust PCA' in the action of exploiting.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "robust PCA",
                "Method"
            ],
            [
                "features of entities",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is part of the object of the preposition 'of', depending on 'problem'. Entity 2 ('features of entities') is the object of the preposition 'of', depending on 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, where they are mentioned as aspects being exploited for recovery.\"",
        "sdp_path_text": "PCA → of → problem → exploited → structure → features",
        "sentence": "Robust PCA exploits features of entities for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the subject, depending on the verb 'exploits'. Entity 2 ('features of entities') is the object, depending on 'exploits' with 'robust PCA'. There is a direct dependency between Entity 1 and Entity 2, as 'features of entities' is directly exploited by 'robust PCA'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "robust PCA",
                "Method"
            ],
            [
                "recovery",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is part of the noun phrase 'the problem of robust PCA with side information', where it serves as the object of the preposition 'of', depending on 'problem'. Entity 2 ('recovery') is the object of the preposition 'for', depending on 'exploited'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence, where 'robust PCA' is part of the problem being studied, and 'recovery' is the goal that utilizes the information from the problem.\"",
        "sdp_path_text": "PCA → of → problem → exploited → for → recovery",
        "sentence": "Robust PCA is exploited for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the subject, depending on the verb 'is exploited'. Entity 2 ('recovery') is the object, depending on the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'is exploited' which indicates that 'robust PCA' is used for the purpose of 'recovery'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "prior structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object of the preposition 'with', depending on the preposition 'with' in the phrase 'with side information'. Entity 2 ('prior structure') is part of a coordination, depending on 'and' in the phrase 'prior structure and features'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements that contribute to the context of what is being exploited for recovery.\"",
        "sdp_path_text": "information → with → problem → exploited → structure",
        "sentence": "Side information is exploited with prior structure for the problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'is exploited'. Entity 2 ('prior structure') is the object of the preposition 'with', depending on 'with' in the phrase 'with prior structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which indicates that the exploitation of side information involves or uses prior structure.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "features of entities",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is part of the prepositional phrase modifying 'robust PCA', depending on the preposition 'with'. Entity 2 ('features of entities') is the object of the preposition 'of', depending on 'and' which connects it to 'prior structure' in the clause 'both prior structure and features of entities are exploited for recovery'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is exploited for recovery.\"",
        "sdp_path_text": "information → with → problem → exploited → structure → features",
        "sentence": "Side information and features of entities are exploited for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is part of a coordination, depending on the conjunction 'and' with 'features of entities'. Entity 2 ('features of entities') is also part of the coordination, depending on the same conjunction 'and' with 'side information'. Both Entity 1 and Entity 2 are the subjects of the verb 'are exploited'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "recovery",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object of the preposition 'with', depending on 'problem'. Entity 2 ('recovery') is the object of the preposition 'for', depending on 'exploited'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing aspects of the problem being studied.\"",
        "sdp_path_text": "information → with → problem → exploited → for → recovery",
        "sentence": "Side information is exploited for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'exploited'. Entity 2 ('recovery') is the object, depending on the preposition 'for' in the phrase 'for recovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploited' which indicates that 'side information' is used for the purpose of 'recovery'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "prior structure",
                "OtherScientificTerm"
            ],
            [
                "features of entities",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('prior structure') is part of a coordination, depending on the conjunction 'and' with 'features of entities'. Entity 2 ('features of entities') is also part of the coordination, depending on the conjunction 'and' with 'prior structure'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as objects of the verb 'exploited'.\"",
        "sdp_path_text": "structure → features",
        "sentence": "Prior structure and features of entities are exploited for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('prior structure') is part of a conjunction, depending on 'and' with 'features of entities'. Entity 2 ('features of entities') is also part of the conjunction, depending on 'and' with 'prior structure'. Both are the subjects of the verb 'exploited'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "prior structure",
                "OtherScientificTerm"
            ],
            [
                "recovery",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('prior structure') is part of the compound object, depending on 'and' which connects it with 'features of entities', and together they depend on 'are exploited'. Entity 2 ('recovery') is the purpose or result, depending on 'for' which indicates the goal of the exploitation. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploited' and the preposition 'for'.\"",
        "sdp_path_text": "structure → exploited → for → recovery",
        "sentence": "Prior structure is exploited for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('prior structure') is the subject, depending on the verb 'exploited'. Entity 2 ('recovery') is the object, depending on the preposition 'for' in the phrase 'for recovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploited' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Thus , in this paper , we study the problem of robust PCA with side information , where both prior structure and features of entities are exploited for recovery .",
        "ner_pair": [
            [
                "features of entities",
                "OtherScientificTerm"
            ],
            [
                "recovery",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features of entities') is the object of the preposition 'of', depending on 'structure' within the compound noun 'structure and features of entities'. Entity 2 ('recovery') is the object, depending on the verb 'exploited'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'features of entities' contributes to the context of what is being 'exploited for recovery'.\"",
        "sdp_path_text": "features → structure → exploited → for → recovery",
        "sentence": "Features of entities and their structure are exploited for recovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('features of entities') is the subject, depending on the verb 'are exploited'. Entity 2 ('recovery') is the object, depending on 'for' in the phrase 'for recovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploited' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "convex problem",
                "Task"
            ],
            [
                "side information",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('side information') is the object of the preposition 'in', depending on 'incorporate' in the phrase 'to incorporate side information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what is proposed.\"",
        "sdp_path_text": "problem → propose → incorporate → information",
        "sentence": "We propose a convex problem to incorporate side information.",
        "sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('side information') is the object of the verb 'incorporate', depending on 'incorporate' in the phrase 'to incorporate side information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the infinitive clause 'to incorporate side information' that modifies 'convex problem'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "convex problem",
                "Task"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'incorporate' in the phrase 'to incorporate side information in robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause indicating the use of the convex problem in the context of robust PCA.\"",
        "sdp_path_text": "problem → propose → incorporate → in → PCA",
        "sentence": "We propose a convex problem to incorporate side information in robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'incorporate' in the phrase 'to incorporate side information in robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what is being proposed.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "convex problem",
                "Task"
            ],
            [
                "low rank matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('low rank matrix') is the subject of the clause 'can be exactly recovered', depending on the verb 'recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same broader context where the 'convex problem' is proposed to enable the recovery of the 'low rank matrix'.\"",
        "sdp_path_text": "problem → propose → incorporate → show → recovered → matrix",
        "sentence": "We propose a convex problem to show that the low rank matrix can be recovered.",
        "sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('low rank matrix') is the subject complement, depending on 'be' in the clause 'can be recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence context where the 'convex problem' is proposed to demonstrate the recovery of the 'low rank matrix'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "convex problem",
                "Task"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('method') is the object of the preposition 'via', depending on 'via' in the phrase 'via the proposed method'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the action of proposing and the context of the recovery process described in the sentence.\"",
        "sdp_path_text": "problem → propose → incorporate → show → recovered → via → method",
        "sentence": "We propose a convex problem to incorporate side information, which can recover the low rank matrix via the method.",
        "sentence_llm_dp_info": "\"Entity 1 ('convex problem') is the object of the verb 'propose', depending on 'propose' with 'We'. Entity 2 ('method') is the object of the preposition 'via', depending on 'via' in the phrase 'via the method'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the 'method' is used to solve the 'convex problem'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object of the preposition 'to', depending on 'incorporate'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'in' in the phrase 'in robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'side information' is incorporated into 'robust PCA'.\"",
        "sdp_path_text": "information → incorporate → in → PCA",
        "sentence": "Side information is incorporated in robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'is incorporated'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'in' in the phrase 'in robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is incorporated' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "low rank matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object of the preposition 'in', depending on 'incorporate' in the phrase 'to incorporate side information'. Entity 2 ('low rank matrix') is the subject complement, depending on 'recovered' in the clause 'the low rank matrix can be exactly recovered'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same broader context described in the sentence.\"",
        "sdp_path_text": "information → incorporate → show → recovered → matrix",
        "sentence": "Side information is incorporated to recover the low rank matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'incorporated'. Entity 2 ('low rank matrix') is the object of the verb 'recover', depending on 'recover' in the phrase 'to recover the low rank matrix'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object of the preposition 'in', depending on 'incorporate' with 'problem'. Entity 2 ('method') is the object of the preposition 'via', depending on 'recovered' with 'matrix'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence.\"",
        "sdp_path_text": "information → incorporate → show → recovered → via → method",
        "sentence": "Side information is incorporated via the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the subject, depending on the verb 'incorporated'. Entity 2 ('method') is the object of the preposition 'via', depending on 'via' in the phrase 'via the proposed method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporated' and the preposition 'via'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "robust PCA",
                "Method"
            ],
            [
                "low rank matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the object of the preposition 'in', depending on 'incorporate' with 'side information'. Entity 2 ('low rank matrix') is the subject, depending on 'recovered' with 'can be'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence, where 'robust PCA' is modified by the incorporation of side information, and this modification affects the recovery of the 'low rank matrix'.\"",
        "sdp_path_text": "PCA → in → incorporate → show → recovered → matrix",
        "sentence": "We show that the low rank matrix can be recovered by incorporating side information in robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the object of the preposition 'in', depending on the verb 'incorporating'. Entity 2 ('low rank matrix') is the subject complement, depending on the modal verb 'can be' in the phrase 'can be recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the recovery process described in the sentence.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "robust PCA",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the object of the preposition 'in', depending on 'incorporate' with 'side information'. Entity 2 ('method') is the object, depending on 'proposed' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as part of the same research or process described in the sentence.\"",
        "sdp_path_text": "PCA → in → incorporate → show → recovered → via → method",
        "sentence": "We show that robust PCA can incorporate side information via the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the subject complement, depending on 'can incorporate' with 'that'. Entity 2 ('method') is the object, depending on 'via' with 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporate' and the preposition 'via'.\""
    },
    {
        "raw_sentence": "We propose a convex problem to incorporate side information in robust PCA and show that the low rank matrix can be exactly recovered via the proposed method under certain conditions .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "low rank matrix",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'via' which modifies 'recovered'. Entity 2 ('low rank matrix') is the subject, depending on 'can be' in the phrase 'can be exactly recovered'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the recovery of the 'low rank matrix' is facilitated by the 'method'.\"",
        "sdp_path_text": "method → via → recovered → matrix",
        "sentence": "The method recovers the low rank matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'recovers'. Entity 2 ('low rank matrix') is the direct object, depending on the verb 'recovers'. There is a direct dependency between Entity 1 and Entity 2, where 'method' is the agent performing the action of recovering 'low rank matrix'.\""
    },
    {
        "raw_sentence": "In particular , our guarantee suggests that a substantial amount of low rank matrices , which can not be recovered by standard robust PCA , become re-coverable by our proposed method .",
        "ner_pair": [
            [
                "low rank matrices",
                "OtherScientificTerm"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low rank matrices') is the subject of the relative clause, depending on 'which' with 'can not be recovered'. Entity 2 ('robust PCA') is the object of the preposition 'by', depending on 'recovered'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the recovery process described in the sentence.\"",
        "sdp_path_text": "matrices → recovered → by → PCA",
        "sentence": "Low rank matrices, which cannot be recovered by standard robust PCA, become recoverable by the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('low rank matrices') is the subject, depending on 'become' with 'recoverable'. Entity 2 ('robust PCA') is the object of the relative clause modifier 'which cannot be recovered by', depending on 'by'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of recovery methods described in the sentence.\""
    },
    {
        "raw_sentence": "In particular , our guarantee suggests that a substantial amount of low rank matrices , which can not be recovered by standard robust PCA , become re-coverable by our proposed method .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "low rank matrices",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'proposed' with 'our'. Entity 2 ('low rank matrices') is the subject, depending on 'recovered' with 'become'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where the method affects the recoverability of the low rank matrices.\"",
        "sdp_path_text": "method → by → become → amount → of → matrices",
        "sentence": "Our proposed method makes a substantial amount of low rank matrices recoverable.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'makes'. Entity 2 ('low rank matrices') is the object, depending on 'recoverable' with 'makes'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is responsible for making 'low rank matrices' recoverable.\""
    },
    {
        "raw_sentence": "In particular , our guarantee suggests that a substantial amount of low rank matrices , which can not be recovered by standard robust PCA , become re-coverable by our proposed method .",
        "ner_pair": [
            [
                "robust PCA",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the object of the negative clause 'can not be recovered', depending on 'recovered'. Entity 2 ('method') is the object of the verb 'become re-coverable', depending on 'become re-coverable' in the phrase 'become re-coverable by our proposed method'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the discussion of recovery methods for matrices.\"",
        "sdp_path_text": "PCA → by → recovered → matrices → of → amount → become → by → method",
        "sentence": "Matrices not recoverable by robust PCA become re-coverable by the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust PCA') is the object of the preposition 'by', depending on 'recoverable'. Entity 2 ('method') is the object of the preposition 'by', depending on 're-coverable'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of 'recoverability' through the verbs 'recoverable' and 're-coverable'.\""
    },
    {
        "raw_sentence": "The result theoretically justifies the effectiveness of features in robust PCA .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "robust PCA",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the object of the preposition 'of', depending on 'the effectiveness of features'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'in robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify 'effectiveness'.\"",
        "sdp_path_text": "features → in → PCA",
        "sentence": "The features justify the effectiveness in robust PCA.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'justify'. Entity 2 ('robust PCA') is the object of the preposition 'in', depending on 'in' in the phrase 'in robust PCA'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'justify' and the prepositional phrase 'in robust PCA'.\""
    },
    {
        "raw_sentence": "In addition , we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information .",
        "ner_pair": [
            [
                "noisy image classification",
                "Task"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('noisy image classification') is the object of the preposition 'on', depending on 'application'. Entity 2 ('method') is the object, depending on 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'method' is described as improving performance in the context of 'noisy image classification'.\"",
        "sdp_path_text": "classification → on → application → experiments → conduct → show → improves → method",
        "sentence": "Our method improves performance in noisy image classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('noisy image classification') is the object of the preposition 'in', depending on 'performance'. Entity 2 ('method') is the subject, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' and the prepositional phrase 'in performance'.\""
    },
    {
        "raw_sentence": "In addition , we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information .",
        "ner_pair": [
            [
                "noisy image classification",
                "Task"
            ],
            [
                "side information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('noisy image classification') is the object of the preposition 'on', depending on 'conduct' via the prepositional phrase 'on noisy image classification'. Entity 2 ('side information') is the object of the verb 'exploiting', depending on 'improves' in the clause 'improves the performance in practice by exploiting side information'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same larger clause describing the purpose and method of the experiments and application.\"",
        "sdp_path_text": "classification → on → application → experiments → conduct → show → improves → by → exploiting → information",
        "sentence": "Noisy image classification improves by exploiting side information.",
        "sentence_llm_dp_info": "\"Entity 1 ('noisy image classification') is the subject, depending on the verb 'improves'. Entity 2 ('side information') is the object of the preposition 'by', depending on the preposition 'by' in the phrase 'by exploiting side information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploiting' which modifies how Entity 1 is affected.\""
    },
    {
        "raw_sentence": "In addition , we conduct synthetic experiments as well as a real application on noisy image classification to show that our method also improves the performance in practice by exploiting side information .",
        "ner_pair": [
            [
                "side information",
                "OtherScientificTerm"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('side information') is the object, depending on 'exploiting' which modifies the verb 'improves'. Entity 2 ('method') is part of the possessive noun phrase 'our method', depending on 'shows' as the subject of the clause. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the same clause describing how the method improves performance by using side information.\"",
        "sdp_path_text": "information → exploiting → by → improves → method",
        "sentence": "The method improves performance by exploiting side information.",
        "sentence_llm_dp_info": "\"Entity 1 ('side information') is the object, depending on the verb 'exploiting'. Entity 2 ('method') is the subject, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploiting' which modifies how the 'method' achieves its effect on 'performance'.\""
    },
    {
        "raw_sentence": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms .",
        "ner_pair": [
            [
                "demonstrative expressions",
                "OtherScientificTerm"
            ],
            [
                "English",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('demonstrative expressions') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('English') is the object of the preposition 'in', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify 'conditions' and 'use', respectively.\"",
        "sdp_path_text": "expressions → of → use → in → English",
        "sentence": "This paper discusses the use of demonstrative expressions in English.",
        "sentence_llm_dp_info": "\"Entity 1 ('demonstrative expressions') is the object of the preposition 'of', depending on 'use'. Entity 2 ('English') is the complement of the preposition 'in', depending on 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is discussed in the paper.\""
    },
    {
        "raw_sentence": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms .",
        "ner_pair": [
            [
                "demonstrative expressions",
                "OtherScientificTerm"
            ],
            [
                "implications",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('demonstrative expressions') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('implications') is the object of the verb 'discusses', depending on 'discusses' in the clause 'discusses implications'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context provided by the sentence.\"",
        "sdp_path_text": "expressions → of → use → for → conditions → presents → discusses → implications",
        "sentence": "This paper discusses implications of conditions for the use of demonstrative expressions.",
        "sentence_llm_dp_info": "\"Entity 1 ('demonstrative expressions') is the object of the preposition 'of', depending on 'use'. Entity 2 ('implications') is the object, depending on 'discusses' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'implications' is the main topic being discussed, and 'demonstrative expressions' are part of the conditions related to this discussion.\""
    },
    {
        "raw_sentence": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms .",
        "ner_pair": [
            [
                "demonstrative expressions",
                "OtherScientificTerm"
            ],
            [
                "discourse processing algorithms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('demonstrative expressions') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('discourse processing algorithms') is the object of the preposition 'for', depending on 'implications'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure that describes the content of the paper.\"",
        "sdp_path_text": "expressions → of → use → for → conditions → presents → discusses → implications → for → algorithms",
        "sentence": "This paper discusses implications of conditions for using demonstrative expressions in discourse processing algorithms.",
        "sentence_llm_dp_info": "\"Entity 1 ('demonstrative expressions') is the object of the preposition 'for', depending on 'conditions'. Entity 2 ('discourse processing algorithms') is the object of the preposition 'in', depending on 'using'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\""
    },
    {
        "raw_sentence": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "implications",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'for', depending on 'use' in the phrase 'for the use of demonstrative expressions in English'. Entity 2 ('implications') is the object of the verb 'discusses', depending on 'discusses' in the phrase 'discusses implications for current discourse processing algorithms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "English → in → use → for → conditions → presents → discusses → implications",
        "sentence": "This paper discusses implications for discourse processing algorithms related to the use of demonstrative expressions in English.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'of', depending on 'expressions'. Entity 2 ('implications') is the object, depending on 'discusses' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause structure, connected through the verb 'discusses' and the prepositional phrase 'for discourse processing algorithms related to the use of demonstrative expressions in English'.\""
    },
    {
        "raw_sentence": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "discourse processing algorithms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'for', depending on 'use' in the phrase 'for the use of demonstrative expressions in English'. Entity 2 ('discourse processing algorithms') is the object of the preposition 'for', depending on 'implications' in the phrase 'implications for current discourse processing algorithms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "English → in → use → for → conditions → presents → discusses → implications → for → algorithms",
        "sentence": "This paper presents conditions for using English and discusses implications for discourse processing algorithms.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'using', depending on 'conditions'. Entity 2 ('discourse processing algorithms') is the object of the preposition 'for', depending on 'implications'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "This paper presents necessary and sufficient conditions for the use of demonstrative expressions in English and discusses implications for current discourse processing algorithms .",
        "ner_pair": [
            [
                "implications",
                "Generic"
            ],
            [
                "discourse processing algorithms",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('implications') is the object, depending on 'discusses' with 'discusses implications'. Entity 2 ('discourse processing algorithms') is the object of the preposition 'for', depending on 'for' in the phrase 'for current discourse processing algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'discusses' is the main verb.\"",
        "sdp_path_text": "implications → for → algorithms",
        "sentence": "This paper discusses implications for discourse processing algorithms.",
        "sentence_llm_dp_info": "\"Entity 1 ('implications') is the object, depending on the verb 'discusses' with 'This paper'. Entity 2 ('discourse processing algorithms') is the object of the preposition 'for', depending on 'for' in the phrase 'for discourse processing algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This research is part of a larger study of anaphoric expressions , the results of which will be incorporated into a natural language generation system .",
        "ner_pair": [
            [
                "anaphoric expressions",
                "OtherScientificTerm"
            ],
            [
                "natural language generation system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anaphoric expressions') is the object of the preposition 'of', depending on 'study' in the phrase 'study of anaphoric expressions'. Entity 2 ('natural language generation system') is the object of the preposition 'into', depending on 'incorporated' in the phrase 'incorporated into a natural language generation system'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the structure of the sentence through different prepositional phrases.\"",
        "sdp_path_text": "expressions → incorporated → into → system",
        "sentence": "Anaphoric expressions will be incorporated into a natural language generation system.",
        "sentence_llm_dp_info": "\"Entity 1 ('anaphoric expressions') is the subject, depending on the verb 'incorporated'. Entity 2 ('natural language generation system') is the object, depending on the preposition 'into'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporated' and the preposition 'into'.\""
    },
    {
        "raw_sentence": "Using the IEMOCAP database , discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments evaluated by the actors and na ¨ ıve listeners are compared .",
        "ner_pair": [
            [
                "IEMOCAP database",
                "Material"
            ],
            [
                "discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('IEMOCAP database') is the object of the preposition 'using', depending on the verb 'compared'. Entity 2 ('discrete -LRB- categorical -RRB- and continuous -LRB- attribute -RRB- emotional assessments') is the subject, depending on the verb 'are compared'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the assessments are being compared using the database.\"",
        "sdp_path_text": "database → Using → compared → -RRB-",
        "sentence": "Using the IEMOCAP database, discrete and continuous emotional assessments are compared.",
        "sentence_llm_dp_info": "\"Entity 1 ('IEMOCAP database') is the object of the preposition 'using', depending on 'using' in the phrase 'Using the IEMOCAP database'. Entity 2 ('discrete (categorical) and continuous (attribute) emotional assessments') is the subject, depending on the verb 'are' in the phrase 'are compared'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related in the same clause where the assessments are being compared using the database.\""
    },
    {
        "raw_sentence": "The speakers in the database assigned their own emotions to more specific emotional categories , which led to more extreme values in the activation-valence space .",
        "ner_pair": [
            [
                "database",
                "Generic"
            ],
            [
                "activation-valence space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('database') is part of the prepositional phrase 'in the database', where it serves as the object of the preposition 'in', depending on 'speakers'. Entity 2 ('activation-valence space') is the object of the preposition 'in', depending on 'values'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the sentence structure involving 'speakers', 'emotions', 'categories', and 'values'.\"",
        "sdp_path_text": "database → in → speakers → assigned → led → to → values → in → space",
        "sentence": "The database led to more extreme values in the activation-valence space.",
        "sentence_llm_dp_info": "\"Entity 1 ('database') is the subject, depending on the verb 'led'. Entity 2 ('activation-valence space') is the object of the preposition 'in', depending on 'in' in the phrase 'in the activation-valence space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'led' and the prepositional phrase 'in the activation-valence space'.\""
    },
    {
        "raw_sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "blind separation of underdetermined instantaneous mixtures of independent signals",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'relying' and is part of the prepositional phrase 'through a method'. Entity 2 ('blind separation of underdetermined instantaneous mixtures of independent signals') is the subject, depending on the verb 'addressed'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the context provided by the sentence, where the method is described as addressing the problem related to Entity 2.\"",
        "sdp_path_text": "method → through → addressed → problem → of → separation",
        "sentence": "The method addresses the problem of blind separation of underdetermined instantaneous mixtures of independent signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'addresses'. Entity 2 ('blind separation of underdetermined instantaneous mixtures of independent signals') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'addresses' and the prepositional phrase 'of the problem'.\""
    },
    {
        "raw_sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals .",
        "ner_pair": [
            [
                "blind separation of underdetermined instantaneous mixtures of independent signals",
                "Task"
            ],
            [
                "nonstationarity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('blind separation of underdetermined instantaneous mixtures of independent signals') is the subject, depending on 'addressed' as the main verb. Entity 2 ('nonstationarity') is the object of the preposition 'on', depending on 'relying' in the phrase 'relying on nonstationarity'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'addressed' and the prepositional phrase 'relying on nonstationarity'.\"",
        "sdp_path_text": "separation → of → problem → addressed → through → method → relying → on → nonstationarity",
        "sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity.",
        "sentence_llm_dp_info": "\"Entity 1 ('blind separation of underdetermined instantaneous mixtures of independent signals') is the subject complement, depending on 'addressed' with 'problem'. Entity 2 ('nonstationarity') is the object of the preposition 'on', depending on 'relying' in the phrase 'relying on nonstationarity'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where the method addresses the problem involving Entity 1 by relying on Entity 2.\""
    },
    {
        "raw_sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals .",
        "ner_pair": [
            [
                "blind separation of underdetermined instantaneous mixtures of independent signals",
                "Task"
            ],
            [
                "original signals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('blind separation of underdetermined instantaneous mixtures of independent signals') is the subject complement, depending on 'addressed' with 'problem'. Entity 2 ('original signals') is the object of the preposition 'of', depending on 'nonstationarity'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence, where the method addressing the problem of Entity 1 relies on the nonstationarity of Entity 2.\"",
        "sdp_path_text": "separation → of → problem → addressed → through → method → relying → on → nonstationarity → of → signals",
        "sentence": "The problem of blind separation of underdetermined instantaneous mixtures is addressed through a method relying on the nonstationarity of original signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('blind separation of underdetermined instantaneous mixtures') is the subject, depending on 'addressed' with 'is addressed'. Entity 2 ('original signals') is the object, depending on 'relying' with 'method'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger context where the method addresses the problem related to the nonstationarity of Entity 2.\""
    },
    {
        "raw_sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals .",
        "ner_pair": [
            [
                "nonstationarity",
                "OtherScientificTerm"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nonstationarity') is the object of the preposition 'on', depending on 'relying' in the phrase 'relying on nonstationarity'. Entity 2 ('method') is the object of the preposition 'through', depending on 'addressed' in the phrase 'addressed through a method'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'relying' which describes how the method operates.\"",
        "sdp_path_text": "nonstationarity → on → relying → method",
        "sentence": "The method relies on the nonstationarity of the original signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('nonstationarity') is the complement, depending on the preposition 'on' within the prepositional phrase 'on the nonstationarity'. Entity 2 ('method') is the subject, depending on the verb 'relies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' which indicates that the method depends on the nonstationarity.\""
    },
    {
        "raw_sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "original signals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'relying' as its verb, which modifies 'method'. Entity 2 ('original signals') is the object of the preposition 'of', depending on 'nonstationarity'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'on nonstationarity of the original signals'.\"",
        "sdp_path_text": "method → relying → on → nonstationarity → of → signals",
        "sentence": "The method relies on the nonstationarity of the original signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'relies'. Entity 2 ('original signals') is the object of the preposition 'of', depending on 'nonstationarity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on the nonstationarity of the original signals'.\""
    },
    {
        "raw_sentence": "The problem of blind separation of underdetermined instantaneous mixtures of independent signals is addressed through a method relying on nonstationarity of the original signals .",
        "ner_pair": [
            [
                "nonstationarity",
                "OtherScientificTerm"
            ],
            [
                "original signals",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nonstationarity') is the object of the preposition 'on', depending on 'relying' in the phrase 'relying on nonstationarity'. Entity 2 ('original signals') is the object of the preposition 'of', depending on 'nonstationarity' in the phrase 'nonstationarity of the original signals'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 modifies Entity 1.\"",
        "sdp_path_text": "nonstationarity → of → signals",
        "sentence": "Nonstationarity of the original signals is utilized in the method.",
        "sentence_llm_dp_info": "\"Entity 1 ('nonstationarity') is the subject, depending on the verb 'is'. Entity 2 ('original signals') is the object of the preposition 'of', depending on 'nonstationarity' in the phrase 'of the original signals'. There is a direct dependency between Entity 1 and Entity 2, as 'original signals' modifies 'nonstationarity'.\""
    },
    {
        "raw_sentence": "In comparison with previous works , in this paper it is assumed that the signals are not i.i.d. in each epoch , but obey a first-order autoregressive model .",
        "ner_pair": [
            [
                "first-order autoregressive model",
                "Method"
            ],
            [
                "signals",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('first-order autoregressive model') is the object, depending on the verb 'obey'. Entity 2 ('signals') is the subject, depending on the verb 'are' (part of the phrase 'are not i.i.d.'). There is a direct dependency between Entity 1 and Entity 2, as 'signals' are described as obeying the 'first-order autoregressive model'.\"",
        "sdp_path_text": "model → obey → are → signals",
        "sentence": "Signals obey a first-order autoregressive model.",
        "sentence_llm_dp_info": "\"Entity 1 ('first-order autoregressive model') is the complement, depending on the verb 'obey'. Entity 2 ('signals') is the subject, depending on the verb 'obey'. There is a direct dependency between Entity 1 and Entity 2, where 'signals' is the subject that obeys the 'first-order autoregressive model'.\""
    },
    {
        "raw_sentence": "This model was shown to be more appropriate for blind separation of natural speech signals .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "blind separation of natural speech signals .",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'shown'. Entity 2 ('blind separation of natural speech signals') is the complement, depending on the preposition 'for' which modifies the adjective 'appropriate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for blind separation of natural speech signals' that describes the context in which the model is considered appropriate.\"",
        "sdp_path_text": "model → shown → be → appropriate → for → separation",
        "sentence": "This model was shown to be appropriate for blind separation of natural speech signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on 'shown' with 'was shown'. Entity 2 ('blind separation of natural speech signals') is the object of the preposition 'for', depending on 'for' in the phrase 'for blind separation of natural speech signals'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A separation method is proposed that is nearly statistically efficient -LRB- approaching the corresponding Cramér-Rao lower bound -RRB- , if the separated signals obey the assumed model .",
        "ner_pair": [
            [
                "Cramér-Rao lower bound -RRB-",
                "OtherScientificTerm"
            ],
            [
                "separation method",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Cramér-Rao lower bound -RRB-') is the object of the preposition 'approaching', depending on 'approaching' in the phrase 'approaching the corresponding Cramér-Rao lower bound -RRB-'. Entity 2 ('separation method') is the subject, depending on the verb 'is' in the phrase 'A separation method is proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'proposed' and the prepositional phrase 'approaching the corresponding Cramér-Rao lower bound -RRB-'.\"\nThis analysis shows how the 'separation method' is the main subject being discussed, while the 'Cramér-Rao lower bound -RRB-' is a benchmark or standard that the method approaches in terms of statistical efficiency.",
        "sdp_path_text": "-RRB- → approaching → efficient → is → method",
        "sentence": "The separation method approaches the Cramér-Rao lower bound efficiency.",
        "sentence_llm_dp_info": "\"Entity 1 ('Cramér-Rao lower bound') is the object of the preposition 'to', depending on 'approaches'. Entity 2 ('separation method') is the subject, depending on the verb 'approaches'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 approaches Entity 1.\""
    },
    {
        "raw_sentence": "A separation method is proposed that is nearly statistically efficient -LRB- approaching the corresponding Cramér-Rao lower bound -RRB- , if the separated signals obey the assumed model .",
        "ner_pair": [
            [
                "separation method",
                "Method"
            ],
            [
                "assumed model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('separation method') is the subject, depending on the verb 'proposed'. Entity 2 ('assumed model') is the object of the relative clause, depending on 'obey' with 'signals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conditional clause 'if the separated signals obey the assumed model'.\"",
        "sdp_path_text": "method → proposed → obey → model",
        "sentence": "A separation method is proposed for signals that obey the assumed model.",
        "sentence_llm_dp_info": "\"Entity 1 ('separation method') is the subject, depending on the verb 'is proposed'. Entity 2 ('assumed model') is the object of the relative clause, depending on 'obey' with 'signals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause 'that obey the assumed model'.\""
    },
    {
        "raw_sentence": "A separation method is proposed that is nearly statistically efficient -LRB- approaching the corresponding Cramér-Rao lower bound -RRB- , if the separated signals obey the assumed model .",
        "ner_pair": [
            [
                "Cramér-Rao lower bound -RRB-",
                "OtherScientificTerm"
            ],
            [
                "assumed model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Cramér-Rao lower bound -RRB-') is the object of the preposition 'approaching', depending on 'approaching' in the phrase 'approaching the corresponding Cramér-Rao lower bound'. Entity 2 ('assumed model') is the object of the preposition 'obey', depending on 'obey' in the clause 'if the separated signals obey the assumed model'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "-RRB- → approaching → efficient → is → method → proposed → obey → model",
        "sentence": "A method proposed approaches the Cramér-Rao lower bound if the signals obey the assumed model.",
        "sentence_llm_dp_info": "\"Entity 1 ('Cramér-Rao lower bound') is the object of the preposition 'to', depending on 'approaches' in the phrase 'approaches the Cramér-Rao lower bound'. Entity 2 ('assumed model') is the object of the preposition 'the', depending on 'obey' in the phrase 'obey the assumed model'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In the case of natural speech signals , the method is shown to have separation accuracy better than the state-of-the-art methods .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "natural speech signals",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is shown'. Entity 2 ('natural speech signals') is part of a prepositional phrase, depending on 'case' in 'the case of natural speech signals'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the sentence structure.\"",
        "sdp_path_text": "method → shown → In → case → of → signals",
        "sentence": "The method is shown to be effective in the case of natural speech signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'is shown' with 'The'. Entity 2 ('natural speech signals') is the object of the preposition 'of', depending on 'case'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the case of natural speech signals'.\""
    },
    {
        "raw_sentence": "In the case of natural speech signals , the method is shown to have separation accuracy better than the state-of-the-art methods .",
        "ner_pair": [
            [
                "natural speech signals",
                "OtherScientificTerm"
            ],
            [
                "separation accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural speech signals') is the object of the preposition 'of', depending on 'case'. Entity 2 ('separation accuracy') is the subject complement, depending on the verb 'have'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'the method' is described as having 'separation accuracy' that is better in the context of 'natural speech signals'.\"",
        "sdp_path_text": "signals → of → case → In → shown → have → accuracy",
        "sentence": "Natural speech signals have separation accuracy better than state-of-the-art methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural speech signals') is the subject, depending on the verb 'have'. Entity 2 ('separation accuracy') is the object, depending on 'have' with 'natural speech signals'. There is a direct dependency between Entity 1 and Entity 2, as 'separation accuracy' is possessed by 'natural speech signals'.\""
    },
    {
        "raw_sentence": "In the case of natural speech signals , the method is shown to have separation accuracy better than the state-of-the-art methods .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "natural speech signals",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the object, depending on the comparative adjective 'better' through the prepositional phrase 'than the state-of-the-art methods'. Entity 2 ('natural speech signals') is the object of the preposition 'of', depending on 'case'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context describing the conditions under which the method's performance is evaluated.\"",
        "sdp_path_text": "methods → than → better → have → shown → In → case → of → signals",
        "sentence": "The method has better separation accuracy for natural speech signals.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on the verb 'has'. Entity 2 ('natural speech signals') is the object of the preposition 'for', depending on 'for' in the phrase 'for natural speech signals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for natural speech signals' which modifies the noun 'accuracy'.\""
    },
    {
        "raw_sentence": "In the case of natural speech signals , the method is shown to have separation accuracy better than the state-of-the-art methods .",
        "ner_pair": [
            [
                "separation accuracy",
                "Metric"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('separation accuracy') is the subject complement, depending on 'have' with 'method'. Entity 2 ('method') is the subject, depending on 'is shown' with 'the'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is the possessor of 'separation accuracy' through the verb 'have'.\"",
        "sdp_path_text": "accuracy → have → shown → method",
        "sentence": "The method is shown to have separation accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('separation accuracy') is the object, depending on the verb 'have'. Entity 2 ('method') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'separation accuracy' is described as a property that the 'method' has.\""
    },
    {
        "raw_sentence": "In the case of natural speech signals , the method is shown to have separation accuracy better than the state-of-the-art methods .",
        "ner_pair": [
            [
                "separation accuracy",
                "Metric"
            ],
            [
                "methods",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('separation accuracy') is the subject complement, depending on the verb 'have'. Entity 2 ('methods') is the object of the preposition 'than', depending on 'better'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure 'better than'.\"",
        "sdp_path_text": "accuracy → have → better → than → methods",
        "sentence": "The method has separation accuracy better than other methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('separation accuracy') is the subject complement, depending on the comparative adjective 'better'. Entity 2 ('methods') is the object of the preposition 'than', depending on 'than' in the phrase 'than other methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'better than'.\""
    },
    {
        "raw_sentence": "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction .",
        "ner_pair": [
            [
                "convolution kernel over parse trees",
                "Method"
            ],
            [
                "syntactic structure information",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convolution kernel over parse trees') is the object of the preposition 'over', depending on 'use' in the phrase 'to use a convolution kernel over parse trees'. Entity 2 ('syntactic structure information') is the object of the preposition 'for', depending on 'model' in the phrase 'to model syntactic structure information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the purpose of the proposed method.\"",
        "sdp_path_text": "kernel → use → model → information",
        "sentence": "A convolution kernel over parse trees is used to model syntactic structure information.",
        "sentence_llm_dp_info": "\"Entity 1 ('convolution kernel over parse trees') is the subject, depending on the verb 'used'. Entity 2 ('syntactic structure information') is the object, depending on the verb 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' to describe the purpose of the convolution kernel.\""
    },
    {
        "raw_sentence": "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction .",
        "ner_pair": [
            [
                "convolution kernel over parse trees",
                "Method"
            ],
            [
                "relation extraction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convolution kernel over parse trees') is the object of the preposition 'over', depending on 'use' which is part of the infinitive phrase 'to use'. Entity 2 ('relation extraction') is the purpose or goal, depending on 'for' which indicates the intended use of the syntactic structure information. There is no direct dependency between Entity 1 and Entity 2, but they are related through the overall structure of the sentence where the convolution kernel is used to model information that aids in relation extraction.\"",
        "sdp_path_text": "kernel → use → model → for → extraction",
        "sentence": "A convolution kernel over parse trees is used to model information for relation extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('convolution kernel over parse trees') is the subject complement, depending on 'used' with the verb 'is used'. Entity 2 ('relation extraction') is the object, depending on 'for' in the prepositional phrase 'for relation extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is used' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction .",
        "ner_pair": [
            [
                "syntactic structure information",
                "OtherScientificTerm"
            ],
            [
                "relation extraction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntactic structure information') is the object, depending on 'model' with 'to model'. Entity 2 ('relation extraction') is the purpose, depending on 'for' with 'for relation extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'model' and the preposition 'for'.\"",
        "sdp_path_text": "information → model → for → extraction",
        "sentence": "Syntactic structure information is modeled for relation extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntactic structure information') is the subject, depending on the verb 'modeled'. Entity 2 ('relation extraction') is the object of the preposition 'for', depending on 'for' in the phrase 'for relation extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "syntactic structure features",
                "OtherScientificTerm"
            ],
            [
                "parse tree",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntactic structure features') is the subject, depending on 'are' as the main verb. Entity 2 ('parse tree') is the object of the preposition 'in', depending on 'embedded'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'embedded in a parse tree'.\"",
        "sdp_path_text": "features → embedded → in → tree",
        "sentence": "Syntactic structure features are embedded in a parse tree.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntactic structure features') is the subject, depending on the verb 'are embedded'. Entity 2 ('parse tree') is the object of the preposition 'in', depending on 'in' in the phrase 'in a parse tree'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are embedded' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "syntactic structure features",
                "OtherScientificTerm"
            ],
            [
                "relation extraction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntactic structure features') is the subject complement, depending on the verb 'are' in the clause 'are very effective'. Entity 2 ('relation extraction') is the object of the preposition 'for', depending on 'for' in the phrase 'for relation extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the effectiveness statement in the sentence.\"",
        "sdp_path_text": "features → are → effective → for → extraction",
        "sentence": "Syntactic structure features are effective for relation extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntactic structure features') is the subject, depending on the verb 'are'. Entity 2 ('relation extraction') is the object of the preposition 'for', depending on 'for' in the phrase 'for relation extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "syntactic structure features",
                "OtherScientificTerm"
            ],
            [
                "convolution tree kernel",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntactic structure features') is the subject, depending on 'are' with 'reveals'. It also depends on 'embedded' with 'in' in the phrase 'embedded in a parse tree'. Entity 2 ('convolution tree kernel') is the subject complement, depending on 'captured' with 'can be'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause and related through the context of effectiveness for relation extraction and being captured by the kernel.\"",
        "sdp_path_text": "features → are → captured → by → kernel",
        "sentence": "Syntactic structure features are captured by the convolution tree kernel.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntactic structure features') is the subject, depending on the passive verb 'are captured'. Entity 2 ('convolution tree kernel') is the agent, depending on 'by' in the phrase 'by the convolution tree kernel'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction where 'convolution tree kernel' performs the action of capturing 'syntactic structure features'.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "parse tree",
                "OtherScientificTerm"
            ],
            [
                "relation extraction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parse tree') is the object of the preposition 'in', depending on 'features'. Entity 2 ('relation extraction') is the object of the preposition 'for', depending on 'effective'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'features' and the adjective 'effective' which describes the utility of the features found in the parse tree for the process of relation extraction.\"",
        "sdp_path_text": "tree → in → embedded → features → are → effective → for → extraction",
        "sentence": "Features embedded in a parse tree are effective for relation extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('parse tree') is the object of the preposition 'in', depending on 'embedded'. Entity 2 ('relation extraction') is the complement of the adjective 'effective', depending on 'for' in the phrase 'for relation extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause that describes the effectiveness of features embedded in a parse tree for relation extraction.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "parse tree",
                "OtherScientificTerm"
            ],
            [
                "features",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parse tree') is the object of the preposition 'in', depending on 'embedded'. Entity 2 ('features') is the subject, depending on 'are' and also the object of 'reveals' through the clause 'that the syntactic structure features... are very effective'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'features embedded in a parse tree'.\"",
        "sdp_path_text": "tree → in → embedded → features",
        "sentence": "Features are embedded in a parse tree.",
        "sentence_llm_dp_info": "\"Entity 1 ('parse tree') is the object, depending on the preposition 'in' which is part of the prepositional phrase 'in a parse tree'. Entity 2 ('features') is the subject, depending on the verb 'are embedded'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in a parse tree' where 'features' are embedded.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "parse tree",
                "OtherScientificTerm"
            ],
            [
                "convolution tree kernel",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parse tree') is the object of the preposition 'in', depending on 'features'. Entity 2 ('convolution tree kernel') is the subject complement, depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sentence structure where the features from the 'parse tree' are said to be captured by the 'convolution tree kernel'.\"",
        "sdp_path_text": "tree → in → embedded → features → are → captured → by → kernel",
        "sentence": "Features embedded in a parse tree are captured by the convolution tree kernel.",
        "sentence_llm_dp_info": "\"Entity 1 ('parse tree') is the object of the preposition 'in', depending on 'embedded'. Entity 2 ('convolution tree kernel') is the subject, depending on the verb 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'captured' which indicates that the features from Entity 1 are processed by Entity 2.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "relation extraction",
                "Task"
            ],
            [
                "features",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relation extraction') is the object of the preposition 'for', depending on 'are' in the clause 'are very effective for relation extraction'. Entity 2 ('features') is the subject, depending on 'are' in the same clause 'features are very effective'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'features' are described as being effective for 'relation extraction'.\"",
        "sdp_path_text": "extraction → for → effective → are → features",
        "sentence": "Features are effective for relation extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('relation extraction') is the object, depending on the preposition 'for', which modifies 'effective'. Entity 2 ('features') is the subject, depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'effective' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "relation extraction",
                "Task"
            ],
            [
                "convolution tree kernel",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relation extraction') is the object of the preposition 'for', depending on 'effective'. Entity 2 ('convolution tree kernel') is the subject complement, depending on 'captured'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where 'features' are described as being effective for 'relation extraction' and captured by the 'convolution tree kernel'.\"",
        "sdp_path_text": "extraction → for → effective → are → captured → by → kernel",
        "sentence": "Syntactic structure features for relation extraction can be effectively captured by the convolution tree kernel.",
        "sentence_llm_dp_info": "\"Entity 1 ('relation extraction') is the object of the preposition 'for', depending on 'features'. Entity 2 ('convolution tree kernel') is the subject complement, depending on the verb 'be' (can be). There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sentence structure where 'features' for 'relation extraction' can be captured 'by the convolution tree kernel'.\""
    },
    {
        "raw_sentence": "Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .",
        "ner_pair": [
            [
                "convolution tree kernel",
                "Method"
            ],
            [
                "features",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convolution tree kernel') is the subject complement, depending on 'captured' with 'can be well captured'. Entity 2 ('features') is the subject, depending on 'are' with 'very effective'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'captured' which indicates that the features can be captured by the convolution tree kernel.\"",
        "sdp_path_text": "kernel → by → captured → are → features",
        "sentence": "The convolution tree kernel captures features effectively.",
        "sentence_llm_dp_info": "\"Entity 1 ('convolution tree kernel') is the subject, depending on the verb 'captures'. Entity 2 ('features') is the direct object, depending on 'captures' in the verb-object relationship. There is a direct dependency between Entity 1 and Entity 2, where 'convolution tree kernel' is the agent performing the action of capturing 'features'.\""
    },
    {
        "raw_sentence": "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes .",
        "ner_pair": [
            [
                "ACE 2003 corpus",
                "Material"
            ],
            [
                "convolution kernel over parse trees",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE 2003 corpus') is the object of the preposition 'on', depending on 'Evaluation'. Entity 2 ('convolution kernel over parse trees') is the subject of the clause, depending on 'can achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure where Entity 2's performance is evaluated using Entity 1.\"",
        "sdp_path_text": "corpus → on → Evaluation → shows → achieve → kernel",
        "sentence": "Evaluation on the ACE 2003 corpus shows the convolution kernel over parse trees achieves comparable performance.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE 2003 corpus') is the object of the preposition 'on', depending on 'Evaluation'. Entity 2 ('convolution kernel over parse trees') is the subject, depending on 'achieves' with 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the evaluation results.\""
    },
    {
        "raw_sentence": "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes .",
        "ner_pair": [
            [
                "ACE 2003 corpus",
                "Material"
            ],
            [
                "feature-based methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE 2003 corpus') is the object of the preposition 'on', depending on 'Evaluation'. Entity 2 ('feature-based methods') is the object of the preposition 'with', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the evaluation and comparison of performance.\"",
        "sdp_path_text": "corpus → on → Evaluation → shows → achieve → with → methods",
        "sentence": "Evaluation on the ACE 2003 corpus shows comparable performance with feature-based methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE 2003 corpus') is the object of the preposition 'on', depending on 'Evaluation'. Entity 2 ('feature-based methods') is the object of the preposition 'with', depending on 'shows'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the evaluation results.\""
    },
    {
        "raw_sentence": "Evaluation on the ACE 2003 corpus shows that the convolution kernel over parse trees can achieve comparable performance with the previous best-reported feature-based methods on the 24 ACE relation subtypes .",
        "ner_pair": [
            [
                "feature-based methods",
                "Method"
            ],
            [
                "convolution kernel over parse trees",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature-based methods') is the object, depending on the preposition 'with', which is part of the comparative clause 'with the previous best-reported feature-based methods'. Entity 2 ('convolution kernel over parse trees') is the subject of the clause, depending on the verb 'can achieve'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparative clause indicating that both can achieve similar performance.\"",
        "sdp_path_text": "methods → with → achieve → kernel",
        "sentence": "The convolution kernel over parse trees achieves comparable performance with feature-based methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature-based methods') is the object, depending on the preposition 'with', which is part of the comparative phrase 'with feature-based methods'. Entity 2 ('convolution kernel over parse trees') is the subject, depending on the verb 'achieves'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'achieves comparable performance with'.\""
    },
    {
        "raw_sentence": "It also shows that our method significantly outperforms the previous two dependency tree kernels on the 5 ACE relation major types .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "dependency tree kernels",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('dependency tree kernels') is the object, depending on 'outperforms' with 'method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is performing the action (outperforming) on 'dependency tree kernels'.\"",
        "sdp_path_text": "method → outperforms → kernels",
        "sentence": "Our method significantly outperforms dependency tree kernels.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'outperforms'. Entity 2 ('dependency tree kernels') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, where 'method' is the subject performing the action (outperforming) on 'dependency tree kernels'.\""
    },
    {
        "raw_sentence": "This paper presents the results of automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon from a Turkish dependency treebank .",
        "ner_pair": [
            [
                "automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon",
                "Task"
            ],
            [
                "Turkish dependency treebank",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon') is the object of the preposition 'of', depending on 'results'. Entity 2 ('Turkish dependency treebank') is the object of the preposition 'from', depending on 'inducing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the process and its source.\"",
        "sdp_path_text": "inducing → from → treebank",
        "sentence": "This paper presents results of automatically inducing a CCG lexicon from a Turkish dependency treebank.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically inducing a Combinatory Categorial Grammar (CCG) lexicon') is the object of the preposition 'of', depending on 'results'. Entity 2 ('Turkish dependency treebank') is the object of the preposition 'from', depending on 'inducing'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'inducing' which is part of Entity 1 and takes Entity 2 as its source.\""
    },
    {
        "raw_sentence": "This paper presents the results of automatically inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon from a Turkish dependency treebank .",
        "ner_pair": [
            [
                "Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon",
                "OtherScientificTerm"
            ],
            [
                "Turkish dependency treebank",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon') is the object of the verb 'inducing', depending on 'inducing' in the phrase 'inducing a Combinatory Categorial Grammar -LRB- CCG -RRB- lexicon'. Entity 2 ('Turkish dependency treebank') is the object of the preposition 'from', depending on 'from' in the phrase 'from a Turkish dependency treebank'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'inducing' and the preposition 'from'.\"",
        "sdp_path_text": "lexicon → inducing → from → treebank",
        "sentence": "A Combinatory Categorial Grammar (CCG) lexicon is induced from a Turkish dependency treebank.",
        "sentence_llm_dp_info": "\"Entity 1 ('Combinatory Categorial Grammar (CCG) lexicon') is the subject, depending on the verb 'induced'. Entity 2 ('Turkish dependency treebank') is the source, depending on the preposition 'from' in the phrase 'from a Turkish dependency treebank'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' indicating the origin of the induction process.\""
    },
    {
        "raw_sentence": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories .",
        "ner_pair": [
            [
                "Turkish",
                "Material"
            ],
            [
                "agglutinating free word order language",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject of the clause, depending on 'is' as the copula linking it to its complement. Entity 2 ('agglutinating free word order language') is the complement of the copula 'is', describing 'Turkish'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 specifies the characteristics of Entity 1.\"",
        "sdp_path_text": "Turkish → is → language",
        "sentence": "Turkish is an agglutinating free word order language.",
        "sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the copula 'is'. Entity 2 ('agglutinating free word order language') is the predicate nominal, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 describes what Entity 1 is.\""
    },
    {
        "raw_sentence": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories .",
        "ner_pair": [
            [
                "Turkish",
                "Material"
            ],
            [
                "language theories",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject complement, depending on the verb 'is' within the clause 'that Turkish is an agglutinating free word order language'. Entity 2 ('language theories') is the object, depending on the verb 'presents' with 'challenge'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where the characteristics of Turkish (Entity 1) present a challenge to language theories (Entity 2).\"",
        "sdp_path_text": "Turkish → is → fact → presents → for → theories",
        "sentence": "The fact that Turkish is an agglutinating language presents a challenge for language theories.",
        "sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject complement, depending on 'is' in the clause 'Turkish is an agglutinating language'. Entity 2 ('language theories') is the object, depending on 'presents' with 'challenge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence, connected through the predicate 'presents a challenge for'.\""
    },
    {
        "raw_sentence": "The fact that Turkish is an agglutinating free word order language presents a challenge for language theories .",
        "ner_pair": [
            [
                "agglutinating free word order language",
                "Material"
            ],
            [
                "language theories",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('agglutinating free word order language') is the subject complement, depending on the verb 'is' in the clause 'Turkish is an agglutinating free word order language'. Entity 2 ('language theories') is the object, depending on the verb 'presents' with 'challenge'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'presents' which indicates that the nature of Entity 1 poses a challenge to Entity 2.\"",
        "sdp_path_text": "language → is → fact → presents → for → theories",
        "sentence": "{\n  \"Simplified sentence\": \"The fact that Turkish is an agglutinating free word order language presents a challenge for language theories.\"\n} \n\nHowever, to better adhere to the instructions and make the sentence more concise while retaining the relationship between the two entities:\n\n{\n  \"Simplified sentence\": \"Turkish, an agglutinating free word order language, presents a challenge for language theories.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('agglutinating free word order language') is a modifier, depending on the noun 'Turkish'. Entity 2 ('language theories') is the object of the preposition 'for', depending on 'presents' in the phrase 'presents a challenge for language theories'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the clause describing the challenge presented by the characteristics of Turkish.\""
    },
    {
        "raw_sentence": "We explored possible ways to obtain a compact lexicon , consistent with CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .",
        "ner_pair": [
            [
                "compact lexicon",
                "OtherScientificTerm"
            ],
            [
                "CCG principles",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compact lexicon') is the object of the verb 'obtain', depending on 'ways'. Entity 2 ('CCG principles') is the complement of the preposition 'with', depending on 'consistent'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the goal of obtaining a compact lexicon that is consistent with CCG principles.\"",
        "sdp_path_text": "lexicon → consistent → with → principles",
        "sentence": "A compact lexicon is consistent with CCG principles.",
        "sentence_llm_dp_info": "\"Entity 1 ('compact lexicon') is the subject, depending on the verb 'is'. Entity 2 ('CCG principles') is the object of the preposition 'with', depending on 'with' in the phrase 'with CCG principles'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' and the linking verb 'is'.\""
    },
    {
        "raw_sentence": "We explored possible ways to obtain a compact lexicon , consistent with CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .",
        "ner_pair": [
            [
                "compact lexicon",
                "OtherScientificTerm"
            ],
            [
                "treebank",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compact lexicon') is the object of the verb 'obtain', depending on the verb 'obtained'. Entity 2 ('treebank') is the subject of the relative clause, depending on the verb 'is' in the clause 'which is an order of magnitude smaller than Penn WSJ'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the process of obtaining the lexicon from the treebank.\"",
        "sdp_path_text": "lexicon → obtain → from → treebank",
        "sentence": "A compact lexicon can be obtained from a treebank.",
        "sentence_llm_dp_info": "\"Entity 1 ('compact lexicon') is the subject, depending on the verb 'obtained'. Entity 2 ('treebank') is the object of the preposition 'from', depending on 'from' in the phrase 'from a treebank'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We explored possible ways to obtain a compact lexicon , consistent with CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .",
        "ner_pair": [
            [
                "compact lexicon",
                "OtherScientificTerm"
            ],
            [
                "Penn WSJ",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compact lexicon') is the object, depending on 'obtain' with 'ways'. Entity 2 ('Penn WSJ') is the complement, depending on 'smaller' with 'treebank'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "lexicon → obtain → from → treebank → is → smaller → than → WSJ",
        "sentence": "A compact lexicon can be obtained from a treebank smaller than Penn WSJ.",
        "sentence_llm_dp_info": "\"Entity 1 ('compact lexicon') is the subject, depending on the verb 'obtained'. Entity 2 ('Penn WSJ') is the object of the comparative preposition 'than', depending on 'smaller'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparison 'smaller than'.\""
    },
    {
        "raw_sentence": "We explored possible ways to obtain a compact lexicon , consistent with CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .",
        "ner_pair": [
            [
                "CCG principles",
                "Method"
            ],
            [
                "treebank",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CCG principles') is the object of the preposition 'with', depending on 'consistent'. Entity 2 ('treebank') is the subject of the relative clause, depending on 'which'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause structure, where the treebank is described as being consistent with CCG principles.\"",
        "sdp_path_text": "principles → with → consistent → lexicon → obtain → from → treebank",
        "sentence": "A lexicon consistent with CCG principles can be obtained from a treebank.",
        "sentence_llm_dp_info": "\"Entity 1 ('CCG principles') is the complement of the preposition 'with', depending on 'consistent'. Entity 2 ('treebank') is the object of the preposition 'from', depending on 'obtained'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We explored possible ways to obtain a compact lexicon , consistent with CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .",
        "ner_pair": [
            [
                "CCG principles",
                "Method"
            ],
            [
                "Penn WSJ",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CCG principles') is the object of the preposition 'with', depending on 'consistent'. Entity 2 ('Penn WSJ') is the object of the preposition 'than', depending on 'smaller'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "principles → with → consistent → lexicon → obtain → from → treebank → is → smaller → than → WSJ",
        "sentence": "A lexicon consistent with CCG principles can be obtained from a treebank smaller than Penn WSJ.",
        "sentence_llm_dp_info": "\"Entity 1 ('CCG principles') is the object of the preposition 'with', depending on 'consistent' in the phrase 'consistent with CCG principles'. Entity 2 ('Penn WSJ') is the complement of the comparison, depending on 'smaller' in the phrase 'smaller than Penn WSJ'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We explored possible ways to obtain a compact lexicon , consistent with CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .",
        "ner_pair": [
            [
                "treebank",
                "Generic"
            ],
            [
                "Penn WSJ",
                "Material"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('treebank') is the subject complement, depending on 'obtain' with 'ways'. Entity 2 ('Penn WSJ') is the object of comparison, depending on 'smaller' in the comparative clause 'smaller than Penn WSJ'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative relation expressed by 'smaller than'.\"",
        "sdp_path_text": "treebank → is → smaller → than → WSJ",
        "sentence": "The treebank is an order of magnitude smaller than Penn WSJ.",
        "sentence_llm_dp_info": "\"Entity 1 ('treebank') is the subject, depending on the comparative clause introduced by 'than'. Entity 2 ('Penn WSJ') is the complement in the comparative clause, depending on 'than'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure involving 'smaller than'.\""
    },
    {
        "raw_sentence": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres , because of the conversational nature of email communication where utterances are made in relation to one made previously , sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent .",
        "ner_pair": [
            [
                "sentence extraction",
                "Method"
            ],
            [
                "summarization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sentence extraction') is the subject, depending on 'has been shown' as part of the clause 'sentence extraction has been shown to work'. Entity 2 ('summarization') is the object of the preposition 'to', depending on 'approach' in the phrase 'approach to summarization'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where 'sentence extraction' is described as an 'approach to summarization'.\"",
        "sdp_path_text": "extraction → as → approach → to → summarization",
        "sentence": "Sentence extraction has been used as an approach to summarization.",
        "sentence_llm_dp_info": "\"Entity 1 ('sentence extraction') is the subject, depending on the verb 'has been used'. Entity 2 ('summarization') is the object of the preposition 'to', depending on 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'as an approach to summarization'.\""
    },
    {
        "raw_sentence": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres , because of the conversational nature of email communication where utterances are made in relation to one made previously , sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent .",
        "ner_pair": [
            [
                "sentence extraction",
                "Method"
            ],
            [
                "email communication",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sentence extraction') is the subject of the clause, depending on 'work' with the verb phrase 'has been shown to work'. Entity 2 ('email communication') is the object of the preposition 'of', depending on 'nature' in the phrase 'the conversational nature of email communication'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the discussion of the effectiveness of sentence extraction in different types of documents, including email communication.\"",
        "sdp_path_text": "extraction → shown → capture → because → nature → of → communication",
        "sentence": "Sentence extraction may not capture necessary dialogue segments due to the conversational nature of email communication.",
        "sentence_llm_dp_info": "\"Entity 1 ('sentence extraction') is the subject, depending on the modal verb 'may' which leads into the main verb 'capture'. Entity 2 ('email communication') is the object of the preposition 'of', depending on 'nature'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same causal context described in the sentence.\""
    },
    {
        "raw_sentence": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres , because of the conversational nature of email communication where utterances are made in relation to one made previously , sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent .",
        "ner_pair": [
            [
                "summarization",
                "Task"
            ],
            [
                "email communication",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('summarization') is part of the noun phrase 'an approach to summarization', which acts as the object of the preposition 'to', depending on 'approach'. Entity 2 ('email communication') is the object of the preposition 'of', depending on 'nature'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses and are related through the context of discussing the effectiveness of sentence extraction in different types of documents.\"",
        "sdp_path_text": "summarization → to → approach → as → extraction → shown → capture → because → nature → of → communication",
        "sentence": "Summarization through sentence extraction may not capture necessary dialogue segments in email communication due to its conversational nature.",
        "sentence_llm_dp_info": "\"Entity 1 ('summarization') is the subject, depending on the verb 'may not capture'. Entity 2 ('email communication') is the object of the preposition 'in', depending on 'in' in the phrase 'in email communication'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'capture' and the prepositional phrase 'in email communication'.\""
    },
    {
        "raw_sentence": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres , because of the conversational nature of email communication where utterances are made in relation to one made previously , sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent .",
        "ner_pair": [
            [
                "sentence extraction",
                "Method"
            ],
            [
                "summarization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sentence extraction') is the subject, depending on the verb 'has been shown' and is modified by 'as an approach'. Entity 2 ('summarization') is the object of the preposition 'to', depending on 'approach' in the phrase 'an approach to summarization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' and the noun 'approach'.\"",
        "sdp_path_text": "extraction → as → approach → to → summarization",
        "sentence": "Sentence extraction is an approach to summarization.",
        "sentence_llm_dp_info": "\"Entity 1 ('sentence extraction') is the subject, depending on the verb 'is'. Entity 2 ('summarization') is the complement, depending on the verb 'is' as part of the predicate nominal. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' which establishes that 'sentence extraction' is an approach to 'summarization'.\""
    },
    {
        "raw_sentence": "While sentence extraction as an approach to summarization has been shown to work in documents of certain genres , because of the conversational nature of email communication where utterances are made in relation to one made previously , sentence extraction may not capture the necessary segments of dialogue that would make a summary coherent .",
        "ner_pair": [
            [
                "email communication",
                "Material"
            ],
            [
                "sentence extraction",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('email communication') is the subject, depending on 'nature' with 'conversational'. Entity 2 ('sentence extraction') is the subject, depending on 'may not capture' with 'segments'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context discussing the effectiveness of sentence extraction in the specific genre of email communication.\"",
        "sdp_path_text": "communication → of → nature → because → capture → shown → extraction",
        "sentence": "Email communication's conversational nature may prevent sentence extraction from capturing necessary dialogue segments for a coherent summary.",
        "sentence_llm_dp_info": "\"Entity 1 ('email communication') is the possessor, depending on the noun 'nature' through the possessive form 'communication’s'. Entity 2 ('sentence extraction') is the subject, depending on the verb 'prevent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'prevent' and the prepositional phrase 'from capturing necessary dialogue segments for a coherent summary'.\""
    },
    {
        "raw_sentence": "In this paper , we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization .",
        "ner_pair": [
            [
                "email conversation",
                "Material"
            ],
            [
                "detection of question-answer pairs",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('email conversation') is the object of the preposition 'in', depending on 'pairs'. Entity 2 ('detection of question-answer pairs') is the object of the preposition 'on', depending on 'work'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'detection of question-answer pairs' is described as being conducted 'in an email conversation'.\" \n\nHowever, to be more precise, let's correct the dependency for Entity 1:\n\n\"Entity 1 ('email conversation') is the object of the preposition 'in', depending on 'work'. Entity 2 ('detection of question-answer pairs') is the object of the preposition 'on', depending on 'work'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the 'work' presented in the sentence.\"",
        "sdp_path_text": "conversation → in → detection",
        "sentence": "The detection of question-answer pairs occurs in an email conversation.",
        "sentence_llm_dp_info": "\"Entity 1 ('email conversation') is the object, depending on 'occurs' with 'detection of question-answer pairs'. Entity 2 ('detection of question-answer pairs') is the subject, depending on the verb 'occurs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'occurs'.\""
    },
    {
        "raw_sentence": "In this paper , we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization .",
        "ner_pair": [
            [
                "detection of question-answer pairs",
                "Task"
            ],
            [
                "email summarization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection of question-answer pairs') is the object of the preposition 'on', depending on 'work'. Entity 2 ('email summarization') is the object of the preposition 'for', depending on 'task'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence, where 'work' is presented 'on' Entity 1 'for the task of' Entity 2.\"",
        "sdp_path_text": "detection → on → work → present → for → task → of → summarization",
        "sentence": "The detection of question-answer pairs is presented for the task of email summarization.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection of question-answer pairs') is the subject, depending on the verb 'is presented'. Entity 2 ('email summarization') is the object of the preposition 'for', depending on 'for' in the phrase 'for the task of email summarization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating the purpose or context of the detection.\""
    },
    {
        "raw_sentence": "In this paper , we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization .",
        "ner_pair": [
            [
                "email conversation",
                "Material"
            ],
            [
                "email summarization",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('email conversation') is the object of the preposition 'in', depending on 'detection'. Entity 2 ('email summarization') is the object of the preposition 'for', depending on 'task'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "conversation → in → detection → on → work → present → for → task → of → summarization",
        "sentence": "We present work on detecting question-answer pairs in an email conversation for email summarization.",
        "sentence_llm_dp_info": "\"Entity 1 ('email conversation') is the object of the preposition 'in', depending on 'detecting'. Entity 2 ('email summarization') is the purpose or goal, depending on 'for' in the phrase 'for email summarization'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the scope of the sentence.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "structure of email-threads",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'of', depending on 'features'. Entity 2 ('features') is the subject, depending on 'based' with 'various'. There is a direct dependency between Entity 1 and Entity 2, as 'structure of email-threads' modifies 'features' to specify what kind of features are being discussed.\"",
        "sdp_path_text": "structure → on → based → features",
        "sentence": "Features based on the structure of email-threads can be used.",
        "sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the structure of email-threads'. Entity 2 ('features') is the subject, depending on the passive verb 'can be used'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'based on the structure of email-threads'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "lexical similarity",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on 'can be used' as part of the clause 'features can be used'. Entity 2 ('lexical similarity') is the object of the preposition 'of', depending on 'improve upon' in the phrase 'improve upon lexical similarity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve upon' which indicates that the features are used to enhance the lexical similarity.\"",
        "sdp_path_text": "features → used → improve → upon → similarity",
        "sentence": "Features can be used to improve lexical similarity.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'can be used'. Entity 2 ('lexical similarity') is the object, depending on 'improve' with 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "discourse segments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the subject complement, depending on the verb 'can be used'. Entity 2 ('discourse segments') is the object of the preposition 'of', depending on 'similarity' in the phrase 'similarity of discourse segments'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "features → used → improve → upon → similarity → of → segments",
        "sentence": "Features can be used to improve the similarity of discourse segments.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'can be used'. Entity 2 ('discourse segments') is the object of the preposition 'of', depending on 'similarity'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "question-answer pairing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the object of the preposition 'based on', depending on 'that'. Entity 2 ('question-answer pairing') is the object of the preposition 'for', depending on 'improve'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing what can be used to improve the lexical similarity of discourse segments.\"",
        "sdp_path_text": "features → used → improve → for → pairing",
        "sentence": "Features can be used to improve question-answer pairing.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'can be used'. Entity 2 ('question-answer pairing') is the object, depending on 'improve' with 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improve'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "structure of email-threads",
                "OtherScientificTerm"
            ],
            [
                "lexical similarity",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'on', depending on 'based'. Entity 2 ('lexical similarity') is the object of the preposition 'of', depending on 'similarity'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what can be used to improve the process mentioned in the sentence.\"",
        "sdp_path_text": "structure → on → based → features → used → improve → upon → similarity",
        "sentence": "Features based on the structure of email-threads can be used to improve lexical similarity.",
        "sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'based', depending on 'based' in the phrase 'based on the structure of email-threads'. Entity 2 ('lexical similarity') is the object, depending on 'improve' with 'can be used to improve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to improve lexical similarity'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "structure of email-threads",
                "OtherScientificTerm"
            ],
            [
                "discourse segments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'based on', depending on 'features'. Entity 2 ('discourse segments') is the object of the preposition 'of', depending on 'similarity'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the clause describing the improvement of lexical similarity.\"",
        "sdp_path_text": "structure → on → based → features → used → improve → upon → similarity → of → segments",
        "sentence": "Features based on the structure of email-threads are used to improve the similarity of discourse segments.",
        "sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the structure of email-threads'. Entity 2 ('discourse segments') is the object of the preposition 'of', depending on 'similarity' in the phrase 'similarity of discourse segments'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence's structure that describes the features used to improve the similarity.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "structure of email-threads",
                "OtherScientificTerm"
            ],
            [
                "question-answer pairing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the structure of email-threads'. Entity 2 ('question-answer pairing') is the object of the preposition 'for', depending on 'improve' in the phrase 'improve upon lexical similarity of discourse segments for question-answer pairing'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the features derived from Entity 1 are used to enhance the process described by Entity 2.\"",
        "sdp_path_text": "structure → on → based → features → used → improve → for → pairing",
        "sentence": "Features based on the structure of email-threads can be used to improve question-answer pairing.",
        "sentence_llm_dp_info": "\"Entity 1 ('structure of email-threads') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the structure of email-threads'. Entity 2 ('question-answer pairing') is the object of the verb 'improve', depending on 'improve' in the phrase 'to improve question-answer pairing'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'improve' which indicates that the features based on Entity 1 can be used to enhance Entity 2.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "lexical similarity",
                "OtherScientificTerm"
            ],
            [
                "discourse segments",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical similarity') is the object, depending on 'improve' with 'can be used to improve'. Entity 2 ('discourse segments') is the object of the preposition 'of', depending on 'of' in the phrase 'of discourse segments'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'lexical similarity' is modified by 'of discourse segments'.\"",
        "sdp_path_text": "similarity → of → segments",
        "sentence": "Features improve lexical similarity of discourse segments.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical similarity') is the object, depending on the verb 'improve' with 'Features'. Entity 2 ('discourse segments') is the object of the preposition 'of', depending on 'of' in the phrase 'of discourse segments'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'of' which connects 'lexical similarity' to 'discourse segments'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "lexical similarity",
                "OtherScientificTerm"
            ],
            [
                "question-answer pairing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical similarity') is the object of the preposition 'upon', depending on 'improve'. Entity 2 ('question-answer pairing') is the object of the prepositional phrase 'for question-answer pairing', depending on 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'lexical similarity' is what is being improved upon for the purpose of enhancing 'question-answer pairing'.\"",
        "sdp_path_text": "similarity → upon → improve → for → pairing",
        "sentence": "Features based on email-thread structure can improve lexical similarity for question-answer pairing.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical similarity') is the object, depending on the verb 'improve'. Entity 2 ('question-answer pairing') is the object of the preposition 'for', depending on 'for' in the phrase 'for question-answer pairing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .",
        "ner_pair": [
            [
                "discourse segments",
                "OtherScientificTerm"
            ],
            [
                "question-answer pairing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse segments') is the object of the preposition 'of', depending on 'similarity'. Entity 2 ('question-answer pairing') is the complement of the preposition 'for', depending on 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the features improve.\"",
        "sdp_path_text": "segments → of → similarity → upon → improve → for → pairing",
        "sentence": "Features based on the structure of email-threads can improve the lexical similarity of discourse segments for question-answer pairing.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse segments') is the object of the preposition 'of', depending on 'similarity'. Entity 2 ('question-answer pairing') is the object of the preposition 'for', depending on 'for' in the phrase 'for question-answer pairing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the features can improve.\""
    },
    {
        "raw_sentence": "Specifically , we show how to incorporate a simple prior on the distribution of natural images into support vector machines .",
        "ner_pair": [
            [
                "prior on the distribution of natural images",
                "OtherScientificTerm"
            ],
            [
                "support vector machines",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('prior on the distribution of natural images') is the object of the preposition 'on', depending on 'incorporate'. Entity 2 ('support vector machines') is the object, depending on 'into' which is part of the verb phrase 'incorporate ... into'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate' and the preposition 'into'.\"",
        "sdp_path_text": "prior → incorporate → into → machines",
        "sentence": "We show how to incorporate a prior on the distribution of natural images into support vector machines.",
        "sentence_llm_dp_info": "\"Entity 1 ('prior on the distribution of natural images') is the object of the preposition 'on', depending on 'incorporate'. Entity 2 ('support vector machines') is the object, depending on 'into' with 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the action described by the verb 'incorporate'.\""
    },
    {
        "raw_sentence": "SVMs are known to be robust to overfitting ; however , a few training examples usually do not represent well the structure of the class .",
        "ner_pair": [
            [
                "SVMs",
                "Method"
            ],
            [
                "overfitting",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('SVMs') is the subject, depending on the verb 'are' in the clause 'SVMs are known'. Entity 2 ('overfitting') is the object of the preposition 'to', depending on 'robust' in the phrase 'robust to overfitting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'robust' and the preposition 'to'.\"",
        "sdp_path_text": "SVMs → known → be → robust → to → overfitting",
        "sentence": "SVMs are known to be robust to overfitting.",
        "sentence_llm_dp_info": "\"Entity 1 ('SVMs') is the subject, depending on the verb 'are known'. Entity 2 ('overfitting') is the object of the preposition 'to', depending on 'robust' in the phrase 'robust to overfitting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the adjective 'robust' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We incorporate the prior on natural images by requiring that the separating hyperplane will not only yield a wide margin , but also that the corresponding positive half space will have a low probability to contain natural images -LRB- the background -RRB- .",
        "ner_pair": [
            [
                "prior on natural images",
                "OtherScientificTerm"
            ],
            [
                "hyperplane",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('prior on natural images') is the object of the preposition 'on', depending on the verb 'incorporate'. Entity 2 ('hyperplane') is part of the compound noun 'separating hyperplane', which is the subject of the clause 'the separating hyperplane will not only yield a wide margin'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same complex sentence structure where the 'prior on natural images' influences the conditions set for the 'hyperplane'.\"",
        "sdp_path_text": "prior → incorporate → by → requiring → yield → hyperplane",
        "sentence": "We incorporate the prior on natural images by requiring the hyperplane to yield a wide margin.",
        "sentence_llm_dp_info": "\"Entity 1 ('prior on natural images') is the object of the preposition 'on', depending on 'incorporate' with 'We'. Entity 2 ('hyperplane') is the subject, depending on the infinitive 'to yield'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and contribute to the meaning of the sentence, with Entity 1 being incorporated into the model and Entity 2 being required to yield a wide margin.\""
    },
    {
        "raw_sentence": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples .",
        "ner_pair": [
            [
                "real data sets",
                "Material"
            ],
            [
                "detector",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('real data sets') is the object of the preposition 'on', depending on 'experiments'. Entity 2 ('detector') is the subject complement, depending on the verb 'is' in the clause 'the resulting detector is more robust'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger clause where 'experiments' conducted 'on real data sets' lead to conclusions about the 'detector'.\"",
        "sdp_path_text": "sets → on → experiments → show → is → detector",
        "sentence": "Experiments on real data sets show the resulting detector is more robust.",
        "sentence_llm_dp_info": "\"Entity 1 ('real data sets') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('detector') is the subject complement, depending on 'is' in the clause 'the resulting detector is more robust'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples .",
        "ner_pair": [
            [
                "real data sets",
                "Material"
            ],
            [
                "linear and kernel SVM",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('real data sets') is the object of the preposition 'on', depending on 'experiments'. Entity 2 ('linear and kernel SVM') is the object of the verb 'improves', depending on 'improves' in the clause 'improves both linear and kernel SVM'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "sets → on → experiments → show → is → improves → SVM",
        "sentence": "Experiments on real data sets show improvements in linear and kernel SVM.",
        "sentence_llm_dp_info": "\"Entity 1 ('real data sets') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('linear and kernel SVM') is the object of the preposition 'in', depending on 'show'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing the context and outcome of the experiments.\""
    },
    {
        "raw_sentence": "Our experiments on real data sets show that the resulting detector is more robust to the choice of training examples , and substantially improves both linear and kernel SVM when trained on 10 positive and 10 negative examples .",
        "ner_pair": [
            [
                "detector",
                "Method"
            ],
            [
                "linear and kernel SVM",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detector') is the subject complement, depending on 'is' with 'the resulting'. Entity 2 ('linear and kernel SVM') is the object, depending on 'improves' with 'detector'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves'.\"",
        "sdp_path_text": "detector → is → improves → SVM",
        "sentence": "The detector improves both linear and kernel SVM.",
        "sentence_llm_dp_info": "\"Entity 1 ('detector') is the subject, depending on the verb 'improves'. Entity 2 ('linear and kernel SVM') is the object, depending on the verb 'improves'. There is a direct dependency between Entity 1 and Entity 2, as 'detector' directly affects 'linear and kernel SVM' through the action of 'improves'.\""
    },
    {
        "raw_sentence": "Although the study of clustering is centered around an intuitively compelling goal , it has been very difficult to develop a unified framework for reasoning about it at a technical level , and profoundly diverse approaches to clustering abound in the research community .",
        "ner_pair": [
            [
                "clustering",
                "Task"
            ],
            [
                "unified framework",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clustering') is the object of the preposition 'of', depending on 'study'. It also appears as the object of the preposition 'for', depending on 'framework'. Entity 2 ('unified framework') is the object, depending on 'develop'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the verb 'develop'.\"",
        "sdp_path_text": "clustering → of → study → centered → been → develop → framework",
        "sentence": "Developing a unified framework for the study of clustering has been difficult.",
        "sentence_llm_dp_info": "\"Entity 1 ('clustering') is the object of the preposition 'of', depending on 'study'. Entity 2 ('unified framework') is the object of the preposition 'for', depending on 'framework' in the phrase 'for the study'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different aspects of the main clause.\""
    },
    {
        "raw_sentence": "Although the study of clustering is centered around an intuitively compelling goal , it has been very difficult to develop a unified framework for reasoning about it at a technical level , and profoundly diverse approaches to clustering abound in the research community .",
        "ner_pair": [
            [
                "clustering",
                "Task"
            ],
            [
                "reasoning",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clustering') is the object of the preposition 'of', depending on 'study'. It also appears as part of the noun phrase 'approaches to clustering', where it is the object of the preposition 'to'. Entity 2 ('reasoning') is part of the noun phrase 'reasoning about it', where it is the gerund verbal form, and it depends on 'framework' as the object of the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2; however, they are both involved in the broader context of the sentence, which discusses challenges related to clustering and the development of frameworks for reasoning about it.\"",
        "sdp_path_text": "clustering → of → study → centered → been → develop → framework → for → reasoning",
        "sentence": "The study of clustering has been centered around developing a framework for reasoning.",
        "sentence_llm_dp_info": "\"Entity 1 ('clustering') is the object of the preposition 'of', depending on 'study'. Entity 2 ('reasoning') is the object of the preposition 'for', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'clustering' is studied and 'reasoning' is the goal of the developed framework.\""
    },
    {
        "raw_sentence": "Although the study of clustering is centered around an intuitively compelling goal , it has been very difficult to develop a unified framework for reasoning about it at a technical level , and profoundly diverse approaches to clustering abound in the research community .",
        "ner_pair": [
            [
                "unified framework",
                "Method"
            ],
            [
                "reasoning",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unified framework') is the object, depending on 'develop' with 'it has been very difficult to develop'. Entity 2 ('reasoning') is part of a nominal compound, depending on 'about' with 'for reasoning about it at a technical level'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the verb 'reasoning' within the larger clause.\"",
        "sdp_path_text": "framework → for → reasoning",
        "sentence": "A unified framework for reasoning about clustering has been difficult to develop.",
        "sentence_llm_dp_info": "\"Entity 1 ('unified framework') is the subject, depending on the verb 'has been' in the phrase 'has been difficult to develop'. Entity 2 ('reasoning') is part of the prepositional phrase 'about clustering', where it serves as the object of the preposition 'about', depending on 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the prepositional phrase 'about clustering'.\""
    },
    {
        "raw_sentence": "Here we suggest a formal perspective on the difficulty in finding such a unification , in the form of an impossibility theorem : for a set of three simple properties , we show that there is no clustering function satisfying all three .",
        "ner_pair": [
            [
                "unification",
                "Method"
            ],
            [
                "impossibility theorem",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unification') is the object of the preposition 'in', depending on 'difficulty'. Entity 2 ('impossibility theorem') is the object of the preposition 'of', depending on 'form'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the content of the suggestion.\"",
        "sdp_path_text": "unification → finding → in → difficulty → on → perspective → suggest → in → form → of → theorem",
        "sentence": "We suggest a perspective on the difficulty of finding unification in the form of an impossibility theorem.",
        "sentence_llm_dp_info": "\"Entity 1 ('unification') is the object of the preposition 'of', depending on 'finding'. Entity 2 ('impossibility theorem') is the complement of the preposition 'of', depending on 'form'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different parts of the sentence.\""
    },
    {
        "raw_sentence": "Here we suggest a formal perspective on the difficulty in finding such a unification , in the form of an impossibility theorem : for a set of three simple properties , we show that there is no clustering function satisfying all three .",
        "ner_pair": [
            [
                "unification",
                "Method"
            ],
            [
                "clustering function",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unification') is the object of the preposition 'in', depending on 'finding' in the phrase 'the difficulty in finding such a unification'. Entity 2 ('clustering function') is the subject complement, depending on 'is' in the clause 'there is no clustering function'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the same sentence.\"",
        "sdp_path_text": "unification → finding → in → difficulty → on → perspective → suggest → show → is → function",
        "sentence": "We suggest a perspective on the difficulty in finding a unification, showing that there is no clustering function satisfying certain properties.",
        "sentence_llm_dp_info": "\"Entity 1 ('unification') is the object of the preposition 'in', depending on 'finding' in the phrase 'difficulty in finding a unification'. Entity 2 ('clustering function') is the subject complement, depending on 'is' in the clause 'there is no clustering function'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Here we suggest a formal perspective on the difficulty in finding such a unification , in the form of an impossibility theorem : for a set of three simple properties , we show that there is no clustering function satisfying all three .",
        "ner_pair": [
            [
                "impossibility theorem",
                "Method"
            ],
            [
                "clustering function",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('impossibility theorem') is the object of the preposition 'of', depending on 'form' in the phrase 'in the form of an impossibility theorem'. Entity 2 ('clustering function') is the subject, depending on 'show' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence context where the 'impossibility theorem' is used to demonstrate something about the 'clustering function'.\"",
        "sdp_path_text": "theorem → of → form → in → suggest → show → is → function",
        "sentence": "We suggest an impossibility theorem showing there is no clustering function satisfying all three properties.",
        "sentence_llm_dp_info": "\"Entity 1 ('impossibility theorem') is the direct object, depending on the verb 'suggest'. Entity 2 ('clustering function') is the subject of the clause 'there is no clustering function', depending on 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the content of the sentence where the theorem is about the non-existence of the clustering function.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "single-linkage",
                "Method"
            ],
            [
                "well-studied clustering techniques",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is a member of a list, depending on the conjunction 'and' with other items like 'sum-of-pairs', 'k-means', and 'k-median', which together form the object of the preposition 'such as'. Entity 2 ('well-studied clustering techniques') is the noun phrase being modified by the prepositional phrase 'such as single-linkage, sum-of-pairs, k-means, and k-median', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the prepositional phrase that lists 'single-linkage' as an example of 'well-studied clustering techniques'.\"",
        "sdp_path_text": "- → as → techniques",
        "sentence": "Single-linkage is one of the well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is the subject, depending on the copula 'is'. Entity 2 ('well-studied clustering techniques') is the complement, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'single-linkage' is described as being 'one of the well-studied clustering techniques'.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "sum-of-pairs",
                "Method"
            ],
            [
                "well-studied clustering techniques",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sum-of-pairs') is part of a list, depending on the conjunction 'and' which links it to other items in the list (such as 'single-linkage', 'k-means', and 'k-median'). Entity 2 ('well-studied clustering techniques') is the object of the preposition 'in', depending on 'in' in the phrase 'in well-studied clustering techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the list structure and the context of being examples of the 'well-studied clustering techniques'.\"",
        "sdp_path_text": "sum → linkage → as → techniques",
        "sentence": "Sum-of-pairs is one of the well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('sum-of-pairs') is the subject, depending on the verb 'is'. Entity 2 ('well-studied clustering techniques') is the complement, depending on the verb 'is' in the phrase 'is one of the well-studied clustering techniques'. There is a direct dependency between Entity 1 and Entity 2, as 'sum-of-pairs' is described as being one of the 'well-studied clustering techniques'.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "k-means",
                "Method"
            ],
            [
                "well-studied clustering techniques",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('k-means') is a member of a list, depending on the conjunction 'and' with other clustering techniques. Entity 2 ('well-studied clustering techniques') is the noun being modified, depending on the preposition 'in' which connects it to the clause 'at work in well-studied clustering techniques'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 1 is part of the list that is an example of Entity 2.\"",
        "sdp_path_text": "k → - → sum → linkage → as → techniques",
        "sentence": "k-means is one of the well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('k-means') is the subject, depending on the copula 'is'. Entity 2 ('well-studied clustering techniques') is the complement, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, where 'k-means' is described as being part of 'well-studied clustering techniques'.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "k-median",
                "Method"
            ],
            [
                "well-studied clustering techniques",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('k-median') is part of a coordination, depending on the conjunction 'and' with 'such as'. Entity 2 ('well-studied clustering techniques') is the object of the preposition 'in', depending on 'work'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'k-median' is listed as an example of 'well-studied clustering techniques'.\"",
        "sdp_path_text": "k → means → k → - → sum → linkage → as → techniques",
        "sentence": "k-median is among well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('k-median') is the subject, depending on the copula 'is'. Entity 2 ('well-studied clustering techniques') is the predicative complement, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'k-median' is described as being among the 'well-studied clustering techniques'.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "single-linkage",
                "Method"
            ],
            [
                "sum-of-pairs",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is part of a list, depending on 'techniques' as an example. Entity 2 ('sum-of-pairs') is also part of the same list, depending on 'techniques' as another example. There is no direct dependency between Entity 1 and Entity 2; both are listed as examples of well-studied clustering techniques.\"",
        "sdp_path_text": "- → as → linkage → sum",
        "sentence": "Single-linkage and sum-of-pairs are well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is the subject, depending on the verb 'are' in the predicate. Entity 2 ('sum-of-pairs') is coordinated with 'single-linkage' as another subject, also depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in the sentence and are connected through coordination.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "single-linkage",
                "Method"
            ],
            [
                "k-means",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is part of a list, depending on the conjunction 'such as', which itself depends on 'techniques'. Entity 2 ('k-means') is also part of the same list, depending on the conjunction 'and', which connects it to other items in the list, ultimately depending on 'such as'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of clustering techniques.\"",
        "sdp_path_text": "- → as → linkage → sum → - → k",
        "sentence": "Single-linkage and k-means are well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is a compound noun, depending on 'are' as part of the subject. Entity 2 ('k-means') is also a compound noun, depending on 'are' as part of the subject. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same subject in the sentence.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "single-linkage",
                "Method"
            ],
            [
                "k-median",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is part of a list, depending on 'such as' which introduces examples of 'clustering techniques'. Entity 2 ('k-median') is also part of the same list, depending on 'and' which connects it to other items in the list introduced by 'such as'. There is no direct dependency between Entity 1 and Entity 2; they are both listed as examples of clustering techniques.\"",
        "sdp_path_text": "- → as → linkage → sum → - → k → means → k",
        "sentence": "Single-linkage and k-median are well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('single-linkage') is a compound noun, depending on 'are' as a subject. Entity 2 ('k-median') is also a compound noun, conjoined with 'and' to form a coordinate subject with 'single-linkage'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the coordinate subject of the sentence.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "sum-of-pairs",
                "Method"
            ],
            [
                "k-means",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sum-of-pairs') is part of a coordination, depending on the conjunction 'and' with 'k-median'. Entity 2 ('k-means') is also part of a coordination, depending on the conjunction 'and' with 'k-median'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated elements in the list of clustering techniques.\"",
        "sdp_path_text": "sum → - → k",
        "sentence": "Sum-of-pairs and k-means are well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('sum-of-pairs') is a compound noun, depending on the verb 'are' as part of the subject. Entity 2 ('k-means') is also a compound noun, depending on the verb 'are' as part of the subject. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same subject in the sentence.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "sum-of-pairs",
                "Method"
            ],
            [
                "k-median",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sum-of-pairs') is part of a list, depending on the conjunction 'and' which connects it with 'k-means'. Entity 2 ('k-median') is also part of the same list, depending on the conjunction 'and' which connects it with 'k-means'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of clustering techniques.\"",
        "sdp_path_text": "sum → - → k → means → k",
        "sentence": "Sum-of-pairs and k-median are well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('sum-of-pairs') is the subject, depending on the verb 'are' in the phrase 'are well-studied'. Entity 2 ('k-median') is coordinated with Entity 1, depending on 'and' in the phrase 'sum-of-pairs and k-median'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a coordinate structure linked by 'and'.\""
    },
    {
        "raw_sentence": "Relaxations of these properties expose some of the interesting -LRB- and unavoidable -RRB- trade-offs at work in well-studied clustering techniques such as single-linkage , sum-of-pairs , k-means , and k-median .",
        "ner_pair": [
            [
                "k-means",
                "Method"
            ],
            [
                "k-median",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('k-means') is a conjunct, depending on 'and' with 'k-median'. Entity 2 ('k-median') is also a conjunct, depending on 'and' with 'k-means'. There is a direct dependency between Entity 1 and Entity 2, as they are part of a conjunction list.\"",
        "sdp_path_text": "k → means → k",
        "sentence": "k-means and k-median are well-studied clustering techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('k-means') is a coordinate, depending on the conjunction 'and' with 'k-median'. Entity 2 ('k-median') is also a coordinate, depending on the conjunction 'and' with 'k-means'. Both entities are part of the subject of the sentence, which depends on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "With relevant approach , we identify important contents by PageRank algorithm on the event map constructed from documents .",
        "ner_pair": [
            [
                "PageRank algorithm",
                "Method"
            ],
            [
                "relevant approach",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PageRank algorithm') is the object of the preposition 'by', depending on 'identify'. Entity 2 ('relevant approach') is the object of the preposition 'With', depending on 'identify'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'identify'.\"",
        "sdp_path_text": "algorithm → by → identify → With → approach",
        "sentence": "The PageRank algorithm identifies important contents with the relevant approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('PageRank algorithm') is the subject, depending on the verb 'identifies'. Entity 2 ('relevant approach') is the object of the preposition 'with', depending on 'with' in the phrase 'with the relevant approach'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "With relevant approach , we identify important contents by PageRank algorithm on the event map constructed from documents .",
        "ner_pair": [
            [
                "relevant approach",
                "Method"
            ],
            [
                "event map",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relevant approach') is the object of the preposition 'With', depending on 'identify'. Entity 2 ('event map') is the object of the preposition 'on', depending on 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'relevant approach' modifies the action of identifying, and 'event map' is the location where the PageRank algorithm is applied.\"",
        "sdp_path_text": "approach → With → identify → on → map",
        "sentence": "With a relevant approach, we identify important contents on the event map.",
        "sentence_llm_dp_info": "\"Entity 1 ('relevant approach') is the object of the preposition 'with', depending on 'identify'. Entity 2 ('event map') is the object of the preposition 'on', depending on 'contents'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where 'identify' is the main verb.\""
    },
    {
        "raw_sentence": "With relevant approach , we identify important contents by PageRank algorithm on the event map constructed from documents .",
        "ner_pair": [
            [
                "relevant approach",
                "Method"
            ],
            [
                "documents",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relevant approach') is the object of the preposition 'With', depending on 'identify'. Entity 2 ('documents') is the object of the preposition 'from', depending on 'constructed'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "approach → With → identify → on → map → constructed → from → documents",
        "sentence": "With the relevant approach, we identify important contents from documents.",
        "sentence_llm_dp_info": "\"Entity 1 ('relevant approach') is the object of the preposition 'with', depending on 'identify'. Entity 2 ('documents') is the object of the preposition 'from', depending on 'from' in the phrase 'from documents'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where 'identify' is the main verb.\""
    },
    {
        "raw_sentence": "With relevant approach , we identify important contents by PageRank algorithm on the event map constructed from documents .",
        "ner_pair": [
            [
                "event map",
                "OtherScientificTerm"
            ],
            [
                "PageRank algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('event map') is the object of the preposition 'on', depending on 'constructed'. Entity 2 ('PageRank algorithm') is the object of the preposition 'by', depending on 'identify'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how important contents are identified.\"",
        "sdp_path_text": "map → on → identify → by → algorithm",
        "sentence": "We identify important contents by PageRank algorithm on the event map.",
        "sentence_llm_dp_info": "\"Entity 1 ('event map') is the object, depending on the preposition 'on', which modifies the verb 'identify'. Entity 2 ('PageRank algorithm') is the object of the preposition 'by', indicating the method used to identify important contents. There is no direct dependency between Entity 1 and Entity 2; both are related to the process of identifying important contents.\""
    },
    {
        "raw_sentence": "With relevant approach , we identify important contents by PageRank algorithm on the event map constructed from documents .",
        "ner_pair": [
            [
                "PageRank algorithm",
                "Method"
            ],
            [
                "documents",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PageRank algorithm') is the object of the preposition 'by', depending on 'identify' in the phrase 'identify important contents by PageRank algorithm'. Entity 2 ('documents') is the object of the preposition 'from', depending on 'constructed' in the phrase 'constructed from documents'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described in the sentence, where the 'PageRank algorithm' is used to identify important contents, and these contents are based on an 'event map' that is constructed from 'documents'.\"",
        "sdp_path_text": "algorithm → by → identify → on → map → constructed → from → documents",
        "sentence": "The PageRank algorithm identifies important contents on the map constructed from documents.",
        "sentence_llm_dp_info": "\"Entity 1 ('PageRank algorithm') is the subject, depending on the verb 'identifies'. Entity 2 ('documents') is the object of the preposition 'from', depending on 'constructed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'identifies' and the prepositional phrase 'on the map constructed from documents'.\""
    },
    {
        "raw_sentence": "With relevant approach , we identify important contents by PageRank algorithm on the event map constructed from documents .",
        "ner_pair": [
            [
                "documents",
                "Material"
            ],
            [
                "event map",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('documents') is the object, depending on 'constructed' with 'event map'. Entity 2 ('event map') is the object of the preposition 'on', depending on 'on' in the phrase 'on the event map'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'constructed'.\"",
        "sdp_path_text": "documents → from → constructed → map",
        "sentence": "We construct an event map from documents.",
        "sentence_llm_dp_info": "\"Entity 1 ('documents') is the object, depending on the preposition 'from', which is part of the prepositional phrase 'from documents'. Entity 2 ('event map') is the direct object, depending on the verb 'construct'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating the source of the construction.\""
    },
    {
        "raw_sentence": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry .",
        "ner_pair": [
            [
                "scanning method",
                "Method"
            ],
            [
                "dense sub-pixel camera-projector correspondence",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scanning method') is the object of the verb 'present', depending on 'We'. Entity 2 ('dense sub-pixel camera-projector correspondence') is the object of the verb 'recovers', depending on 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recovers'.\"",
        "sdp_path_text": "method → recovers → correspondence",
        "sentence": "The scanning method recovers dense sub-pixel camera-projector correspondence.",
        "sentence_llm_dp_info": "\"Entity 1 ('scanning method') is the subject, depending on the verb 'recovers'. Entity 2 ('dense sub-pixel camera-projector correspondence') is the object, depending on 'recovers' with 'scanning method'. There is a direct dependency between Entity 1 and Entity 2, as 'scanning method' recovers 'dense sub-pixel camera-projector correspondence'.\""
    },
    {
        "raw_sentence": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry .",
        "ner_pair": [
            [
                "scanning method",
                "Method"
            ],
            [
                "photometric calibration",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scanning method') is the object, depending on 'present' with 'We'. Entity 2 ('photometric calibration') is part of the object of the preposition 'requiring', depending on 'requiring' in the phrase 'without requiring any photometric calibration'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the negated prepositional phrase indicating what is not required by the method.\"",
        "sdp_path_text": "method → recovers → without → requiring → calibration",
        "sentence": "The scanning method recovers without requiring photometric calibration.",
        "sentence_llm_dp_info": "\"Entity 1 ('scanning method') is the subject, depending on the verb 'recovers'. Entity 2 ('photometric calibration') is the object of the preposition 'requiring', depending on 'requiring' in the phrase 'without requiring photometric calibration'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'without' and the verb 'requiring'.\""
    },
    {
        "raw_sentence": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry .",
        "ner_pair": [
            [
                "scanning method",
                "Method"
            ],
            [
                "relative geometry",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scanning method') is the object, depending on 'present' with 'We'. Entity 2 ('relative geometry') is the object of the preposition 'of', depending on 'knowledge' in the phrase 'knowledge of their relative geometry'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'scanning method' is presented as a technique that does not require 'knowledge of their relative geometry'.\"",
        "sdp_path_text": "method → recovers → without → requiring → calibration → knowledge → of → geometry",
        "sentence": "The scanning method recovers without requiring knowledge of the relative geometry.",
        "sentence_llm_dp_info": "\"Entity 1 ('scanning method') is the subject, depending on the verb 'recovers'. Entity 2 ('relative geometry') is the object of the preposition 'of', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of the relative geometry' which modifies 'knowledge'.\""
    },
    {
        "raw_sentence": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry .",
        "ner_pair": [
            [
                "dense sub-pixel camera-projector correspondence",
                "OtherScientificTerm"
            ],
            [
                "photometric calibration",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dense sub-pixel camera-projector correspondence') is the object of the relative clause, depending on 'recovers' with 'method'. Entity 2 ('photometric calibration') is the object of the preposition 'requiring', depending on 'requiring' in the phrase 'without requiring any photometric calibration'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the method's capabilities and requirements.\"",
        "sdp_path_text": "correspondence → recovers → without → requiring → calibration",
        "sentence": "The method recovers dense sub-pixel camera-projector correspondence without requiring photometric calibration.",
        "sentence_llm_dp_info": "\"Entity 1 ('dense sub-pixel camera-projector correspondence') is the object of the verb 'recovers', depending on 'recovers' with 'The method'. Entity 2 ('photometric calibration') is the object of the preposition 'requiring', depending on 'requiring' in the phrase 'without requiring photometric calibration'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry .",
        "ner_pair": [
            [
                "dense sub-pixel camera-projector correspondence",
                "OtherScientificTerm"
            ],
            [
                "relative geometry",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dense sub-pixel camera-projector correspondence') is the object of the relative clause, depending on 'recovers' with 'method'. Entity 2 ('relative geometry') is the object of the preposition 'of', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence, where the method recovers the correspondence without needing knowledge of the relative geometry.\"",
        "sdp_path_text": "correspondence → recovers → without → requiring → calibration → knowledge → of → geometry",
        "sentence": "The method recovers dense sub-pixel camera-projector correspondence without requiring knowledge of their relative geometry.",
        "sentence_llm_dp_info": "\"Entity 1 ('dense sub-pixel camera-projector correspondence') is the object, depending on the verb 'recovers' with 'The method'. Entity 2 ('relative geometry') is the object of the preposition 'of', depending on 'knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the method does and what it does not require.\""
    },
    {
        "raw_sentence": "We present a scanning method that recovers dense sub-pixel camera-projector correspondence without requiring any photometric calibration nor preliminary knowledge of their relative geometry .",
        "ner_pair": [
            [
                "photometric calibration",
                "OtherScientificTerm"
            ],
            [
                "relative geometry",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric calibration') is the object of the preposition 'requiring', depending on 'requiring' in the phrase 'without requiring any photometric calibration'. Entity 2 ('relative geometry') is also the object of the preposition 'requiring', depending on 'requiring' in the phrase 'preliminary knowledge of their relative geometry'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items not required by the method described.\"",
        "sdp_path_text": "calibration → knowledge → of → geometry",
        "sentence": "The method does not require photometric calibration nor knowledge of relative geometry.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric calibration') is the object of negation, depending on 'require' with 'does not require'. Entity 2 ('relative geometry') is also an object of negation, depending on 'knowledge' in the phrase 'knowledge of relative geometry'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of negation in the context of what is not required by 'the method'.\""
    },
    {
        "raw_sentence": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns .",
        "ner_pair": [
            [
                "zero-crossings",
                "OtherScientificTerm"
            ],
            [
                "Subpixel accuracy",
                "Metric"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('zero-crossings') is the subject, depending on the passive verb 'defined' with 'by the difference between pairs of unstructured patterns'. Entity 2 ('Subpixel accuracy') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the clause 'considering several zero-crossings defined by the difference between pairs of unstructured patterns' which explains how Entity 2 is achieved.\"",
        "sdp_path_text": "- → considering → by → achieved → accuracy",
        "sentence": "Subpixel accuracy is achieved by considering zero-crossings.",
        "sentence_llm_dp_info": "\"Entity 1 ('zero-crossings') is the object of the preposition 'by', depending on 'considering'. Entity 2 ('Subpixel accuracy') is the subject, depending on the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the prepositional phrase 'by considering zero-crossings'.\""
    },
    {
        "raw_sentence": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns .",
        "ner_pair": [
            [
                "Subpixel accuracy",
                "Metric"
            ],
            [
                "unstructured patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Subpixel accuracy') is the subject, depending on the verb 'achieved'. Entity 2 ('unstructured patterns') is the object, depending on 'between' within the prepositional phrase 'between pairs of unstructured patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of dependencies involving 'achieved', 'considering', 'zero-crossings', and 'defined by'.\"",
        "sdp_path_text": "accuracy → achieved → by → considering → crossings → defined → by → difference → between → pairs → of → patterns",
        "sentence": "Subpixel accuracy is achieved by considering zero-crossings defined by the difference between unstructured patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('Subpixel accuracy') is the subject, depending on the verb 'achieved'. Entity 2 ('unstructured patterns') is the object of the preposition 'between', depending on 'difference'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'achieved' and the prepositional phrase 'by considering zero-crossings defined by the difference between unstructured patterns'.\""
    },
    {
        "raw_sentence": "Subpixel accuracy is achieved by considering several zero-crossings defined by the difference between pairs of unstructured patterns .",
        "ner_pair": [
            [
                "zero-crossings",
                "OtherScientificTerm"
            ],
            [
                "unstructured patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('zero-crossings') is the object of the preposition 'by', depending on 'considering'. Entity 2 ('unstructured patterns') is the object of the preposition 'between', depending on 'difference'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrases that describe how the zero-crossings are defined by the difference between pairs of unstructured patterns.\"",
        "sdp_path_text": "- → considering → crossings → defined → by → difference → between → pairs → of → patterns",
        "sentence": "Zero-crossings are defined by the difference between pairs of unstructured patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('zero-crossings') is the subject, depending on the verb 'defined'. Entity 2 ('unstructured patterns') is the object of the preposition 'between', depending on 'between' in the phrase 'between pairs of unstructured patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'by the difference between pairs of unstructured patterns'.\""
    },
    {
        "raw_sentence": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities .",
        "ner_pair": [
            [
                "robustness",
                "Metric"
            ],
            [
                "gray-level band-pass white noise patterns",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object of the verb 'increase', depending on 'increase' with 'patterns'. Entity 2 ('gray-level band-pass white noise patterns') is the subject, depending on 'use' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'increase' which indicates that Entity 2 contributes to an increase in Entity 1.\"",
        "sdp_path_text": "robustness → increase → patterns",
        "sentence": "Gray-level band-pass white noise patterns increase robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object, depending on the verb 'increase'. Entity 2 ('gray-level band-pass white noise patterns') is the subject, depending on the verb 'increase'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 acts as the agent that increases Entity 1.\""
    },
    {
        "raw_sentence": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities .",
        "ner_pair": [
            [
                "gray-level band-pass white noise patterns",
                "OtherScientificTerm"
            ],
            [
                "indirect lighting",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('gray-level band-pass white noise patterns') is the object, depending on the verb 'use' with 'We'. Entity 2 ('indirect lighting') is part of a prepositional phrase, depending on 'to' in the phrase 'to indirect lighting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'increase' and the preposition 'to'.\"",
        "sdp_path_text": "patterns → increase → robustness → to → lighting",
        "sentence": "Gray-level band-pass white noise patterns increase robustness to indirect lighting.",
        "sentence_llm_dp_info": "\"Entity 1 ('gray-level band-pass white noise patterns') is the subject, depending on the verb 'increase'. Entity 2 ('indirect lighting') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'increase' and the prepositional phrase 'to indirect lighting'.\""
    },
    {
        "raw_sentence": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities .",
        "ner_pair": [
            [
                "gray-level band-pass white noise patterns",
                "OtherScientificTerm"
            ],
            [
                "scene discontinuities",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('gray-level band-pass white noise patterns') is the object, depending on 'use' with 'We'. Entity 2 ('scene discontinuities') is the object of the preposition 'to', depending on 'to' in the phrase 'to indirect lighting and scene discontinuities'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\"",
        "sdp_path_text": "patterns → increase → robustness → to → lighting → discontinuities",
        "sentence": "Gray-level band-pass white noise patterns increase robustness to scene discontinuities.",
        "sentence_llm_dp_info": "\"Entity 1 ('gray-level band-pass white noise patterns') is the subject, depending on the verb 'increase'. Entity 2 ('scene discontinuities') is the object, depending on the preposition 'to' in the phrase 'to scene discontinuities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'increase' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities .",
        "ner_pair": [
            [
                "indirect lighting",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indirect lighting') is the object of the preposition 'to', depending on 'robustness'. Entity 2 ('robustness') is the direct object, depending on the verb 'increase' with 'patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'to indirect lighting' which modifies 'robustness'.\"",
        "sdp_path_text": "lighting → to → robustness",
        "sentence": "Gray-level band-pass white noise patterns increase robustness to indirect lighting.",
        "sentence_llm_dp_info": "\"Entity 1 ('indirect lighting') is the object of the preposition 'to', depending on 'to' in the phrase 'to indirect lighting'. Entity 2 ('robustness') is the direct object, depending on the verb 'increase'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'increase' which indicates that 'indirect lighting' affects 'robustness'.\""
    },
    {
        "raw_sentence": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities .",
        "ner_pair": [
            [
                "scene discontinuities",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scene discontinuities') is the object of the preposition 'to', depending on 'to' in the phrase 'to indirect lighting and scene discontinuities'. Entity 2 ('robustness') is the object, depending on 'increase' with 'patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'robustness' is what is increased, and 'scene discontinuities' is one of the factors to which this increase in robustness applies.\"",
        "sdp_path_text": "discontinuities → lighting → to → robustness",
        "sentence": "Scene discontinuities increase robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('scene discontinuities') is the subject, depending on the verb 'increase'. Entity 2 ('robustness') is the object, depending on the verb 'increase'. There is a direct dependency between Entity 1 and Entity 2, where 'scene discontinuities' is the agent that increases 'robustness'.\""
    },
    {
        "raw_sentence": "We use gray-level band-pass white noise patterns that increase robustness to indirect lighting and scene discontinuities .",
        "ner_pair": [
            [
                "indirect lighting",
                "OtherScientificTerm"
            ],
            [
                "scene discontinuities",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indirect lighting') is the object of the preposition 'to', depending on 'robustness'. Entity 2 ('scene discontinuities') is also the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the same prepositional phrase 'to indirect lighting and scene discontinuities'.\"",
        "sdp_path_text": "lighting → discontinuities",
        "sentence": "Gray-level band-pass white noise patterns increase robustness to indirect lighting and scene discontinuities.",
        "sentence_llm_dp_info": "\"Entity 1 ('indirect lighting') is part of a prepositional phrase, depending on 'to' in 'to indirect lighting'. Entity 2 ('scene discontinuities') is also part of a prepositional phrase, depending on 'and' which connects it to 'indirect lighting'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the preposition 'to' in the phrase 'to indirect lighting and scene discontinuities'.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "scene geometry",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'recovers'. Entity 2 ('scene geometry') is the object, depending on 'recovers' with 'method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' directly recovers 'scene geometry'.\"",
        "sdp_path_text": "method → recovers → geometry",
        "sentence": "Our method recovers scene geometry.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'recovers'. Entity 2 ('scene geometry') is the object, depending on the verb 'recovers'. There is a direct dependency between Entity 1 and Entity 2, where 'method' is the agent performing the action of recovering 'scene geometry'.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "subpixel precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the verb 'recovers', depending on 'recovers' in the clause 'our method recovers'. Entity 2 ('subpixel precision') is the object of the preposition 'with', depending on 'with' in the phrase 'with high subpixel precision'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'recovers' and the preposition 'with'.\"",
        "sdp_path_text": "method → recovers → with → precision",
        "sentence": "The method recovers scene geometry with high subpixel precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'recovers'. Entity 2 ('subpixel precision') is part of a noun phrase functioning as an adverbial modifier of degree, depending on 'high'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'recovers' and the adverbial phrase 'with high subpixel precision'.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'recovers' with 'scene geometry'. Entity 2 ('it') is the subject, depending on 'can handle' with 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as 'it' refers back to the method mentioned earlier in the sentence.\"",
        "sdp_path_text": "method → recovers → with",
        "sentence": "The method recovers scene geometry with high precision.",
        "sentence_llm_dp_info": "It appears there might be a slight confusion in the provided example, as \"it\" is not explicitly mentioned in the sentence. However, I will proceed with the dependency parsing analysis for the given sentence focusing on \"method\" and \"scene geometry\" as the two entities.\n\nSentence: The method recovers scene geometry with high precision.\nEntity 1: method\nEntity 2: scene geometry\n\nAnswer:\n\"Entity 1 ('method') is the subject, depending on the verb 'recovers'. Entity 2 ('scene geometry') is the object, depending on the verb 'recovers'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is the agent performing the action (recovering) on 'scene geometry'.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "active reconstruction systems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the verb 'recovers', depending on 'recovers' in the clause 'our method recovers scene geometry'. Entity 2 ('active reconstruction systems') is the object of the preposition 'of', depending on 'challenges' in the phrase 'challenges of active reconstruction systems'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context provided by the sentence.\"",
        "sdp_path_text": "method → recovers → handle → challenges → of → systems",
        "sentence": "The method recovers scene geometry and handles challenges of active reconstruction systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'recovers'. Entity 2 ('active reconstruction systems') is the object of the preposition 'of', depending on 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'handles' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "subpixel precision",
                "Metric"
            ],
            [
                "scene geometry",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('subpixel precision') is the object of the preposition 'with', depending on 'recovers' in the phrase 'recovers scene geometry with high subpixel precision'. Entity 2 ('scene geometry') is the direct object, depending on 'recovers' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'scene geometry' is recovered 'with subpixel precision'.\"",
        "sdp_path_text": "precision → with → recovers → geometry",
        "sentence": "The method recovers scene geometry with subpixel precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('subpixel precision') is the object of the preposition 'with', depending on 'recovers'. Entity 2 ('scene geometry') is the direct object, depending on the verb 'recovers'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'recovers'.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "scene geometry",
                "OtherScientificTerm"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scene geometry') is the object, depending on 'recovers' with 'method'. Entity 2 ('it') is the subject, depending on 'can' with 'handle'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' refers back to the method mentioned earlier in the sentence.\"",
        "sdp_path_text": "geometry → recovers → with",
        "sentence": "The method recovers scene geometry with high precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('scene geometry') is the object, depending on the verb 'recovers'. Entity 2 ('it') is not present in the sentence provided. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 does not appear in the sentence.\"\n\nNote: Since \"it\" was mentioned as Entity 2 but does not appear in the given sentence, I've noted that it is not present in the sentence. If you meant to refer to another word or if there's a different sentence, please clarify."
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "scene geometry",
                "OtherScientificTerm"
            ],
            [
                "active reconstruction systems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scene geometry') is the object of the verb 'recovers', depending on 'method' which is part of the clause 'our method recovers scene geometry'. Entity 2 ('active reconstruction systems') is the object of the verb 'handle', depending on 'it' which refers to the method mentioned earlier. There is no direct dependency between Entity 1 and Entity 2; both are related to the method described in the sentence.\"",
        "sdp_path_text": "geometry → recovers → handle → challenges → of → systems",
        "sentence": "The method recovers scene geometry and handles challenges of active reconstruction systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('scene geometry') is the object of the verb 'recovers', depending on 'recovers' with 'method'. Entity 2 ('active reconstruction systems') is the object of the preposition 'of', depending on 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the capabilities of the method described in the sentence.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "subpixel precision",
                "Metric"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('subpixel precision') is the object, depending on 'with' which modifies 'recovers'. Entity 2 ('it') is the subject, depending on 'can' in the clause 'it can handle'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "precision → with",
        "sentence": "The method recovers scene geometry with high subpixel precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('subpixel precision') is the object of the preposition 'with', depending on 'recovers' in the phrase 'with high subpixel precision'. Entity 2 ('it') is not present in the sentence provided, so no dependencies can be described for Entity 2. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 does not appear in the sentence.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "subpixel precision",
                "Metric"
            ],
            [
                "active reconstruction systems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('subpixel precision') is the object of the preposition 'with', depending on 'recovers' in the phrase 'recovers scene geometry with high subpixel precision'. Entity 2 ('active reconstruction systems') is the object of the preposition 'of', depending on 'challenges' in the phrase 'challenges of active reconstruction systems'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "precision → with → recovers → handle → challenges → of → systems",
        "sentence": "The method recovers scene geometry with subpixel precision and handles challenges of active reconstruction systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('subpixel precision') is the object of the preposition 'with', depending on 'recovers' in the phrase 'recovers scene geometry with subpixel precision'. Entity 2 ('active reconstruction systems') is the object of the preposition 'of', depending on 'challenges' in the phrase 'challenges of active reconstruction systems'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Simulated and experimental results show that our method recovers scene geometry with high subpixel precision , and that it can handle many challenges of active reconstruction systems .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "active reconstruction systems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on 'can handle' with 'handle'. Entity 2 ('active reconstruction systems') is the object, depending on 'of' with 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'handle' and the preposition 'of'.\"",
        "sdp_path_text": "with → recovers → handle → challenges → of → systems",
        "sentence": "It recovers scene geometry with high precision and handles challenges of active reconstruction systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'recovers'. Entity 2 ('active reconstruction systems') is the object of the preposition 'of', depending on 'challenges'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' performs actions that address the challenges of 'active reconstruction systems'.\""
    },
    {
        "raw_sentence": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting .",
        "ner_pair": [
            [
                "mi-cro phase shifting",
                "Method"
            ],
            [
                "state of the art methods",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mi-cro phase shifting') is part of a list, depending on the conjunction 'and' with 'modulated phase shifting'. Entity 2 ('state of the art methods') is the object of the preposition 'to', depending on 'compare' in the phrase 'compare our results to state of the art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same comparison context.\"",
        "sdp_path_text": "shifting → as → methods",
        "sentence": "mi-cro phase shifting is considered among state of the art methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('mi-cro phase shifting') is the subject, depending on the verb 'is considered'. Entity 2 ('state of the art methods') is the complement, depending on 'considered' with 'among'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considered' and the preposition 'among'.\""
    },
    {
        "raw_sentence": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting .",
        "ner_pair": [
            [
                "modulated phase shifting",
                "Method"
            ],
            [
                "state of the art methods",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('modulated phase shifting') is part of a list, depending on the conjunction 'and' with 'mi-cro phase shifting', which together form the object of the preposition 'such as'. Entity 2 ('state of the art methods') is the object of the preposition 'to', depending on 'compare' in the phrase 'compare... to state of the art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase structure.\"",
        "sdp_path_text": "shifting → shifting → as → methods",
        "sentence": "Modulated phase shifting is considered among state of the art methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('modulated phase shifting') is the subject, depending on the verb 'is considered'. Entity 2 ('state of the art methods') is the complement, depending on 'considered' in the phrase 'is considered among state of the art methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considered'.\""
    },
    {
        "raw_sentence": "We compare our results to state of the art methods such as mi-cro phase shifting and modulated phase shifting .",
        "ner_pair": [
            [
                "mi-cro phase shifting",
                "Method"
            ],
            [
                "modulated phase shifting",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mi-cro phase shifting') is the object of the preposition 'such as', depending on 'such as' in the phrase 'such as mi-cro phase shifting'. Entity 2 ('modulated phase shifting') is also the object of the preposition 'such as', depending on 'such as' in the phrase 'such as modulated phase shifting'. There is no direct dependency between Entity 1 and Entity 2; both are listed as examples of state-of-the-art methods.\"",
        "sdp_path_text": "shifting → shifting",
        "sentence": "We compare our results to methods such as mi-cro phase shifting and modulated phase shifting.",
        "sentence_llm_dp_info": "\"Entity 1 ('mi-cro phase shifting') is part of a list, depending on 'such as' with 'methods'. Entity 2 ('modulated phase shifting') is also part of the same list, depending on 'such as' with 'methods'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list introduced by 'such as'.\""
    },
    {
        "raw_sentence": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "acquiring adjectival subcategorization frames -LRB- scfs -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the object of the verb 'describes', depending on 'This paper'. Entity 2 ('acquiring adjectival subcategorization frames -LRB- scfs -RRB-') is the complement of the preposition 'for', depending on 'for' in the phrase 'for acquiring adjectival subcategorization frames -LRB- scfs -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "system → for → acquiring",
        "sentence": "This paper describes a system for acquiring adjectival subcategorization frames.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the object of the verb 'describes', depending on 'describes' with 'This paper'. Entity 2 ('acquiring adjectival subcategorization frames -LRB- scfs -RRB-') is the complement of the preposition 'for', depending on 'for' in the phrase 'for acquiring adjectival subcategorization frames'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "subcategorization frames -LRB- scfs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the object, depending on the verb 'describes' with 'This paper'. Entity 2 ('subcategorization frames -LRB- scfs -RRB-') is the object of the preposition 'for', depending on 'acquiring' in the phrase 'for acquiring'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'for acquiring adjectival subcategorization frames -LRB- scfs -RRB-.'\"",
        "sdp_path_text": "system → for → acquiring → frames",
        "sentence": "This paper describes a system for acquiring subcategorization frames.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the object, depending on the verb 'describes' with 'This paper'. Entity 2 ('subcategorization frames') is the object of the preposition 'for', depending on 'for' in the phrase 'for acquiring subcategorization frames'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "English corpus data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the object of the preposition 'for', depending on 'describes' with 'This paper'. Entity 2 ('English corpus data') is the object of the preposition 'from', depending on 'acquiring'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the purpose and source of the acquisition process.\"",
        "sdp_path_text": "system → for → acquiring → from → data",
        "sentence": "A system acquires information from English corpus data.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'acquires'. Entity 2 ('English corpus data') is the object, depending on the preposition 'from' in the phrase 'from English corpus data'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'acquires' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data .",
        "ner_pair": [
            [
                "acquiring adjectival subcategorization frames -LRB- scfs -RRB-",
                "Task"
            ],
            [
                "English corpus data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('acquiring adjectival subcategorization frames -LRB- scfs -RRB-') is the object of the preposition 'for', depending on 'describes' with 'This paper'. Entity 2 ('English corpus data') is the object of the preposition 'from', depending on 'acquiring'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'acquiring' depends on 'for' and 'data' depends on 'from'.\"",
        "sdp_path_text": "acquiring → from → data",
        "sentence": "This paper describes a system for acquiring adjectival subcategorization frames from English corpus data.",
        "sentence_llm_dp_info": "\"Entity 1 ('acquiring adjectival subcategorization frames -LRB- scfs -RRB-') is the object of the preposition 'for', depending on 'system'. Entity 2 ('English corpus data') is the object of the preposition 'from', depending on 'frames'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of different prepositions that relate to the process described in the sentence.\""
    },
    {
        "raw_sentence": "This paper describes a novel system for acquiring adjectival subcategorization frames -LRB- scfs -RRB- and associated frequency information from English corpus data .",
        "ner_pair": [
            [
                "subcategorization frames -LRB- scfs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "English corpus data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('subcategorization frames -LRB- scfs -RRB-') is the object of the preposition 'for', depending on 'acquiring'. Entity 2 ('English corpus data') is the object of the preposition 'from', depending on 'from' in the phrase 'from English corpus data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described by the sentence, where Entity 1 is what is being acquired, and Entity 2 is the source from which it is acquired.\"",
        "sdp_path_text": "frames → acquiring → from → data",
        "sentence": "This paper describes a system for acquiring subcategorization frames from English corpus data.",
        "sentence_llm_dp_info": "\"Entity 1 ('subcategorization frames') is the object of the preposition 'for', depending on 'acquiring'. Entity 2 ('English corpus data') is the object of the preposition 'from', depending on 'frames'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the verb 'acquiring'.\""
    },
    {
        "raw_sentence": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser .",
        "ner_pair": [
            [
                "decision-tree classifier",
                "Method"
            ],
            [
                "system",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('decision-tree classifier') is the object of the preposition 'a', depending on 'incorporates' with 'system'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, where 'system' is the head of the verb 'incorporates' and 'decision-tree classifier' is the object being incorporated.\"",
        "sdp_path_text": "classifier → incorporates → system",
        "sentence": "The system incorporates a decision-tree classifier.",
        "sentence_llm_dp_info": "\"Entity 1 ('decision-tree classifier') is the object, depending on the verb 'incorporates'. Entity 2 ('system') is the subject, depending on the verb 'incorporates'. There is a direct dependency between Entity 1 and Entity 2, as 'system' incorporates 'decision-tree classifier'.\""
    },
    {
        "raw_sentence": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "grammatical relations -LRB- grs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('grammatical relations -LRB- grs -RRB-') is the object of the preposition 'of', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the series of relationships involving 'incorporates', 'classifier', 'tests', 'presence', and 'grammatical relations -LRB- grs -RRB-.'\"",
        "sdp_path_text": "system → incorporates → classifier → tests → for → presence → of → relations",
        "sentence": "The system incorporates a classifier that tests for the presence of grammatical relations.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('grammatical relations') is the object of the preposition 'of', depending on 'presence' in the phrase 'presence of grammatical relations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporates' and the relative clause 'that tests for the presence of grammatical relations'.\""
    },
    {
        "raw_sentence": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "robust statistical parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('robust statistical parser') is the object of the preposition 'of', depending on 'output' in the phrase 'output of a robust statistical parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporates' and the prepositional phrase describing the output of the parser.\"",
        "sdp_path_text": "system → incorporates → classifier → tests → for → presence → in → output → of → parser",
        "sentence": "The system incorporates a classifier that tests for the presence of grammatical relations in the output of a robust statistical parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'incorporates'. Entity 2 ('robust statistical parser') is the object of the preposition 'of', depending on 'output'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the chain 'system -> incorporates -> classifier -> tests -> presence -> of -> grammatical relations -> in -> output -> of -> robust statistical parser'.\""
    },
    {
        "raw_sentence": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser .",
        "ner_pair": [
            [
                "decision-tree classifier",
                "Method"
            ],
            [
                "grammatical relations -LRB- grs -RRB-",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('decision-tree classifier') is the object of the preposition 'a', depending on 'incorporates' with 'The system'. Entity 2 ('grammatical relations -LRB- grs -RRB-') is the object of the preposition 'of', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where the 'decision-tree classifier' is used to test for the 'presence' of 'grammatical relations -LRB- grs -RRB-.'\"",
        "sdp_path_text": "classifier → tests → for → presence → of → relations",
        "sentence": "The decision-tree classifier tests for the presence of grammatical relations.",
        "sentence_llm_dp_info": "\"Entity 1 ('decision-tree classifier') is the subject, depending on the verb 'tests'. Entity 2 ('grammatical relations') is the object of the preposition 'of', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'tests' and the prepositional phrase 'for the presence of grammatical relations'.\""
    },
    {
        "raw_sentence": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser .",
        "ner_pair": [
            [
                "decision-tree classifier",
                "Method"
            ],
            [
                "robust statistical parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('decision-tree classifier') is the object of the preposition 'a', depending on 'incorporates' with 'The system'. Entity 2 ('robust statistical parser') is the subject complement, depending on 'of' in the phrase 'output of a robust statistical parser'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing components of 'The system'.\"",
        "sdp_path_text": "classifier → tests → for → presence → in → output → of → parser",
        "sentence": "The decision-tree classifier tests for the presence of grammatical relations in the output of a robust statistical parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('decision-tree classifier') is the subject, depending on the verb 'tests'. Entity 2 ('robust statistical parser') is the object of the preposition 'of', depending on 'output'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'tests' and the prepositional phrase 'in the output of a robust statistical parser'.\""
    },
    {
        "raw_sentence": "The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations -LRB- grs -RRB- in the output of a robust statistical parser .",
        "ner_pair": [
            [
                "grammatical relations -LRB- grs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "robust statistical parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grammatical relations -LRB- grs -RRB-') is the object of the preposition 'of', depending on 'tests'. Entity 2 ('robust statistical parser') is the object of the preposition 'of', depending on 'output'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'tests' through the prepositional phrases 'for the presence of grammatical relations -LRB- grs -RRB-' and 'in the output of a robust statistical parser'.\"",
        "sdp_path_text": "relations → of → presence → in → output → of → parser",
        "sentence": "The system tests for the presence of grammatical relations in the output of a robust statistical parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('grammatical relations') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('robust statistical parser') is the object of the preposition 'of', depending on 'output'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that serves as the object of the verb 'tests'.\""
    },
    {
        "raw_sentence": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica .",
        "ner_pair": [
            [
                "pattern-matching language",
                "OtherScientificTerm"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pattern-matching language') is the object of the preposition 'a', depending on 'uses' with 'It'. Entity 2 ('It') is the subject, depending on the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' where 'It' is the subject performing the action and 'pattern-matching language' is part of what is being used.\"",
        "sdp_path_text": "language → uses → It",
        "sentence": "It uses a pattern-matching language.",
        "sentence_llm_dp_info": "\"Entity 1 ('pattern-matching language') is the object, depending on 'uses' with 'It'. Entity 2 ('It') is the subject, depending on the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses'.\""
    },
    {
        "raw_sentence": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "grs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'uses'. Entity 2 ('grs') is the object of the preposition 'into', depending on 'classify'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'classify' and the preposition 'into'.\"",
        "sdp_path_text": "It → uses → classify → grs",
        "sentence": "It uses a pattern-matching language to classify grs.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'uses'. Entity 2 ('grs') is the object, depending on the verb 'classify'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'uses' and 'classify'.\""
    },
    {
        "raw_sentence": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "inheritance-based lexica",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'uses'. Entity 2 ('inheritance-based lexica') is the object of the preposition 'that', depending on 'mirrors' in the clause 'that mirrors inheritance-based lexica'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'mirrors' and the preposition 'that'.\"",
        "sdp_path_text": "It → uses → classify → in → way → mirrors → lexica",
        "sentence": "It uses a method to classify grs in a way that mirrors inheritance-based lexica.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'uses'. Entity 2 ('inheritance-based lexica') is the object of the preposition 'that mirrors', depending on 'mirrors' in the phrase 'that mirrors inheritance-based lexica'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'uses' and the relative clause 'that mirrors inheritance-based lexica'.\""
    },
    {
        "raw_sentence": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica .",
        "ner_pair": [
            [
                "pattern-matching language",
                "OtherScientificTerm"
            ],
            [
                "grs",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pattern-matching language') is the object of the preposition 'a', depending on 'uses' with 'It'. Entity 2 ('grs') is the object of the preposition 'into', depending on 'classify' with 'language'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'classify'.\"",
        "sdp_path_text": "language → uses → classify → grs",
        "sentence": "It uses a pattern-matching language to classify grs.",
        "sentence_llm_dp_info": "\"Entity 1 ('pattern-matching language') is the object of the preposition 'a', depending on 'uses'. Entity 2 ('grs') is the object of the verb 'classify', depending on 'classify'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'classify', where Entity 1 is used to perform the action on Entity 2.\""
    },
    {
        "raw_sentence": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica .",
        "ner_pair": [
            [
                "pattern-matching language",
                "OtherScientificTerm"
            ],
            [
                "inheritance-based lexica",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pattern-matching language') is the object of the preposition 'a', depending on 'uses' with 'It'. Entity 2 ('inheritance-based lexica') is the object of the preposition 'that', depending on 'mirrors' with 'way'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the action described by the verb 'mirrors'.\"",
        "sdp_path_text": "language → uses → classify → in → way → mirrors → lexica",
        "sentence": "A pattern-matching language is used to classify in a way that mirrors inheritance-based lexica.",
        "sentence_llm_dp_info": "\"Entity 1 ('pattern-matching language') is the subject, depending on the verb 'is used'. Entity 2 ('inheritance-based lexica') is the object of the preposition 'that', depending on 'mirrors' in the phrase 'that mirrors inheritance-based lexica'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'mirrors' and the preposition 'that'.\""
    },
    {
        "raw_sentence": "It uses a powerful pattern-matching language to classify grs into frames hierarchically in a way that mirrors inheritance-based lexica .",
        "ner_pair": [
            [
                "grs",
                "OtherScientificTerm"
            ],
            [
                "inheritance-based lexica",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grs') is the object of the preposition 'into', depending on 'classify' with 'pattern-matching language'. Entity 2 ('inheritance-based lexica') is the complement of the clause, depending on 'mirrors' with 'way'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'mirrors' and the prepositional structure 'in a way that mirrors inheritance-based lexica'.\"",
        "sdp_path_text": "grs → classify → in → way → mirrors → lexica",
        "sentence": "grs are classified in a way that mirrors inheritance-based lexica.",
        "sentence_llm_dp_info": "\"Entity 1 ('grs') is the subject, depending on the verb 'classified'. Entity 2 ('inheritance-based lexica') is the object of the preposition 'that mirrors', depending on 'mirrors' in the phrase 'mirrors inheritance-based lexica'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in a way that mirrors'.\""
    },
    {
        "raw_sentence": "The experiments show that the system is able to detect scf types with 70 % precision and 66 % recall rate .",
        "ner_pair": [
            [
                "precision",
                "Metric"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('precision') is the object of the preposition 'with', depending on the verb 'detect'. Entity 2 ('system') is the subject, depending on the verb 'is' in the clause 'the system is able to detect'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'detect' and the preposition 'with'.\"",
        "sdp_path_text": "precision → with → detect → able → is → system",
        "sentence": "The system is able to detect with 70% precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('precision') is the object of the preposition 'with', depending on 'detect'. Entity 2 ('system') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'detect' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "The experiments show that the system is able to detect scf types with 70 % precision and 66 % recall rate .",
        "ner_pair": [
            [
                "recall",
                "Metric"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recall') is part of a compound noun, depending on 'rate' with 'recall rate'. Entity 2 ('system') is the subject, depending on 'is' in the clause 'the system is able to detect scf types'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "recall → rate → precision → with → detect → able → is → system",
        "sentence": "{\n  \"Simplified sentence\": \"The system is able to detect with a recall rate.\"\n} \n\nHowever, this simplification loses some clarity and context. A better approach might be to include the essential verb and object to maintain the full meaning:\n\n{\n  \"Simplified sentence\": \"The system is able to detect with a recall rate of 66%.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('recall') is part of the noun phrase 'recall rate', which is the object of the preposition 'with', depending on 'detect'. Entity 2 ('system') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'detect' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "The experiments show that the system is able to detect scf types with 70 % precision and 66 % recall rate .",
        "ner_pair": [
            [
                "precision",
                "Metric"
            ],
            [
                "recall",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('precision') is the object of the preposition 'with', depending on the verb 'detect'. Entity 2 ('recall') is also the object of the preposition 'with', depending on the verb 'detect'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'detect' through the preposition 'with'.\"",
        "sdp_path_text": "precision → rate → recall",
        "sentence": "The system detects scf types with 70% precision and 66% recall.",
        "sentence_llm_dp_info": "\"Entity 1 ('precision') is the object of the preposition 'with', depending on 'detects'. Entity 2 ('recall') is also the object of the preposition 'with', depending on 'detects'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'with' in the context of the sentence.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "tool",
                "Generic"
            ],
            [
                "linguistic annotation of scfs",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on 'introduced' with 'is also introduced'. Entity 2 ('linguistic annotation of scfs') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic annotation of scfs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "tool → for → annotation",
        "sentence": "A new tool is introduced for linguistic annotation of scfs.",
        "sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on the verb 'introduced'. Entity 2 ('linguistic annotation of scfs') is the object of the preposition 'for', depending on 'for' in the phrase 'for linguistic annotation of scfs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "tool",
                "Generic"
            ],
            [
                "scfs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on 'introduced' with 'is'. Entity 2 ('scfs') is the object of the preposition 'of', depending on 'annotation' in the phrase 'annotation of scfs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for linguistic annotation of scfs'.\"",
        "sdp_path_text": "tool → for → annotation → of → scfs",
        "sentence": "A new tool for annotating scfs is introduced.",
        "sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on the verb 'introduced'. Entity 2 ('scfs') is the object of the preposition 'for', depending on 'for' in the phrase 'for annotating scfs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "tool",
                "Generic"
            ],
            [
                "training and test data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on 'introduced' with 'is also introduced'. Entity 2 ('training and test data') is the object of the preposition 'for', depending on 'obtaining' in the phrase 'obtaining training and test data'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'alleviate' and the preposition 'for'.\"",
        "sdp_path_text": "tool → alleviate → process → of → obtaining → data",
        "sentence": "A new tool can alleviate the process of obtaining training and test data.",
        "sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on the verb 'can alleviate'. Entity 2 ('training and test data') is the object of the preposition 'of', depending on 'process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'alleviate' and the prepositional phrase 'of obtaining training and test data'.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "tool",
                "Generic"
            ],
            [
                "subcategorization acquisition",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on 'introduced' with 'is also introduced'. Entity 2 ('subcategorization acquisition') is the object, depending on 'for' in the phrase 'for subcategorization acquisition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause introduced by 'which can considerably alleviate the process of obtaining training and test data for...'.\"",
        "sdp_path_text": "tool → alleviate → process → of → obtaining → for → acquisition",
        "sentence": "A new tool can alleviate the process of obtaining data for subcategorization acquisition.",
        "sentence_llm_dp_info": "\"Entity 1 ('tool') is the subject, depending on the verb 'can alleviate'. Entity 2 ('subcategorization acquisition') is the object of the preposition 'for', depending on 'for' in the phrase 'for subcategorization acquisition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "linguistic annotation of scfs",
                "Task"
            ],
            [
                "training and test data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic annotation of scfs') is the object of the preposition 'for', depending on 'tool'. Entity 2 ('training and test data') is the object of the preposition 'of', depending on 'process'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, where the tool mentioned is related to the process of obtaining the data.\"",
        "sdp_path_text": "annotation → for → tool → alleviate → process → of → obtaining → data",
        "sentence": "A new tool for linguistic annotation of scfs can alleviate the process of obtaining training and test data.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic annotation of scfs') is the object of the preposition 'for', depending on 'tool'. Entity 2 ('training and test data') is the object of the preposition 'of', depending on 'process'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure that describes the benefits of the new tool.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "linguistic annotation of scfs",
                "Task"
            ],
            [
                "subcategorization acquisition",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic annotation of scfs') is the object of the preposition 'for', depending on 'tool'. Entity 2 ('subcategorization acquisition') is the object of the preposition 'for', depending on 'data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence, where Entity 1 is a component that the tool aims to facilitate, and Entity 2 is the ultimate goal that benefits from the tool's capabilities.\"",
        "sdp_path_text": "annotation → for → tool → alleviate → process → of → obtaining → for → acquisition",
        "sentence": "A tool for linguistic annotation of scfs can alleviate the process of obtaining data for subcategorization acquisition.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic annotation of scfs') is the object of the preposition 'for', depending on 'tool'. Entity 2 ('subcategorization acquisition') is the object of the preposition 'for', depending on 'data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, where a tool aims to alleviate the process of obtaining data relevant to subcategorization acquisition.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "scfs",
                "OtherScientificTerm"
            ],
            [
                "training and test data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scfs') is the object of the preposition 'of', depending on 'annotation'. Entity 2 ('training and test data') is the object of the preposition 'of', depending on 'process'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context related to the tool's function in the sentence.\"",
        "sdp_path_text": "scfs → of → annotation → for → tool → alleviate → process → of → obtaining → data",
        "sentence": "A tool for annotating scfs can alleviate the process of obtaining training and test data.",
        "sentence_llm_dp_info": "\"Entity 1 ('scfs') is the object of the preposition 'for', depending on 'annotating' in the phrase 'for annotating scfs'. Entity 2 ('training and test data') is the object of the preposition 'of', depending on 'process' in the phrase 'the process of obtaining training and test data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "scfs",
                "OtherScientificTerm"
            ],
            [
                "subcategorization acquisition",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scfs') is the object of the preposition 'of', depending on 'annotation'. Entity 2 ('subcategorization acquisition') is the object, depending on 'data' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the broader context of the sentence involving tools and processes for linguistic data handling.\"",
        "sdp_path_text": "scfs → of → annotation → for → tool → alleviate → process → of → obtaining → for → acquisition",
        "sentence": "A tool for annotating scfs can alleviate the process of obtaining data for subcategorization acquisition.",
        "sentence_llm_dp_info": "\"Entity 1 ('scfs') is the object of the preposition 'for', depending on 'annotating'. Entity 2 ('subcategorization acquisition') is the object of the preposition 'for', depending on 'data'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the purpose or function described in the sentence.\""
    },
    {
        "raw_sentence": "A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .",
        "ner_pair": [
            [
                "training and test data",
                "Material"
            ],
            [
                "subcategorization acquisition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training and test data') is the object, depending on 'obtaining' with 'process'. Entity 2 ('subcategorization acquisition') is the object, depending on 'for' with 'data'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for subcategorization acquisition'.\"",
        "sdp_path_text": "data → obtaining → for → acquisition",
        "sentence": "A tool can help obtain training and test data for subcategorization acquisition.",
        "sentence_llm_dp_info": "\"Entity 1 ('training and test data') is the object, depending on 'obtain' with 'can help'. Entity 2 ('subcategorization acquisition') is the object of the preposition 'for', depending on 'for' in the phrase 'for subcategorization acquisition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtain' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Machine transliteration/back-transliteration plays an important role in many multilingual speech and language applications .",
        "ner_pair": [
            [
                "Machine transliteration/back-transliteration",
                "Task"
            ],
            [
                "multilingual speech and language applications",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Machine transliteration/back-transliteration') is the subject, depending on the verb 'plays'. Entity 2 ('multilingual speech and language applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in many multilingual speech and language applications'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\"",
        "sdp_path_text": "transliteration → plays → in → applications",
        "sentence": "Machine transliteration/back-transliteration plays an important role in multilingual speech and language applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('Machine transliteration/back-transliteration') is the subject, depending on the verb 'plays'. Entity 2 ('multilingual speech and language applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in multilingual speech and language applications'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates the domain where Entity 1 plays an important role.\""
    },
    {
        "raw_sentence": "In this paper , a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "machine transliteration/backtransliteration",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('framework') is the subject, depending on the verb 'presented'. Entity 2 ('machine transliteration/backtransliteration') is the object of the preposition 'for', depending on 'for' in the phrase 'for machine transliteration/backtransliteration'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "framework → for → transliteration",
        "sentence": "A novel framework for machine transliteration/backtransliteration is presented.",
        "sentence_llm_dp_info": "\"Entity 1 ('framework') is the subject, depending on the verb 'presented'. Entity 2 ('machine transliteration/backtransliteration') is the object of the preposition 'for', depending on 'for' in the phrase 'for machine transliteration/backtransliteration'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "direct orthographical mapping -LRB- DOM -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('framework') is the subject, depending on the verb 'presented'. Entity 2 ('direct orthographical mapping -LRB- DOM -RRB-') is the object of the preposition 'between', depending on 'mapping' which is part of the noun phrase 'direct orthographical mapping -LRB- DOM -RRB-'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger clause describing what the framework allows (i.e., carrying out direct orthographical mapping between two different languages).\"",
        "sdp_path_text": "framework → allows → carry → mapping",
        "sentence": "A novel framework allows direct orthographical mapping between languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('framework') is the subject, depending on the verb 'allows'. Entity 2 ('direct orthographical mapping') is the object, depending on 'allows' with 'framework'. There is a direct dependency between Entity 1 and Entity 2, as 'framework' allows 'direct orthographical mapping'.\""
    },
    {
        "raw_sentence": "In this paper , a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented .",
        "ner_pair": [
            [
                "machine transliteration/backtransliteration",
                "Task"
            ],
            [
                "direct orthographical mapping -LRB- DOM -RRB-",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine transliteration/backtransliteration') is the object of the preposition 'for', depending on 'framework'. Entity 2 ('direct orthographical mapping -LRB- DOM -RRB-') is the object of the preposition 'out', depending on 'carry'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verb 'allows' and the prepositions 'for' and 'out'.\"",
        "sdp_path_text": "transliteration → for → framework → allows → carry → mapping",
        "sentence": "A framework for machine transliteration/backtransliteration allows direct orthographical mapping between languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine transliteration/backtransliteration') is the object of the preposition 'for', depending on 'framework'. Entity 2 ('direct orthographical mapping') is the subject, depending on 'allows' with 'framework'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause through the verb 'allows'.\""
    },
    {
        "raw_sentence": "Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- n-gram TM -RRB- , is further proposed to model the transliteration process .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "joint source-channel transliteration model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('framework') is the object of the preposition 'Under', depending on the prepositional phrase 'Under this framework'. Entity 2 ('joint source-channel transliteration model') is the subject complement, depending on the verb 'is' and modified by the appositive 'also called n-gram transliteration model -LRB- n-gram TM -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause.\"",
        "sdp_path_text": "framework → Under → proposed → model",
        "sentence": "Under this framework, a joint source-channel transliteration model is proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('framework') is the object of the preposition 'Under', depending on the preposition 'Under'. Entity 2 ('joint source-channel transliteration model') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause.\""
    },
    {
        "raw_sentence": "Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- n-gram TM -RRB- , is further proposed to model the transliteration process .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "n-gram transliteration model -LRB- n-gram TM -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('framework') is the object of the preposition 'Under', depending on the prepositional phrase 'Under this framework'. Entity 2 ('n-gram transliteration model -LRB- n-gram TM -RRB-') is the appositive, depending on 'called' which clarifies its alternative name. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where the framework provides the context in which the model is proposed.\"",
        "sdp_path_text": "framework → Under → proposed → model → called → model",
        "sentence": "Under this framework, an n-gram transliteration model is proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('framework') is the object of the preposition 'Under', depending on the preposition 'Under' in the phrase 'Under this framework'. Entity 2 ('n-gram transliteration model') is the subject, depending on the verb 'is proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause.\""
    },
    {
        "raw_sentence": "Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- n-gram TM -RRB- , is further proposed to model the transliteration process .",
        "ner_pair": [
            [
                "framework",
                "Generic"
            ],
            [
                "transliteration process",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('framework') is the object of the preposition 'Under', depending on the verb 'is proposed' in the clause. Entity 2 ('transliteration process') is the object of the verb 'model', depending on the verb 'to model' in the infinitive phrase 'to model the transliteration process'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where the framework supports the proposal of a model that aims to model the transliteration process.\"",
        "sdp_path_text": "framework → Under → proposed → model → process",
        "sentence": "Under this framework, a model is proposed to model the transliteration process.",
        "sentence_llm_dp_info": "\"Entity 1 ('framework') is the object of the preposition 'Under', depending on the preposition 'Under'. Entity 2 ('transliteration process') is the object of the second 'model', depending on the verb 'to model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the proposal of a model within a specific framework to handle a particular process.\""
    },
    {
        "raw_sentence": "Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- n-gram TM -RRB- , is further proposed to model the transliteration process .",
        "ner_pair": [
            [
                "joint source-channel transliteration model",
                "Method"
            ],
            [
                "n-gram transliteration model -LRB- n-gram TM -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('joint source-channel transliteration model') is the subject, depending on the verb 'proposed'. Entity 2 ('n-gram transliteration model -LRB- n-gram TM -RRB-') is an appositive, depending on 'called' which links it to Entity 1. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 provides an alternative name for Entity 1.\"",
        "sdp_path_text": "model → called → model",
        "sentence": "The joint source-channel transliteration model is called the n-gram transliteration model (n-gram TM).",
        "sentence_llm_dp_info": "\"Entity 1 ('joint source-channel transliteration model') is the subject, depending on the verb 'called'. Entity 2 ('n-gram transliteration model (n-gram TM)') is the object, depending on 'called' with 'joint source-channel transliteration model'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is what Entity 1 is called.\""
    },
    {
        "raw_sentence": "Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- n-gram TM -RRB- , is further proposed to model the transliteration process .",
        "ner_pair": [
            [
                "joint source-channel transliteration model",
                "Method"
            ],
            [
                "transliteration process",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('joint source-channel transliteration model') is the subject complement, depending on 'proposed' with 'is further proposed'. Entity 2 ('transliteration process') is the object of the preposition 'to', depending on 'model' in the phrase 'to model the transliteration process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'model'.\"",
        "sdp_path_text": "model → proposed → model → process",
        "sentence": "A joint source-channel transliteration model is proposed to model the transliteration process.",
        "sentence_llm_dp_info": "\"Entity 1 ('joint source-channel transliteration model') is the subject, depending on the verb 'proposed'. Entity 2 ('transliteration process') is the object of the verb 'model', depending on 'model' in the phrase 'to model the transliteration process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'model'.\""
    },
    {
        "raw_sentence": "Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- n-gram TM -RRB- , is further proposed to model the transliteration process .",
        "ner_pair": [
            [
                "n-gram transliteration model -LRB- n-gram TM -RRB-",
                "Method"
            ],
            [
                "transliteration process",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('n-gram transliteration model -LRB- n-gram TM -RRB-') is the appositive, depending on the noun 'model' with the relation 'appositive'. Entity 2 ('transliteration process') is the object, depending on 'model' with the relation 'dobj'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'proposed' through the noun 'model'.\"",
        "sdp_path_text": "model → called → model → proposed → model → process",
        "sentence": "The n-gram transliteration model (n-gram TM) is proposed to model the transliteration process.",
        "sentence_llm_dp_info": "\"Entity 1 ('n-gram transliteration model (n-gram TM)') is the subject, depending on the verb 'proposed'. Entity 2 ('transliteration process') is the object of the verb 'model', depending on 'model' in the phrase 'to model the transliteration process'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'model'.\""
    },
    {
        "raw_sentence": "We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs .",
        "ner_pair": [
            [
                "transliteration/backtransliteration",
                "Task"
            ],
            [
                "methods",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transliteration/backtransliteration') is the object of the preposition 'through', depending on 'evaluate' with 'We'. Entity 2 ('methods') is the object of the preposition 'the', depending on 'evaluate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what is being evaluated.\"",
        "sdp_path_text": "transliteration → experiments → through → evaluate → methods",
        "sentence": "We evaluate methods through transliteration/backtransliteration experiments.",
        "sentence_llm_dp_info": "\"Entity 1 ('transliteration/backtransliteration') is the object of the preposition 'through', depending on 'evaluate'. Entity 2 ('methods') is the direct object, depending on the verb 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluate'.\""
    },
    {
        "raw_sentence": "We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "English/Chinese and English/Japanese language pairs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('English/Chinese and English/Japanese language pairs') is the object of the preposition 'for', depending on 'for' in the phrase 'for English/Chinese and English/Japanese language pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'evaluate' and the preposition 'for'.\"",
        "sdp_path_text": "methods → evaluate → for → pairs",
        "sentence": "We evaluate methods for English/Chinese and English/Japanese language pairs.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('English/Chinese and English/Japanese language pairs') is the object of the preposition 'for', depending on 'for' in the phrase 'for English/Chinese and English/Japanese language pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs .",
        "ner_pair": [
            [
                "transliteration/backtransliteration",
                "Task"
            ],
            [
                "English/Chinese and English/Japanese language pairs",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transliteration/backtransliteration') is the object of the preposition 'through', depending on 'evaluate' with 'We'. Entity 2 ('English/Chinese and English/Japanese language pairs') is the object of the preposition 'for', depending on 'experiments'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing the conditions under which the evaluation is performed.\"",
        "sdp_path_text": "transliteration → experiments → through → evaluate → for → pairs",
        "sentence": "We evaluate transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs.",
        "sentence_llm_dp_info": "\"Entity 1 ('transliteration/backtransliteration') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('English/Chinese and English/Japanese language pairs') is the object of the preposition 'for', depending on 'for' in the phrase 'for English/Chinese and English/Japanese language pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluate' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the transliteration accuracy significantly .",
        "ner_pair": [
            [
                "transliteration accuracy",
                "Metric"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('transliteration accuracy') is the object, depending on 'improves' with 'method'. Entity 2 ('method') is the subject, depending on 'reduces' and 'improves'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is the agent performing the action that affects 'transliteration accuracy'.\"",
        "sdp_path_text": "accuracy → improves → reduces → method",
        "sentence": "The proposed method improves transliteration accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('transliteration accuracy') is the object, depending on the verb 'improves'. Entity 2 ('method') is the subject, depending on 'proposed' with 'The'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is the agent performing the action that affects 'transliteration accuracy'.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "bio-inspired model",
                "Method"
            ],
            [
                "analog programmable array processor -LRB- APAP -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bio-inspired model') is the subject, depending on the verb 'has permitted'. Entity 2 ('analog programmable array processor -LRB- APAP -RRB-') is the object of the preposition 'for', depending on 'for' in the phrase 'for an analog programmable array processor -LRB- APAP -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "model → for → processor",
        "sentence": "A bio-inspired model is for an analog programmable array processor (APAP).",
        "sentence_llm_dp_info": "\"Entity 1 ('bio-inspired model') is the subject, depending on the verb 'is'. Entity 2 ('analog programmable array processor (APAP)') is the complement of the preposition 'for', depending on 'for' in the phrase 'for an analog programmable array processor (APAP)'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "vertebrate retina",
                "OtherScientificTerm"
            ],
            [
                "bio-inspired model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('vertebrate retina') is the object of the preposition 'on', depending on 'studies'. Entity 2 ('bio-inspired model') is the subject, depending on 'has permitted'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on studies on the vertebrate retina'.\"",
        "sdp_path_text": "retina → on → studies → on → based → model",
        "sentence": "A bio-inspired model is based on studies of the vertebrate retina.",
        "sentence_llm_dp_info": "\"Entity 1 ('vertebrate retina') is the object of the preposition 'of', depending on 'studies'. Entity 2 ('bio-inspired model') is the subject, depending on the verb 'is based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on studies of the vertebrate retina'.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "bio-inspired model",
                "Method"
            ],
            [
                "complex programmable spatio-temporal dynamics",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bio-inspired model') is the subject, depending on the verb 'has permitted'. Entity 2 ('complex programmable spatio-temporal dynamics') is the object, depending on the verb 'realization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has permitted' which indicates that the 'bio-inspired model' enabled the 'realization' of 'complex programmable spatio-temporal dynamics'.\"",
        "sdp_path_text": "model → permitted → realization → of → dynamics",
        "sentence": "A bio-inspired model has permitted the realization of complex programmable spatio-temporal dynamics.",
        "sentence_llm_dp_info": "\"Entity 1 ('bio-inspired model') is the subject, depending on the verb 'has permitted'. Entity 2 ('complex programmable spatio-temporal dynamics') is the object, depending on the verb 'realization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has permitted' and the noun 'realization'.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "bio-inspired model",
                "Method"
            ],
            [
                "VLSI",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bio-inspired model') is the subject, depending on the verb 'has permitted'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'in' in the phrase 'in VLSI'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has permitted' and the prepositional phrase 'in VLSI'.\"",
        "sdp_path_text": "model → permitted → realization → in → VLSI",
        "sentence": "A bio-inspired model has permitted the realization of dynamics in VLSI.",
        "sentence_llm_dp_info": "\"Entity 1 ('bio-inspired model') is the subject, depending on the verb 'has permitted'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'in' in the phrase 'in VLSI'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has permitted' and the prepositional phrase 'in VLSI'.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "analog programmable array processor -LRB- APAP -RRB-",
                "Task"
            ],
            [
                "vertebrate retina",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('analog programmable array processor -LRB- APAP -RRB-') is the object of the preposition 'for', depending on 'model'. Entity 2 ('vertebrate retina') is the object of the preposition 'on', depending on 'studies'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence, where the model inspired by studies on the vertebrate retina is applied to the analog programmable array processor (APAP).\"",
        "sdp_path_text": "processor → for → model → based → on → studies → on → retina",
        "sentence": "A model for the analog programmable array processor (APAP) is based on studies of the vertebrate retina.",
        "sentence_llm_dp_info": "\"Entity 1 ('analog programmable array processor (APAP)') is the object of the preposition 'for', depending on 'model'. Entity 2 ('vertebrate retina') is the object of the preposition 'of', depending on 'studies'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing what the model is based on.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "analog programmable array processor -LRB- APAP -RRB-",
                "Task"
            ],
            [
                "complex programmable spatio-temporal dynamics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('analog programmable array processor -LRB- APAP -RRB-') is the object of the preposition 'for', depending on 'model'. Entity 2 ('complex programmable spatio-temporal dynamics') is the object of the preposition 'of', depending on 'realization'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure that describes the outcome and the subject of the study.\"",
        "sdp_path_text": "processor → for → model → permitted → realization → of → dynamics",
        "sentence": "A model for an analog programmable array processor (APAP) has permitted the realization of complex programmable spatio-temporal dynamics.",
        "sentence_llm_dp_info": "\"Entity 1 ('analog programmable array processor (APAP)') is the object of the preposition 'for', depending on 'model'. Entity 2 ('complex programmable spatio-temporal dynamics') is the object of the preposition 'of', depending on 'realization'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what the model has permitted.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "analog programmable array processor -LRB- APAP -RRB-",
                "Task"
            ],
            [
                "VLSI",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('analog programmable array processor -LRB- APAP -RRB-') is the object of the preposition 'for', depending on 'model'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'dynamics'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the outcome of the model's application.\"",
        "sdp_path_text": "processor → for → model → permitted → realization → in → VLSI",
        "sentence": "A model for an analog programmable array processor (APAP) has permitted the realization of dynamics in VLSI.",
        "sentence_llm_dp_info": "\"Entity 1 ('analog programmable array processor (APAP)') is the object of the preposition 'for', depending on 'model'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'dynamics'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the outcome of the model's development.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "vertebrate retina",
                "OtherScientificTerm"
            ],
            [
                "complex programmable spatio-temporal dynamics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('vertebrate retina') is the object of the preposition 'on', depending on 'studies'. Entity 2 ('complex programmable spatio-temporal dynamics') is the object of the preposition 'of', depending on 'realization'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context where the studies on the vertebrate retina have influenced the realization of the complex programmable spatio-temporal dynamics.\"",
        "sdp_path_text": "retina → on → studies → on → based → model → permitted → realization → of → dynamics",
        "sentence": "Studies on the vertebrate retina have permitted the realization of complex programmable spatio-temporal dynamics.",
        "sentence_llm_dp_info": "\"Entity 1 ('vertebrate retina') is the object of the preposition 'on', depending on 'studies'. Entity 2 ('complex programmable spatio-temporal dynamics') is the object of the noun 'realization', depending on 'of' in the phrase 'of complex programmable spatio-temporal dynamics'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the studies on Entity 1 have led to the realization of Entity 2.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "vertebrate retina",
                "OtherScientificTerm"
            ],
            [
                "VLSI",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('vertebrate retina') is the object of the preposition 'on', depending on 'studies'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'dynamics'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the context of the sentence, where studies on the vertebrate retina inform the development of dynamics realized in VLSI.\"",
        "sdp_path_text": "retina → on → studies → on → based → model → permitted → realization → in → VLSI",
        "sentence": "Studies on the vertebrate retina have permitted the realization of complex dynamics in VLSI.",
        "sentence_llm_dp_info": "\"Entity 1 ('vertebrate retina') is the object of the preposition 'on', depending on 'studies'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'dynamics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sentence structure where studies on the vertebrate retina have led to realizations about complex dynamics in VLSI.\""
    },
    {
        "raw_sentence": "A bio-inspired model for an analog programmable array processor -LRB- APAP -RRB- , based on studies on the vertebrate retina , has permitted the realization of complex programmable spatio-temporal dynamics in VLSI .",
        "ner_pair": [
            [
                "complex programmable spatio-temporal dynamics",
                "OtherScientificTerm"
            ],
            [
                "VLSI",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('complex programmable spatio-temporal dynamics') is the object, depending on 'realization' with 'has permitted'. Entity 2 ('VLSI') is the location or context where the realization occurs, depending on 'in' with 'dynamics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' indicating that the dynamics are realized within the VLSI.\"",
        "sdp_path_text": "dynamics → of → realization → in → VLSI",
        "sentence": "Complex programmable spatio-temporal dynamics have been realized in VLSI.",
        "sentence_llm_dp_info": "\"Entity 1 ('complex programmable spatio-temporal dynamics') is the subject, depending on the verb 'realized'. Entity 2 ('VLSI') is the object of the preposition 'in', depending on 'in' in the phrase 'in VLSI'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "This model mimics the way in which images are processed in the visual pathway , rendering a feasible alternative for the implementation of early vision applications in standard technologies .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'mimics'. Entity 2 ('images') is the object, depending on the verb 'processed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing how the model mimics the processing of images.\"",
        "sdp_path_text": "model → mimics → way → processed → images",
        "sentence": "This model mimics the way images are processed.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'mimics'. Entity 2 ('images') is the object, depending on the verb 'processed'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the action described by the verb 'mimics' and the process described by 'processed'.\""
    },
    {
        "raw_sentence": "This model mimics the way in which images are processed in the visual pathway , rendering a feasible alternative for the implementation of early vision applications in standard technologies .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "visual pathway",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'mimics'. Entity 2 ('visual pathway') is the object of the preposition 'in', depending on 'way' in the phrase 'the way in which images are processed in the visual pathway'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase describing how the model mimics the processing of images.\"",
        "sdp_path_text": "model → mimics → way → processed → in → pathway",
        "sentence": "This model mimics the way images are processed in the visual pathway.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'mimics'. Entity 2 ('visual pathway') is the object of the preposition 'in', depending on 'processed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'mimics' and the prepositional phrase 'in the visual pathway'.\""
    },
    {
        "raw_sentence": "This model mimics the way in which images are processed in the visual pathway , rendering a feasible alternative for the implementation of early vision applications in standard technologies .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "vision applications",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'mimics'. Entity 2 ('vision applications') is the object of the preposition 'of', depending on 'alternative'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure describing the model's role as an alternative for implementing vision applications.\"",
        "sdp_path_text": "model → mimics → rendering → alternative → for → implementation → of → applications",
        "sentence": "The model mimics processes, rendering it an alternative for implementing vision applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'mimics'. Entity 2 ('vision applications') is the object of the preposition 'for', depending on 'alternative'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'alternative' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This model mimics the way in which images are processed in the visual pathway , rendering a feasible alternative for the implementation of early vision applications in standard technologies .",
        "ner_pair": [
            [
                "visual pathway",
                "Method"
            ],
            [
                "images",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual pathway') is the object of the preposition 'in', depending on 'processed'. Entity 2 ('images') is the subject, depending on 'are' in the clause 'images are processed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the processing action described in the sentence.\"",
        "sdp_path_text": "pathway → in → processed → images",
        "sentence": "Images are processed in the visual pathway.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual pathway') is the object of the preposition 'in', depending on 'processed'. Entity 2 ('images') is the subject, depending on the verb 'are processed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are processed' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "This model mimics the way in which images are processed in the visual pathway , rendering a feasible alternative for the implementation of early vision applications in standard technologies .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "vision applications",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the relative clause 'in which images are processed', depending on 'processed'. Entity 2 ('vision applications') is the object of the preposition 'of', depending on 'alternative'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the function and application of the model.\"",
        "sdp_path_text": "images → processed → way → mimics → rendering → alternative → for → implementation → of → applications",
        "sentence": "Images processed in a way that renders them an alternative for vision applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the subject, depending on the verb 'processed'. Entity 2 ('vision applications') is the object of the preposition 'for', depending on 'alternative' in the phrase 'an alternative for vision applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'alternative' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This model mimics the way in which images are processed in the visual pathway , rendering a feasible alternative for the implementation of early vision applications in standard technologies .",
        "ner_pair": [
            [
                "visual pathway",
                "Method"
            ],
            [
                "vision applications",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual pathway') is the object of the preposition 'in', depending on 'processed'. Entity 2 ('vision applications') is the object of the preposition 'of', depending on 'implementation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "pathway → in → processed → way → mimics → rendering → alternative → for → implementation → of → applications",
        "sentence": "The model mimics the processing of images in the visual pathway, providing an alternative for implementing vision applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual pathway') is the object of the preposition 'of', depending on 'processing'. Entity 2 ('vision applications') is the object of the preposition 'for', depending on 'alternative'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the function of the model.\""
    },
    {
        "raw_sentence": "A prototype chip has been designed and fabricated in a 0.5 µm standard CMOS process .",
        "ner_pair": [
            [
                "prototype chip",
                "OtherScientificTerm"
            ],
            [
                "CMOS process",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('prototype chip') is the subject, depending on the passive verb 'has been designed and fabricated'. Entity 2 ('CMOS process') is the object of the preposition 'in', depending on 'in' in the phrase 'in a 0.5 µm standard CMOS process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "chip → designed → fabricated → in → process",
        "sentence": "A prototype chip has been designed and fabricated in a CMOS process.",
        "sentence_llm_dp_info": "\"Entity 1 ('prototype chip') is the subject, depending on the passive verb 'has been designed' and 'fabricated'. Entity 2 ('CMOS process') is the object of the preposition 'in', depending on 'fabricated' in the phrase 'fabricated in a CMOS process'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'designed' and 'fabricated' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Computing power per area and power consumption is amongst the highest reported for a single chip .",
        "ner_pair": [
            [
                "Computing power per area",
                "Metric"
            ],
            [
                "power consumption",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Computing power per area') is part of a coordination, depending on 'and' which connects it with 'power consumption'. Entity 2 ('power consumption') is also part of the coordination, depending on 'and' which connects it with 'Computing power per area'. There is no direct dependency between Entity 1 and Entity 2; they are coordinated elements in the subject of the sentence.\"",
        "sdp_path_text": "power → consumption",
        "sentence": "Computing power per area and power consumption is high.",
        "sentence_llm_dp_info": "\"Entity 1 ('Computing power per area') is the subject, depending on the verb 'is'. Entity 2 ('power consumption') is coordinated with 'Computing power per area' through the conjunction 'and', depending on the same verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as they are both subjects of the same predicate and are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Another problem with determiners is their inherent ambiguity .",
        "ner_pair": [
            [
                "ambiguity",
                "OtherScientificTerm"
            ],
            [
                "determiners",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ambiguity') is the subject complement, depending on 'is' with 'their'. Entity 2 ('determiners') is the object of the preposition 'with', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the possessive pronoun 'their' which refers back to 'determiners'.\"",
        "sdp_path_text": "ambiguity → is → problem → with → determiners",
        "sentence": "Ambiguity is a problem with determiners.",
        "sentence_llm_dp_info": "\"Entity 1 ('ambiguity') is the subject, depending on the verb 'is'. Entity 2 ('determiners') is the object of the preposition 'with', depending on 'with' in the phrase 'with determiners'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with determiners' which modifies 'problem'.\""
    },
    {
        "raw_sentence": "In this paper we propose a logical formalism , which , among other things , is suitable for representing determiners without forcing a particular interpretation when their meaning is still not clear .",
        "ner_pair": [
            [
                "logical formalism",
                "Method"
            ],
            [
                "determiners",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical formalism') is the direct object, depending on the verb 'propose'. Entity 2 ('determiners') is the object of the preposition 'for', depending on 'representing' in the phrase 'representing determiners'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'is suitable for representing determiners'.\"",
        "sdp_path_text": "formalism → is → suitable → for → representing → determiners",
        "sentence": "The logical formalism is suitable for representing determiners.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical formalism') is the subject, depending on the verb 'is'. Entity 2 ('determiners') is the object, depending on 'representing' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is suitable' and the preposition 'for representing'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "verbal and nonverbal means",
                "Method"
            ],
            [
                "grounding",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object, depending on the preposition 'for', which is part of the prepositional phrase 'for grounding'. Entity 2 ('grounding') is the complement of the preposition 'for', directly connected to 'for' in the phrase 'for grounding'. There is a direct dependency between Entity 1 and Entity 2, as 'grounding' is the purpose or goal for which 'verbal and nonverbal means' are used.\"",
        "sdp_path_text": "means → for → grounding",
        "sentence": "Verbal and nonverbal means are used for grounding.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the subject, depending on the verb 'used'. Entity 2 ('grounding') is the object of the preposition 'for', depending on 'for' in the phrase 'for grounding'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "verbal and nonverbal means",
                "Method"
            ],
            [
                "design",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object of the preposition 'for', depending on 'investigate'. Entity 2 ('design') is the object of the preposition 'for', depending on 'propose'. There is no direct dependency between Entity 1 and Entity 2; they are both part of separate clauses within the sentence, each serving as an object of different verbs ('investigate' and 'propose').\"",
        "sdp_path_text": "means → investigate → propose → design",
        "sentence": "We investigate verbal and nonverbal means and propose a design.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object of the verb 'investigate', depending on 'investigate' with 'We'. Entity 2 ('design') is the object of the verb 'propose', depending on 'propose' with 'and'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the compound predicate structure of the sentence.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "verbal and nonverbal means",
                "Method"
            ],
            [
                "embodied conversational agents",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object of the preposition 'for', depending on 'grounding' in the phrase 'for grounding'. Entity 2 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design' in the phrase 'a design for embodied conversational agents'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, which discusses methods and designs for improving communication in human-computer interactions.\"",
        "sdp_path_text": "means → investigate → propose → design → for → agents",
        "sentence": "We investigate verbal and nonverbal means and propose a design for embodied conversational agents.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object, depending on the verb 'investigate' with 'We'. Entity 2 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design' in the phrase 'a design for embodied conversational agents'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "verbal and nonverbal means",
                "Method"
            ],
            [
                "common ground",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object of the preposition 'for', depending on 'investigate'. Entity 2 ('common ground') is the object of the preposition 'in', depending on 'establish'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'investigate' and 'establish' which describe actions related to the investigation of means for grounding and the establishment of common ground, respectively.\"",
        "sdp_path_text": "means → investigate → propose → design → relies → establish → ground",
        "sentence": "We investigate verbal and nonverbal means to establish common ground.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object, depending on 'investigate' with 'We'. Entity 2 ('common ground') is the object of the preposition 'to', depending on 'to' in the phrase 'to establish common ground'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'establish'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "verbal and nonverbal means",
                "Method"
            ],
            [
                "human-computer interaction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object of the preposition 'for', depending on 'grounding'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'interaction' within the clause 'to establish common ground in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same semantic context related to establishing common ground.\"",
        "sdp_path_text": "means → investigate → propose → design → relies → establish → in → interaction",
        "sentence": "We investigate verbal and nonverbal means to establish common ground in human-computer interaction.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal means') is the object, depending on the verb 'investigate'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'in' in the phrase 'in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where Entity 1 is what is being investigated and Entity 2 specifies the context or domain of the investigation.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "grounding",
                "Task"
            ],
            [
                "design",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'means'. Entity 2 ('design') is the object of the verb 'propose', depending on 'propose'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "grounding → for → means → investigate → propose → design",
        "sentence": "We propose a design for grounding through investigated means.",
        "sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'design'. Entity 2 ('design') is the object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for grounding'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "grounding",
                "Task"
            ],
            [
                "embodied conversational agents",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'means'. Entity 2 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, which discusses methods and designs related to establishing common ground in human-computer interaction.\"",
        "sdp_path_text": "grounding → for → means → investigate → propose → design → for → agents",
        "sentence": "We investigate means for grounding and propose a design for embodied conversational agents.",
        "sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'means'. Entity 2 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different prepositional phrases that are part of the larger structure of the sentence.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "grounding",
                "Task"
            ],
            [
                "common ground",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'means'. Entity 2 ('common ground') is the object of the verb 'establish', depending on 'establish' in the phrase 'to establish common ground'. There is no direct dependency between Entity 1 and Entity 2, but they are conceptually related through the context of the sentence, where 'grounding' is a means to achieve 'common ground'.\"",
        "sdp_path_text": "grounding → for → means → investigate → propose → design → relies → establish → ground",
        "sentence": "We investigate means for grounding and propose a design that establishes common ground.",
        "sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'means'. Entity 2 ('common ground') is the object of the clause, depending on 'establishes' with 'design'. There is no direct dependency between Entity 1 and Entity 2, but they are thematically related through the context of the sentence.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "grounding",
                "Task"
            ],
            [
                "human-computer interaction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grounding') is the object of the preposition 'for', depending on 'means'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'establish'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'grounding' is discussed as a goal within the context of 'human-computer interaction'.\"",
        "sdp_path_text": "grounding → for → means → investigate → propose → design → relies → establish → in → interaction",
        "sentence": "We investigate means for grounding and propose a design that relies on these means to establish common ground in human-computer interaction.",
        "sentence_llm_dp_info": "\"Entity 1 ('grounding') is part of the object complement, depending on 'means' in the phrase 'means for grounding'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'in' in the phrase 'in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of the investigation and proposal described in the sentence.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "design",
                "Generic"
            ],
            [
                "embodied conversational agents",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('design') is the object of the verb 'propose', depending on 'propose' with 'we'. Entity 2 ('embodied conversational agents') is the object of the preposition 'for', depending on 'for' in the phrase 'for embodied conversational agents'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'a design for embodied conversational agents'.\"",
        "sdp_path_text": "design → for → agents",
        "sentence": "We propose a design for embodied conversational agents.",
        "sentence_llm_dp_info": "\"Entity 1 ('design') is the object of the preposition 'for', depending on 'propose'. Entity 2 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 specifies what the design is for.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "design",
                "Generic"
            ],
            [
                "common ground",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('design') is the object, depending on the verb 'propose'. Entity 2 ('common ground') is the object of the preposition 'in', depending on 'interaction' in the phrase 'human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where the 'design' is proposed to help establish 'common ground'.\"",
        "sdp_path_text": "design → relies → establish → ground",
        "sentence": "The design relies on signals to establish common ground.",
        "sentence_llm_dp_info": "\"Entity 1 ('design') is the subject, depending on the verb 'relies'. Entity 2 ('common ground') is the object of the verb 'establish', depending on 'establish' in the phrase 'to establish common ground'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'establish' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "design",
                "Generic"
            ],
            [
                "human-computer interaction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('design') is the object, depending on 'propose' with 'We'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'in' in the phrase 'in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the proposed design's application area.\"",
        "sdp_path_text": "design → relies → establish → in → interaction",
        "sentence": "The design relies on signals to establish common ground in human-computer interaction.",
        "sentence_llm_dp_info": "\"Entity 1 ('design') is the subject, depending on the verb 'relies'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'establish'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence of dependencies involving 'relies', 'signals', 'establish', and 'common ground'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "embodied conversational agents",
                "Method"
            ],
            [
                "common ground",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design' which is part of the verb phrase 'propose a design for'. Entity 2 ('common ground') is the object of the preposition 'in', depending on 'establish' which is part of the verb phrase 'to establish common ground'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'establish' and the preposition 'in'.\"",
        "sdp_path_text": "agents → for → design → relies → establish → ground",
        "sentence": "Embodied conversational agents rely on signals to establish common ground.",
        "sentence_llm_dp_info": "\"Entity 1 ('embodied conversational agents') is the subject, depending on the verb 'rely'. Entity 2 ('common ground') is the object of the preposition 'on', depending on 'establish' in the phrase 'to establish common ground'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'rely' and 'establish'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "embodied conversational agents",
                "Method"
            ],
            [
                "human-computer interaction",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('embodied conversational agents') is the object of the preposition 'for', depending on 'design' which is part of the phrase 'a design for embodied conversational agents'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'ground' in the phrase 'establish common ground in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the context of the research described in the sentence.\"",
        "sdp_path_text": "agents → for → design → relies → establish → in → interaction",
        "sentence": "Embodied conversational agents rely on signals to establish common ground in human-computer interaction.",
        "sentence_llm_dp_info": "\"Entity 1 ('embodied conversational agents') is the subject, depending on the verb 'rely'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'in' in the phrase 'in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in human-computer interaction'.\""
    },
    {
        "raw_sentence": "We investigate the verbal and nonverbal means for grounding , and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction .",
        "ner_pair": [
            [
                "common ground",
                "Task"
            ],
            [
                "human-computer interaction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('common ground') is the object, depending on the verb 'establish'. Entity 2 ('human-computer interaction') is the prepositional object, depending on the preposition 'in' within the phrase 'in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'establish' which indicates the action of setting up 'common ground' within the context of 'human-computer interaction'.\"",
        "sdp_path_text": "ground → establish → in → interaction",
        "sentence": "Common ground is established in human-computer interaction.",
        "sentence_llm_dp_info": "\"Entity 1 ('common ground') is the subject, depending on the verb 'is established'. Entity 2 ('human-computer interaction') is the object of the preposition 'in', depending on 'in' in the phrase 'in human-computer interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .",
        "ner_pair": [
            [
                "eye gaze",
                "OtherScientificTerm"
            ],
            [
                "head nods",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eye gaze') is part of a coordination, depending on the conjunction 'and' with 'head nods'. Entity 2 ('head nods') is also part of a coordination, depending on the conjunction 'and' with 'eye gaze'. Both are objects of the verb 'analyzed'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together as part of the list of items being analyzed.\"",
        "sdp_path_text": "gaze → nods",
        "sentence": "We analyzed eye gaze and head nods.",
        "sentence_llm_dp_info": "\"Entity 1 ('eye gaze') is the object of the conjunction 'and', depending on 'analyzed' with 'We'. Entity 2 ('head nods') is also an object, depending on the conjunction 'and' with 'eye gaze'. There is no direct dependency between Entity 1 and Entity 2; they are both objects connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .",
        "ner_pair": [
            [
                "eye gaze",
                "OtherScientificTerm"
            ],
            [
                "attentional focus",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eye gaze') is part of a coordinated list, depending on the verb 'analyzed' with 'We'. Entity 2 ('attentional focus') is also part of the same coordinated list, depending on the conjunction 'and' with 'head nods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of items that were analyzed.\"",
        "sdp_path_text": "gaze → nods → focus",
        "sentence": "We analyzed eye gaze and attentional focus.",
        "sentence_llm_dp_info": "\"Entity 1 ('eye gaze') is the object of the verb 'analyzed', depending on 'analyzed' with 'We'. Entity 2 ('attentional focus') is also an object of the verb 'analyzed', depending on 'and' which connects it with 'eye gaze'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'analyzed' and are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .",
        "ner_pair": [
            [
                "eye gaze",
                "OtherScientificTerm"
            ],
            [
                "direction-giving task",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('eye gaze') is part of a list of items being analyzed, depending on the verb 'analyzed'. Entity 2 ('direction-giving task') is the object of the preposition 'of', specifying the context in which the analysis was conducted. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with the analysis (verb 'analyzed') connecting them contextually.\"",
        "sdp_path_text": "gaze → analyzed → in → context → of → task",
        "sentence": "Eye gaze was analyzed in the context of a direction-giving task.",
        "sentence_llm_dp_info": "\"Entity 1 ('eye gaze') is the subject, depending on the verb 'analyzed'. Entity 2 ('direction-giving task') is the object of the preposition 'of', depending on 'context'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the context of a direction-giving task'.\""
    },
    {
        "raw_sentence": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .",
        "ner_pair": [
            [
                "head nods",
                "OtherScientificTerm"
            ],
            [
                "attentional focus",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('head nods') is part of a coordinated list, depending on the verb 'analyzed' with 'We'. Entity 2 ('attentional focus') is also part of the same coordinated list, depending on the verb 'analyzed' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'analyzed'.\"",
        "sdp_path_text": "nods → focus",
        "sentence": "We analyzed head nods and attentional focus.",
        "sentence_llm_dp_info": "\"Entity 1 ('head nods') is a conjunct, depending on 'and' with 'attentional focus'. Entity 2 ('attentional focus') is also a conjunct, depending on 'and' with 'head nods'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .",
        "ner_pair": [
            [
                "head nods",
                "OtherScientificTerm"
            ],
            [
                "direction-giving task",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('head nods') is part of a conjunction, depending on the verb 'analyzed' with 'We'. Entity 2 ('direction-giving task') is the object of the preposition 'of', depending on 'context'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what was analyzed in the context of the task.\"",
        "sdp_path_text": "nods → gaze → analyzed → in → context → of → task",
        "sentence": "Head nods were analyzed in the context of a direction-giving task.",
        "sentence_llm_dp_info": "\"Entity 1 ('head nods') is the subject, depending on the verb 'analyzed'. Entity 2 ('direction-giving task') is the object of the preposition 'of', depending on 'context'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the context of'.\""
    },
    {
        "raw_sentence": "We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .",
        "ner_pair": [
            [
                "attentional focus",
                "OtherScientificTerm"
            ],
            [
                "direction-giving task",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('attentional focus') is part of a coordination, depending on 'analyzed' with 'We'. Entity 2 ('direction-giving task') is the object of the preposition 'of', depending on 'context'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'analyzed' and the prepositional phrase 'in the context of'.\"",
        "sdp_path_text": "focus → nods → gaze → analyzed → in → context → of → task",
        "sentence": "Attentional focus was analyzed in the context of the direction-giving task.",
        "sentence_llm_dp_info": "\"Entity 1 ('attentional focus') is the subject, depending on the verb 'analyzed'. Entity 2 ('direction-giving task') is the object of the preposition 'of', depending on 'context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the context of'.\""
    },
    {
        "raw_sentence": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded , and the overall pattern reflected a monitoring of lack of negative feedback .",
        "ner_pair": [
            [
                "nonverbal behaviors",
                "OtherScientificTerm"
            ],
            [
                "dialogue move",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nonverbal behaviors') is the subject, depending on the verb 'differed'. Entity 2 ('dialogue move') is the object of the preposition 'on', depending on 'depending' in the phrase 'depending on the type of dialogue move'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'depending on the type of dialogue move'.\"",
        "sdp_path_text": "behaviors → of → distribution → differed → depending → on → type → of → move",
        "sentence": "The distribution of nonverbal behaviors differed depending on the type of dialogue move.",
        "sentence_llm_dp_info": "\"Entity 1 ('nonverbal behaviors') is the object of the preposition 'of', depending on 'distribution'. Entity 2 ('dialogue move') is the object of the preposition 'of', depending on 'type'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the distribution differed depending on.\""
    },
    {
        "raw_sentence": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded , and the overall pattern reflected a monitoring of lack of negative feedback .",
        "ner_pair": [
            [
                "nonverbal behaviors",
                "OtherScientificTerm"
            ],
            [
                "negative feedback",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nonverbal behaviors') is the subject, depending on 'differed' with the verb 'differed'. Entity 2 ('negative feedback') is the object of the preposition 'of', depending on 'monitoring' in the phrase 'monitoring of lack of negative feedback'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, particularly the clause describing the pattern reflecting monitoring of the lack of negative feedback.\"",
        "sdp_path_text": "behaviors → of → distribution → differed → reflected → monitoring → of → lack → of → feedback",
        "sentence": "The distribution of nonverbal behaviors reflected a monitoring of lack of negative feedback.",
        "sentence_llm_dp_info": "\"Entity 1 ('nonverbal behaviors') is the object of the preposition 'of', depending on 'distribution'. Entity 2 ('negative feedback') is the object of the preposition 'of', depending on 'lack'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where 'nonverbal behaviors' are described as being distributed in a way that reflects monitoring of a lack of 'negative feedback'.\""
    },
    {
        "raw_sentence": "The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded , and the overall pattern reflected a monitoring of lack of negative feedback .",
        "ner_pair": [
            [
                "dialogue move",
                "OtherScientificTerm"
            ],
            [
                "negative feedback",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dialogue move') is part of a prepositional phrase, depending on 'type' with the preposition 'of' in the phrase 'type of dialogue move'. Entity 2 ('negative feedback') is part of a noun phrase, depending on 'lack' with the preposition 'of' in the phrase 'lack of negative feedback'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the sentence structure through different prepositional phrases.\"",
        "sdp_path_text": "move → of → type → on → depending → differed → reflected → monitoring → of → lack → of → feedback",
        "sentence": "The type of dialogue move reflected a monitoring of lack of negative feedback.",
        "sentence_llm_dp_info": "\"Entity 1 ('dialogue move') is the subject, depending on the verb 'reflected'. Entity 2 ('negative feedback') is the object, depending on 'lack of' in the phrase 'lack of negative feedback'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reflected' and the prepositional phrase 'of lack of negative feedback'.\""
    },
    {
        "raw_sentence": "Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .",
        "ner_pair": [
            [
                "verbal and nonverbal grounding acts",
                "OtherScientificTerm"
            ],
            [
                "ECA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal grounding acts') is the object of the preposition 'uses', depending on 'ECA'. Entity 2 ('ECA') is the object of the relative clause, depending on 'present' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'uses'.\"",
        "sdp_path_text": "acts → uses → ECA",
        "sentence": "ECA uses verbal and nonverbal grounding acts.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal grounding acts') is the object, depending on the verb 'uses' with 'ECA'. Entity 2 ('ECA') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'ECA' is the agent performing the action of using 'verbal and nonverbal grounding acts'.\""
    },
    {
        "raw_sentence": "Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .",
        "ner_pair": [
            [
                "ECA",
                "Method"
            ],
            [
                "dialogue state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ECA') is the subject complement, depending on 'present' with 'we'. Entity 2 ('dialogue state') is the object of the verb 'update', depending on 'update' in the clause 'to update dialogue state'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'update' which describes the action performed by the ECA on the dialogue state.\"",
        "sdp_path_text": "ECA → uses → update → state",
        "sentence": "ECA uses verbal and nonverbal grounding acts to update dialogue state.",
        "sentence_llm_dp_info": "\"Entity 1 ('ECA') is the subject, depending on the verb 'uses'. Entity 2 ('dialogue state') is the object, depending on 'update' with 'ECA'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'update'.\""
    },
    {
        "raw_sentence": "Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .",
        "ner_pair": [
            [
                "verbal and nonverbal grounding acts",
                "OtherScientificTerm"
            ],
            [
                "dialogue state",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal grounding acts') is the object of the preposition 'uses', depending on 'uses' in the phrase 'uses verbal and nonverbal grounding acts'. Entity 2 ('dialogue state') is the object of the verb 'update', depending on 'update' in the phrase 'to update dialogue state'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'update' which indicates that Entity 1 is used to modify or change Entity 2.\"",
        "sdp_path_text": "acts → uses → update → state",
        "sentence": "An ECA uses verbal and nonverbal grounding acts to update dialogue state.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal and nonverbal grounding acts') is the object, depending on the verb 'uses' with 'An ECA'. Entity 2 ('dialogue state') is the object, depending on the verb 'update' with 'acts'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'update'.\""
    },
    {
        "raw_sentence": "Sentence boundary detection in speech is important for enriching speech recognition output , making it easier for humans to read and downstream modules to process .",
        "ner_pair": [
            [
                "speech",
                "Material"
            ],
            [
                "Sentence boundary detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech') is the object, depending on the preposition 'in', which is part of the prepositional phrase 'in speech' modifying 'detection'. Entity 2 ('Sentence boundary detection') is the subject, depending on the copula 'is' in the clause 'Sentence boundary detection is important'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in speech' that modifies 'detection'.\"",
        "sdp_path_text": "speech → in → detection",
        "sentence": "Sentence boundary detection is important in speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech') is the object, depending on 'in' with the phrase 'in speech'. Entity 2 ('Sentence boundary detection') is the subject, depending on 'is' with 'important'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is important in'.\""
    },
    {
        "raw_sentence": "Sentence boundary detection in speech is important for enriching speech recognition output , making it easier for humans to read and downstream modules to process .",
        "ner_pair": [
            [
                "Sentence boundary detection",
                "Task"
            ],
            [
                "speech recognition output",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Sentence boundary detection') is the subject, depending on 'is' as the main verb. Entity 2 ('speech recognition output') is the object, depending on 'enriching' which is part of the verbal phrase describing what is being enriched. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where the detection enriches the output.\"",
        "sdp_path_text": "detection → is → important → for → enriching → output",
        "sentence": "Sentence boundary detection is important for enriching speech recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('Sentence boundary detection') is the subject, depending on the verb 'is'. Entity 2 ('speech recognition output') is the object of the preposition 'for', depending on 'for' in the phrase 'for enriching speech recognition output'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' and the prepositional phrase 'for enriching'.\""
    },
    {
        "raw_sentence": "Sentence boundary detection in speech is important for enriching speech recognition output , making it easier for humans to read and downstream modules to process .",
        "ner_pair": [
            [
                "Sentence boundary detection",
                "Task"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Sentence boundary detection') is the subject, depending on the verb 'is'. Entity 2 ('it') is the object, depending on the verb 'making' which is part of the participial phrase 'making it easier'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the logical flow of the sentence where 'it' refers back to the importance of 'Sentence boundary detection'.\"",
        "sdp_path_text": "detection → is → important → for → enriching → output → recognition",
        "sentence": "Sentence boundary detection is important for enriching speech recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('Sentence boundary detection') is the subject, depending on the verb 'is'. Entity 2 ('it') is the subject of the clause, depending on 'important'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the predicate 'is important for enriching speech recognition output'.\""
    },
    {
        "raw_sentence": "Sentence boundary detection in speech is important for enriching speech recognition output , making it easier for humans to read and downstream modules to process .",
        "ner_pair": [
            [
                "speech",
                "Material"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech') is the object of the preposition 'in', depending on 'detection'. Entity 2 ('it') is the object of the verb 'making', referring back to the speech recognition output. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the discussion of speech recognition output.\"",
        "sdp_path_text": "speech → in → detection → is → important → for → enriching → output → recognition",
        "sentence": "Speech detection is important for enriching recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech') is part of the compound noun 'speech detection', which is the subject, depending on the verb 'is'. Entity 2 ('it') is the subject pronoun, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2; however, 'it' likely refers back to 'speech detection' in the context of the sentence.\"\n\nNote: In this sentence, \"it\" is used as a pronoun that may refer to \"speech detection,\" but in terms of syntactic dependency, there is no direct link between \"speech\" and \"it.\" The word \"it\" functions as the subject of the clause \"it is important,\" while \"speech detection\" is the subject of the main clause."
    },
    {
        "raw_sentence": "In previous work , we have developed hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries .",
        "ner_pair": [
            [
                "textual and prosodic knowledge sources",
                "Material"
            ],
            [
                "hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('textual and prosodic knowledge sources') is the object of the verb 'integrate', depending on 'integrate' within the clause 'that integrate textual and prosodic knowledge sources'. Entity 2 ('hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers') is the subject of the relative clause, depending on 'that' which introduces the clause modifying 'classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'integrate' in the context of the classifiers integrating these knowledge sources.\"",
        "sdp_path_text": "sources → integrate → classifiers",
        "sentence": "Classifiers integrate textual and prosodic knowledge sources.",
        "sentence_llm_dp_info": "\"Entity 1 ('textual and prosodic knowledge sources') is the object, depending on the verb 'integrate' with 'Classifiers'. Entity 2 ('hidden Markov model (HMM) and maximum entropy (Maxent) classifiers') is not explicitly mentioned in the sentence provided, so it cannot be directly analyzed for dependencies within this context. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not part of the given sentence.\"\n\nHowever, if we assume that \"Classifiers\" in the sentence refers to the classifiers mentioned in Entity 2, we can provide a more detailed analysis based on that assumption:\n\n\"Entity 1 ('textual and prosodic knowledge sources') is the object, depending on the verb 'integrate' with 'Classifiers'. Entity 2 ('hidden Markov model (HMM) and maximum entropy (Maxent) classifiers') is implied to be the subject, as 'Classifiers' in the sentence likely refers to these types of classifiers. There is no explicit direct dependency between Entity 1 and Entity 2 in the sentence, but they are related through the action of integration performed by the classifiers.\""
    },
    {
        "raw_sentence": "In previous work , we have developed hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries .",
        "ner_pair": [
            [
                "hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers",
                "Method"
            ],
            [
                "detecting sentence boundaries",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers') is the subject, depending on the verb 'have developed'. Entity 2 ('detecting sentence boundaries') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting sentence boundaries'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "classifiers → integrate → sources → for → detecting",
        "sentence": "Classifiers integrate sources for detecting sentence boundaries.",
        "sentence_llm_dp_info": "\"Entity 1 ('hidden Markov model (HMM) and maximum entropy (Maxent) classifiers') is the subject, depending on the verb 'integrate'. Entity 2 ('detecting sentence boundaries') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting sentence boundaries'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose of integrating the classifiers.\""
    },
    {
        "raw_sentence": "In previous work , we have developed hidden Markov model -LRB- HMM -RRB- and maximum entropy -LRB- Maxent -RRB- classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries .",
        "ner_pair": [
            [
                "textual and prosodic knowledge sources",
                "Material"
            ],
            [
                "detecting sentence boundaries",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('textual and prosodic knowledge sources') is the object of the preposition 'for', depending on 'integrate'. Entity 2 ('detecting sentence boundaries') is the complement of 'for', depending on 'for' in the phrase 'for detecting sentence boundaries'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the purpose clause introduced by 'for'.\"",
        "sdp_path_text": "sources → for → detecting",
        "sentence": "Textual and prosodic knowledge sources are used for detecting sentence boundaries.",
        "sentence_llm_dp_info": "\"Entity 1 ('textual and prosodic knowledge sources') is the subject, depending on the verb 'used'. Entity 2 ('detecting sentence boundaries') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting sentence boundaries'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose for using Entity 1.\""
    },
    {
        "raw_sentence": "In this paper , we evaluate the use of a conditional random field -LRB- CRF -RRB- for this task and relate results with this model to our prior work .",
        "ner_pair": [
            [
                "conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conditional random field -LRB- CRF -RRB-') is the object of the preposition 'of', depending on 'use'. Entity 2 ('task') is the object of the preposition 'for', depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "-RRB- → evaluate → for → task",
        "sentence": "We evaluate the conditional random field (CRF) for the task.",
        "sentence_llm_dp_info": "\"Entity 1 ('conditional random field (CRF)') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('task') is the object of the preposition 'for', depending on 'for' in the phrase 'for the task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluate' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , we evaluate the use of a conditional random field -LRB- CRF -RRB- for this task and relate results with this model to our prior work .",
        "ner_pair": [
            [
                "conditional random field -LRB- CRF -RRB-",
                "Method"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conditional random field -LRB- CRF -RRB-') is the object of the preposition 'of', depending on 'use'. Entity 2 ('model') is the object of the preposition 'to', depending on 'relate'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the evaluation and results described in the sentence.\"",
        "sdp_path_text": "-RRB- → evaluate → relate → with → model",
        "sentence": "We evaluate the use of a conditional random field (CRF) and relate results with this model.",
        "sentence_llm_dp_info": "\"Entity 1 ('conditional random field (CRF)') is the object of the preposition 'of', depending on 'use'. Entity 2 ('model') is the object of the preposition 'with', depending on 'relate'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'evaluate' and 'relate' respectively.\""
    },
    {
        "raw_sentence": "In this paper , we evaluate the use of a conditional random field -LRB- CRF -RRB- for this task and relate results with this model to our prior work .",
        "ner_pair": [
            [
                "task",
                "Generic"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task') is the object of the preposition 'for', depending on 'evaluate' with the phrase 'evaluate the use...for this task'. Entity 2 ('model') is the object of the preposition 'with', depending on 'relate' in the phrase 'relate results with this model'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "task → for → evaluate → relate → with → model",
        "sentence": "We evaluate the task and relate results with the model.",
        "sentence_llm_dp_info": "\"Entity 1 ('task') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('model') is the object of the preposition 'with', depending on 'with' in the phrase 'with the model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure involving actions performed by 'We'.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "conversational telephone speech",
                "Material"
            ],
            [
                "corpora",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is the appositive, depending on 'corpora' with the preposition 'across'. Entity 2 ('corpora') is the object of the preposition 'across', depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'across two corpora' where Entity 1 specifies one type of the corpora being evaluated.\"",
        "sdp_path_text": "speech → corpora",
        "sentence": "Conversational telephone speech is one of the corpora evaluated.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is the subject, depending on the verb 'is'. Entity 2 ('corpora') is the object of the preposition 'of', depending on 'evaluated' in the phrase 'one of the corpora evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'one of the corpora evaluated'.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "broadcast news speech",
                "Material"
            ],
            [
                "corpora",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('broadcast news speech') is part of a conjunction, depending on the coordinating conjunction 'and' with 'conversational telephone speech'. It is also an element within the prepositional phrase 'across two corpora...'. Entity 2 ('corpora') is the object of the preposition 'across', depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the preposition 'across' and the conjunction 'and'.\"",
        "sdp_path_text": "speech → speech → corpora",
        "sentence": "Broadcast news speech is one of the corpora evaluated.",
        "sentence_llm_dp_info": "\"Entity 1 ('broadcast news speech') is the subject, depending on the verb 'is'. Entity 2 ('corpora') is the complement, depending on 'evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'broadcast news speech' is described as being one of the 'corpora' that were evaluated.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "corpora",
                "Generic"
            ],
            [
                "human transcriptions",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpora') is the object of the preposition 'across', depending on 'evaluate'. Entity 2 ('human transcriptions') is the object of the preposition 'on', depending on 'on' in the phrase 'on both human transcriptions and speech recognition output'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "corpora → across → evaluate → on → transcriptions",
        "sentence": "We evaluate corpora on human transcriptions.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpora') is the object, depending on the verb 'evaluate' with 'We'. Entity 2 ('human transcriptions') is the object of the preposition 'on', depending on 'on' in the phrase 'on human transcriptions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same evaluative action described by the verb 'evaluate'.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "corpora",
                "Generic"
            ],
            [
                "speech recognition output",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpora') is the object of the preposition 'across', depending on 'evaluate'. Entity 2 ('speech recognition output') is the object of the preposition 'on', part of the compound object 'human transcriptions and speech recognition output', depending on 'on'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "corpora → across → evaluate → on → transcriptions → output",
        "sentence": "We evaluate across corpora on speech recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpora') is the object of the preposition 'across', depending on 'evaluate'. Entity 2 ('speech recognition output') is the object of the preposition 'on', also depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'evaluate' through different prepositions.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "conversational telephone speech",
                "Material"
            ],
            [
                "broadcast news speech",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is part of a coordination, depending on 'across' with 'evaluate'. Entity 2 ('broadcast news speech') is also part of the same coordination, depending on 'and' with 'conversational telephone speech'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the coordinating conjunction 'and' within the prepositional phrase 'across two corpora'.\"",
        "sdp_path_text": "speech → speech",
        "sentence": "We evaluate on conversational telephone speech and broadcast news speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is the object of the preposition 'on', depending on 'evaluate'. Entity 2 ('broadcast news speech') is also the object of the preposition 'on', depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same preposition 'on'.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "conversational telephone speech",
                "Material"
            ],
            [
                "human transcriptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is part of a coordination, depending on 'across' with 'evaluate'. Entity 2 ('human transcriptions') is the object of the preposition 'on', depending on 'on' in the phrase 'on both human transcriptions and speech recognition output'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the evaluation scope described in the sentence.\"",
        "sdp_path_text": "speech → corpora → across → evaluate → on → transcriptions",
        "sentence": "We evaluate conversational telephone speech on human transcriptions.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('human transcriptions') is the object of the preposition 'on', depending on 'on' in the phrase 'on human transcriptions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the evaluation process described in the sentence.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "conversational telephone speech",
                "Material"
            ],
            [
                "speech recognition output",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is part of a list, depending on 'across' with 'evaluate'. Entity 2 ('speech recognition output') is the object of the preposition 'on', depending on 'on' in the phrase 'on both human transcriptions and speech recognition output'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the evaluation process described in the sentence.\"",
        "sdp_path_text": "speech → corpora → across → evaluate → on → transcriptions → output",
        "sentence": "We evaluate conversational telephone speech on speech recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational telephone speech') is the object, depending on the verb 'evaluate'. Entity 2 ('speech recognition output') is the object of the preposition 'on', depending on 'on' in the phrase 'on speech recognition output'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the evaluation process described in the sentence.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "broadcast news speech",
                "Material"
            ],
            [
                "human transcriptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('broadcast news speech') is part of a coordination, depending on 'across' with 'evaluate'. Entity 2 ('human transcriptions') is the object of the preposition 'on', depending on 'on' in the phrase 'on both human transcriptions and speech recognition output'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger structure describing what is being evaluated.\"",
        "sdp_path_text": "speech → speech → corpora → across → evaluate → on → transcriptions",
        "sentence": "We evaluate broadcast news speech on human transcriptions.",
        "sentence_llm_dp_info": "\"Entity 1 ('broadcast news speech') is the object, depending on the verb 'evaluate' with 'We'. Entity 2 ('human transcriptions') is the object of the preposition 'on', depending on 'on' in the phrase 'on human transcriptions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the evaluation process described in the sentence.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "broadcast news speech",
                "Material"
            ],
            [
                "speech recognition output",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('broadcast news speech') is part of a list, depending on the preposition 'across' with 'evaluate'. Entity 2 ('speech recognition output') is the object of the preposition 'on', depending on 'on' in the phrase 'on both human transcriptions and speech recognition output'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of what is being evaluated.\"",
        "sdp_path_text": "speech → speech → corpora → across → evaluate → on → transcriptions → output",
        "sentence": "We evaluate broadcast news speech on speech recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('broadcast news speech') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('speech recognition output') is the object of the preposition 'on', depending on 'on' in the phrase 'on speech recognition output'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'evaluate' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "We evaluate across two corpora -LRB- conversational telephone speech and broadcast news speech -RRB- on both human transcriptions and speech recognition output .",
        "ner_pair": [
            [
                "human transcriptions",
                "OtherScientificTerm"
            ],
            [
                "speech recognition output",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('human transcriptions') is the object of the preposition 'on', depending on 'evaluate'. Entity 2 ('speech recognition output') is also the object of the preposition 'on', depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase modifying the verb 'evaluate'.\"",
        "sdp_path_text": "transcriptions → output",
        "sentence": "We evaluate human transcriptions and speech recognition output.",
        "sentence_llm_dp_info": "\"Entity 1 ('human transcriptions') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('speech recognition output') is also an object of the verb 'evaluate', depending on 'evaluate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same verb 'evaluate'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "CRF model",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error rate') is the subject complement, depending on 'yields' with 'CRF model'. Entity 2 ('CRF model') is the subject, depending on 'yields' with 'error rate'. There is a direct dependency between Entity 1 and Entity 2, as 'CRF model' yields 'error rate'.\"",
        "sdp_path_text": "rate → yields → model",
        "sentence": "The CRF model yields a lower error rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('error rate') is the object, depending on 'yields' with 'CRF model'. Entity 2 ('CRF model') is the subject, depending on the verb 'yields'. There is a direct dependency between Entity 1 and Entity 2, where 'CRF model' yields 'error rate'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "CRF model",
                "Method"
            ],
            [
                "HMM and Max-ent models",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CRF model') is the subject, depending on the verb 'yields' in the clause 'our CRF model yields a lower error rate'. Entity 2 ('HMM and Max-ent models') is the object of the preposition 'than', depending on 'than' in the comparative phrase 'than the HMM and Max-ent models'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in the context of their performance on the NIST sentence boundary detection task.\"",
        "sdp_path_text": "model → yields → rate → than → models",
        "sentence": "The CRF model yields a lower error rate than the HMM and Max-ent models.",
        "sentence_llm_dp_info": "\"Entity 1 ('CRF model') is the subject, depending on the verb 'yields'. Entity 2 ('HMM and Max-ent models') is the object of comparison, depending on 'than' in the comparative clause 'than the HMM and Max-ent models'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure involving the verb 'yields' and the preposition 'than'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "NIST sentence boundary detection task",
                "Material"
            ],
            [
                "CRF model",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. Entity 2 ('CRF model') is the subject, depending on 'yields' with 'a lower error rate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields' which describes the performance of the CRF model on the NIST sentence boundary detection task.\"",
        "sdp_path_text": "task → on → rate → yields → model",
        "sentence": "The CRF model yields a lower error rate on the NIST sentence boundary detection task.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'yields'. Entity 2 ('CRF model') is the subject, depending on the verb 'yields'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields' which indicates that the CRF model produces a result (lower error rate) in the context of the NIST sentence boundary detection task.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "CRF model",
                "Method"
            ],
            [
                "speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CRF model') is the subject, depending on the verb 'yields' with 'our'. Entity 2 ('speech') is the object of the preposition 'in', depending on the prepositional phrase 'in speech'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the sentence structure, where the performance of the 'CRF model' is described in the context of 'speech'.\"",
        "sdp_path_text": "model → yields → rate → on → task → in → speech",
        "sentence": "The CRF model yields a lower error rate on the sentence boundary detection task in speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('CRF model') is the subject, depending on the verb 'yields'. Entity 2 ('speech') is the object of the preposition 'in', depending on 'in' in the phrase 'in speech'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in speech'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "CRF model",
                "Method"
            ],
            [
                "three-way voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CRF model') is the subject, depending on the verb 'yields' in the phrase 'yields a lower error rate'. Entity 2 ('three-way voting') is part of the object complement, depending on the verb 'achieved' in the clause 'the best results are achieved by three-way voting'. There is no direct dependency between Entity 1 and Entity 2; they are both related to the performance comparison described in the sentence.\"",
        "sdp_path_text": "model → yields → is → note → achieved → by → voting",
        "sentence": "The CRF model's performance is noted to be surpassed by three-way voting among classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('CRF model') is part of a possessive structure, where 'performance' depends on it as a modifier. Entity 2 ('three-way voting') is the subject complement, depending on 'surpassed' with the verb 'be'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the comparative structure indicating that the performance of Entity 2 surpasses that of Entity 1.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "CRF model",
                "Method"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CRF model') is the subject, depending on the verb 'yields' with the object 'a lower error rate'. Entity 2 ('classifiers') is part of the prepositional phrase 'among the classifiers', depending on the preposition 'among'. There is no direct dependency between Entity 1 and Entity 2; however, they are both involved in the context of comparing performance on the NIST sentence boundary detection task.\"",
        "sdp_path_text": "model → yields → is → note → achieved → by → voting → among → classifiers",
        "sentence": "The CRF model's performance is noted to be achieved through voting among classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('CRF model') is part of the possessive noun phrase, depending on 'performance' with the possessive relation. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'voting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'achieved' and the prepositional phrase 'through voting among classifiers'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "HMM and Max-ent models",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error rate') is the object, depending on 'yields' with 'CRF model'. Entity 2 ('HMM and Max-ent models') is the object of the preposition 'than', depending on 'than' in the phrase 'than the HMM and Max-ent models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure involving 'lower'.\"",
        "sdp_path_text": "rate → than → models",
        "sentence": "The error rate is lower than that of the HMM and Max-ent models.",
        "sentence_llm_dp_info": "\"Entity 1 ('error rate') is the subject, depending on the copula 'is'. Entity 2 ('HMM and Max-ent models') is the object of the preposition 'of', depending on 'that'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparison structure involving 'than' and 'of'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "NIST sentence boundary detection task",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error rate') is the object of the verb 'yields', depending on 'yields' with 'CRF model'. Entity 2 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'yields' and the preposition 'on'.\"",
        "sdp_path_text": "rate → on → task",
        "sentence": "The CRF model yields a lower error rate on the NIST sentence boundary detection task.",
        "sentence_llm_dp_info": "\"Entity 1 ('error rate') is the object of the verb 'yields', depending on 'yields' with 'CRF model'. Entity 2 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error rate') is the subject complement, depending on the verb 'yields' with 'model'. Entity 2 ('speech') is the object of the preposition 'in', depending on 'detection' in the phrase 'detection task in speech'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the performance of the CRF model compared to other models on a specific task.\"",
        "sdp_path_text": "rate → on → task → in → speech",
        "sentence": "The error rate is lower on the sentence boundary detection task in speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('error rate') is the subject, depending on the verb 'is'. Entity 2 ('speech') is the object of the preposition 'in', depending on 'in' in the phrase 'in speech'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in speech'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "three-way voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error rate') is the object of the verb 'yields', depending on 'yields' with 'CRF model'. Entity 2 ('three-way voting') is the subject complement, depending on 'achieved' with 'results'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of comparing performance outcomes in the sentence.\"",
        "sdp_path_text": "rate → yields → is → note → achieved → by → voting",
        "sentence": "The error rate is achieved by three-way voting.",
        "sentence_llm_dp_info": "\"Entity 1 ('error rate') is the subject, depending on the verb 'achieved'. Entity 2 ('three-way voting') is the object, depending on 'by' in the phrase 'by three-way voting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "error rate",
                "Metric"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error rate') is the object, depending on 'yields' with 'model'. Entity 2 ('classifiers') is part of a compound noun, depending on 'voting' in the phrase 'three-way voting among the classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same sentence, discussing performance metrics and methods.\"",
        "sdp_path_text": "rate → yields → is → note → achieved → by → voting → among → classifiers",
        "sentence": "The error rate is achieved by voting among classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('error rate') is the subject, depending on the verb 'achieved'. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'voting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the prepositional phrase 'by voting among classifiers'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "NIST sentence boundary detection task",
                "Material"
            ],
            [
                "HMM and Max-ent models",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. Entity 2 ('HMM and Max-ent models') is the subject complement, depending on the comparative construction 'than' in the phrase 'than the HMM and Max-ent models'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the comparison of error rates.\"",
        "sdp_path_text": "task → on → rate → than → models",
        "sentence": "The CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. Entity 2 ('HMM and Max-ent models') is the complement of the preposition 'than', depending on 'than' in the phrase 'than the HMM and Max-ent models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparative structure centered around 'yields a lower error rate'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "HMM and Max-ent models",
                "Method"
            ],
            [
                "speech",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('HMM and Max-ent models') is the object of the preposition 'than', depending on 'than' in the phrase 'than the HMM and Max-ent models'. Entity 2 ('speech') is the object of the preposition 'in', depending on 'in' in the phrase 'in speech'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing the context and comparison of the CRF model's performance.\"",
        "sdp_path_text": "models → than → rate → on → task → in → speech",
        "sentence": "HMM and Max-ent models have a higher error rate than our CRF model on the speech task.",
        "sentence_llm_dp_info": "\"Entity 1 ('HMM and Max-ent models') is the subject, depending on the verb 'have'. Entity 2 ('speech') is the object of the preposition 'on', depending on 'task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on the speech task'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "HMM and Max-ent models",
                "Method"
            ],
            [
                "three-way voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('HMM and Max-ent models') is the object of the preposition 'than', depending on 'than' in the phrase 'than the HMM and Max-ent models'. Entity 2 ('three-way voting') is the subject complement, depending on 'achieved' in the clause 'are achieved by three-way voting'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the comparison and performance context in the sentence.\"",
        "sdp_path_text": "models → than → rate → yields → is → note → achieved → by → voting",
        "sentence": "The HMM and Max-ent models yield a higher error rate than the best results achieved by three-way voting.",
        "sentence_llm_dp_info": "\"Entity 1 ('HMM and Max-ent models') is the subject, depending on the verb 'yield'. Entity 2 ('three-way voting') is the object of the preposition 'by', depending on 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the comparative clause 'a higher error rate than the best results achieved by three-way voting'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "HMM and Max-ent models",
                "Method"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('HMM and Max-ent models') is the object of the preposition 'than', depending on 'yields' in the clause 'yields a lower error rate than the HMM and Max-ent models'. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'voting' in the phrase 'voting among the classifiers'. There is no direct dependency between Entity 1 and Entity 2, but both are part of comparative and descriptive clauses within the same sentence.\"",
        "sdp_path_text": "models → than → rate → yields → is → note → achieved → by → voting → among → classifiers",
        "sentence": "The HMM and Max-ent models yield a higher error rate than the classifiers, which achieve the best results through three-way voting.",
        "sentence_llm_dp_info": "\"Entity 1 ('HMM and Max-ent models') is the subject, depending on the verb 'yield'. Entity 2 ('classifiers') is the subject of the relative clause, depending on 'which'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in the context of the sentence through the comparative structure 'than'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "speech",
                "Material"
            ],
            [
                "NIST sentence boundary detection task",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech') is the object of the preposition 'in', depending on 'task' within the phrase 'task in speech'. Entity 2 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'yields' in the clause 'yields a lower error rate on the NIST sentence boundary detection task'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'speech' specifies the domain of the 'task'.\"",
        "sdp_path_text": "speech → in → task",
        "sentence": "The CRF model performs on the NIST sentence boundary detection task in speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech') is the object, depending on the preposition 'in', which modifies the verb 'performs'. Entity 2 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where the 'CRF model' performs.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "NIST sentence boundary detection task",
                "Material"
            ],
            [
                "three-way voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. Entity 2 ('three-way voting') is part of the noun phrase 'three-way voting among the classifiers', acting as the subject complement of the clause 'the best results are achieved by three-way voting'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the performance context described in the sentence.\"",
        "sdp_path_text": "task → on → rate → yields → is → note → achieved → by → voting",
        "sentence": "The NIST sentence boundary detection task's best results are achieved by three-way voting.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the possessive noun, depending on 'results' with the possessive marker '’s'. Entity 2 ('three-way voting') is the subject complement, depending on 'achieved' with 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the possessive structure indicating that the results of the task are achieved by the method described by Entity 2.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "NIST sentence boundary detection task",
                "Material"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the object of the preposition 'on', depending on 'on' in the phrase 'on the NIST sentence boundary detection task'. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'among' in the phrase 'among the classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context describing the performance comparison of different models in a specific task.\"",
        "sdp_path_text": "task → on → rate → yields → is → note → achieved → by → voting → among → classifiers",
        "sentence": "The NIST sentence boundary detection task achieves better results through voting among classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST sentence boundary detection task') is the subject, depending on the verb 'achieves'. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'voting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'through voting among classifiers'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "speech",
                "Material"
            ],
            [
                "three-way voting",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech') is the object of the preposition 'in', depending on the prepositional phrase 'in speech'. Entity 2 ('three-way voting') is the subject complement, depending on 'achieved' with 'are'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence context describing the performance of different models.\"",
        "sdp_path_text": "speech → in → task → on → rate → yields → is → note → achieved → by → voting",
        "sentence": "The best results on the speech task are achieved by three-way voting.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech') is part of the compound noun 'speech task', which is the object of the preposition 'on', depending on 'achieved'. Entity 2 ('three-way voting') is the subject complement, depending on 'are' in the phrase 'are achieved by three-way voting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "speech",
                "Material"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech') is the object of the preposition 'in', depending on 'task' in the phrase 'task in speech'. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'voting' in the phrase 'voting among the classifiers'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "speech → in → task → on → rate → yields → is → note → achieved → by → voting → among → classifiers",
        "sentence": "The CRF model yields a lower error rate on the NIST sentence boundary detection task in speech, with the best results achieved by voting among classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech') is the object of the preposition 'in', depending on 'task'. Entity 2 ('classifiers') is the object of the preposition 'among', depending on 'voting'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three-way voting among the classifiers .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "three-way voting",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the object, depending on 'among' in the phrase 'among the classifiers'. Entity 2 ('three-way voting') is the subject complement, depending on 'achieved' in the clause 'are achieved by three-way voting'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'three-way voting' is described as being used among the classifiers.\"",
        "sdp_path_text": "classifiers → among → voting",
        "sentence": "The best results are achieved by three-way voting among the classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the object of the preposition 'among', depending on 'among' in the phrase 'among the classifiers'. Entity 2 ('three-way voting') is the subject complement, depending on the verb 'achieved' in the phrase 'are achieved by'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'among' and the verb 'achieved'.\""
    },
    {
        "raw_sentence": "This probably occurs because each model has different strengths and weaknesses for modeling the knowledge sources .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "knowledge sources",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on 'has' with 'each'. Entity 2 ('knowledge sources') is the object, depending on 'modeling' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'modeling' and the preposition 'for'.\"",
        "sdp_path_text": "model → has → strengths → for → modeling → sources",
        "sentence": "Each model has strengths for modeling knowledge sources.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'has'. Entity 2 ('knowledge sources') is the object of the preposition 'for', depending on 'for' in the phrase 'for modeling knowledge sources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the verb 'modeling'.\""
    },
    {
        "raw_sentence": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "PTZ cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject complement, depending on 'propose' with 'We'. Entity 2 ('PTZ cameras') is the object of the preposition 'across', depending on 'across' in the phrase 'across multiple PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'across' which indicates the scope or domain where the 'approach' is applied.\"",
        "sdp_path_text": "approach → associate → across → cameras",
        "sentence": "We propose an approach to associate objects across PTZ cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object, depending on 'propose' with 'We'. Entity 2 ('PTZ cameras') is the object of the preposition 'across', depending on 'across' in the phrase 'across PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'across'.\""
    },
    {
        "raw_sentence": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "camera handoff in wide-area surveillance scenarios",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'propose' with 'We'. Entity 2 ('camera handoff in wide-area surveillance scenarios') is the object of the preposition 'to', depending on 'perform' in the clause 'that can be used to perform camera handoff in wide-area surveillance scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'that can be used to perform'.\"",
        "sdp_path_text": "approach → used → perform → handoff",
        "sentence": "We propose an approach to perform camera handoff in wide-area surveillance scenarios.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the direct object, depending on the verb 'propose' with 'We'. Entity 2 ('camera handoff in wide-area surveillance scenarios') is the object of the preposition 'to', depending on 'perform' in the phrase 'to perform camera handoff in wide-area surveillance scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'perform' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform camera handoff in wide-area surveillance scenarios .",
        "ner_pair": [
            [
                "PTZ cameras",
                "OtherScientificTerm"
            ],
            [
                "camera handoff in wide-area surveillance scenarios",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PTZ cameras') is the object of the preposition 'across', depending on 'associate' in the phrase 'to associate objects across multiple PTZ cameras'. Entity 2 ('camera handoff in wide-area surveillance scenarios') is the object of the preposition 'to', depending on 'perform' in the phrase 'to perform camera handoff in wide-area surveillance scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger purpose clause introduced by 'to'.\"",
        "sdp_path_text": "cameras → across → associate → approach → used → perform → handoff",
        "sentence": "PTZ cameras are used to perform camera handoff in wide-area surveillance scenarios.",
        "sentence_llm_dp_info": "\"Entity 1 ('PTZ cameras') is the subject, depending on the verb 'are used'. Entity 2 ('camera handoff in wide-area surveillance scenarios') is the object of the preposition 'to', depending on 'perform' in the phrase 'to perform camera handoff in wide-area surveillance scenarios'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'perform' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "geometric , appearance , or correlation-based information",
                "OtherScientificTerm"
            ],
            [
                "approaches",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the object, depending on the preposition 'on', which itself depends on 'relied' in the phrase 'relied on'. Entity 2 ('approaches') is the subject, depending on 'relied' with 'previous' in the phrase 'previous approaches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'relied' and the preposition 'on'.\"",
        "sdp_path_text": "information → on → relied → approaches",
        "sentence": "Previous approaches relied on geometric, appearance, or correlation-based information.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the object, depending on the preposition 'on', which modifies 'relied'. Entity 2 ('approaches') is the subject, depending on the verb 'relied'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is what Entity 2 relied on.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "static cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the past participle 'relied' with 'While previous'. Entity 2 ('static cameras') is the object of the preposition 'between', depending on 'between' in the phrase 'between static cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for establishing correspondences between static cameras'.\"",
        "sdp_path_text": "approaches → relied → for → establishing → correspondences → between → cameras",
        "sentence": "Previous approaches relied on information for establishing correspondences between static cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'relied'. Entity 2 ('static cameras') is the object of the preposition 'between', depending on 'between' in the phrase 'between static cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for establishing correspondences between static cameras'.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "wide-area settings",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'relied'. Entity 2 ('wide-area settings') is the object of the preposition 'to', depending on 'extendable'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the limitations and extendability discussed in the sentence.\"",
        "sdp_path_text": "approaches → relied → have → are → extendable → to → settings",
        "sentence": "Previous approaches, which relied on specific information, are not extendable to wide-area settings.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'are' with the negation 'not'. Entity 2 ('wide-area settings') is the object of the preposition 'to', depending on 'extendable'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'are not extendable to'.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "PTZ cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'relied' in the clause 'previous approaches relied on geometric, appearance, or correlation-based information'. Entity 2 ('PTZ cameras') is the object of the preposition 'with', depending on 'settings' in the phrase 'wide-area settings with PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "approaches → relied → have → are → extendable → to → settings → with → cameras",
        "sentence": "Previous approaches, which relied on specific information, are not extendable to settings with PTZ cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'are' (are not extendable). Entity 2 ('PTZ cameras') is the object of the preposition 'with', depending on 'settings'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause that describes the settings in which the approaches are not extendable.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "geometric , appearance , or correlation-based information",
                "OtherScientificTerm"
            ],
            [
                "static cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the object of the preposition 'on', depending on 'relied' in the clause 'relied on geometric, appearance, or correlation-based information'. Entity 2 ('static cameras') is the object of the preposition 'between', depending on 'establishing' in the phrase 'establishing correspondences between static cameras'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing what previous approaches relied on and how it was used.\"",
        "sdp_path_text": "information → on → relied → for → establishing → correspondences → between → cameras",
        "sentence": "Geometric, appearance, or correlation-based information was relied on for establishing correspondences between static cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the subject, depending on the verb 'was relied on'. Entity 2 ('static cameras') is the object of the preposition 'between', depending on 'between' in the phrase 'between static cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for establishing correspondences between static cameras'.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "geometric , appearance , or correlation-based information",
                "OtherScientificTerm"
            ],
            [
                "wide-area settings",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the object of the preposition 'on', depending on 'relied' in the clause 'previous approaches relied on...'. Entity 2 ('wide-area settings') is the object of the preposition 'to', depending on 'extendable' in the phrase 'not extendable to wide-area settings'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence structure describing the limitations of previous approaches and their applicability.\"",
        "sdp_path_text": "information → on → relied → have → are → extendable → to → settings",
        "sentence": "Geometric, appearance, or correlation-based information relied upon for static cameras are not extendable to wide-area settings.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the subject, depending on the verb 'relied'. Entity 2 ('wide-area settings') is the object of the preposition 'to', depending on 'to' in the phrase 'to wide-area settings'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating that the information is not extendable to these settings.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "geometric , appearance , or correlation-based information",
                "OtherScientificTerm"
            ],
            [
                "PTZ cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the object, depending on the preposition 'on', which modifies 'relied' in the clause 'previous approaches relied on...'. Entity 2 ('PTZ cameras') is the object of the preposition 'with', which modifies 'settings' in the phrase 'wide-area settings with PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses that describe the context and limitations of the approaches and settings.\"",
        "sdp_path_text": "information → on → relied → have → are → extendable → to → settings → with → cameras",
        "sentence": "Geometric, appearance, or correlation-based information, which previous approaches relied on, are not extendable to settings with PTZ cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric, appearance, or correlation-based information') is the subject, depending on the verb 'are' and modified by the relative clause 'which previous approaches relied on'. Entity 2 ('PTZ cameras') is the object of the preposition 'to', depending on 'to' in the phrase 'to settings with PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the negated predicate 'are not extendable to settings with PTZ cameras'.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "static cameras",
                "OtherScientificTerm"
            ],
            [
                "wide-area settings",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('static cameras') is the object of the preposition 'between', depending on 'establishing' in the phrase 'establishing correspondences between static cameras'. Entity 2 ('wide-area settings') is the complement of the preposition 'to', depending on 'extendable' in the phrase 'not extendable to wide-area settings'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "cameras → between → correspondences → establishing → for → relied → have → are → extendable → to → settings",
        "sentence": "Correspondences between static cameras are not extendable to wide-area settings.",
        "sentence_llm_dp_info": "\"Entity 1 ('static cameras') is part of the subject, depending on the preposition 'between' with 'correspondences'. Entity 2 ('wide-area settings') is the object of the preposition 'to', depending on 'to' in the phrase 'to wide-area settings'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the negated verb 'are not extendable'.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "static cameras",
                "OtherScientificTerm"
            ],
            [
                "PTZ cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('static cameras') is the object of the preposition 'between', depending on 'for' in the phrase 'for establishing correspondences between static cameras'. Entity 2 ('PTZ cameras') is the object of the preposition 'with', depending on 'to' in the phrase 'to wide-area settings with PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context describing different types of camera systems in the sentence.\"",
        "sdp_path_text": "cameras → between → correspondences → establishing → for → relied → have → are → extendable → to → settings → with → cameras",
        "sentence": "Correspondences between static cameras are not extendable to settings with PTZ cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('static cameras') is the object of the preposition 'between', depending on 'Correspondences'. Entity 2 ('PTZ cameras') is the object of the preposition 'with', depending on 'settings'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparison in the sentence.\""
    },
    {
        "raw_sentence": "While previous approaches relied on geometric , appearance , or correlation-based information for establishing correspondences between static cameras , they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras .",
        "ner_pair": [
            [
                "wide-area settings",
                "OtherScientificTerm"
            ],
            [
                "PTZ cameras",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('wide-area settings') is the object of the preposition 'to', depending on 'extendable'. Entity 2 ('PTZ cameras') is part of a compound noun, depending on 'settings' in the phrase 'wide-area settings with PTZ cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\"",
        "sdp_path_text": "settings → with → cameras",
        "sentence": "Wide-area settings include PTZ cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('wide-area settings') is the subject, depending on the verb 'include'. Entity 2 ('PTZ cameras') is the object, depending on the verb 'include'. There is a direct dependency between Entity 1 and Entity 2, as 'PTZ cameras' is included in 'wide-area settings'.\""
    },
    {
        "raw_sentence": "In our approach , the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery , thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "slave camera",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'In', depending on the prepositional phrase 'In our approach'. Entity 2 ('slave camera') is the subject, depending on the verb 'follows'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause, where 'slave camera' performs an action that is described within the context of 'our approach'.\"",
        "sdp_path_text": "approach → In → follows → camera",
        "sentence": "In our approach, the slave camera follows the target.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'In', depending on 'In' in the phrase 'In our approach'. Entity 2 ('slave camera') is the subject, depending on the verb 'follows'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'slave camera' performs an action described within the context of 'our approach'.\""
    },
    {
        "raw_sentence": "In our approach , the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery , thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "model transfer",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'In', depending on the prepositional phrase 'In our approach'. Entity 2 ('model transfer') is the object of the preposition 'to', depending on the verb 'perform' within the clause 'avoiding the need to perform any model transfer'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same larger context where the 'approach' avoids the 'model transfer'.\"",
        "sdp_path_text": "approach → In → follows → bootstraps → circumventing → avoiding → need → perform → transfer",
        "sentence": "Our approach avoids the need to perform model transfer.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'avoids'. Entity 2 ('model transfer') is the object of the preposition 'to', depending on 'need' in the phrase 'the need to perform model transfer'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'avoids' and the prepositional phrase 'to perform model transfer'.\""
    },
    {
        "raw_sentence": "In our approach , the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery , thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer .",
        "ner_pair": [
            [
                "slave camera",
                "OtherScientificTerm"
            ],
            [
                "approaches",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('slave camera') is the subject, depending on 'follows' with 'target'. It also depends on 'bootstraps' as the subject in the clause 'and bootstraps itself from its own incoming imagery'. Entity 2 ('approaches') is the object of the preposition 'by', depending on 'circumventing' in the phrase 'circumventing the problems faced by previous approaches'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "camera → follows → bootstraps → circumventing → problems → faced → by → approaches",
        "sentence": "The slave camera circumvents problems faced by previous approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('slave camera') is the subject, depending on the verb 'circumvents'. Entity 2 ('approaches') is the object of the preposition 'by', part of the prepositional phrase 'by previous approaches', which modifies 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'circumvents' and the prepositional phrase 'by previous approaches'.\""
    },
    {
        "raw_sentence": "In our approach , the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery , thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer .",
        "ner_pair": [
            [
                "slave camera",
                "OtherScientificTerm"
            ],
            [
                "model transfer",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('slave camera') is the subject, depending on 'follows' with 'target'. It also depends on 'bootstraps' as the subject of that clause. Entity 2 ('model transfer') is the object of the preposition 'to', depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "camera → follows → bootstraps → circumventing → avoiding → need → perform → transfer",
        "sentence": "The slave camera avoids the need to perform model transfer.",
        "sentence_llm_dp_info": "\"Entity 1 ('slave camera') is the subject, depending on the verb 'avoids'. Entity 2 ('model transfer') is the object, depending on the noun 'need' in the phrase 'the need to perform model transfer'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'avoids' and the phrase 'the need to perform'.\""
    },
    {
        "raw_sentence": "In our approach , the slave camera only passively follows the target -LRB- by loose registration with the master -RRB- and bootstraps itself from its own incoming imagery , thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "model transfer",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the preposition 'by', depending on 'circumventing' in the phrase 'circumventing the problems faced by previous approaches'. Entity 2 ('model transfer') is the object of the infinitive 'to perform', depending on 'avoiding' in the phrase 'avoiding the need to perform any model transfer'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "approaches → by → faced → problems → circumventing → avoiding → need → perform → transfer",
        "sentence": "Our approach circumvents problems faced by previous approaches and avoids the need to perform model transfer.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the preposition 'by', depending on 'faced'. Entity 2 ('model transfer') is the object of the infinitive 'to perform', depending on 'avoid'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Towards this goal , we also propose a novel Multiple Instance Learning -LRB- MIL -RRB- formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework .",
        "ner_pair": [
            [
                "logistic softmax function of covariance-based region features",
                "OtherScientificTerm"
            ],
            [
                "Multiple Instance Learning -LRB- MIL -RRB- formulation",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic softmax function of covariance-based region features') is the object of the preposition 'of', depending on 'formulation'. Entity 2 ('Multiple Instance Learning -LRB- MIL -RRB- formulation') is the direct object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on the logistic softmax function of covariance-based region features' which modifies Entity 2.\"",
        "sdp_path_text": "function → on → based → formulation",
        "sentence": "A Multiple Instance Learning (MIL) formulation is based on the logistic softmax function of covariance-based region features.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic softmax function of covariance-based region features') is the object of the preposition 'on', depending on 'based'. Entity 2 ('Multiple Instance Learning (MIL) formulation') is the subject, depending on the verb 'is' in the phrase 'is based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' which indicates that the 'formulation' is based 'on' the 'logistic softmax function of covariance-based region features'.\""
    },
    {
        "raw_sentence": "Towards this goal , we also propose a novel Multiple Instance Learning -LRB- MIL -RRB- formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework .",
        "ner_pair": [
            [
                "MAP estimation framework",
                "Method"
            ],
            [
                "Multiple Instance Learning -LRB- MIL -RRB- formulation",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MAP estimation framework') is the object of the preposition 'within', depending on 'within' in the phrase 'within a MAP estimation framework'. Entity 2 ('Multiple Instance Learning -LRB- MIL -RRB- formulation') is the object, depending on 'propose' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, with Entity 2 being proposed and Entity 1 providing the context in which it is applied.\"",
        "sdp_path_text": "framework → within → based → formulation",
        "sentence": "A Multiple Instance Learning (MIL) formulation is based on a MAP estimation framework.",
        "sentence_llm_dp_info": "\"Entity 1 ('MAP estimation framework') is the object of the preposition 'on', depending on the preposition 'on' in the phrase 'based on a MAP estimation framework'. Entity 2 ('Multiple Instance Learning (MIL) formulation') is the subject, depending on the verb 'is' in the clause 'A Multiple Instance Learning (MIL) formulation is based...'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Towards this goal , we also propose a novel Multiple Instance Learning -LRB- MIL -RRB- formulation for the problem based on the logistic softmax function of covariance-based region features within a MAP estimation framework .",
        "ner_pair": [
            [
                "logistic softmax function of covariance-based region features",
                "OtherScientificTerm"
            ],
            [
                "MAP estimation framework",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic softmax function of covariance-based region features') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the logistic softmax function of covariance-based region features'. Entity 2 ('MAP estimation framework') is the object of the preposition 'within', depending on 'within' in the phrase 'within a MAP estimation framework'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the formulation proposed for the problem.\"",
        "sdp_path_text": "function → on → based → within → framework",
        "sentence": "The logistic softmax function of covariance-based region features is used within a MAP estimation framework.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic softmax function of covariance-based region features') is the subject, depending on the verb 'is used'. Entity 2 ('MAP estimation framework') is the object of the preposition 'within', depending on 'within' in the phrase 'within a MAP estimation framework'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'within'.\""
    },
    {
        "raw_sentence": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches .",
        "ner_pair": [
            [
                "multiple PTZ camera sequences",
                "OtherScientificTerm"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple PTZ camera sequences') is the object of the preposition 'with', depending on 'demonstrate'. Entity 2 ('approach') is the direct object, depending on the verb 'demonstrate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is demonstrated.\"",
        "sdp_path_text": "sequences → with → demonstrate → approach",
        "sentence": "We demonstrate our approach with multiple PTZ camera sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple PTZ camera sequences') is the object, depending on the preposition 'with', which itself depends on the verb 'demonstrate'. Entity 2 ('approach') is the object, depending on the possessive pronoun 'our', and it is part of the larger structure where it serves as the direct object of the verb 'demonstrate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrate' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "outdoor surveillance settings",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'our', depending on 'demonstrate' with 'We'. Entity 2 ('outdoor surveillance settings') is the object of the preposition 'in', depending on 'sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'approach' is demonstrated in the context of 'outdoor surveillance settings'.\"",
        "sdp_path_text": "approach → demonstrate → with → sequences → in → settings",
        "sentence": "We demonstrate our approach in outdoor surveillance settings.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object, depending on the verb 'demonstrate'. Entity 2 ('outdoor surveillance settings') is the object of the preposition 'in', depending on 'in' in the phrase 'in outdoor surveillance settings'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'approach' is demonstrated 'in outdoor surveillance settings'.\""
    },
    {
        "raw_sentence": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches .",
        "ner_pair": [
            [
                "multiple PTZ camera sequences",
                "OtherScientificTerm"
            ],
            [
                "outdoor surveillance settings",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple PTZ camera sequences') is the object of the preposition 'with', depending on 'demonstrate'. Entity 2 ('outdoor surveillance settings') is the object of the preposition 'in', depending on 'sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and both contribute to describing the context in which the demonstration is performed.\"",
        "sdp_path_text": "sequences → in → settings",
        "sentence": "Multiple PTZ camera sequences are used in outdoor surveillance settings.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple PTZ camera sequences') is the subject, depending on the verb 'are used'. Entity 2 ('outdoor surveillance settings') is the object of the preposition 'in', depending on 'in' in the phrase 'in outdoor surveillance settings'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches .",
        "ner_pair": [
            [
                "multiple PTZ camera sequences",
                "OtherScientificTerm"
            ],
            [
                "state-of-the-art approaches",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple PTZ camera sequences') is the object of the preposition 'with', depending on 'demonstrate'. Entity 2 ('state-of-the-art approaches') is the object of the preposition 'with', depending on 'show'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different prepositional phrases in the sentence.\"",
        "sdp_path_text": "sequences → with → demonstrate → show → comparison → with → approaches",
        "sentence": "We demonstrate our approach with multiple PTZ camera sequences and show a comparison with state-of-the-art approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple PTZ camera sequences') is the object of the preposition 'with', depending on 'demonstrate'. Entity 2 ('state-of-the-art approaches') is the object of the preposition 'with', depending on 'comparison'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where 'approach' is demonstrated and compared.\""
    },
    {
        "raw_sentence": "We demonstrate our approach with multiple PTZ camera sequences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches .",
        "ner_pair": [
            [
                "outdoor surveillance settings",
                "OtherScientificTerm"
            ],
            [
                "state-of-the-art approaches",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('outdoor surveillance settings') is the object of the preposition 'in', depending on 'sequences'. Entity 2 ('state-of-the-art approaches') is the object of the preposition 'with', depending on 'comparison'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "settings → in → sequences → with → demonstrate → show → comparison → with → approaches",
        "sentence": "We show a comparison with state-of-the-art approaches in outdoor surveillance settings.",
        "sentence_llm_dp_info": "\"Entity 1 ('outdoor surveillance settings') is the object of the preposition 'in', depending on 'comparison'. Entity 2 ('state-of-the-art approaches') is the object of the preposition 'with', depending on 'comparison'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the noun 'comparison'.\""
    },
    {
        "raw_sentence": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .",
        "ner_pair": [
            [
                "specialized regression problem",
                "Task"
            ],
            [
                "sampling probabilities",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('specialized regression problem') is the object of the verb 'solves', depending on 'solves' with 'This paper'. Entity 2 ('sampling probabilities') is the object of the infinitive 'to obtain', depending on 'obtain'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where solving the problem leads to obtaining the probabilities.\"",
        "sdp_path_text": "problem → solves → obtain → probabilities",
        "sentence": "This paper solves a specialized regression problem to obtain sampling probabilities.",
        "sentence_llm_dp_info": "\"Entity 1 ('specialized regression problem') is the object, depending on the verb 'solves' with 'This paper'. Entity 2 ('sampling probabilities') is the object, depending on the verb 'obtain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of solving the problem to achieve the goal of obtaining the sampling probabilities.\""
    },
    {
        "raw_sentence": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .",
        "ner_pair": [
            [
                "specialized regression problem",
                "Task"
            ],
            [
                "records",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('specialized regression problem') is the object, depending on 'solves' with 'This paper'. Entity 2 ('records') is the object of the preposition 'for', depending on 'for' in the phrase 'for records'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'obtain' and the preposition 'for'.\"",
        "sdp_path_text": "problem → solves → obtain → probabilities → for → records",
        "sentence": "This paper solves a specialized regression problem to obtain probabilities for records.",
        "sentence_llm_dp_info": "\"Entity 1 ('specialized regression problem') is the object of the verb 'solves', depending on 'solves' with 'This paper'. Entity 2 ('records') is the object of the preposition 'for', depending on 'for' in the phrase 'for records'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose of solving the problem to obtain probabilities for the records.\""
    },
    {
        "raw_sentence": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .",
        "ner_pair": [
            [
                "specialized regression problem",
                "Task"
            ],
            [
                "databases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('specialized regression problem') is the object of the verb 'solves', depending on 'solves' with 'This paper'. Entity 2 ('databases') is the object of the preposition 'in', depending on 'in' in the phrase 'in databases'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where the action of solving the problem is related to obtaining probabilities for records in databases.\"",
        "sdp_path_text": "problem → solves → obtain → probabilities → for → records → in → databases",
        "sentence": "This paper solves a specialized regression problem to obtain probabilities for records in databases.",
        "sentence_llm_dp_info": "\"Entity 1 ('specialized regression problem') is the object of the verb 'solves', depending on 'solves' with 'This paper'. Entity 2 ('databases') is the object of the preposition 'in', depending on 'in' in the phrase 'in databases'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the action of solving the problem leads to obtaining probabilities for records in databases.\""
    },
    {
        "raw_sentence": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .",
        "ner_pair": [
            [
                "sampling probabilities",
                "OtherScientificTerm"
            ],
            [
                "records",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sampling probabilities') is the object, depending on 'obtain' which is part of the infinitive phrase 'to obtain'. Entity 2 ('records') is the object of the preposition 'for', depending on 'for' in the phrase 'for records'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger goal described by the sentence.\"",
        "sdp_path_text": "probabilities → for → records",
        "sentence": "This paper obtains sampling probabilities for records.",
        "sentence_llm_dp_info": "\"Entity 1 ('sampling probabilities') is the direct object, depending on the verb 'obtains'. Entity 2 ('records') is the object of the preposition 'for', depending on 'for' in the phrase 'for records'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtains' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .",
        "ner_pair": [
            [
                "sampling probabilities",
                "OtherScientificTerm"
            ],
            [
                "databases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sampling probabilities') is the object of the verb 'obtain', depending on 'to obtain'. Entity 2 ('databases') is the object of the preposition 'in', depending on 'in' in the phrase 'in databases'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose of solving the regression problem.\"",
        "sdp_path_text": "probabilities → for → records → in → databases",
        "sentence": "This paper obtains sampling probabilities for records in databases.",
        "sentence_llm_dp_info": "\"Entity 1 ('sampling probabilities') is the object, depending on the verb 'obtains'. Entity 2 ('databases') is the object of the preposition 'in', depending on 'in' in the phrase 'in databases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .",
        "ner_pair": [
            [
                "records",
                "Material"
            ],
            [
                "databases",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('records') is the object, depending on the preposition 'for' in the phrase 'for records'. Entity 2 ('databases') is the object, depending on the preposition 'in' in the phrase 'in databases'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for records in databases' which modifies 'sampling probabilities'.\"",
        "sdp_path_text": "records → in → databases",
        "sentence": "Sampling probabilities for records in databases are obtained.",
        "sentence_llm_dp_info": "\"Entity 1 ('records') is the object of the preposition 'for', depending on 'probabilities'. Entity 2 ('databases') is the object of the preposition 'in', depending on 'records'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'for records' and 'in databases'.\""
    },
    {
        "raw_sentence": "The goal is to sample a small set of records over which evaluating aggregate queries can be done both efficiently and accurately .",
        "ner_pair": [
            [
                "aggregate queries",
                "OtherScientificTerm"
            ],
            [
                "records",
                "Material"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('aggregate queries') is the object, depending on 'evaluating' which modifies the clause 'evaluating aggregate queries'. Entity 2 ('records') is the object of the preposition 'of', depending on 'set' in the phrase 'a small set of records'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose of sampling the records for the evaluation of the aggregate queries.\"",
        "sdp_path_text": "queries → evaluating → done → set → of → records",
        "sentence": "Evaluating aggregate queries can be done over a set of records.",
        "sentence_llm_dp_info": "\"Entity 1 ('aggregate queries') is the subject, depending on the verb 'can be done'. Entity 2 ('records') is the object of the preposition 'over', depending on 'over' in the phrase 'over a set of records'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'over'.\""
    },
    {
        "raw_sentence": "We provide a principled and provable solution for this problem ; it is parameterless and requires no data insights .",
        "ner_pair": [
            [
                "principled and provable solution",
                "Method"
            ],
            [
                "problem",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('principled and provable solution') is the object, depending on the verb 'provide'. Entity 2 ('problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for this problem'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for'.\"",
        "sdp_path_text": "solution → for → problem",
        "sentence": "We provide a principled and provable solution for the problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('principled and provable solution') is the direct object, depending on the verb 'provide'. Entity 2 ('problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We provide a principled and provable solution for this problem ; it is parameterless and requires no data insights .",
        "ner_pair": [
            [
                "principled and provable solution",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('principled and provable solution') is the object, depending on 'provide' with 'We'. Entity 2 ('it') is the subject, depending on 'is' with 'parameterless'. There is no direct dependency between Entity 1 and Entity 2, but 'it' likely refers back to 'principled and provable solution' in the context of the sentence.\"",
        "sdp_path_text": "solution → provide → is → it",
        "sentence": "{\n  \"Simplified sentence\": \"We provide a principled and provable solution; it is parameterless and requires no data insights.\"\n} \n\nHowever, since the task is to focus on the relationship between \"principled and provable solution\" and \"it,\" and to remove extraneous information, a more refined simplification would be:\n\n{\n  \"Simplified sentence\": \"The principled and provable solution is parameterless and requires no data insights.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('principled and provable solution') is the subject, depending on the verb 'is'. Entity 2 ('it') is a pronoun that refers back to 'principled and provable solution', depending on the verb 'is' as well. There is no direct dependency between Entity 1 and Entity 2, but 'it' serves as a reference to 'principled and provable solution'.\""
    },
    {
        "raw_sentence": "We provide a principled and provable solution for this problem ; it is parameterless and requires no data insights .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('problem') is the object of the preposition 'for', depending on 'solution'. Entity 2 ('it') is the subject, depending on 'is' with 'is parameterless and requires no data insights'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "problem → for → solution → provide → is → it",
        "sentence": "It is a solution for the problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the problem'. Entity 2 ('it') is the subject, depending on 'is' as the copula verb. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the predicate 'a solution for'.\""
    },
    {
        "raw_sentence": "Unlike standard regression problems , the loss is inversely proportional to the regressed-to values .",
        "ner_pair": [
            [
                "regression problems",
                "Task"
            ],
            [
                "loss",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regression problems') is the subject of the clause 'Unlike standard regression problems', depending on the preposition 'Unlike'. Entity 2 ('loss') is the subject of the main clause, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the comparison introduced by 'Unlike'.\"",
        "sdp_path_text": "problems → Unlike → is → loss",
        "sentence": "The loss is inversely proportional to the values in regression problems.",
        "sentence_llm_dp_info": "\"Entity 1 ('regression problems') is the object, depending on the preposition 'in', which modifies 'values'. Entity 2 ('loss') is the subject, depending on the verb 'is' and modified by 'inversely proportional to the values in regression problems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relationship described by 'inversely proportional to the values in'.\""
    },
    {
        "raw_sentence": "Unlike standard regression problems , the loss is inversely proportional to the regressed-to values .",
        "ner_pair": [
            [
                "regression problems",
                "Task"
            ],
            [
                "regressed-to values",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regression problems') is the subject complement, depending on 'Unlike' with 'standard'. Entity 2 ('regressed-to values') is the object of the preposition 'to', depending on 'proportional' in the phrase 'proportional to the regressed-to values'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence that describes the relationship between the loss and these values.\"",
        "sdp_path_text": "problems → Unlike → is → proportional → to → values",
        "sentence": "The loss in regression problems is inversely proportional to the regressed-to values.",
        "sentence_llm_dp_info": "\"Entity 1 ('regression problems') is the object of the preposition 'in', depending on 'loss'. Entity 2 ('regressed-to values') is the object of the preposition 'to', depending on 'proportional'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the relationship between the loss and the values.\""
    },
    {
        "raw_sentence": "Unlike standard regression problems , the loss is inversely proportional to the regressed-to values .",
        "ner_pair": [
            [
                "loss",
                "OtherScientificTerm"
            ],
            [
                "regressed-to values",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on 'is' with 'inversely proportional'. Entity 2 ('regressed-to values') is the object, depending on 'to' in the phrase 'to the regressed-to values'. There is a direct dependency between Entity 1 and Entity 2, as they are connected through the preposition 'to' indicating the relationship of being inversely proportional.\"",
        "sdp_path_text": "loss → is → proportional → to → values",
        "sentence": "The loss is inversely proportional to the regressed-to values.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on the verb 'is'. Entity 2 ('regressed-to values') is the object of the preposition 'to', depending on 'proportional' in the phrase 'proportional to'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate 'is inversely proportional to'.\""
    },
    {
        "raw_sentence": "Moreover , a cost zero solution always exists and can only be excluded by hard budget constraints .",
        "ner_pair": [
            [
                "hard budget constraints",
                "OtherScientificTerm"
            ],
            [
                "cost zero solution",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hard budget constraints') is the subject, depending on the verb 'excluded'. Entity 2 ('cost zero solution') is the subject of the clause 'a cost zero solution always exists', depending on the verb 'exists'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context where 'hard budget constraints' can exclude the existence of a 'cost zero solution'.\"",
        "sdp_path_text": "constraints → by → excluded → exists → solution",
        "sentence": "Hard budget constraints can exclude a cost zero solution.",
        "sentence_llm_dp_info": "\"Entity 1 ('hard budget constraints') is the subject, depending on the verb 'can exclude'. Entity 2 ('cost zero solution') is the object, depending on the verb 'can exclude'. There is a direct dependency between Entity 1 and Entity 2, as 'hard budget constraints' directly excludes 'cost zero solution'.\""
    },
    {
        "raw_sentence": "Our extensive experimental results significantly improve over both uniform sampling and standard stratified sampling which are de-facto the industry standards .",
        "ner_pair": [
            [
                "uniform sampling",
                "Method"
            ],
            [
                "stratified sampling",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('uniform sampling') is the object of the preposition 'over', depending on 'improve'. Entity 2 ('stratified sampling') is also the object of the preposition 'over', depending on 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'over both uniform sampling and standard stratified sampling'.\"",
        "sdp_path_text": "sampling → sampling",
        "sentence": "Experimental results improve over uniform sampling and stratified sampling.",
        "sentence_llm_dp_info": "\"Entity 1 ('uniform sampling') is the object of the preposition 'over', depending on 'improve' in the phrase 'improve over uniform sampling'. Entity 2 ('stratified sampling') is also the object of the preposition 'over', depending on 'improve' in the phrase 'improve over stratified sampling'. There is no direct dependency between Entity 1 and Entity 2; both are independently related to the verb 'improve' through the preposition 'over'.\""
    },
    {
        "raw_sentence": "We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton .",
        "ner_pair": [
            [
                "Kullback-Leibler distance",
                "Method"
            ],
            [
                "relative entropy",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kullback-Leibler distance') is the object of the preposition 'of', depending on 'computing'. Entity 2 ('relative entropy') is the object of the preposition 'called', depending on 'distance'. There is no direct dependency between Entity 1 and Entity 2, but they are semantically equivalent terms linked through the preposition 'called'.\"",
        "sdp_path_text": "distance → called → entropy",
        "sentence": "The Kullback-Leibler distance is also called the relative entropy.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kullback-Leibler distance') is the subject, depending on the verb 'is'. Entity 2 ('relative entropy') is the subject complement, depending on the verb 'called'. There is a direct dependency between Entity 1 and Entity 2, as 'relative entropy' is the term used to describe or rename 'Kullback-Leibler distance' in this sentence.\""
    },
    {
        "raw_sentence": "We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton .",
        "ner_pair": [
            [
                "Kullback-Leibler distance",
                "Method"
            ],
            [
                "probabilistic context-free grammar",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kullback-Leibler distance') is the object of the preposition 'computing', depending on 'problem'. Entity 2 ('probabilistic context-free grammar') is one of the objects of the preposition 'between', depending on 'between'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being computed in the problem.\"",
        "sdp_path_text": "distance → computing → between → grammar",
        "sentence": "The Kullback-Leibler distance is computed between a probabilistic context-free grammar and a probabilistic finite automaton.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kullback-Leibler distance') is the subject, depending on the verb 'is computed'. Entity 2 ('probabilistic context-free grammar') is one of the objects of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'between'.\""
    },
    {
        "raw_sentence": "We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton .",
        "ner_pair": [
            [
                "Kullback-Leibler distance",
                "Method"
            ],
            [
                "probabilistic finite automaton",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kullback-Leibler distance') is the object of the preposition 'between', depending on 'computing'. Entity 2 ('probabilistic finite automaton') is also the object of the preposition 'between', depending on 'distance'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'between' in the context of the sentence.\"",
        "sdp_path_text": "distance → computing → between → grammar → automaton",
        "sentence": "The Kullback-Leibler distance is computed between a probabilistic context-free grammar and a probabilistic finite automaton.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kullback-Leibler distance') is the subject, depending on the verb 'is computed'. Entity 2 ('probabilistic finite automaton') is the second object of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'between'.\""
    },
    {
        "raw_sentence": "We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton .",
        "ner_pair": [
            [
                "relative entropy",
                "Method"
            ],
            [
                "probabilistic context-free grammar",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relative entropy') is the appositive, depending on 'called' with 'Kullback-Leibler distance'. Entity 2 ('probabilistic context-free grammar') is the object of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "entropy → called → distance → computing → between → grammar",
        "sentence": "The relative entropy is computed between a probabilistic context-free grammar and a probabilistic finite automaton.",
        "sentence_llm_dp_info": "\"Entity 1 ('relative entropy') is the subject, depending on the verb 'is computed'. Entity 2 ('probabilistic context-free grammar') is the first object of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'relative entropy' is being computed in relation to both 'probabilistic context-free grammar' and 'probabilistic finite automaton'.\""
    },
    {
        "raw_sentence": "We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton .",
        "ner_pair": [
            [
                "relative entropy",
                "Method"
            ],
            [
                "probabilistic finite automaton",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relative entropy') is the appositive, depending on the noun 'distance' with the conjunction 'also called'. Entity 2 ('probabilistic finite automaton') is the second object of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "entropy → called → distance → computing → between → grammar → automaton",
        "sentence": "The relative entropy is computed between a probabilistic context-free grammar and a probabilistic finite automaton.",
        "sentence_llm_dp_info": "\"Entity 1 ('relative entropy') is the subject, depending on the verb 'is computed'. Entity 2 ('probabilistic finite automaton') is the second object of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure involving the verb 'is computed' and the preposition 'between'.\""
    },
    {
        "raw_sentence": "We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton .",
        "ner_pair": [
            [
                "probabilistic context-free grammar",
                "Method"
            ],
            [
                "probabilistic finite automaton",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('probabilistic context-free grammar') is the object of the preposition 'between', depending on 'between' in the phrase 'between a probabilistic context-free grammar and a probabilistic finite automaton'. Entity 2 ('probabilistic finite automaton') is also the object of the preposition 'between', depending on 'between' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are connected through the preposition 'between'.\"",
        "sdp_path_text": "grammar → automaton",
        "sentence": "The problem of computing the distance between a probabilistic context-free grammar and a probabilistic finite automaton is considered.",
        "sentence_llm_dp_info": "\"Entity 1 ('probabilistic context-free grammar') is the object of the preposition 'between', depending on 'distance'. Entity 2 ('probabilistic finite automaton') is also the object of the preposition 'between', depending on 'distance'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the preposition 'between' in the phrase 'the distance between a probabilistic context-free grammar and a probabilistic finite automaton'.\""
    },
    {
        "raw_sentence": "We show that there is a closed-form -LRB- analytical -RRB- solution for one part of the Kullback-Leibler distance , viz the cross-entropy .",
        "ner_pair": [
            [
                "closed-form -LRB- analytical -RRB- solution",
                "Method"
            ],
            [
                "Kullback-Leibler distance",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('closed-form -LRB- analytical -RRB- solution') is the subject complement, depending on the verb 'is'. Entity 2 ('Kullback-Leibler distance') is the object of the preposition 'for', depending on 'for' in the phrase 'for one part of the Kullback-Leibler distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for one part of the Kullback-Leibler distance'.\"",
        "sdp_path_text": "solution → for → part → of → distance",
        "sentence": "There is a closed-form solution for part of the Kullback-Leibler distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('closed-form (analytical) solution') is the subject complement, depending on the verb 'is' with 'There'. Entity 2 ('Kullback-Leibler distance') is the object of the preposition 'for', depending on 'for' in the phrase 'for part of the Kullback-Leibler distance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We show that there is a closed-form -LRB- analytical -RRB- solution for one part of the Kullback-Leibler distance , viz the cross-entropy .",
        "ner_pair": [
            [
                "closed-form -LRB- analytical -RRB- solution",
                "Method"
            ],
            [
                "cross-entropy",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('closed-form -LRB- analytical -RRB- solution') is the subject complement, depending on the verb 'is'. Entity 2 ('cross-entropy') is the object of the preposition 'for', depending on 'part'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger clause describing what has a closed-form solution, with 'cross-entropy' being specified as a part of the Kullback-Leibler distance.\"",
        "sdp_path_text": "solution → for → part → viz → cross",
        "sentence": "There is a closed-form solution for the cross-entropy.",
        "sentence_llm_dp_info": "\"Entity 1 ('closed-form (analytical) solution') is the subject complement, depending on the verb 'is'. Entity 2 ('cross-entropy') is the object of the preposition 'for', depending on 'for' in the phrase 'for the cross-entropy'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We show that there is a closed-form -LRB- analytical -RRB- solution for one part of the Kullback-Leibler distance , viz the cross-entropy .",
        "ner_pair": [
            [
                "cross-entropy",
                "Method"
            ],
            [
                "Kullback-Leibler distance",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cross-entropy') is the appositive, depending on 'viz' which clarifies a part of 'Kullback-Leibler distance'. Entity 2 ('Kullback-Leibler distance') is the object of the preposition 'of', depending on 'solution'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the appositive structure where 'cross-entropy' specifies a part of 'Kullback-Leibler distance'.\"",
        "sdp_path_text": "cross → viz → part → of → distance",
        "sentence": "Cross-entropy is a part of the Kullback-Leibler distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('cross-entropy') is the subject, depending on the verb 'is'. Entity 2 ('Kullback-Leibler distance') is the object of the preposition 'of', depending on 'part'. There is a direct dependency between Entity 1 and Entity 2, as 'cross-entropy' is described as being a part of the 'Kullback-Leibler distance'.\""
    },
    {
        "raw_sentence": "We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata .",
        "ner_pair": [
            [
                "distributional approximation",
                "Task"
            ],
            [
                "probabilistic context-free grammars",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distributional approximation') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('probabilistic context-free grammars') is the object of the preposition 'of', also depending on 'approximation'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is part of the prepositional phrase that modifies Entity 1.\"",
        "sdp_path_text": "approximation → of → grammars",
        "sentence": "We discuss the distributional approximation of probabilistic context-free grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('distributional approximation') is the object of the preposition 'of', depending on 'discuss' in the phrase 'the distributional approximation of'. Entity 2 ('probabilistic context-free grammars') is also the object of the preposition 'of', depending on 'approximation' in the phrase 'approximation of probabilistic context-free grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'of probabilistic context-free grammars'.\""
    },
    {
        "raw_sentence": "We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata .",
        "ner_pair": [
            [
                "probabilistic finite automata",
                "Method"
            ],
            [
                "distributional approximation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('probabilistic finite automata') is the object of the preposition 'by means of', depending on 'by means of' in the phrase 'by means of probabilistic finite automata'. Entity 2 ('distributional approximation') is part of the noun phrase, depending on 'problem' in the phrase 'the problem of distributional approximation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'by means of' which describes how the 'distributional approximation' is achieved.\"",
        "sdp_path_text": "automata → of → means → by → approximation",
        "sentence": "Probabilistic finite automata are used as means for distributional approximation.",
        "sentence_llm_dp_info": "\"Entity 1 ('probabilistic finite automata') is the subject, depending on the verb 'are used'. Entity 2 ('distributional approximation') is the object of the preposition 'for', depending on 'for' in the phrase 'for distributional approximation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the verb 'are used'.\""
    },
    {
        "raw_sentence": "We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata .",
        "ner_pair": [
            [
                "probabilistic context-free grammars",
                "Method"
            ],
            [
                "probabilistic finite automata",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('probabilistic context-free grammars') is the object of the preposition 'of', depending on 'approximation'. Entity 2 ('probabilistic finite automata') is the object of the preposition 'of', depending on 'means'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the method of approximation.\"",
        "sdp_path_text": "grammars → of → approximation → by → means → of → automata",
        "sentence": "Probabilistic context-free grammars can be approximated by probabilistic finite automata.",
        "sentence_llm_dp_info": "\"Entity 1 ('probabilistic context-free grammars') is the subject, depending on the verb 'can be approximated'. Entity 2 ('probabilistic finite automata') is the object, depending on the verb 'can be approximated'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the means or result of the approximation action performed on Entity 1.\""
    },
    {
        "raw_sentence": "In spite of over two decades of intense research , illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications .",
        "ner_pair": [
            [
                "illumination",
                "Task"
            ],
            [
                "pose invariance",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a coordination, depending on 'and' with 'pose invariance'. Entity 2 ('pose invariance') is also part of the same coordination, depending on 'and' with 'illumination'. Both entities are the subjects, depending on the verb 'remain'. There is a direct dependency between Entity 1 and Entity 2 through the coordinating conjunction 'and'.\"",
        "sdp_path_text": "illumination → invariance",
        "sentence": "Illumination and pose invariance remain challenging aspects of face recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a conjunction, depending on 'and' with 'pose invariance'. Entity 2 ('pose invariance') is also part of a conjunction, depending on 'and' with 'illumination'. Both entities are subjects, depending on the verb 'remain'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "In spite of over two decades of intense research , illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications .",
        "ner_pair": [
            [
                "illumination",
                "Task"
            ],
            [
                "face recognition",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a coordination, depending on 'and' with 'pose invariance'. Entity 2 ('face recognition') is the object of the preposition 'of', depending on 'aspects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'illumination and pose invariance' are described as aspects of 'face recognition'.\"",
        "sdp_path_text": "illumination → remain → aspects → of → recognition",
        "sentence": "Illumination remains a challenging aspect of face recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is the subject, depending on the verb 'remains'. Entity 2 ('face recognition') is the object of the preposition 'of', depending on 'aspect'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'aspect' which describes a challenging part of 'face recognition' that includes 'illumination'.\""
    },
    {
        "raw_sentence": "In spite of over two decades of intense research , illumination and pose invariance remain prohibitively challenging aspects of face recognition for most practical applications .",
        "ner_pair": [
            [
                "pose invariance",
                "Task"
            ],
            [
                "face recognition",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose invariance') is part of a conjunction, depending on 'and' with 'illumination'. It is also a subject complement, depending on 'remain' with the phrase 'remain prohibitively challenging aspects'. Entity 2 ('face recognition') is the object of the preposition 'of', depending on 'aspects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'pose invariance' is described as an aspect of 'face recognition'.\"",
        "sdp_path_text": "invariance → illumination → remain → aspects → of → recognition",
        "sentence": "Pose invariance remains a challenging aspect of face recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose invariance') is the subject, depending on the verb 'remains'. Entity 2 ('face recognition') is the object of the preposition 'of', depending on 'aspect'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure where 'pose invariance' is described as a part of the challenges in 'face recognition'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "video sequences",
                "Material"
            ],
            [
                "lighting",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'using', depending on 'recognize'. Entity 2 ('lighting') is part of a list of factors, depending on 'have' with 'wide variability'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "sequences → using → recognize → in → setup → have → lighting",
        "sentence": "Video sequences are used in a setup where lighting has variability.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the subject, depending on the verb 'used'. Entity 2 ('lighting') is the subject of the relative clause, depending on 'has' with 'variability'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same sentence.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "video sequences",
                "Material"
            ],
            [
                "pose",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'using', depending on the verb 'recognize'. Entity 2 ('pose') is part of a list of items (lighting, pose, user motion pattern) that are the subjects of the clause 'have a wide variability', depending on the verb 'have'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "sequences → using → recognize → in → setup → have → lighting → pose",
        "sentence": "Video sequences are used to recognize faces in a setup where pose has variability.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the subject, depending on the verb 'used'. Entity 2 ('pose') is part of a noun phrase, depending on 'variability' with the preposition 'has'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "video sequences",
                "Material"
            ],
            [
                "user motion pattern",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'using', depending on 'recognize' in the phrase 'to recognize faces using video sequences'. Entity 2 ('user motion pattern') is part of a list of items, depending on 'have' in the phrase 'lighting, pose and user motion pattern have a wide variability'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "sequences → using → recognize → in → setup → have → lighting → pose → pattern",
        "sentence": "Video sequences are used to recognize faces in a setup where user motion patterns have variability.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the subject, depending on the verb 'are used'. Entity 2 ('user motion pattern') is part of a noun phrase that modifies 'variability', depending on the possessive 'user's' and the noun 'pattern'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence, where 'video sequences' are used in a setup characterized by the variability of 'user motion patterns'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "video sequences",
                "Material"
            ],
            [
                "face images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'using', depending on 'using' in the phrase 'using video sequences'. Entity 2 ('face images') is the subject, depending on 'are' in the clause 'face images are of low resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same context within the sentence, describing aspects of the setup used for recognizing faces.\"",
        "sdp_path_text": "sequences → using → recognize → in → setup → have → are → images",
        "sentence": "Video sequences are used to recognize face images in an unconstrained setup.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the subject, depending on the verb 'are used'. Entity 2 ('face images') is the object of the infinitive 'to recognize', depending on 'recognize'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the purpose clause introduced by 'to recognize'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "video sequences",
                "Material"
            ],
            [
                "resolution",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'using', depending on the verb 'recognize'. Entity 2 ('resolution') is the complement of the preposition 'of', depending on the noun 'variability'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "sequences → using → recognize → in → setup → have → are → of → resolution",
        "sentence": "Video sequences are used in a setup where face images are of low resolution.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the subject, depending on the verb 'are used'. Entity 2 ('resolution') is part of the noun phrase 'low resolution', which is the complement of the preposition 'of', modifying 'face images'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence structure.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "lighting",
                "OtherScientificTerm"
            ],
            [
                "pose",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a list, depending on 'have' with the subject 'which'. Entity 2 ('pose') is also part of the same list, depending on 'and' with 'lighting'. There is no direct dependency between Entity 1 and Entity 2; they are both elements in a list of factors that 'have a wide variability'.\"",
        "sdp_path_text": "lighting → pose",
        "sentence": "Lighting and pose have a wide variability.",
        "sentence_llm_dp_info": "\"Entity 1 ('lighting') is the subject, depending on the conjunction 'and' with 'pose'. Entity 2 ('pose') is the subject, also depending on the conjunction 'and' with 'lighting'. Both 'lighting' and 'pose' are subjects of the verb 'have'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and share the same predicate 'have a wide variability'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "lighting",
                "OtherScientificTerm"
            ],
            [
                "user motion pattern",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a list of factors, depending on 'have' with 'variability'. Entity 2 ('user motion pattern') is also part of the same list, depending on 'have' with 'variability'. There is no direct dependency between Entity 1 and Entity 2; they are both listed as factors contributing to the variability in the described setup.\"",
        "sdp_path_text": "lighting → pose → pattern",
        "sentence": "Lighting, pose, and user motion pattern have a wide variability.",
        "sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a coordination, depending on 'and' with 'pose'. Entity 2 ('user motion pattern') is also part of the same coordination, depending on 'and' with 'pose'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the subject of the sentence.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "lighting",
                "OtherScientificTerm"
            ],
            [
                "face images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a list of factors, depending on the conjunction 'and' with 'pose and user motion pattern'. These factors collectively depend on the preposition 'in' as part of the phrase 'in which lighting, pose and user motion pattern have a wide variability'. Entity 2 ('face images') is the subject of the clause 'face images are of low resolution', depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the description of the conditions in the realistic, unconstrained setup.\"",
        "sdp_path_text": "lighting → have → are → images",
        "sentence": "Lighting and other factors affect the quality of face images.",
        "sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a coordination, depending on 'affect' as a subject. Entity 2 ('face images') is the object, depending on 'affect'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'affect'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "lighting",
                "OtherScientificTerm"
            ],
            [
                "resolution",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a list of factors, depending on the conjunction 'and' within the clause 'lighting, pose and user motion pattern have a wide variability'. Entity 2 ('resolution') is an attribute of 'face images', depending on the preposition 'of' in the phrase 'of low resolution'. There is no direct dependency between Entity 1 and Entity 2; both are elements within the larger context of challenges in a realistic, unconstrained setup.\"",
        "sdp_path_text": "lighting → have → are → of → resolution",
        "sentence": "Lighting and other factors have an impact on the resolution of face images.",
        "sentence_llm_dp_info": "\"Entity 1 ('lighting') is part of a coordination, depending on 'have' with 'factors'. Entity 2 ('resolution') is the object of the preposition 'of', depending on 'impact'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'have' and the prepositional phrase 'on the resolution of face images'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "user motion pattern",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a coordination, depending on 'and' with 'lighting' and 'user motion pattern'. Entity 2 ('user motion pattern') is also part of the same coordination, depending on 'and' with 'lighting' and 'pose'. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated elements in the list of factors that have a wide variability.\"",
        "sdp_path_text": "pose → pattern",
        "sentence": "Pose and user motion pattern have a wide variability.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is the subject, depending on the verb 'have'. Entity 2 ('user motion pattern') is the conjunct, joined with 'pose' through the conjunction 'and', also depending on the verb 'have'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of the same verb 'have'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "face images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a list, depending on 'have' with the phrase 'in which lighting, pose and user motion pattern have a wide variability'. Entity 2 ('face images') is the subject, depending on 'are' with the phrase 'face images are of low resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the descriptive clause that follows 'in which'.\"",
        "sdp_path_text": "pose → lighting → have → are → images",
        "sentence": "Pose and lighting affect the quality of face images.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is the subject, depending on the verb 'affect'. Entity 2 ('face images') is the object, depending on the verb 'affect'. There is a direct dependency between Entity 1 and Entity 2, as both are involved in the predicate 'affect the quality of'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "resolution",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a list of elements, depending on the conjunction 'and' within the prepositional phrase 'in which lighting, pose and user motion pattern have a wide variability'. Entity 2 ('resolution') is the object of the preposition 'of', depending on 'low' in the phrase 'face images are of low resolution'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "pose → lighting → have → are → of → resolution",
        "sentence": "Pose and lighting have an effect on the resolution of face images.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a coordination, depending on 'have' as a subject. Entity 2 ('resolution') is the object of the preposition 'of', depending on 'of' in the phrase 'of face images'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what has an effect on the resolution of face images.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "user motion pattern",
                "OtherScientificTerm"
            ],
            [
                "face images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('user motion pattern') is part of a list of elements, depending on the preposition 'of' within the prepositional phrase 'of low resolution' and 'wide variability'. Entity 2 ('face images') is the subject of the clause, depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger descriptive context within the sentence, specifically describing aspects that have a wide variability and are of low resolution in the 'realistic, unconstrained setup'.\"",
        "sdp_path_text": "pattern → pose → lighting → have → are → images",
        "sentence": "User motion pattern, pose, and lighting affect the quality of face images.",
        "sentence_llm_dp_info": "\"Entity 1 ('user motion pattern') is part of a compound subject, depending on 'affect' as one of the elements that influence the object. Entity 2 ('face images') is the object, depending on 'affect' as what is influenced by the subject. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'affect'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "user motion pattern",
                "OtherScientificTerm"
            ],
            [
                "resolution",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('user motion pattern') is part of a list of elements, depending on the conjunction 'and' within the clause 'lighting, pose and user motion pattern have a wide variability'. Entity 2 ('resolution') is an attribute, depending on 'low' in the phrase 'face images are of low resolution'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger descriptive clause that characterizes the conditions of the setup.\"",
        "sdp_path_text": "pattern → pose → lighting → have → are → of → resolution",
        "sentence": "User motion pattern, along with lighting and pose, affects the resolution of face images.",
        "sentence_llm_dp_info": "\"Entity 1 ('user motion pattern') is part of a coordination, depending on 'affects' as a subject. Entity 2 ('resolution') is the object, depending on 'affects' with the prepositional phrase 'of face images'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'affects'.\""
    },
    {
        "raw_sentence": "The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .",
        "ner_pair": [
            [
                "resolution",
                "Metric"
            ],
            [
                "face images",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('resolution') is the attribute, depending on 'low' with 'of'. Entity 2 ('face images') is the subject, depending on 'are' with 'of'. There is a direct dependency between Entity 1 and Entity 2, as 'resolution' is an attribute of 'face images' in the phrase 'face images are of low resolution'.\"",
        "sdp_path_text": "resolution → of → are → images",
        "sentence": "Face images are of low resolution.",
        "sentence_llm_dp_info": "\"Entity 1 ('resolution') is the subject complement, depending on the adjective 'low' and the copula 'are'. Entity 2 ('face images') is the subject, depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, as 'resolution' modifies 'face images' through the copula 'are'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "image formation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject of the clause, depending on 'combined' as part of the passive construction 'can be combined'. Entity 2 ('image formation') is the object of the preposition 'of', depending on 'model' in the phrase 'model of image formation'. There is a direct dependency between Entity 1 and Entity 2, as 'image formation' specifies what the 'photometric model' models.\"",
        "sdp_path_text": "model → of → formation",
        "sentence": "A photometric model of image formation is used.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'is used'. Entity 2 ('image formation') is the complement of the preposition 'of', depending on 'photometric model'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 specifies what the model is about.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "statistical model",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the object of the clause, depending on the verb 'combined' with 'can be combined'. Entity 2 ('statistical model') is also part of the object of the clause, depending on 'of' in the phrase 'model of generic face appearance variation'. There is a direct dependency between Entity 1 and Entity 2 through the verb 'combined', indicating that the two models are used together in the described process.\"",
        "sdp_path_text": "model → combined → with → model",
        "sentence": "A photometric model is combined with a statistical model.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject complement, depending on the verb 'combined'. Entity 2 ('statistical model') is the object of the preposition 'with', depending on 'with' in the phrase 'with a statistical model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combined' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "generic face appearance variation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the compound noun 'photometric model of image formation', which is the subject of the clause 'a photometric model of image formation can be combined with a statistical model of generic face appearance variation'. Entity 2 ('generic face appearance variation') is the object of the preposition 'of' in the phrase 'model of generic face appearance variation', which modifies the noun 'statistical model'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'combined' within the same clause.\"",
        "sdp_path_text": "model → combined → with → model → of → variation",
        "sentence": "A photometric model is combined with a statistical model of generic face appearance variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on 'combined' with the verb 'is combined'. Entity 2 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model' in the phrase 'statistical model of generic face appearance variation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combined' and the prepositional phrase 'with a statistical model of generic face appearance variation'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the compound noun 'photometric model of image formation', which is the object of the verb 'combined'. Entity 1 depends on 'combined' with 'a statistical model'. Entity 2 ('extreme illumination changes') is the object of the preposition 'in', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger clause describing how the combination of models helps to generalize in the presence of Entity 2.\"",
        "sdp_path_text": "model → combined → show → generalize → in → presence → of → changes",
        "sentence": "A photometric model is combined to generalize in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'combined'. Entity 2 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the context in which the model is combined to generalize.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the object of the clause, depending on the verb 'show' through the prepositional phrase 'how a photometric model...can be combined'. Entity 2 ('smoothness') is the subject of the clause, depending on the verb 'use' through the phrase 'we use the smoothness...'. There is no direct dependency between Entity 1 and Entity 2; they are parts of different clauses within the sentence.\"",
        "sdp_path_text": "model → combined → show → use → smoothness",
        "sentence": "A photometric model is used in combination with the smoothness of geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'is used'. Entity 2 ('smoothness') is the object of the preposition 'with', depending on 'with' in the phrase 'with the smoothness'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a larger structure described by the sentence.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the subject complement, depending on 'combined' with 'statistical model'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "model → combined → show → use → smoothness → of → structure",
        "sentence": "A photometric model is used to leverage the smoothness of the geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'used'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the prepositional phrase 'to leverage the smoothness of the geodesically local appearance manifold structure'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of a compound noun, depending on the verb 'combined' in the clause 'can be combined with a statistical model'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'to', depending on 'use' in the clause 'we use the smoothness... to achieve invariance to unseen head poses'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "model → combined → show → use → smoothness → likelihood",
        "sentence": "A photometric model is used in combination with a robust same-identity likelihood.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'is used'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'with', depending on 'with' in the phrase 'in combination with a robust same-identity likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in combination with'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of a compound noun, depending on 'combined' as its object, which itself depends on 'show' as part of the clause 'we show how...'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance' in the phrase 'invariance to unseen head poses', which is part of the larger clause describing the second area of novelty. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "model → combined → show → use → achieve → invariance → to → poses",
        "sentence": "A photometric model is used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'used'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance' in the phrase 'invariance to unseen head poses'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the prepositional phrase 'to achieve invariance to'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of a compound noun, depending on 'combined' with 'statistical model'. Entity 2 ('video sequence '' reillumination '' algorithm') is the object of the verb 'introduce', depending on 'introduce'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, connected through the overall context of describing areas of novelty in the research.\"",
        "sdp_path_text": "model → combined → show → use → introduce → algorithm",
        "sentence": "A photometric model is introduced in an algorithm for video sequence 'reillumination'.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'introduced'. Entity 2 ('video sequence 'reillumination' algorithm') is the object of the preposition 'in', depending on 'in' in the phrase 'in an algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates that the 'photometric model' is introduced within the context of the 'algorithm'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of a compound noun, depending on 'combined' as its object, which is part of the clause describing how it is used with another model. Entity 2 ('robustness') is the object of the preposition 'to', depending on 'achieve' in the context of achieving robustness to specific conditions. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, connected through the overall context of the methods described.\"",
        "sdp_path_text": "model → combined → show → use → introduce → achieve → robustness",
        "sentence": "A photometric model is used to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'used'. Entity 2 ('robustness') is the object, depending on the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieve' which is part of the purpose for using the 'photometric model'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the object of the clause 'how a photometric model of image formation can be combined with a statistical model of generic face appearance variation', depending on the verb 'combined'. Entity 2 ('face motion patterns') is the object of the preposition 'to' in the phrase 'to face motion patterns in video', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the larger sentence.\"",
        "sdp_path_text": "model → combined → show → use → introduce → achieve → robustness → to → patterns",
        "sentence": "A photometric model is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on 'is used'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'to' in the phrase 'to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "photometric model",
                "Method"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('photometric model') is part of the object of the clause, depending on 'combined' with 'statistical model'. Entity 2 ('video') is part of the object of the clause, depending on 'sequence' in the noun phrase 'video sequence'. There is no direct dependency between Entity 1 and Entity 2; both are components of different clauses within the complex sentence structure.\"",
        "sdp_path_text": "model → combined → show → use → introduce → algorithm → sequence → video",
        "sentence": "A photometric model is used in an algorithm for video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('photometric model') is the subject, depending on the verb 'used'. Entity 2 ('video') is part of the noun phrase 'video sequences', which is the object of the preposition 'for', depending on 'for' in the phrase 'for video sequences'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "statistical model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' as a modifier in the phrase 'photometric model of image formation'. Entity 2 ('statistical model') is also part of a noun phrase, depending on 'combined' as the object of the clause 'can be combined with a statistical model'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger clause that describes how these models are used together.\"",
        "sdp_path_text": "formation → of → model → combined → with → model",
        "sentence": "A photometric model of image formation is combined with a statistical model.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' with the preposition 'of' in 'a photometric model of image formation'. Entity 2 ('statistical model') is the object of the preposition 'with', depending on 'combined' in the phrase 'is combined with a statistical model'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is being combined.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "generic face appearance variation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, acting as the object of the preposition 'of', depending on 'model'. Entity 2 ('generic face appearance variation') is also part of a noun phrase, acting as the object of the preposition 'of', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause where they are described as being combined in a model.\"",
        "sdp_path_text": "formation → of → model → combined → with → model → of → variation",
        "sentence": "A photometric model of image formation is combined with a statistical model of generic face appearance variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, where it depends on 'model' as a modifier, forming 'a photometric model of image formation'. Entity 2 ('generic face appearance variation') is also part of a noun phrase, where it depends on 'model' as a modifier, forming 'a statistical model of generic face appearance variation'. There is no direct dependency between Entity 1 and Entity 2; both are indirectly related through the main clause structure, where they are the objects of their respective prepositional phrases that modify 'model'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' as a modifier. It is also part of a larger clause where it serves as the object of the verb 'combined'. Entity 2 ('extreme illumination changes') is the object of the preposition 'in', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the clause describing the combination of models to handle situations involving Entity 2.\"",
        "sdp_path_text": "formation → of → model → combined → show → generalize → in → presence → of → changes",
        "sentence": "A photometric model of image formation can be combined to generalize in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' with 'of' in the phrase 'model of image formation'. Entity 2 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence' in the phrase 'presence of extreme illumination changes'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of the object of the clause, depending on 'combined' as the first element being combined in the context of the photometric model. Entity 2 ('smoothness') is the subject complement, depending on 'use' as the property being used in the context of the geodesically local appearance manifold structure. There is no direct dependency between Entity 1 and Entity 2; they are parts of different clauses within the complex sentence.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → smoothness",
        "sentence": "A model of image formation is combined to use the smoothness of appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' with the preposition 'of'. Entity 2 ('smoothness') is the subject complement, depending on 'use' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence through prepositional phrases.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, where it depends on 'model' as a modifier, and this noun phrase is the object of the preposition 'of' in the clause 'a photometric model of image formation'. Entity 2 ('geodesically local appearance manifold structure') is also part of a noun phrase, acting as the object of the preposition 'of' in the clause 'the smoothness of geodesically local appearance manifold structure'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the larger sentence.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → smoothness → of → structure",
        "sentence": "A model of image formation is used to leverage the smoothness of geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of the noun phrase functioning as the object of the preposition 'of', depending on 'model'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that describe different aspects of the sentence.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' with the prepositional phrase 'of image formation'. It is also part of a larger clause where it is combined with another model, depending on the verb 'can be combined'. Entity 2 ('robust same-identity likelihood') is a noun phrase, depending on 'use' as the object of the verb 'use'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence, each contributing to the description of a distinct area of novelty.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → smoothness → likelihood",
        "sentence": "A model of image formation is used with a robust same-identity likelihood.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'with', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the model and its usage involve.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a nominal clause, depending on 'combined' with 'photometric model'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence structure.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → achieve → invariance → to → poses",
        "sentence": "A model of image formation is used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; both are part of the clause describing what the model is used for.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of the noun phrase 'photometric model of image formation', which is the object of the clause 'how a photometric model of image formation can be combined with a statistical model of generic face appearance variation'. Entity 2 ('video sequence '' reillumination '' algorithm') is the object of the verb 'introduce', which is part of the clause 'we introduce an accurate video sequence '' reillumination '' algorithm'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the larger sentence.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → introduce → algorithm",
        "sentence": "A model of image formation is combined and used to introduce a video sequence 'reillumination' algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' as a complement. Entity 2 ('video sequence 'reillumination' algorithm') is the object, depending on 'introduce' with 'used'. There is no direct dependency between Entity 1 and Entity 2; both are parts of different clauses that are connected through the verb 'used'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, acting as the object of the preposition 'of' in the phrase 'model of image formation', which itself is the object of the verb 'combined'. Entity 2 ('robustness') is the object of the preposition 'to' in the phrase 'to achieve robustness', which modifies the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → introduce → achieve → robustness",
        "sentence": "A model of image formation is used to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('robustness') is the object of the verb 'achieve', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'image formation' is part of what the model represents, and 'robustness' is the goal that is achieved using this model.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a nominal clause, depending on 'combined' with 'photometric model'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness' in the phrase 'to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2; they are both part of complex clauses that describe different aspects of the methodology discussed in the sentence.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → introduce → achieve → robustness → to → patterns",
        "sentence": "A model of image formation is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is the complement of the preposition 'of', depending on 'model'. Entity 2 ('face motion patterns') is the complement of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing what the model is used for.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "image formation",
                "Task"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' with the prepositional phrase 'of image formation'. It is also part of a larger clause where it is the object of the verb 'combined'. Entity 2 ('video') is part of a noun phrase, depending on 'sequence' with the compound modifier 'video sequence'. It is also part of a larger clause where it is the object of the preposition 'in' within the prepositional phrase 'in video'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses and are not directly connected in the sentence structure.\"",
        "sdp_path_text": "formation → of → model → combined → show → use → introduce → algorithm → sequence → video",
        "sentence": "A model of image formation is combined and used to introduce an algorithm for video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('image formation') is part of a noun phrase, depending on 'model' with 'of'. Entity 2 ('video') is the object of the preposition 'for', depending on 'sequences' in the phrase 'for video sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'image formation' is part of a model that is used to introduce an algorithm relevant to 'video sequences'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "generic face appearance variation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object of the preposition 'with', depending on the noun phrase 'photometric model of image formation'. Entity 2 ('generic face appearance variation') is the object of the preposition 'of', depending on 'statistical model'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is part of the description of what the statistical model models.\"",
        "sdp_path_text": "model → of → variation",
        "sentence": "A statistical model of generic face appearance variation is used.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'is used'. Entity 2 ('generic face appearance variation') is the object of the preposition 'of', depending on 'of' in the phrase 'of generic face appearance variation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of generic face appearance variation'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is part of a compound noun, depending on 'combined' with 'photometric model'. Entity 2 ('extreme illumination changes') is the object of the preposition 'in', depending on 'generalize'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the combination of models to handle different conditions, specifically 'extreme illumination changes'.\"",
        "sdp_path_text": "model → with → combined → show → generalize → in → presence → of → changes",
        "sentence": "A statistical model combined with a photometric model helps generalize in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is part of the subject, depending on the verb 'helps' and modified by the prepositional phrase 'combined with a photometric model'. Entity 2 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence' in the phrase 'presence of extreme illumination changes'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the clause describing the context in which the statistical model helps generalize.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is part of the object complement, depending on the verb 'combined' with 'photometric model'. Entity 2 ('smoothness') is the subject of the clause, depending on the verb 'use'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "model → with → combined → show → use → smoothness",
        "sentence": "A statistical model is used with the smoothness of the appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'is used'. Entity 2 ('smoothness') is the subject complement, depending on the preposition 'with' in the phrase 'with the smoothness'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'is used' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object of the preposition 'with', depending on 'combined' in the clause 'can be combined with a statistical model'. Entity 2 ('geodesically local appearance manifold structure') is the subject complement, depending on 'smoothness' in the phrase 'the smoothness of geodesically local appearance manifold structure'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "model → with → combined → show → use → smoothness → of → structure",
        "sentence": "A statistical model is used with the smoothness of the geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'used'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'with the smoothness of the geodesically local appearance manifold structure'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object of the preposition 'with', depending on the phrase 'combined with a statistical model'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'of', depending on the noun 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses that describe aspects of the methodology being discussed.\"",
        "sdp_path_text": "model → with → combined → show → use → smoothness → likelihood",
        "sentence": "A statistical model is used with a robust same-identity likelihood to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'used'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'with', depending on 'with' in the phrase 'with a robust same-identity likelihood'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object of the preposition 'with', depending on 'combined' in the clause 'can be combined with a statistical model of generic face appearance variation'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance' in the phrase 'to achieve invariance to unseen head poses'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "model → with → combined → show → use → achieve → invariance → to → poses",
        "sentence": "A statistical model combined with other techniques achieves invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on 'achieves' as the main verb. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'achieves' and the prepositional phrase 'invariance to unseen head poses'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is part of a compound noun, depending on 'combined' as a complement. It is used in the context of being combined with a 'photometric model of image formation' to generalize in the presence of extreme illumination changes. Entity 2 ('video sequence \"reillumination\" algorithm') is the object of the verb 'introduce', indicating that it is introduced in the sentence to achieve robustness to face motion patterns in video. There is no direct dependency between Entity 1 and Entity 2; they are mentioned in different parts of the sentence and serve different roles in the overall structure.\"",
        "sdp_path_text": "model → with → combined → show → use → introduce → algorithm",
        "sentence": "A statistical model is used to introduce a video sequence 'reillumination' algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'used'. Entity 2 ('video sequence 'reillumination' algorithm') is the object of the preposition 'to', depending on 'to' in the phrase 'to introduce a video sequence 'reillumination' algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object of the preposition 'with', depending on 'combined' in the phrase 'combined with a statistical model'. Entity 2 ('robustness') is the object of the preposition 'to', depending on 'achieve' in the phrase 'to achieve robustness'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "model → with → combined → show → use → introduce → achieve → robustness",
        "sentence": "A statistical model combined with other techniques achieves robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'achieves'. Entity 2 ('robustness') is the object, depending on the verb 'achieves'. There is a direct dependency between Entity 1 and Entity 2, as 'statistical model' is the agent that achieves 'robustness'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object of the preposition 'of', depending on 'model' in the phrase 'a statistical model of generic face appearance variation'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness' in the phrase 'robustness to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "model → with → combined → show → use → introduce → achieve → robustness → to → patterns",
        "sentence": "A statistical model is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'is used'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness' in the phrase 'robustness to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the concept of 'robustness'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is part of a compound noun, depending on 'combined' with 'photometric model'. Entity 2 ('video') is part of a compound noun, depending on 'sequence' in the phrase 'video sequence'. There is no direct dependency between Entity 1 and Entity 2; they are both part of larger clauses that describe different aspects of the research described in the sentence.\"",
        "sdp_path_text": "model → with → combined → show → use → introduce → algorithm → sequence → video",
        "sentence": "A statistical model is used in an algorithm for video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'is used'. Entity 2 ('video') is part of a compound noun, depending on 'sequences' in the phrase 'video sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in an algorithm for video sequences'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the combination of models to handle different conditions.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → generalize → in → presence → of → changes",
        "sentence": "A model of generic face appearance variation combined with a photometric model can generalize in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is part of the subject complement, depending on 'model' with the preposition 'of'. Entity 2 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence' in the phrase 'in the presence of extreme illumination changes'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause through the verb 'can generalize'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('smoothness') is the subject complement, depending on 'is' in the clause 'the smoothness is of geodesically local appearance manifold structure'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → smoothness",
        "sentence": "A model of generic face appearance variation is combined to use the smoothness of geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('smoothness') is the object of the preposition 'of', depending on 'the'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is being combined and used.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → smoothness → of → structure",
        "sentence": "A model of generic face appearance variation is combined to utilize the smoothness of geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context where the model of Entity 1 is combined to utilize the smoothness of Entity 2.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'to', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of methods used for achieving invariance and robustness in the described system.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → smoothness → likelihood",
        "sentence": "A model of generic face appearance variation is used with a robust same-identity likelihood.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'with', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the use of the model.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → achieve → invariance → to → poses",
        "sentence": "A model of generic face appearance variation is used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the purpose of the model.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. It is part of a larger clause where it is described as being modeled statistically and combined with a photometric model of image formation. Entity 2 ('video sequence \"reillumination\" algorithm') is the object of the verb 'introduce', depending on 'we'. It is introduced as a method to achieve robustness to face motion patterns in video. There is no direct dependency between Entity 1 and Entity 2; they are parts of different clauses within the same complex sentence.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → introduce → algorithm",
        "sentence": "A model of generic face appearance variation is combined with an algorithm for video sequence reillumination.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('video sequence reillumination algorithm') is the object of the preposition 'with', depending on 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is being combined.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('robustness') is the object of the preposition 'to', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → introduce → achieve → robustness",
        "sentence": "A model of generic face appearance variation is combined to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('robustness') is the object, depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'model' is used to describe the variation that is combined to achieve 'robustness'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → introduce → achieve → robustness → to → patterns",
        "sentence": "A model of generic face appearance variation is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the complement of the preposition 'of', depending on 'model'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of achieving robustness in the context of the sentence.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "generic face appearance variation",
                "Task"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is the object of the preposition 'of', depending on 'model'. It is part of a larger clause where it is described as being combined with a photometric model of image formation. Entity 2 ('video') is the object of the preposition 'in', depending on 'patterns'. It is part of a clause that describes an algorithm introduced to achieve robustness to face motion patterns in video. There is no direct dependency between Entity 1 and Entity 2; they are mentioned in different parts of the sentence, each contributing to separate aspects of the overall methodology described.\"",
        "sdp_path_text": "variation → of → model → with → combined → show → use → introduce → algorithm → sequence → video",
        "sentence": "A model of generic face appearance variation is combined with other techniques to introduce an accurate video sequence algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('generic face appearance variation') is part of the noun phrase 'a model of generic face appearance variation', where it serves as the complement of the preposition 'of', depending on 'model'. Entity 2 ('video') is part of the noun phrase 'video sequence algorithm', serving as the modifier of 'sequence', which itself modifies 'algorithm'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of larger noun phrases that are related through the verb 'combined' and the purpose clause introduced by 'to introduce'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('smoothness') is the subject, depending on 'use'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → smoothness",
        "sentence": "The method uses smoothness to generalize in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object, depending on the preposition 'of' within the phrase 'in the presence of extreme illumination changes'. Entity 2 ('smoothness') is the object of the preposition 'to', depending on 'uses' in the phrase 'uses smoothness to generalize'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how the method generalizes under certain conditions.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'in', depending on 'generalize'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → smoothness → of → structure",
        "sentence": "We show how to generalize in the presence of extreme illumination changes by using the smoothness of the geodesically local appearance manifold structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'in the presence of', depending on the preposition 'of'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; both are part of the clause that describes the conditions under which generalization can be achieved.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'with', depending on 'presence'. Entity 2 ('robust same-identity likelihood') is the object, depending on 'use' with 'we'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the larger sentence.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → smoothness → likelihood",
        "sentence": "A method is shown to generalize in the presence of extreme illumination changes using a robust same-identity likelihood.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('robust same-identity likelihood') is the object, depending on 'using'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing how the method generalizes.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, each describing a distinct aspect of the research contributions.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → achieve → invariance → to → poses",
        "sentence": "We show how to generalize in the presence of extreme illumination changes and achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'in', depending on 'presence'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what is achieved and generalized.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('video sequence '' reillumination '' algorithm') is the object of the verb 'introduce'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → introduce → algorithm",
        "sentence": "An algorithm is introduced to generalize in the presence of extreme illumination changes in video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('video sequences') is the object of the preposition 'in', depending on 'presence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'in the presence of extreme illumination changes in video sequences' which modifies the main clause.\"\n\nNote: The term \"reillumination algorithm\" was not included in the original sentence provided, so it was not considered in the dependency analysis. If you meant to analyze \"video sequences\" as Entity 2, the answer reflects that. If \"reillumination algorithm\" is a required part of the analysis, please clarify how it fits into the sentence structure."
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'with', depending on 'presence'. Entity 2 ('robustness') is the object, depending on 'achieve' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as part of the same clause describing the algorithm's capability to handle various conditions, including those mentioned by Entity 1.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → introduce → achieve → robustness",
        "sentence": "A model is introduced to achieve robustness in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('robustness') is the object, depending on 'achieve' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the presence of extreme illumination changes'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence' in the phrase 'in the presence of extreme illumination changes'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness' in the phrase 'to face motion patterns in video'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → introduce → achieve → robustness → to → patterns",
        "sentence": "An algorithm is introduced to achieve robustness to face motion patterns in the presence of extreme illumination changes.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'of', depending on 'presence'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause that describes the conditions under which robustness is achieved.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "extreme illumination changes",
                "OtherScientificTerm"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'in', depending on 'generalize'. Entity 2 ('video') is part of a compound noun, depending on 'sequence' in the phrase 'video sequence'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence, where 'extreme illumination changes' is mentioned in the context of generalizing a model, and 'video' is used to describe a specific application of the introduced algorithm.\"",
        "sdp_path_text": "changes → of → presence → in → generalize → show → use → introduce → algorithm → sequence → video",
        "sentence": "An algorithm is introduced to handle extreme illumination changes in video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('extreme illumination changes') is the object of the preposition 'in', depending on 'handle'. Entity 2 ('video') is part of the compound noun 'video sequences', depending on 'sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'in video sequences'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on 'use' with 'we'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 modifies Entity 1 to specify what kind of smoothness is being used.\"",
        "sdp_path_text": "smoothness → of → structure",
        "sentence": "The smoothness of the geodesically local appearance manifold structure is used.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on the verb 'is used'. Entity 2 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'of' in the phrase 'of the geodesically local appearance manifold structure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on the verb 'use' within the clause '-LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure'. Entity 2 ('robust same-identity likelihood') is the object, also depending on the verb 'use' in the same clause. There is no direct dependency between Entity 1 and Entity 2; both are independently related to the verb 'use'.\"",
        "sdp_path_text": "smoothness → likelihood",
        "sentence": "The smoothness of the appearance manifold structure and a robust same-identity likelihood are used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject of the clause, depending on 'used' with the prepositional phrase 'of the appearance manifold structure'. Entity 2 ('robust same-identity likelihood') is also the subject of the clause, depending on 'used' and coordinated with 'smoothness'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a coordinated subject in the sentence.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject of the clause, depending on 'use' as part of the phrase 'we use the smoothness'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'achieve invariance to' in the phrase 'to achieve invariance to unseen head poses'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'use' and the purpose clause introduced by 'to achieve invariance to'.\"",
        "sdp_path_text": "smoothness → use → achieve → invariance → to → poses",
        "sentence": "The smoothness of the appearance manifold structure is used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on the verb 'is' and modified by the prepositional phrase 'of the appearance manifold structure'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the purpose clause 'to achieve invariance to unseen head poses'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject of the clause 'the smoothness of geodesically local appearance manifold structure', depending on 'use' with 'we'. Entity 2 ('video sequence '' reillumination '' algorithm') is the object of the verb 'introduce', depending on 'introduce' with 'we'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "smoothness → use → introduce → algorithm",
        "sentence": "The smoothness is used to introduce a video sequence 'reillumination' algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on the verb 'used'. Entity 2 ('video sequence \"reillumination\" algorithm') is the object, depending on the verb 'introduce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' which introduces the purpose of using the smoothness.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on 'use' with 'we'. It is part of the noun phrase 'the smoothness of geodesically local appearance manifold structure', which is used as an object complement to describe what is being used. Entity 2 ('robustness') is the object, depending on 'achieve' with 'to'. It is part of the noun phrase 'to achieve robustness to face motion patterns in video', which describes the goal of introducing an accurate video sequence 'reillumination' algorithm. There is no direct dependency between Entity 1 and Entity 2; both are parts of separate clauses describing different aspects of the methodology.\"",
        "sdp_path_text": "smoothness → use → introduce → achieve → robustness",
        "sentence": "The smoothness of the appearance manifold structure is used to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on the verb 'is' in the clause 'the smoothness... is used'. Entity 2 ('robustness') is the object, depending on the verb 'achieve' in the infinitive phrase 'to achieve robustness'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to achieve robustness' which describes the goal for which the smoothness is used.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on 'use' with the clause 'we use the smoothness of geodesically local appearance manifold structure'. Entity 2 ('face motion patterns') is the object, depending on 'robustness' with the phrase 'robustness to face motion patterns in video'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the larger sentence.\"",
        "sdp_path_text": "smoothness → use → introduce → achieve → robustness → to → patterns",
        "sentence": "The smoothness of the appearance manifold structure is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on 'is used' as the main verb. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to achieve robustness to face motion patterns'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "smoothness",
                "OtherScientificTerm"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject, depending on 'use' with the verb 'use' in the clause '-LRB- ii -RRB- we use the smoothness...'. Entity 2 ('video') is part of a compound noun, depending on 'sequence' in the phrase 'video sequence' within the clause '-LRB- iii -RRB- we introduce an accurate video sequence...'. There is no direct dependency between Entity 1 and Entity 2; they appear in different clauses of the sentence.\"",
        "sdp_path_text": "smoothness → use → introduce → algorithm → sequence → video",
        "sentence": "The smoothness of the appearance manifold structure is used to introduce an accurate video sequence algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('smoothness') is the subject of the clause, depending on 'is used' as the main verb. Entity 2 ('video') is part of a compound noun, 'video sequence algorithm', which is the object of the verb 'introduce'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'used' and the purpose clause 'to introduce an accurate video sequence algorithm'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            [
                "robust same-identity likelihood",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('robust same-identity likelihood') is the object of the preposition 'to', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing methods used to achieve invariance to unseen head poses.\"",
        "sdp_path_text": "structure → of → smoothness → likelihood",
        "sentence": "The smoothness of the geodesically local appearance manifold structure and a robust same-identity likelihood are used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('robust same-identity likelihood') is the subject complement, depending on 'and' which connects it to 'structure' as part of a list of elements that are used. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of what is being used to achieve invariance to unseen head poses.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is part of a larger noun phrase acting as the object of the preposition 'of', depending on 'use'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how the smoothness of the manifold structure and a robust likelihood are used to achieve invariance to unseen head poses.\"",
        "sdp_path_text": "structure → of → smoothness → use → achieve → invariance → to → poses",
        "sentence": "The smoothness of the geodesically local appearance manifold structure is used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing how the smoothness of the structure is used to achieve invariance.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is part of a larger noun phrase acting as the subject complement, depending on 'use' with 'we'. It is modified by 'smoothness' and further described by the prepositional phrase 'of geodesically local appearance manifold structure'. Entity 2 ('video sequence '' reillumination '' algorithm') is the direct object of the verb 'introduce', depending on 'introduce' with 'we'. There is no direct dependency between Entity 1 and Entity 2; both are parts of different clauses within the complex sentence.\"",
        "sdp_path_text": "structure → of → smoothness → use → introduce → algorithm",
        "sentence": "The smoothness of the geodesically local appearance manifold structure is used to introduce a video sequence 'reillumination' algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('video sequence 'reillumination' algorithm') is the object of the verb 'introduce', depending on 'is used to introduce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence, where the smoothness of Entity 1 is utilized in the introduction of Entity 2.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('robustness') is the object of the preposition 'to', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of a larger clause that discusses achieving invariance and robustness in the context of face recognition techniques.\"",
        "sdp_path_text": "structure → of → smoothness → use → introduce → achieve → robustness",
        "sentence": "The smoothness of the geodesically local appearance manifold structure is used to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('robustness') is the object, depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the smoothness of the structure is used to achieve robustness.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is part of the subject complement, depending on 'use' through the prepositional phrase 'of geodesically local appearance manifold structure'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness' in the phrase 'to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the overall meaning of the sentence by describing different aspects of the methodology used.\"",
        "sdp_path_text": "structure → of → smoothness → use → introduce → achieve → robustness → to → patterns",
        "sentence": "The smoothness of the geodesically local appearance manifold structure is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause where the smoothness of the structure contributes to achieving robustness to the patterns.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "geodesically local appearance manifold structure",
                "OtherScientificTerm"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('video') is part of a compound noun, depending on 'sequence' in the phrase 'video sequence'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the complex sentence.\"",
        "sdp_path_text": "structure → of → smoothness → use → introduce → algorithm → sequence → video",
        "sentence": "The smoothness of the geodesically local appearance manifold structure is used to introduce an accurate video sequence algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('geodesically local appearance manifold structure') is the object of the preposition 'of', depending on 'smoothness'. Entity 2 ('video') is part of the compound noun 'video sequence algorithm', depending on 'sequence'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robust same-identity likelihood",
                "Method"
            ],
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the object, depending on 'use' with 'we'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'achieve invariance to'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the 'robust same-identity likelihood' is used to 'achieve invariance to unseen head poses'.\"",
        "sdp_path_text": "likelihood → smoothness → use → achieve → invariance → to → poses",
        "sentence": "A robust same-identity likelihood is used to achieve invariance to unseen head poses.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the subject, depending on the verb 'used'. Entity 2 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance' in the phrase 'invariance to unseen head poses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the prepositional phrase 'to achieve invariance to'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robust same-identity likelihood",
                "Method"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the object of the preposition 'to', depending on 'achieve invariance'. Entity 2 ('video sequence '' reillumination '' algorithm') is the object of the verb 'introduce', depending on 'we'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, each serving a distinct role in explaining the novelties of the research.\"",
        "sdp_path_text": "likelihood → smoothness → use → introduce → algorithm",
        "sentence": "A robust same-identity likelihood is used to introduce a video sequence reillumination algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the subject, depending on the verb 'used'. Entity 2 ('video sequence reillumination algorithm') is the object, depending on 'introduce' with 'is used to'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the purpose clause introduced by 'to introduce'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robust same-identity likelihood",
                "Method"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the object of the preposition 'of', depending on 'smoothness' which itself is part of a larger clause describing one of the novelties. Entity 2 ('robustness') is the object of the preposition 'to', depending on 'achieve' in the last novelty described. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses describing different aspects of the novelties introduced.\"",
        "sdp_path_text": "likelihood → smoothness → use → introduce → achieve → robustness",
        "sentence": "The robust same-identity likelihood is used to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the subject, depending on the verb 'is used'. Entity 2 ('robustness') is the object, depending on 'achieve' with 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is used' and the purpose clause 'to achieve robustness'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robust same-identity likelihood",
                "Method"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the object, depending on the preposition 'to' within the clause 'to achieve invariance to unseen head poses'. Entity 2 ('face motion patterns') is the object, depending on the preposition 'to' within the clause 'to achieve robustness to face motion patterns in video'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses that describe methods used in the research described in the sentence.\"",
        "sdp_path_text": "likelihood → smoothness → use → introduce → achieve → robustness → to → patterns",
        "sentence": "A robust same-identity likelihood is used to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the subject, depending on the verb 'used'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'to' in the phrase 'to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to achieve robustness to face motion patterns'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robust same-identity likelihood",
                "Method"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the object, depending on the verb 'use' in the clause 'we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood'. Entity 2 ('video') is part of a noun phrase, depending on 'sequence' in the phrase 'video sequence'. There is no direct dependency between Entity 1 and Entity 2; they are parts of different clauses within the sentence.\"",
        "sdp_path_text": "likelihood → smoothness → use → introduce → algorithm → sequence → video",
        "sentence": "A robust same-identity likelihood is used to introduce an accurate video sequence algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust same-identity likelihood') is the subject, depending on the verb 'used'. Entity 2 ('video') is part of the compound noun 'video sequence algorithm', depending on 'sequence'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('video sequence ''reillumination'' algorithm') is the subject complement, depending on 'introduce'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "poses → to → invariance → achieve → use → introduce → algorithm",
        "sentence": "An algorithm is introduced to achieve invariance to unseen head poses in video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('video sequences') is the object of the preposition 'in', depending on 'invariance'. There is no direct dependency between Entity 1 and Entity 2, but both are related to 'invariance' through different prepositions ('to' and 'in').\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('robustness') is the object, depending on 'achieve' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing different aspects of the system's capabilities.\"",
        "sdp_path_text": "poses → to → invariance → achieve → use → introduce → achieve → robustness",
        "sentence": "We use techniques to achieve invariance to unseen head poses and robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('robustness') is the object, depending on the conjunction 'and' which links it to 'invariance'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of objectives for the techniques used.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses describing different aspects of the system's capabilities.\"",
        "sdp_path_text": "poses → to → invariance → achieve → use → introduce → achieve → robustness → to → patterns",
        "sentence": "We introduce an algorithm to achieve invariance to unseen head poses and robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the purpose clause introduced by 'to achieve'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "unseen head poses",
                "OtherScientificTerm"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('video') is the object of the preposition 'in', depending on 'patterns'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of achieving invariance and robustness in different aspects of the described system.\"",
        "sdp_path_text": "poses → to → invariance → achieve → use → introduce → algorithm → sequence → video",
        "sentence": "An algorithm is introduced to achieve invariance to unseen head poses in video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('unseen head poses') is the object of the preposition 'to', depending on 'invariance'. Entity 2 ('video') is part of a compound noun, depending on 'sequences' in the phrase 'video sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'to achieve invariance to unseen head poses in video sequences'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robustness",
                "Metric"
            ],
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object, depending on the preposition 'to' within the phrase 'to achieve robustness'. Entity 2 ('video sequence \"reillumination\" algorithm') is the subject, depending on 'introduce' with 'we'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause where the introduction of Entity 2 contributes to achieving the property described by Entity 1.\"",
        "sdp_path_text": "robustness → achieve → introduce → algorithm",
        "sentence": "An accurate video sequence 'reillumination' algorithm is introduced to achieve robustness.",
        "sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object, depending on 'achieve' with 'algorithm'. Entity 2 ('video sequence 'reillumination' algorithm') is the subject, depending on the verb 'introduced'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to achieve robustness'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "video sequence '' reillumination '' algorithm",
                "Method"
            ],
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequence '' reillumination '' algorithm') is the object of the verb 'introduce', depending on 'we'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the algorithm introduced is aimed at achieving robustness to face motion patterns.\"",
        "sdp_path_text": "algorithm → introduce → achieve → robustness → to → patterns",
        "sentence": "An accurate video sequence 'reillumination' algorithm is introduced to achieve robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequence 'reillumination' algorithm') is the subject, depending on the verb 'introduced'. Entity 2 ('face motion patterns') is the object of the preposition 'to', depending on 'to' in the phrase 'to achieve robustness to face motion patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'achieve'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            [
                "robustness",
                "Metric"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. Entity 2 ('robustness') is the object, depending on 'achieve' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, where 'face motion patterns' modifies 'robustness' to specify what the robustness is against.\"",
        "sdp_path_text": "patterns → to → robustness",
        "sentence": "An algorithm achieves robustness to face motion patterns.",
        "sentence_llm_dp_info": "\"Entity 1 ('face motion patterns') is the object of the preposition 'to', depending on 'to' in the phrase 'to face motion patterns'. Entity 2 ('robustness') is the direct object, depending on the verb 'achieves' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' indicating the scope of 'robustness'.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "robustness",
                "Metric"
            ],
            [
                "video",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object, depending on 'achieve' in the clause 'to achieve robustness to face motion patterns in video'. Entity 2 ('video') is part of a prepositional phrase, depending on 'in' in the phrase 'in video'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the same clause but are connected through the verb 'achieve' and the preposition 'in'.\"",
        "sdp_path_text": "robustness → achieve → introduce → algorithm → sequence → video",
        "sentence": "An algorithm is introduced to achieve robustness in video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object, depending on 'achieve' with 'algorithm'. Entity 2 ('video') is part of a compound noun, depending on 'sequences' with 'video sequences'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In particular there are three areas of novelty : -LRB- i -RRB- we show how a photometric model of image formation can be combined with a statistical model of generic face appearance variation , learnt offline , to generalize in the presence of extreme illumination changes ; -LRB- ii -RRB- we use the smoothness of geodesically local appearance manifold structure and a robust same-identity likelihood to achieve invariance to unseen head poses ; and -LRB- iii -RRB- we introduce an accurate video sequence '' reillumination '' algorithm to achieve robustness to face motion patterns in video .",
        "ner_pair": [
            [
                "face motion patterns",
                "OtherScientificTerm"
            ],
            [
                "video",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. Entity 2 ('video') is the object of the preposition 'in', depending on 'patterns'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase 'to face motion patterns in video'.\"",
        "sdp_path_text": "patterns → to → robustness → achieve → introduce → algorithm → sequence → video",
        "sentence": "An algorithm is introduced to achieve robustness to face motion patterns in video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('face motion patterns') is the object of the preposition 'to', depending on 'robustness'. Entity 2 ('video') is part of the noun compound 'video sequences', depending on 'sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of achieving robustness in video sequences.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "fully automatic recognition system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the proposed method'. Entity 2 ('fully automatic recognition system') is the object, depending on 'describe' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on the proposed method' which modifies Entity 2.\"",
        "sdp_path_text": "method → on → based → system",
        "sentence": "A fully automatic recognition system is based on the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'based'. Entity 2 ('fully automatic recognition system') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on the proposed method'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "video sequences",
                "Material"
            ],
            [
                "fully automatic recognition system",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'on', depending on 'evaluation'. Entity 2 ('fully automatic recognition system') is the object of the verb 'describe', depending on 'We'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "sequences → evaluation → system",
        "sentence": "An extensive evaluation of video sequences was conducted on the fully automatic recognition system.",
        "sentence_llm_dp_info": "\"Entity 1 ('video sequences') is the object of the preposition 'of', depending on 'evaluation'. Entity 2 ('fully automatic recognition system') is the object of the preposition 'on', depending on 'conducted'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where 'evaluation' and 'conducted' serve as connecting verbs.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "fully automatic recognition system",
                "Method"
            ],
            [
                "illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('fully automatic recognition system') is the subject complement, depending on the verb 'describe' with 'We'. Entity 2 ('illumination') is part of a list of objects, depending on 'variation' in the phrase 'extreme illumination, pose and head motion variation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "system → evaluation → sequences → with → illumination",
        "sentence": "A fully automatic recognition system was evaluated on sequences with extreme illumination variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('fully automatic recognition system') is the subject, depending on the verb 'was evaluated'. Entity 2 ('illumination') is part of a noun phrase functioning as an attribute, depending on 'variation' in the phrase 'illumination variation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation context described in the sentence.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "fully automatic recognition system",
                "Method"
            ],
            [
                "pose",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('fully automatic recognition system') is the subject, depending on the verb 'describe' with 'We'. Entity 2 ('pose') is part of a list of objects, depending on 'variation' in the phrase 'pose and head motion variation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "system → based → on → method → proposed",
        "sentence": "We describe a fully automatic recognition system based on the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('fully automatic recognition system') is the subject, depending on the verb 'describe'. Entity 2 ('pose') does not appear in the given sentence, so it cannot be analyzed for dependencies within this context. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "fully automatic recognition system",
                "Method"
            ],
            [
                "head motion variation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('fully automatic recognition system') is the object, depending on the verb 'describe' with 'We'. Entity 2 ('head motion variation') is part of a list of items, depending on 'variation' which modifies 'video sequences'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing the system and its evaluation.\"",
        "sdp_path_text": "system → evaluation → sequences → with → illumination → variation",
        "sentence": "We describe a fully automatic recognition system evaluated with head motion variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('fully automatic recognition system') is the subject, depending on 'describe' with 'We'. Entity 2 ('head motion variation') is the object of the preposition 'with', depending on 'evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation context provided by the verb 'evaluated'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "video sequences",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is part of a noun phrase, depending on 'based' as the object of the preposition 'on' in the phrase 'based on the proposed method'. Entity 2 ('video sequences') is the object of the preposition 'on' in the phrase 'on 171 individuals and over 1300 video sequences'. There is no direct dependency between Entity 1 and Entity 2; both are part of different prepositional phrases that modify the main clause.\"",
        "sdp_path_text": "method → on → based → system → evaluation → sequences",
        "sentence": "The method is evaluated on video sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is evaluated'. Entity 2 ('video sequences') is the object, depending on the preposition 'on' with 'evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation process described by the verb 'is evaluated'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the proposed method'. Entity 2 ('illumination') is part of a compound noun, depending on 'variation' with 'extreme'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "method → on → based → system → evaluation → sequences → with → illumination",
        "sentence": "The method is evaluated on sequences with extreme illumination.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'evaluated'. Entity 2 ('illumination') is the modifier, depending on the adjective 'extreme' and part of the noun phrase 'extreme illumination'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'on sequences with extreme illumination' where 'sequences' is the object of the preposition 'on' and 'extreme illumination' modifies 'sequences'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "pose",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is part of a noun phrase, depending on 'based' with 'system'. Entity 2 ('pose') is one of the objects in a list, depending on 'variation' with 'and'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "method → proposed",
        "sentence": "We describe a system based on the proposed method evaluated with pose variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the proposed method'. Entity 2 ('pose') is part of a compound noun, depending on 'variation' in the phrase 'pose variation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the evaluation context described in the sentence.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "head motion variation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the proposed method'. Entity 2 ('head motion variation') is part of a list of objects, depending on 'variation' which itself depends on 'with' in the phrase 'with extreme illumination, pose and head motion variation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "method → on → based → system → evaluation → sequences → with → illumination → variation",
        "sentence": "A system based on the proposed method was evaluated with sequences featuring head motion variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the proposed method'. Entity 2 ('head motion variation') is the object of the participle 'featuring', depending on 'sequences'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "illumination",
                "OtherScientificTerm"
            ],
            [
                "video sequences",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a noun phrase, depending on 'variation' with the preposition 'with'. Entity 2 ('video sequences') is the object of the preposition 'on', depending on 'evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the conditions under which the evaluation was conducted.\"",
        "sdp_path_text": "illumination → with → sequences",
        "sentence": "Video sequences have extreme illumination variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is the object of the noun 'variation', depending on 'variation' with the adjective 'extreme'. Entity 2 ('video sequences') is the subject, depending on the verb 'have'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'have' and the noun 'variation'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "video sequences",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a list of items, depending on the conjunction 'and' with 'illumination' and 'head motion variation', which together form the object of the preposition 'with'. Entity 2 ('video sequences') is the object of the preposition 'on', depending on 'evaluation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "proposed → method → on → based → system → evaluation → sequences",
        "sentence": "An evaluation of video sequences with pose variations was conducted using the proposed method.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is part of the noun phrase 'pose variations', which modifies 'video sequences', depending on the preposition 'with' in the phrase 'with pose variations'. Entity 2 ('video sequences') is the object of the preposition 'of', depending on 'evaluation' in the phrase 'an evaluation of video sequences'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrases 'of video sequences' and 'with pose variations'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "head motion variation",
                "OtherScientificTerm"
            ],
            [
                "video sequences",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('head motion variation') is part of a list of features, depending on the preposition 'with' which modifies 'video sequences'. Entity 2 ('video sequences') is the object of the preposition 'on', depending on the verb 'evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase structure where 'video sequences' is modified by the list of features including 'head motion variation'.\"",
        "sdp_path_text": "variation → illumination → with → sequences",
        "sentence": "The system was evaluated on video sequences with head motion variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('head motion variation') is the object of the preposition 'with', depending on 'with' in the phrase 'with head motion variation'. Entity 2 ('video sequences') is the object of the preposition 'on', depending on 'on' in the phrase 'on video sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying the main clause of the sentence.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "illumination",
                "OtherScientificTerm"
            ],
            [
                "pose",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a list of elements in a prepositional phrase, depending on 'variation' with 'with'. Entity 2 ('pose') is also part of the same list, depending on 'variation' with 'and'. There is no direct dependency between Entity 1 and Entity 2; both are listed as types of variation in the sentence.\"",
        "sdp_path_text": "illumination → with → sequences → evaluation → system → based → on → method → proposed",
        "sentence": "The system, based on the proposed method, evaluates sequences with illumination and pose variations.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a compound noun, depending on 'variations' with 'and'. Entity 2 ('pose') is also part of the same compound noun, depending on 'variations' with 'and'. There is no direct dependency between Entity 1 and Entity 2; both are components of the noun phrase 'illumination and pose variations'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "illumination",
                "OtherScientificTerm"
            ],
            [
                "head motion variation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a list, depending on the conjunction 'and' with 'pose' and 'head motion variation', which together form the object of the preposition 'with'. Entity 2 ('head motion variation') is also part of the same list, depending on the conjunction 'and' with 'illumination' and 'pose'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a coordinated structure listed as variations affecting the video sequences.\"",
        "sdp_path_text": "illumination → variation",
        "sentence": "The system was evaluated with extreme illumination and head motion variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a compound noun, depending on 'extreme' with 'extreme illumination'. Entity 2 ('head motion variation') is a compound noun, depending on 'motion' with 'head motion variation'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'with' in the phrase 'with extreme illumination and head motion variation'.\""
    },
    {
        "raw_sentence": "We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "head motion variation",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a coordination, depending on the conjunction 'and' with 'illumination'. Entity 2 ('head motion variation') is also part of a coordination, depending on the conjunction 'and' with 'pose'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated elements in the list of variations described in the sentence.\"",
        "sdp_path_text": "proposed → method → on → based → system → evaluation → sequences → with → illumination → variation",
        "sentence": "The system undergoes evaluation with sequences featuring illumination, pose, and head motion variation.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a coordination, depending on the conjunction 'and' with 'illumination'. Entity 2 ('head motion variation') is also part of the same coordination, depending on the conjunction 'and' with 'pose'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the list of features.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "data set",
                "Generic"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'demonstrated' with 'our system'. Entity 2 ('system') is the subject, depending on 'demonstrated' with the verb 'demonstrated'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the context provided by the sentence where the 'system' demonstrates performance on the 'data set'.\"",
        "sdp_path_text": "set → On → demonstrated → system",
        "sentence": "{\n  \"Simplified sentence\": \"On this data set, the system demonstrated.\"\n} \n\nHowever, this simplification seems to lose too much information, particularly the impressive performance metric. Given the SDP and the need to retain the relationship and key performance aspect, a better approach might be:\n\n{\n  \"Simplified sentence\": \"The system demonstrated a nearly perfect recognition rate on this challenging data set.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('system') is the subject, depending on the verb 'demonstrated'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'demonstrated' where 'system' performs the action and 'data set' is part of the context in which the action takes place.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "data set",
                "Generic"
            ],
            [
                "recognition rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on the adverbial phrase 'On this challenging data set'. Entity 2 ('recognition rate') is the subject complement, depending on 'demonstrated' with 'our system'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the performance described in the sentence.\"",
        "sdp_path_text": "set → On → demonstrated → rate",
        "sentence": "On this data set, our system demonstrated a high recognition rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('recognition rate') is the object, depending on 'demonstrated' with 'our system'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the action 'demonstrated'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "data set",
                "Generic"
            ],
            [
                "databases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on the adverbial phrase 'On this challenging data set'. Entity 2 ('databases') is part of the prepositional phrase 'on all three databases', depending on the preposition 'on'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of the performance of the system described in the sentence.\"",
        "sdp_path_text": "set → On → demonstrated → on → databases",
        "sentence": "On this data set, the system demonstrated performance on databases.",
        "sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'on' in the phrase 'on this data set'. Entity 2 ('databases') is the object of the preposition 'on', depending on 'performance' in the phrase 'performance on databases'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "data set",
                "Generic"
            ],
            [
                "commercial software",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'On' in the phrase 'On this challenging data set'. Entity 2 ('commercial software') is part of a compound noun, depending on 'out-performing' as an object. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context where the performance of a system is being described.\"",
        "sdp_path_text": "set → On → demonstrated → - → performing → software",
        "sentence": "On this data set, our system significantly outperformed commercial software.",
        "sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'outperformed'. Entity 2 ('commercial software') is the object, depending on the verb 'outperformed'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the context in which the action described by 'outperformed' takes place.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "data set",
                "Generic"
            ],
            [
                "methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'demonstrated' with 'our system'. Entity 2 ('methods') is part of a compound noun, depending on 'out-performing' with 'software'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the performance comparison described in the sentence.\"",
        "sdp_path_text": "set → On → demonstrated → - → performing → software → methods",
        "sentence": "On this data set, our system significantly outperformed methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('data set') is the object of the preposition 'on', depending on 'on' in the phrase 'on this data set'. Entity 2 ('methods') is the object, depending on the verb 'outperformed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context describing the performance comparison.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "recognition rate",
                "Metric"
            ],
            [
                "system",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the object, depending on 'demonstrated' with 'system'. Entity 2 ('system') is the subject, depending on 'demonstrated' with 'recognition rate'. There is a direct dependency between Entity 1 and Entity 2, as 'system' demonstrates the 'recognition rate'.\"",
        "sdp_path_text": "rate → demonstrated → system",
        "sentence": "The system demonstrated a high recognition rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the object, depending on 'demonstrated' with 'system'. Entity 2 ('system') is the subject, depending on the verb 'demonstrated'. There is a direct dependency between Entity 1 and Entity 2, where 'system' is the subject that 'demonstrated' the 'recognition rate'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "databases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'demonstrated'. Entity 2 ('databases') is the object of the preposition 'on', depending on the prepositional phrase 'over 99.7% on all three databases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'demonstrated' and the prepositional phrase that modifies the performance metric.\"",
        "sdp_path_text": "system → demonstrated → on → databases",
        "sentence": "Our system demonstrated a high recognition rate on databases.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'demonstrated'. Entity 2 ('databases') is the object of the preposition 'on', depending on 'on' in the phrase 'on databases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "commercial software",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on 'demonstrated' with 'consistently'. Entity 2 ('commercial software') is part of a compound noun, depending on 'out-performing' with 'significantly'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the comparative action described by 'out-performing'.\"",
        "sdp_path_text": "system → demonstrated → - → performing → software",
        "sentence": "Our system significantly outperformed commercial software.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'outperformed'. Entity 2 ('commercial software') is the object, depending on 'outperformed' with 'system'. There is a direct dependency between Entity 1 and Entity 2, where 'system' is the subject performing the action of 'outperforming' the 'commercial software'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "methods",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on 'demonstrated' with 'our'. Entity 2 ('methods') is the object, depending on 'out-performing' with 'software'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause where the 'system' is compared to 'methods' and 'software' in terms of performance.\"",
        "sdp_path_text": "system → demonstrated → - → performing → software → methods",
        "sentence": "Our system significantly outperformed methods from the literature.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'outperformed'. Entity 2 ('methods') is the object, depending on 'outperformed' with 'system'. There is a direct dependency between Entity 1 and Entity 2, where 'system' outperforms 'methods'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "recognition rate",
                "Metric"
            ],
            [
                "databases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the object, depending on the verb 'demonstrated' with 'our system'. Entity 2 ('databases') is the object of the preposition 'on', depending on the prepositional phrase 'over 99.7% on all three databases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'demonstrated' and the preposition 'on'.\"",
        "sdp_path_text": "rate → demonstrated → on → databases",
        "sentence": "The recognition rate was demonstrated on databases.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the subject, depending on the verb 'was demonstrated'. Entity 2 ('databases') is the object of the preposition 'on', depending on 'on' in the phrase 'on databases'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "recognition rate",
                "Metric"
            ],
            [
                "commercial software",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the object of the preposition 'a', depending on 'demonstrated' with 'our system'. Entity 2 ('commercial software') is part of a compound object, depending on 'out-performing' with 'significantly'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'out-performing' which describes the performance comparison.\"",
        "sdp_path_text": "rate → demonstrated → - → performing → software",
        "sentence": "The recognition rate significantly outperformed commercial software.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the subject, depending on the verb 'outperformed'. Entity 2 ('commercial software') is the object, depending on the verb 'outperformed'. There is a direct dependency between Entity 1 and Entity 2, as 'recognition rate' is the subject that performs the action (outperforming) on 'commercial software'.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "recognition rate",
                "Metric"
            ],
            [
                "methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the subject complement, depending on the verb 'demonstrated' with 'system'. Entity 2 ('methods') is part of a comparative structure, depending on 'out-performing' with 'system'. There is no direct dependency between Entity 1 and Entity 2; both are related to the performance of the system described in the sentence.\"",
        "sdp_path_text": "rate → demonstrated → - → performing → software → methods",
        "sentence": "Our system demonstrated a high recognition rate, outperforming methods from the literature.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition rate') is the object of the preposition 'a', depending on 'demonstrated' with 'system'. Entity 2 ('methods') is the object of the preposition 'from', depending on 'outperforming'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'outperforming' which indicates that the 'recognition rate' of 'our system' was higher than that of the 'methods' from the literature.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "databases",
                "Material"
            ],
            [
                "commercial software",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('databases') is part of the prepositional phrase 'on all three databases', which modifies the noun 'rate'. Entity 2 ('commercial software') is part of the compound object in the comparative clause, depending on the verb 'out-performing'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "databases → on → demonstrated → - → performing → software",
        "sentence": "Our system demonstrated a high recognition rate on databases, outperforming commercial software.",
        "sentence_llm_dp_info": "\"Entity 1 ('databases') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('commercial software') is the object of the verb 'outperforming', depending on 'outperforming'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "databases",
                "Material"
            ],
            [
                "methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('databases') is the object of the preposition 'on', depending on 'over 99.7%'. Entity 2 ('methods') is part of a compound noun, depending on 'from' in the phrase 'from the literature'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "databases → on → demonstrated → - → performing → software → methods",
        "sentence": "Our system demonstrated a high recognition rate on databases, outperforming methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('databases') is the object of the preposition 'on', depending on 'on' in the phrase 'on databases'. Entity 2 ('methods') is the object of the verb 'outperforming', depending on 'outperforming' in the phrase 'outperforming methods'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "On this challenging data set our system consistently demonstrated a nearly perfect recognition rate -LRB- over 99.7 % on all three databases -RRB- , significantly out-performing state-of-the-art commercial software and methods from the literature .",
        "ner_pair": [
            [
                "commercial software",
                "Method"
            ],
            [
                "methods",
                "Generic"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('commercial software') is part of a compound noun, depending on 'out-performing' as an object. Entity 2 ('methods') is also part of a compound noun, depending on 'out-performing' as an object. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the verb 'out-performing'.\"",
        "sdp_path_text": "software → methods",
        "sentence": "Our system significantly out-performed commercial software and methods from the literature.",
        "sentence_llm_dp_info": "\"Entity 1 ('commercial software') is the object of the conjunction 'and', depending on 'out-performed'. Entity 2 ('methods') is also an object, depending on the conjunction 'and' with 'commercial software'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and both are objects of the verb 'out-performed'.\""
    },
    {
        "raw_sentence": "We present Minimum Bayes-Risk -LRB- MBR -RRB- decoding for statistical machine translation .",
        "ner_pair": [
            [
                "Minimum Bayes-Risk -LRB- MBR -RRB- decoding",
                "Method"
            ],
            [
                "statistical machine translation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Minimum Bayes-Risk -LRB- MBR -RRB- decoding') is the subject, depending on the verb 'present'. Entity 2 ('statistical machine translation') is the object of the preposition 'for', depending on 'for' in the phrase 'for statistical machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "decoding → for → translation",
        "sentence": "Minimum Bayes-Risk (MBR) decoding is for statistical machine translation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Minimum Bayes-Risk (MBR) decoding') is the subject, depending on the verb 'is'. Entity 2 ('statistical machine translation') is the complement, depending on the preposition 'for', which is part of the prepositional phrase 'for statistical machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "statistical approach",
                "Method"
            ],
            [
                "expected loss",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('expected loss') is the object of the preposition 'of', depending on 'minimize' in the phrase 'to minimize expected loss'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aims' and the preposition 'of'.\"",
        "sdp_path_text": "approach → aims → minimize → loss",
        "sentence": "The statistical approach aims to minimize expected loss.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('expected loss') is the object, depending on 'minimize' with 'aims'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aims' which indicates the purpose of the 'statistical approach' is to 'minimize expected loss'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "statistical approach",
                "Method"
            ],
            [
                "translation errors",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('translation errors') is the object of the preposition 'of', depending on 'loss' in the phrase 'expected loss of translation errors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aims' and the prepositional phrase 'of translation errors'.\"",
        "sdp_path_text": "approach → aims → minimize → loss → of → errors",
        "sentence": "The statistical approach aims to minimize the loss of translation errors.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('translation errors') is the object, depending on the noun 'loss' in the phrase 'loss of translation errors'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'aims' and the prepositional phrase 'to minimize the loss of'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "statistical approach",
                "Method"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('loss functions') is the subject complement, depending on the relative clause 'that measure translation performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'loss functions' being further described in a relative clause.\"",
        "sdp_path_text": "approach → aims → minimize → under → functions",
        "sentence": "The statistical approach aims to minimize loss under loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('loss functions') is the object of the preposition 'under', depending on 'under' in the phrase 'under loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'under loss functions' which modifies the verb 'minimize'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "statistical approach",
                "Method"
            ],
            [
                "translation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('translation') is part of the noun phrase 'translation errors', which is the object of the preposition 'of', depending on 'loss'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'aims' and the prepositional phrase 'of translation errors'.\"",
        "sdp_path_text": "approach → aims → minimize → loss → of → errors → translation",
        "sentence": "The statistical approach aims to minimize translation errors.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical approach') is the subject, depending on the verb 'aims'. Entity 2 ('translation') is part of a compound noun, depending on 'errors' in the phrase 'translation errors'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'minimize' and the noun 'errors'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "expected loss",
                "OtherScientificTerm"
            ],
            [
                "translation errors",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expected loss') is the object of the verb 'minimize', depending on 'aims' in the clause 'aims to minimize'. Entity 2 ('translation errors') is the object of the preposition 'of', depending on 'expected loss' in the phrase 'expected loss of translation errors'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 modifies Entity 1.\"",
        "sdp_path_text": "loss → of → errors",
        "sentence": "The approach aims to minimize expected loss of translation errors.",
        "sentence_llm_dp_info": "\"Entity 1 ('expected loss') is the object, depending on 'minimize' with 'aims'. Entity 2 ('translation errors') is the object of the preposition 'of', depending on 'of' in the phrase 'of translation errors'. There is a direct dependency between Entity 1 and Entity 2, as 'translation errors' modifies 'expected loss'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "expected loss",
                "OtherScientificTerm"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expected loss') is the object of the verb 'minimize', depending on 'aims' with 'This statistical approach'. Entity 2 ('loss functions') is the subject, depending on 'that' which introduces a relative clause modifying 'loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same semantic context where 'loss functions' measure the 'expected loss'.\"",
        "sdp_path_text": "loss → minimize → under → functions",
        "sentence": "The approach aims to minimize expected loss under loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('expected loss') is the object of the verb 'minimize', depending on 'aims' with 'The approach'. Entity 2 ('loss functions') is the object of the preposition 'under', depending on 'under' in the phrase 'under loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'expected loss' is being minimized under 'loss functions'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "expected loss",
                "OtherScientificTerm"
            ],
            [
                "translation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expected loss') is the object of the verb 'minimize', depending on 'aims' in the clause 'aims to minimize'. Entity 2 ('translation') is part of the compound noun 'translation errors', which is the genitive modifier of 'expected loss'. There is a direct dependency between Entity 1 and Entity 2, as 'translation' modifies 'errors', which in turn specifies the type of 'expected loss' being minimized.\"",
        "sdp_path_text": "loss → of → errors → translation",
        "sentence": "The approach aims to minimize expected loss of translation errors.",
        "sentence_llm_dp_info": "\"Entity 1 ('expected loss') is the object, depending on the verb 'minimize'. Entity 2 ('translation') is part of the compound noun 'translation errors', depending on 'errors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'errors' in the phrase 'expected loss of translation errors'.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "translation errors",
                "OtherScientificTerm"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('translation errors') is the object of the preposition 'of', depending on 'loss'. Entity 2 ('loss functions') is the subject, depending on 'that' which introduces the relative clause 'that measure translation performance'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure where 'loss functions' measure the 'expected loss of translation errors'.\"",
        "sdp_path_text": "errors → of → loss → minimize → under → functions",
        "sentence": "The approach aims to minimize translation errors under loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('translation errors') is the object, depending on 'minimize' with 'aims'. Entity 2 ('loss functions') is the object of the preposition 'under', depending on 'under' in the phrase 'under loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what the approach aims to achieve.\""
    },
    {
        "raw_sentence": "This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .",
        "ner_pair": [
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            [
                "translation",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss functions') is the subject, depending on the verb 'measure' with 'that'. Entity 2 ('translation') is the object, depending on the preposition 'of' within the phrase 'loss of translation'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'loss of translation' and the clause 'that measure translation performance'.\"",
        "sdp_path_text": "functions → under → minimize → loss → of → errors → translation",
        "sentence": "Loss functions aim to minimize the loss of translation errors.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss functions') is the subject, depending on the verb 'aim'. Entity 2 ('translation') is part of the compound noun 'translation errors', which is the object of the preposition 'of', depending on 'minimize'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'minimize' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object of the preposition 'of', depending on 'incorporate' which is part of the verb phrase 'that incorporate'. Entity 2 ('loss functions') is the direct object of the verb 'describe', depending on 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate' where Entity 1 is what Entity 2 incorporates.\"",
        "sdp_path_text": "information → of → levels → incorporate → functions",
        "sentence": "Loss functions incorporate different levels of linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object, depending on the verb 'incorporate'. Entity 2 ('loss functions') is the subject, depending on the verb 'incorporate'. There is a direct dependency between Entity 1 and Entity 2, as 'linguistic information' is directly incorporated by 'loss functions'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "word-to-word alignments",
                "OtherScientificTerm"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is the object of the preposition 'from', depending on 'incorporate' with 'loss functions'. Entity 2 ('loss functions') is the object of the preposition 'of', depending on 'hierarchy'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporate'.\"",
        "sdp_path_text": "alignments → information → of → levels → incorporate → functions",
        "sentence": "Word-to-word alignments provide information incorporated into loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is the subject, depending on the verb 'provide'. Entity 2 ('loss functions') is the object of the preposition 'into', depending on 'incorporated' in the phrase 'incorporated into loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provide' and the prepositional phrase 'into loss functions'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            [
                "MT system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss functions') is the object of the verb 'describe', depending on the pronoun 'We'. Entity 2 ('MT system') is the object of the preposition 'from', depending on 'word-to-word alignments'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same descriptive clause that outlines sources of linguistic information.\"",
        "sdp_path_text": "functions → incorporate → levels → of → information → alignments → from → system",
        "sentence": "Loss functions incorporate information from alignments generated by an MT system.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss functions') is the subject, depending on the verb 'incorporate'. Entity 2 ('MT system') is the object of the preposition 'by', depending on 'generated' in the phrase 'by an MT system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporate' and the prepositional phrase 'by an MT system'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "syntactic structure",
                "OtherScientificTerm"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntactic structure') is part of a list, depending on the preposition 'from', which is part of the prepositional phrase 'from parse-trees of source and target language sentences'. Entity 2 ('loss functions') is the object of the clause, depending on the verb 'describe'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing components of the hierarchy being discussed.\"",
        "sdp_path_text": "structure → alignments → information → of → levels → incorporate → functions",
        "sentence": "Syntactic structure is incorporated into loss functions through alignments and information levels.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntactic structure') is the subject, depending on the verb 'incorporated'. Entity 2 ('loss functions') is the object of the preposition 'into', depending on 'into' in the phrase 'into loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporated' and the preposition 'into'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            [
                "parse-trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss functions') is the object of the verb 'describe', depending on 'We'. Entity 2 ('parse-trees') is part of a list of items, depending on the preposition 'from' in the phrase 'from parse-trees'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing the components that provide linguistic information.\"",
        "sdp_path_text": "functions → incorporate → levels → of → information → alignments → structure → from → -",
        "sentence": "Loss functions incorporate linguistic information from parse-trees.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss functions') is the subject, depending on the verb 'incorporate'. Entity 2 ('parse-trees') is the object, depending on 'from' in the prepositional phrase 'from parse-trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "word-to-word alignments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object of the preposition 'from', depending on 'incorporate' in the phrase 'incorporate different levels of linguistic information'. Entity 2 ('word-to-word alignments') is also the object of the preposition 'from', depending on 'incorporate' in the phrase 'incorporate different levels of... word-to-word alignments from an MT system'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items that the loss functions incorporate.\"",
        "sdp_path_text": "information → alignments",
        "sentence": "Linguistic information includes word-to-word alignments.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the subject, depending on the verb 'includes'. Entity 2 ('word-to-word alignments') is the object, depending on 'includes' with 'linguistic information'. There is a direct dependency between Entity 1 and Entity 2, as 'word-to-word alignments' is directly included in 'linguistic information'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "MT system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object of the preposition 'from', depending on 'incorporate' with 'loss functions'. Entity 2 ('MT system') is the noun modifier, depending on 'alignments' with 'word-to-word'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of items that the loss functions incorporate.\"",
        "sdp_path_text": "information → alignments → from → system",
        "sentence": "Linguistic information includes alignments from an MT system.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the subject, depending on the verb 'includes'. Entity 2 ('MT system') is the noun modifier, depending on 'alignments' in the phrase 'alignments from an MT system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the prepositional phrase 'from an MT system'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "syntactic structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object of the preposition 'from', depending on 'incorporate' in the phrase 'incorporate different levels of linguistic information'. Entity 2 ('syntactic structure') is also the object of the preposition 'from', depending on 'incorporate' in the phrase 'and syntactic structure from parse-trees'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of items that the loss functions incorporate.\"",
        "sdp_path_text": "information → alignments → structure",
        "sentence": "Linguistic information includes word-to-word alignments and syntactic structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the subject, depending on the verb 'includes'. Entity 2 ('syntactic structure') is the object, depending on 'and' which connects it with 'word-to-word alignments' as part of the list included by 'linguistic information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "parse-trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object of the preposition 'of', depending on 'incorporate' in the phrase 'incorporate different levels of linguistic information'. Entity 2 ('parse-trees') is the object of the preposition 'from', depending on 'structure' in the phrase 'syntactic structure from parse-trees'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of items that the loss functions incorporate.\"",
        "sdp_path_text": "information → alignments → structure → from → -",
        "sentence": "Linguistic information includes alignments and syntactic structure from parse-trees.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the subject, depending on the verb 'includes'. Entity 2 ('parse-trees') is the object, depending on the preposition 'from' in the phrase 'from parse-trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "word-to-word alignments",
                "OtherScientificTerm"
            ],
            [
                "MT system",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is the object of the preposition 'from', depending on 'incorporate' in the clause 'that incorporate different levels of linguistic information'. Entity 2 ('MT system') is the noun modifier, depending on 'alignments' in the phrase 'alignments from an MT system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.\"",
        "sdp_path_text": "alignments → from → system",
        "sentence": "Word-to-word alignments come from the MT system.",
        "sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is the subject, depending on the verb 'come'. Entity 2 ('MT system') is the source, depending on the preposition 'from' in the phrase 'from the MT system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "word-to-word alignments",
                "OtherScientificTerm"
            ],
            [
                "syntactic structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is part of a list, depending on the preposition 'from' with 'an MT system'. Entity 2 ('syntactic structure') is also part of a list, depending on the preposition 'from' with 'parse-trees of source and target language sentences'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of sources of linguistic information.\"",
        "sdp_path_text": "alignments → structure",
        "sentence": "Word-to-word alignments and syntactic structure are incorporated in the loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is the subject, depending on the verb 'are incorporated'. Entity 2 ('syntactic structure') is the conjunction, depending on 'and' with 'word-to-word alignments'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "word-to-word alignments",
                "OtherScientificTerm"
            ],
            [
                "parse-trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is the object of the preposition 'from', depending on 'incorporate' with 'loss functions'. Entity 2 ('parse-trees') is also the object of the preposition 'from', depending on 'incorporate' with 'loss functions'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items that the loss functions incorporate.\"",
        "sdp_path_text": "alignments → structure → from → -",
        "sentence": "Word-to-word alignments and syntactic structures from parse-trees are used in the hierarchy of loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('word-to-word alignments') is part of a conjunction, depending on the conjunction 'and' with 'syntactic structures'. Entity 2 ('parse-trees') is the source of the prepositional phrase 'from parse-trees', depending on 'from'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure that serves as the subject of the clause, which is then used in the hierarchy of loss functions.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "MT system",
                "Method"
            ],
            [
                "syntactic structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT system') is the object of the preposition 'from', depending on 'alignments'. Entity 2 ('syntactic structure') is also the object of the preposition 'from', depending on 'parse-trees'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of sources of linguistic information described in the sentence.\"",
        "sdp_path_text": "system → from → alignments → structure",
        "sentence": "Alignments from an MT system incorporate syntactic structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT system') is the object of the preposition 'from', depending on 'Alignments'. Entity 2 ('syntactic structure') is the object, depending on 'incorporate' with 'MT system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "MT system",
                "Method"
            ],
            [
                "parse-trees",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT system') is part of a prepositional phrase, depending on 'alignments' with the preposition 'from'. Entity 2 ('parse-trees') is part of a prepositional phrase, depending on 'structure' with the preposition 'from'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of incorporating linguistic information into the hierarchy of loss functions.\"",
        "sdp_path_text": "system → from → alignments → structure → from → -",
        "sentence": "Alignments from an MT system and syntactic structure from parse-trees are used.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT system') is the object of the preposition 'from', depending on 'Alignments'. Entity 2 ('parse-trees') is also the object of the preposition 'from', depending on 'syntactic structure'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences .",
        "ner_pair": [
            [
                "parse-trees",
                "OtherScientificTerm"
            ],
            [
                "syntactic structure",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parse-trees') is the object of the preposition 'from', depending on 'incorporate' through the prepositional phrase 'from parse-trees'. Entity 2 ('syntactic structure') is the subject complement, depending on 'incorporate' through the prepositional phrase 'from syntactic structure'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of items incorporated by the loss functions.\"",
        "sdp_path_text": "- → from → structure",
        "sentence": "Parse-trees provide syntactic structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('parse-trees') is the subject, depending on the verb 'provide'. Entity 2 ('syntactic structure') is the direct object, depending on 'provide'. There is a direct dependency between Entity 1 and Entity 2, where 'parse-trees' provides 'syntactic structure'.\""
    },
    {
        "raw_sentence": "We report the performance of the MBR decoders on a Chinese-to-English translation task .",
        "ner_pair": [
            [
                "MBR decoders",
                "Method"
            ],
            [
                "Chinese-to-English translation task",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MBR decoders') is the object of the preposition 'of', depending on 'performance'. Entity 2 ('Chinese-to-English translation task') is the object of the preposition 'on', depending on 'report'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what is being reported.\"",
        "sdp_path_text": "decoders → of → performance → on → task",
        "sentence": "MBR decoders perform on the Chinese-to-English translation task.",
        "sentence_llm_dp_info": "\"Entity 1 ('MBR decoders') is the subject, depending on the verb 'perform'. Entity 2 ('Chinese-to-English translation task') is the object, depending on the preposition 'on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' which indicates the domain or context in which the action of performing takes place.\""
    },
    {
        "raw_sentence": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions .",
        "ner_pair": [
            [
                "MBR decoding",
                "Method"
            ],
            [
                "statistical MT",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MBR decoding') is the subject complement, depending on the verb 'can be used'. Entity 2 ('statistical MT') is the object of the preposition 'for', depending on 'tune'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what can be used and what it can tune, respectively.\"",
        "sdp_path_text": "decoding → used → tune → performance → statistical",
        "sentence": "MBR decoding can be used to tune statistical MT performance.",
        "sentence_llm_dp_info": "\"Entity 1 ('MBR decoding') is the subject, depending on the verb 'can be used'. Entity 2 ('statistical MT') is the modifier of the noun 'performance', depending on 'performance' in the phrase 'statistical MT performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'MBR decoding' is used to affect 'statistical MT performance'.\""
    },
    {
        "raw_sentence": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions .",
        "ner_pair": [
            [
                "MBR decoding",
                "Method"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MBR decoding') is the subject complement, depending on the verb 'can be used'. Entity 2 ('loss functions') is the object of the preposition 'for', depending on 'for' in the phrase 'for specific loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can be used to tune' and the preposition 'for'.\"",
        "sdp_path_text": "decoding → used → tune → for → functions",
        "sentence": "MBR decoding can be used to tune performance for specific loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('MBR decoding') is the subject, depending on the verb 'can be used'. Entity 2 ('loss functions') is the object of the preposition 'for', depending on 'for' in the phrase 'for specific loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions .",
        "ner_pair": [
            [
                "statistical MT",
                "Method"
            ],
            [
                "loss functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical MT') is part of the object complement, depending on 'tune' with 'can be used to tune'. Entity 2 ('loss functions') is the object of the preposition 'for', depending on 'for' in the phrase 'for specific loss functions'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the action described by 'tune'.\"",
        "sdp_path_text": "statistical → performance → tune → for → functions",
        "sentence": "MBR decoding can tune statistical MT performance for specific loss functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical MT') is part of the noun phrase 'statistical MT performance', acting as an attributive modifier, depending on 'performance'. Entity 2 ('loss functions') is the object of the preposition 'for', depending on 'tune'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'tune' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper presents a critical discussion of the various approaches that have been used in the evaluation of Natural Language systems .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "evaluation of Natural Language systems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the relative clause, depending on 'that' which is part of 'that have been used'. Entity 2 ('evaluation of Natural Language systems') is the object of the preposition 'of', depending on 'of' in the phrase 'of the evaluation of Natural Language systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of the evaluation of Natural Language systems' where 'approaches' are discussed in the context of this evaluation.\"",
        "sdp_path_text": "approaches → used → in → evaluation",
        "sentence": "Various approaches have been used in the evaluation of Natural Language systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'have been used'. Entity 2 ('evaluation of Natural Language systems') is the object of the preposition 'in', depending on 'in' in the phrase 'in the evaluation of Natural Language systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "This paper presents a critical discussion of the various approaches that have been used in the evaluation of Natural Language systems .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "Natural Language systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the relative clause, depending on 'that' with 'have been used'. Entity 2 ('Natural Language systems') is the object of the preposition 'of', depending on 'evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence, where 'approaches' are discussed in the context of evaluating 'Natural Language systems'.\"",
        "sdp_path_text": "approaches → used → in → evaluation → of → systems",
        "sentence": "Various approaches have been used in the evaluation of Natural Language systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'have been used'. Entity 2 ('Natural Language systems') is the object of the preposition 'of', depending on 'evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the prepositional phrase 'in the evaluation of'.\""
    },
    {
        "raw_sentence": "We conclude that previous approaches have neglected to evaluate systems in the context of their use , e.g. solving a task requiring data retrieval .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "systems",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the verb 'have neglected', depending on 'neglected'. Entity 2 ('systems') is the object of the verb 'evaluate', depending on 'evaluate' within the clause 'to evaluate systems'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the action of neglecting to evaluate.\"",
        "sdp_path_text": "approaches → neglected → evaluate → systems",
        "sentence": "Previous approaches have neglected to evaluate systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'have neglected'. Entity 2 ('systems') is the object, depending on the verb 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluate' which is part of the action that the subject ('approaches') has neglected to perform.\""
    },
    {
        "raw_sentence": "We conclude that previous approaches have neglected to evaluate systems in the context of their use , e.g. solving a task requiring data retrieval .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'have neglected'. Entity 2 ('task') is the object, depending on 'solving' which is part of the gerund phrase 'solving a task requiring data retrieval'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "approaches → neglected → evaluate → solving → task",
        "sentence": "Previous approaches have neglected to evaluate solving a task.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'neglected'. Entity 2 ('task') is the object of the verb 'solving', which is part of the infinitive phrase 'to evaluate solving a task', depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'neglected' and 'evaluate'.\""
    },
    {
        "raw_sentence": "We conclude that previous approaches have neglected to evaluate systems in the context of their use , e.g. solving a task requiring data retrieval .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "data retrieval",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the verb 'have neglected', depending on 'neglected'. Entity 2 ('data retrieval') is the object of the verb 'requiring', depending on 'requiring'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the verb 'neglected' and the phrase 'solving a task requiring data retrieval'.\"",
        "sdp_path_text": "approaches → neglected → evaluate → solving → task → requiring → retrieval",
        "sentence": "Previous approaches have neglected evaluating tasks requiring data retrieval.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'have neglected'. Entity 2 ('data retrieval') is the object of the preposition 'requiring', depending on 'tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'have neglected' and the prepositional phrase 'requiring data retrieval'.\""
    },
    {
        "raw_sentence": "We conclude that previous approaches have neglected to evaluate systems in the context of their use , e.g. solving a task requiring data retrieval .",
        "ner_pair": [
            [
                "systems",
                "Generic"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('systems') is the object of the verb 'evaluate', depending on 'have neglected' with 'previous approaches'. Entity 2 ('task') is the object of the verb 'solving', depending on 'requiring' with 'data retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence.\"",
        "sdp_path_text": "systems → evaluate → solving → task",
        "sentence": "Systems have been neglected to evaluate in the context of solving a task.",
        "sentence_llm_dp_info": "\"Entity 1 ('systems') is the subject, depending on the verb 'neglected'. Entity 2 ('task') is the object of the preposition 'of', depending on 'context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'in the context of solving a task'.\""
    },
    {
        "raw_sentence": "We conclude that previous approaches have neglected to evaluate systems in the context of their use , e.g. solving a task requiring data retrieval .",
        "ner_pair": [
            [
                "systems",
                "Generic"
            ],
            [
                "data retrieval",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('systems') is the object of the verb 'evaluate', depending on 'neglected' with the structure 'neglected to evaluate systems'. Entity 2 ('data retrieval') is part of a nominal modifier, depending on 'task' in the phrase 'a task requiring data retrieval'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "systems → evaluate → solving → task → requiring → retrieval",
        "sentence": "Systems have been neglected to evaluate in the context of tasks requiring data retrieval.",
        "sentence_llm_dp_info": "\"Entity 1 ('systems') is the subject, depending on the verb 'neglected'. Entity 2 ('data retrieval') is part of the prepositional phrase 'of tasks requiring data retrieval', where it depends on 'requiring'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure involving 'tasks' and 'requiring'.\""
    },
    {
        "raw_sentence": "We conclude that previous approaches have neglected to evaluate systems in the context of their use , e.g. solving a task requiring data retrieval .",
        "ner_pair": [
            [
                "data retrieval",
                "Task"
            ],
            [
                "task",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data retrieval') is the object, depending on the verb 'requiring' in the clause 'requiring data retrieval'. Entity 2 ('task') is the object of the preposition 'a' in the phrase 'a task', which itself is part of the gerund phrase 'solving a task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requiring' within the gerund phrase 'solving a task requiring data retrieval'.\"",
        "sdp_path_text": "retrieval → requiring → task",
        "sentence": "Data retrieval is required for solving a task.",
        "sentence_llm_dp_info": "\"Entity 1 ('data retrieval') is the subject, depending on the verb 'is' in the phrase 'is required'. Entity 2 ('task') is the object of the preposition 'for', depending on 'for' in the phrase 'for solving a task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'solving' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "In the second half of the paper , we report a laboratory study using the Wizard of Oz technique to identify NL requirements for carrying out this task .",
        "ner_pair": [
            [
                "Wizard of Oz technique",
                "Method"
            ],
            [
                "NL requirements",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Wizard of Oz technique') is the object of the preposition 'using', depending on 'study'. Entity 2 ('NL requirements') is the object of the infinitive 'to identify', depending on 'identify'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the purpose and method of the study.\"",
        "sdp_path_text": "technique → using → identify → requirements",
        "sentence": "The Wizard of Oz technique is used to identify NL requirements.",
        "sentence_llm_dp_info": "\"Entity 1 ('Wizard of Oz technique') is the subject, depending on the verb 'is used'. Entity 2 ('NL requirements') is the object, depending on the verb 'identify'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'is used' and 'identify'.\""
    },
    {
        "raw_sentence": "In the second half of the paper , we report a laboratory study using the Wizard of Oz technique to identify NL requirements for carrying out this task .",
        "ner_pair": [
            [
                "Wizard of Oz technique",
                "Method"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Wizard of Oz technique') is the object of the preposition 'using', depending on 'study'. Entity 2 ('task') is the object of the preposition 'out', part of the phrasal verb 'carrying out', depending on 'carrying out'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the structure describing the purpose and method of the study.\"",
        "sdp_path_text": "technique → using → identify → requirements → for → carrying → task",
        "sentence": "The Wizard of Oz technique was used to identify requirements for carrying out the task.",
        "sentence_llm_dp_info": "\"Entity 1 ('Wizard of Oz technique') is the subject, depending on the verb 'used'. Entity 2 ('task') is the object of the preposition 'for', depending on 'for' in the phrase 'for carrying out the task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for carrying out the task'.\""
    },
    {
        "raw_sentence": "In the second half of the paper , we report a laboratory study using the Wizard of Oz technique to identify NL requirements for carrying out this task .",
        "ner_pair": [
            [
                "NL requirements",
                "OtherScientificTerm"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NL requirements') is the object of the verb 'identify', depending on 'identify' in the clause 'to identify NL requirements'. Entity 2 ('task') is the object of the preposition 'for', depending on 'carrying out' in the phrase 'for carrying out this task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of identifying the requirements for carrying out the task.\"",
        "sdp_path_text": "requirements → for → carrying → task",
        "sentence": "The study identified NL requirements for carrying out the task.",
        "sentence_llm_dp_info": "\"Entity 1 ('NL requirements') is the object, depending on the verb 'identified' with 'The study'. Entity 2 ('task') is the object of the preposition 'for', depending on 'for' in the phrase 'for carrying out the task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'identified' and the prepositional phrase 'for carrying out the task'.\""
    },
    {
        "raw_sentence": "We evaluate the demands that task dialogues collected using this technique , place upon a prototype Natural Language system .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "task dialogues",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the object of the preposition 'using', depending on 'collected'. Entity 2 ('task dialogues') is the subject, depending on 'evaluate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause 'task dialogues collected using this technique'.\"",
        "sdp_path_text": "technique → using → collected → dialogues",
        "sentence": "Task dialogues are collected using this technique.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the object, depending on 'using' with 'collected'. Entity 2 ('task dialogues') is the subject, depending on the verb 'are collected'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'are collected' and the preposition 'using'.\""
    },
    {
        "raw_sentence": "We evaluate the demands that task dialogues collected using this technique , place upon a prototype Natural Language system .",
        "ner_pair": [
            [
                "task dialogues",
                "Material"
            ],
            [
                "prototype Natural Language system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task dialogues') is the object of the relative clause, depending on 'evaluate' with 'We'. Entity 2 ('prototype Natural Language system') is the object of the preposition 'upon', depending on 'place' in the phrase 'place upon a prototype Natural Language system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'place' and the preposition 'upon'.\"",
        "sdp_path_text": "dialogues → collected → demands → place → upon → system",
        "sentence": "Task dialogues collected place demands upon a prototype Natural Language system.",
        "sentence_llm_dp_info": "\"Entity 1 ('task dialogues') is the subject, depending on the verb 'collected'. Entity 2 ('prototype Natural Language system') is the object of the preposition 'upon', depending on 'demands'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'place' and the preposition 'upon'.\""
    },
    {
        "raw_sentence": "We evaluate the demands that task dialogues collected using this technique , place upon a prototype Natural Language system .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "prototype Natural Language system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the object of the preposition 'using', depending on 'collected'. Entity 2 ('prototype Natural Language system') is the object of the preposition 'upon', depending on 'place'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the evaluation of demands placed on the system by dialogues collected using the technique.\"",
        "sdp_path_text": "technique → using → collected → demands → place → upon → system",
        "sentence": "The technique places demands upon the prototype Natural Language system.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'places'. Entity 2 ('prototype Natural Language system') is the object of the preposition 'upon', depending on 'demands'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'places' and the preposition 'upon'.\""
    },
    {
        "raw_sentence": "We identify three important requirements which arose from the task that we gave our subjects : operators specific to the task of database access , complex contextual reference and reference to the structure of the information source .",
        "ner_pair": [
            [
                "task",
                "Generic"
            ],
            [
                "database access",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task') is the antecedent, depending on 'arose' with 'requirements'. Entity 2 ('database access') is the object, depending on 'specific' with 'operators'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun phrase 'operators specific to the task of database access'.\"",
        "sdp_path_text": "task → from → arose → requirements → operators → specific → to → task → of → access",
        "sentence": "The task of database access requires specific operators.",
        "sentence_llm_dp_info": "\"Entity 1 ('task') is the subject, depending on the verb 'requires'. Entity 2 ('database access') is the object of the preposition 'of', depending on 'of' in the phrase 'of database access'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "We identify three important requirements which arose from the task that we gave our subjects : operators specific to the task of database access , complex contextual reference and reference to the structure of the information source .",
        "ner_pair": [
            [
                "task",
                "Generic"
            ],
            [
                "contextual reference",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task') is the antecedent of the relative clause, depending on 'arose' with 'which'. Entity 2 ('contextual reference') is part of a list of items, depending on 'identify' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence.\"",
        "sdp_path_text": "task → from → arose → requirements → operators → reference",
        "sentence": "The task required operators for database access and complex contextual reference.",
        "sentence_llm_dp_info": "\"Entity 1 ('task') is the subject, depending on the verb 'required'. Entity 2 ('contextual reference') is part of a compound noun, depending on 'complex' and is the object of the preposition 'for', which is part of the phrase 'for database access and complex contextual reference'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'required' and the prepositional phrase that follows it.\""
    },
    {
        "raw_sentence": "We identify three important requirements which arose from the task that we gave our subjects : operators specific to the task of database access , complex contextual reference and reference to the structure of the information source .",
        "ner_pair": [
            [
                "task",
                "Generic"
            ],
            [
                "database access",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task') is the antecedent of the relative clause, depending on 'arose' with 'which'. Entity 2 ('database access') is part of the object complement, depending on 'operators' with 'specific to'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the description of the requirements that arose from the task involving database access.\"",
        "sdp_path_text": "task → from → arose → requirements → operators → specific → to → task → of → access",
        "sentence": "The task of database access requires specific operators.",
        "sentence_llm_dp_info": "\"Entity 1 ('task') is the subject, depending on the verb 'requires'. Entity 2 ('database access') is the object of the preposition 'of', depending on 'of' in the phrase 'of database access'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "We identify three important requirements which arose from the task that we gave our subjects : operators specific to the task of database access , complex contextual reference and reference to the structure of the information source .",
        "ner_pair": [
            [
                "task",
                "Generic"
            ],
            [
                "contextual reference",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('task') is the object of the relative clause, depending on 'arose' with 'which'. Entity 2 ('contextual reference') is part of a list of objects, depending on 'operators' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the broader context of the requirements identified for the task.\"",
        "sdp_path_text": "task → from → arose → requirements → operators → reference",
        "sentence": "The task led to requirements including complex contextual reference.",
        "sentence_llm_dp_info": "\"Entity 1 ('task') is the subject, depending on 'led' as the verb. Entity 2 ('contextual reference') is part of the compound object of the preposition 'including', depending on 'including' in the phrase 'including complex contextual reference'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'led' and the prepositional phrase 'including complex contextual reference'.\""
    },
    {
        "raw_sentence": "We identify three important requirements which arose from the task that we gave our subjects : operators specific to the task of database access , complex contextual reference and reference to the structure of the information source .",
        "ner_pair": [
            [
                "database access",
                "Task"
            ],
            [
                "contextual reference",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('database access') is part of a noun phrase, depending on 'operators' as a modifier. Entity 2 ('contextual reference') is part of a noun phrase, depending on 'complex' as an adjective modifier. There is no direct dependency between Entity 1 and Entity 2; both are elements within a list of requirements identified in the sentence.\"",
        "sdp_path_text": "access → of → task → to → specific → operators → reference",
        "sentence": "Database access involves specific operators for complex contextual reference.",
        "sentence_llm_dp_info": "\"Entity 1 ('database access') is the subject, depending on the verb 'involves'. Entity 2 ('contextual reference') is part of the noun phrase that is the object of the preposition 'for', depending on 'for' in the phrase 'for complex contextual reference'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' and the prepositional phrase 'for complex contextual reference'.\""
    },
    {
        "raw_sentence": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers .",
        "ner_pair": [
            [
                "Bayesian Network",
                "Method"
            ],
            [
                "addressee identification in four-participants face-to-face meetings",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian Network') is part of a compound noun, depending on 'using' as one of the tools used. Entity 2 ('addressee identification in four-participants face-to-face meetings') is the object of the preposition 'on', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence structure, with Entity 1 being a tool used in the research and Entity 2 being the subject of the research results.\"",
        "sdp_path_text": "Network → classifiers → using → meetings → in",
        "sentence": "Bayesian Network classifiers are used for addressee identification in face-to-face meetings.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian Network') is part of a compound noun 'Bayesian Network classifiers', which is the subject, depending on the verb 'are used'. Entity 2 ('addressee identification in face-to-face meetings') is the object of the preposition 'for', depending on 'for' in the phrase 'for addressee identification in face-to-face meetings'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers .",
        "ner_pair": [
            [
                "Naive Bayes classifiers",
                "Method"
            ],
            [
                "addressee identification in four-participants face-to-face meetings",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Naive Bayes classifiers') is the object of the preposition 'using', depending on the verb 'present'. Entity 2 ('addressee identification in four-participants face-to-face meetings') is the object of the preposition 'on', depending on the verb 'present'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being presented.\"",
        "sdp_path_text": "classifiers → using → meetings → in",
        "sentence": "Naive Bayes classifiers are used for addressee identification in face-to-face meetings.",
        "sentence_llm_dp_info": "\"Entity 1 ('Naive Bayes classifiers') is the subject, depending on the verb 'used'. Entity 2 ('addressee identification in face-to-face meetings') is the object of the preposition 'for', depending on 'for' in the phrase 'for addressee identification in face-to-face meetings'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive Bayes classifiers .",
        "ner_pair": [
            [
                "Naive Bayes classifiers",
                "Method"
            ],
            [
                "Bayesian Network",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Naive Bayes classifiers') is the conjunct, depending on 'and' which connects it to 'Bayesian Network'. Entity 2 ('Bayesian Network') is also a conjunct, depending on 'and' which connects it to 'Naive Bayes classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the coordinating conjunction 'and'.\"",
        "sdp_path_text": "classifiers → Network",
        "sentence": "Naive Bayes classifiers and Bayesian Network are used for addressee identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('Naive Bayes classifiers') is part of a coordination, depending on 'and' with 'Bayesian Network'. Entity 2 ('Bayesian Network') is also part of a coordination, depending on 'and' with 'Naive Bayes classifiers'. Both entities together form the subject of the sentence, depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2; they are coordinated subjects.\""
    },
    {
        "raw_sentence": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features .",
        "ner_pair": [
            [
                "gaze",
                "OtherScientificTerm"
            ],
            [
                "addressee of a dialogue act",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('gaze') is one of the objects, depending on the preposition 'based on' with 'features'. Entity 2 ('addressee of a dialogue act') is the subject of the clause, depending on 'can be predicted'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the prediction of Entity 2 is based on features including Entity 1.\"",
        "sdp_path_text": "gaze → features → on → based → predicted → addressee",
        "sentence": "Gaze features help predict the addressee of a dialogue act.",
        "sentence_llm_dp_info": "\"Entity 1 ('gaze') is part of the compound noun 'gaze features', which is the subject, depending on the verb 'help'. Entity 2 ('addressee of a dialogue act') is the object, depending on 'predict' with 'help'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'help' and the verb 'predict'.\""
    },
    {
        "raw_sentence": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features .",
        "ner_pair": [
            [
                "utterance",
                "OtherScientificTerm"
            ],
            [
                "addressee of a dialogue act",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('utterance') is part of a list of features, depending on the conjunction 'and' with 'gaze' and 'conversational context features'. Entity 2 ('addressee of a dialogue act') is the subject complement, depending on 'predicted' in the phrase 'can be predicted'. There is no direct dependency between Entity 1 and Entity 2; both are related to the prediction process described in the sentence.\"",
        "sdp_path_text": "utterance → gaze → features → on → based → predicted → addressee",
        "sentence": "The addressee of a dialogue act can be predicted based on utterance and other features.",
        "sentence_llm_dp_info": "\"Entity 1 ('utterance') is part of a compound noun, depending on 'features' with the conjunction 'and'. Entity 2 ('addressee of a dialogue act') is the subject, depending on the verb 'can be predicted'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what can be predicted based on certain features.\""
    },
    {
        "raw_sentence": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features .",
        "ner_pair": [
            [
                "conversational context features",
                "OtherScientificTerm"
            ],
            [
                "addressee of a dialogue act",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational context features') is part of a list of items, depending on 'based on' with 'predicted'. Entity 2 ('addressee of a dialogue act') is the subject of the clause, depending on 'investigate' with 'how well...can be predicted'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate involving prediction based on various features.\"",
        "sdp_path_text": "features → on → based → predicted → addressee",
        "sentence": "Conversational context features are used to predict the addressee of a dialogue act.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational context features') is the subject, depending on the verb 'used'. Entity 2 ('addressee of a dialogue act') is the object, depending on 'predict' with 'to predict the addressee of a dialogue act'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'predict' which indicates that the features are used for predicting the addressee.\""
    },
    {
        "raw_sentence": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features .",
        "ner_pair": [
            [
                "gaze",
                "OtherScientificTerm"
            ],
            [
                "utterance",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('gaze') is the object of the preposition 'based on', depending on the preposition 'based'. Entity 2 ('utterance') is also the object of the preposition 'based on', depending on the preposition 'based'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a list of items that are objects of the same preposition 'based on'.\"",
        "sdp_path_text": "gaze → utterance",
        "sentence": "Gaze and utterance are used to predict the addressee of a dialogue act.",
        "sentence_llm_dp_info": "\"Entity 1 ('gaze') is a conjunct, depending on 'and' which connects it with 'utterance'. Entity 2 ('utterance') is also a conjunct, depending on 'and' which connects it back to 'gaze'. Both 'gaze' and 'utterance' are part of the compound subject of the sentence, depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features .",
        "ner_pair": [
            [
                "gaze",
                "OtherScientificTerm"
            ],
            [
                "conversational context features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('gaze') is part of a coordination, depending on the conjunction 'and' with 'utterance'. Entity 2 ('conversational context features') is also part of the same coordination, depending on the conjunction 'and' with 'utterance'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the list of features used for prediction.\"",
        "sdp_path_text": "gaze → features",
        "sentence": "Gaze and conversational context features are used to predict the addressee of a dialogue act.",
        "sentence_llm_dp_info": "\"Entity 1 ('gaze') is part of a coordination, depending on the conjunction 'and' with 'conversational context features'. Entity 2 ('conversational context features') is also part of the coordination, depending on the conjunction 'and' with 'gaze'. Both together serve as the subject of the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated subjects in the sentence.\""
    },
    {
        "raw_sentence": "First , we investigate how well the addressee of a dialogue act can be predicted based on gaze , utterance and conversational context features .",
        "ner_pair": [
            [
                "utterance",
                "OtherScientificTerm"
            ],
            [
                "conversational context features",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('utterance') is part of a coordination, depending on the conjunction 'and' with 'gaze' and 'conversational context features'. Entity 2 ('conversational context features') is also part of the same coordination, depending on the conjunction 'and' with 'gaze' and 'utterance'. There is no direct dependency between Entity 1 and Entity 2; they are both elements in a list of features used to predict the addressee of a dialogue act.\"",
        "sdp_path_text": "utterance → gaze → features",
        "sentence": "Utterance and conversational context features are used to predict the addressee of a dialogue act.",
        "sentence_llm_dp_info": "\"Entity 1 ('utterance') is part of a coordination, depending on 'and' with 'conversational context features'. Entity 2 ('conversational context features') is also part of the coordination, depending on 'are used' as the subject. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated subjects in the sentence.\""
    },
    {
        "raw_sentence": "Then , we explore whether information about meeting context can aid classifiers ' performances .",
        "ner_pair": [
            [
                "meeting context",
                "OtherScientificTerm"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('meeting context') is the object of the preposition 'about', depending on 'information'. Entity 2 ('classifiers') is the possessor, depending on 'performances' with the possessive form 'classifiers'’. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verb 'aid'.\"",
        "sdp_path_text": "meeting → about → information → aid → performances → classifiers",
        "sentence": "Information about meeting context can aid classifiers' performances.",
        "sentence_llm_dp_info": "\"Entity 1 ('meeting context') is the object of the preposition 'about', depending on 'information'. Entity 2 ('classifiers') is the possessive noun, depending on 'performances'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'information about meeting context' is the subject and 'can aid classifiers' performances' is the predicate.\""
    },
    {
        "raw_sentence": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information .",
        "ner_pair": [
            [
                "conversational context",
                "OtherScientificTerm"
            ],
            [
                "classifiers",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational context') is part of the subject complement, depending on 'combined' with 'utterance features'. Entity 2 ('classifiers') is the subject, depending on 'perform' with 'the best'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the condition described in the clause 'when conversational context and utterance features are combined with speaker's gaze information'.\"",
        "sdp_path_text": "context → combined → perform → classifiers",
        "sentence": "Classifiers perform best when conversational context is combined.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational context') is the subject complement, depending on 'combined' with 'is'. Entity 2 ('classifiers') is the subject, depending on 'perform' with 'perform best'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where the performance of classifiers is improved by combining conversational context.\""
    },
    {
        "raw_sentence": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information .",
        "ner_pair": [
            [
                "utterance features",
                "OtherScientificTerm"
            ],
            [
                "classifiers",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('utterance features') is part of the conjunction, depending on 'combined' with 'conversational context'. Entity 2 ('classifiers') is the subject, depending on the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the conditions under which the classifiers perform the best.\"",
        "sdp_path_text": "features → context → combined → perform → classifiers",
        "sentence": "Classifiers perform best when utterance features are combined with conversational context.",
        "sentence_llm_dp_info": "\"Entity 1 ('utterance features') is the subject complement, depending on 'are' in the clause 'features are combined'. Entity 2 ('classifiers') is the subject, depending on 'perform' in the main clause. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the performance of classifiers is influenced by the combination of utterance features and conversational context.\""
    },
    {
        "raw_sentence": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information .",
        "ner_pair": [
            [
                "speaker 's gaze information",
                "OtherScientificTerm"
            ],
            [
                "classifiers",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speaker's gaze information') is the object, depending on the preposition 'with' which is part of the prepositional phrase 'with speaker's gaze information'. Entity 2 ('classifiers') is the subject, depending on the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combined' within the clause 'are combined with speaker's gaze information'.\"",
        "sdp_path_text": "information → with → combined → perform → classifiers",
        "sentence": "Classifiers perform best when combined with speaker's gaze information.",
        "sentence_llm_dp_info": "\"Entity 1 ('speaker's gaze information') is the object of the preposition 'with', depending on 'combined'. Entity 2 ('classifiers') is the subject, depending on the verb 'perform'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combined' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information .",
        "ner_pair": [
            [
                "conversational context",
                "OtherScientificTerm"
            ],
            [
                "utterance features",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational context') is part of a conjunction, depending on 'combined' with 'and'. Entity 2 ('utterance features') is also part of the same conjunction, depending on 'combined' with 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a larger conjunctive structure that is the object of 'combined'.\"",
        "sdp_path_text": "context → features",
        "sentence": "Conversational context and utterance features are combined.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational context') is the subject, depending on the verb 'combined'. Entity 2 ('utterance features') is also a subject, depending on the same verb 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of the same verb 'combined'.\""
    },
    {
        "raw_sentence": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information .",
        "ner_pair": [
            [
                "conversational context",
                "OtherScientificTerm"
            ],
            [
                "speaker 's gaze information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('conversational context') is part of a coordinated subject, depending on 'are' with the verb 'combined'. Entity 2 ('speaker's gaze information') is also part of the coordinated subject, depending on 'are' with the verb 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of the coordination that forms the subject of the clause 'are combined'.\"",
        "sdp_path_text": "context → combined → with → information",
        "sentence": "Conversational context is combined with speaker's gaze information.",
        "sentence_llm_dp_info": "\"Entity 1 ('conversational context') is the subject, depending on the verb 'combined'. Entity 2 ('speaker's gaze information') is the object, depending on 'with' in the phrase 'with speaker's gaze information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Both classifiers perform the best when conversational context and utterance features are combined with speaker 's gaze information .",
        "ner_pair": [
            [
                "speaker 's gaze information",
                "OtherScientificTerm"
            ],
            [
                "utterance features",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speaker's gaze information') is the object of the preposition 'with', depending on 'combined'. Entity 2 ('utterance features') is the subject, depending on 'are' in the clause 'utterance features are combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and are connected through the verb 'combined'.\"",
        "sdp_path_text": "information → with → combined → context → features",
        "sentence": "Speaker's gaze information is combined with utterance features.",
        "sentence_llm_dp_info": "\"Entity 1 ('speaker's gaze information') is the subject, depending on the verb 'combined'. Entity 2 ('utterance features') is the object, also depending on the verb 'combined'. There is a direct dependency between Entity 1 and Entity 2, as both are directly involved in the action described by the verb 'combined'.\""
    },
    {
        "raw_sentence": "The classifiers show little gain from information about meeting context .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "meeting context",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the subject, depending on the verb 'show'. Entity 2 ('meeting context') is the object of the preposition 'from', depending on 'gain' in the phrase 'from information about meeting context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'show' and the prepositional phrase 'from information about meeting context'.\"",
        "sdp_path_text": "classifiers → show → gain → from → information → about → context",
        "sentence": "Classifiers show little gain from information about meeting context.",
        "sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the subject, depending on the verb 'show'. Entity 2 ('meeting context') is the object of the preposition 'about', depending on 'from' in the phrase 'from information about meeting context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from information about meeting context'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "class-oriented framework",
                "Method"
            ],
            [
                "compositional classes of paraphrases",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the object of the preposition 'for', depending on 'examined' with 'we have'. Entity 2 ('compositional classes of paraphrases') is the object of the preposition 'of', depending on 'analysis' in the phrase 'deep analysis of compositional classes of paraphrases'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the topic of paraphrases within the context of the sentence.\"",
        "sdp_path_text": "framework → examined → Towards → analysis → of → classes",
        "sentence": "A class-oriented framework was examined for the deep analysis of compositional classes of paraphrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the subject, depending on the verb 'examined'. Entity 2 ('compositional classes of paraphrases') is the object of the preposition 'of', depending on 'analysis' in the phrase 'analysis of compositional classes of paraphrases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'examined' and the prepositional phrase 'for the deep analysis of...'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "compositional classes of paraphrases",
                "Task"
            ],
            [
                "paraphrase examples",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the object of the preposition 'of', depending on 'analysis' in the phrase 'deep analysis of compositional classes of paraphrases'. Entity 2 ('paraphrase examples') is the object, depending on 'collecting' in the phrase 'for collecting paraphrase examples'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of paraphrase analysis and collection.\"",
        "sdp_path_text": "classes → of → analysis → Towards → examined → framework → for → collecting → examples",
        "sentence": "Compositional classes of paraphrases have been examined in a framework for collecting paraphrase examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the subject, depending on the verb 'examined'. Entity 2 ('paraphrase examples') is the object, depending on 'collecting' within the prepositional phrase 'for collecting paraphrase examples'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence structure.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "compositional classes of paraphrases",
                "Task"
            ],
            [
                "sentential paraphrases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the object of the preposition 'of', depending on 'analysis'. Entity 2 ('sentential paraphrases') is the subject, depending on 'are collected'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the broader context of paraphrase analysis and collection described in the sentence.\"",
        "sdp_path_text": "classes → of → analysis → Towards → examined → framework → collected → paraphrases",
        "sentence": "Compositional classes of paraphrases have been examined in a framework where sentential paraphrases are collected.",
        "sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the subject, depending on the verb 'have been examined'. Entity 2 ('sentential paraphrases') is the subject complement, depending on 'are' within the relative clause 'where sentential paraphrases are collected'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same semantic context, with Entity 2 being described in a framework that examines Entity 1.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "compositional classes of paraphrases",
                "Task"
            ],
            [
                "automatic candidate generation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the object of the preposition 'of', depending on 'analysis'. Entity 2 ('automatic candidate generation') is part of a coordination, depending on 'by' in the phrase 'by means of automatic candidate generation and manual judgement'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger structure of the sentence but do not directly interact syntactically.\"",
        "sdp_path_text": "classes → of → analysis → Towards → examined → framework → collected → by → means → of → generation",
        "sentence": "Compositional classes of paraphrases are analyzed using automatic candidate generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the subject, depending on the verb 'analyzed'. Entity 2 ('automatic candidate generation') is the object of the preposition 'using', depending on 'using' in the phrase 'using automatic candidate generation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'using'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "compositional classes of paraphrases",
                "Task"
            ],
            [
                "manual judgement",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the object of the preposition 'of', depending on 'analysis' in the phrase 'analysis of compositional classes of paraphrases'. Entity 2 ('manual judgement') is part of a coordination, depending on 'by' in the phrase 'by means of automatic candidate generation and manual judgement'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "classes → of → analysis → Towards → examined → framework → collected → by → means → of → generation → judgement",
        "sentence": "Compositional classes of paraphrases are analyzed through a framework involving automatic candidate generation and manual judgement.",
        "sentence_llm_dp_info": "\"Entity 1 ('compositional classes of paraphrases') is the subject, depending on the verb 'analyzed'. Entity 2 ('manual judgement') is part of the compound object, depending on 'involving' in the phrase 'involving automatic candidate generation and manual judgement'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "class-oriented framework",
                "Method"
            ],
            [
                "paraphrase examples",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the object of the preposition 'for', depending on 'examined' with 'we have examined a class-oriented framework'. Entity 2 ('paraphrase examples') is the object of the preposition 'for', depending on 'collecting' in the phrase 'for collecting paraphrase examples'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the purpose and method of examination.\"",
        "sdp_path_text": "framework → for → collecting → examples",
        "sentence": "A class-oriented framework is used for collecting paraphrase examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the subject, depending on the verb 'used'. Entity 2 ('paraphrase examples') is the object, depending on the verb 'collecting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used for collecting'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "class-oriented framework",
                "Method"
            ],
            [
                "sentential paraphrases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the object of the preposition 'for', depending on 'examined' with 'we have'. Entity 2 ('sentential paraphrases') is the subject of the clause, depending on 'are collected' within the relative clause 'which sentential paraphrases are collected'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same larger context related to the examination and collection process of paraphrases.\"",
        "sdp_path_text": "framework → collected → paraphrases",
        "sentence": "A class-oriented framework collects sentential paraphrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the subject, depending on the verb 'collects'. Entity 2 ('sentential paraphrases') is the object, depending on 'collects' with 'class-oriented framework'. There is a direct dependency between Entity 1 and Entity 2, where 'class-oriented framework' is the agent performing the action of collecting 'sentential paraphrases'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "class-oriented framework",
                "Method"
            ],
            [
                "automatic candidate generation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the object of the preposition 'for', depending on 'examined'. Entity 2 ('automatic candidate generation') is part of a compound object, depending on 'by means of'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process of collecting paraphrase examples.\"",
        "sdp_path_text": "framework → collected → by → means → of → generation",
        "sentence": "A class-oriented framework collects paraphrase examples by means of automatic candidate generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the subject, depending on the verb 'collects'. Entity 2 ('automatic candidate generation') is the object of the preposition 'by', depending on 'by' in the phrase 'by means of automatic candidate generation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'by means of'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "class-oriented framework",
                "Method"
            ],
            [
                "manual judgement",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the object of the preposition 'for', depending on 'examined' with 'we have'. Entity 2 ('manual judgement') is part of a compound noun, depending on 'means' in the phrase 'by means of automatic candidate generation and manual judgement'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the methods used in the examination.\"",
        "sdp_path_text": "framework → collected → by → means → of → generation → judgement",
        "sentence": "A class-oriented framework collects paraphrase examples by means of automatic candidate generation and manual judgement.",
        "sentence_llm_dp_info": "\"Entity 1 ('class-oriented framework') is the subject, depending on the verb 'collects'. Entity 2 ('manual judgement') is part of a compound object, depending on 'and' which connects it with 'automatic candidate generation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'collects' and the prepositional phrase 'by means of'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "paraphrase examples",
                "Material"
            ],
            [
                "sentential paraphrases",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase examples') is the object, depending on 'collecting' with 'framework'. Entity 2 ('sentential paraphrases') is the subject, depending on 'are collected' within the clause describing the collection method. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same context related to the collection process of paraphrases.\"",
        "sdp_path_text": "examples → collecting → for → framework → collected → paraphrases",
        "sentence": "Paraphrase examples are collected as sentential paraphrases within a class-oriented framework.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase examples') is the subject, depending on the verb 'collected'. Entity 2 ('sentential paraphrases') is the object of the preposition 'as', depending on 'as' in the phrase 'as sentential paraphrases'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'as' which indicates that Entity 1 is collected in the form of Entity 2.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "paraphrase examples",
                "Material"
            ],
            [
                "automatic candidate generation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase examples') is the object, depending on the verb 'collecting'. Entity 2 ('automatic candidate generation') is part of a prepositional phrase, depending on 'by means of' in the clause 'by means of automatic candidate generation and manual judgement'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the method used to collect paraphrase examples.\"",
        "sdp_path_text": "examples → collecting → for → framework → collected → by → means → of → generation",
        "sentence": "Paraphrase examples are collected by means of automatic candidate generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase examples') is the subject, depending on the verb 'collected'. Entity 2 ('automatic candidate generation') is the object of the preposition 'by', depending on 'by' in the phrase 'by means of automatic candidate generation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'by means of'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "paraphrase examples",
                "Material"
            ],
            [
                "manual judgement",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase examples') is the object, depending on the preposition 'for' in the phrase 'for collecting paraphrase examples'. Entity 2 ('manual judgement') is part of a coordination, depending on the conjunction 'and' with 'automatic candidate generation'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "examples → collecting → for → framework → collected → by → means → of → generation → judgement",
        "sentence": "Paraphrase examples are collected by means of automatic candidate generation and manual judgement.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase examples') is the subject, depending on the verb 'collected'. Entity 2 ('manual judgement') is part of a compound noun, depending on 'and' which connects it to 'automatic candidate generation'. There is no direct dependency between Entity 1 and Entity 2; both are related to the process described by the verb 'collected'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "automatic candidate generation",
                "Method"
            ],
            [
                "sentential paraphrases",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatic candidate generation') is part of the instrumental clause, depending on 'by means of' with 'collected'. Entity 2 ('sentential paraphrases') is the subject of the relative clause, depending on 'are collected' with 'collected'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the verb 'collected'.\"",
        "sdp_path_text": "generation → of → means → by → collected → paraphrases",
        "sentence": "Sentential paraphrases are collected by means of automatic candidate generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatic candidate generation') is the object of the preposition 'by', depending on 'collected'. Entity 2 ('sentential paraphrases') is the subject, depending on the verb 'are collected'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' which indicates the method used to collect Entity 2.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "manual judgement",
                "Method"
            ],
            [
                "sentential paraphrases",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manual judgement') is part of a coordination, depending on 'and' with 'automatic candidate generation'. Entity 2 ('sentential paraphrases') is the subject, depending on 'collected' with 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the clause describing the method of collection for paraphrase examples.\"",
        "sdp_path_text": "judgement → generation → of → means → by → collected → paraphrases",
        "sentence": "Sentential paraphrases are collected by means of manual judgement.",
        "sentence_llm_dp_info": "\"Entity 1 ('manual judgement') is the object of the preposition 'by', depending on 'by' in the phrase 'by means of manual judgement'. Entity 2 ('sentential paraphrases') is the subject, depending on the verb 'collected'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'by' and the verb 'collected'.\""
    },
    {
        "raw_sentence": "Towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement .",
        "ner_pair": [
            [
                "automatic candidate generation",
                "Method"
            ],
            [
                "manual judgement",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatic candidate generation') is part of a compound noun, depending on 'means' with the preposition 'of'. Entity 2 ('manual judgement') is also part of a compound noun, depending on 'means' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of the list connected through the conjunction 'and' under the prepositional phrase 'by means of'.\"",
        "sdp_path_text": "generation → judgement",
        "sentence": "Sentential paraphrases are collected using automatic candidate generation and manual judgement.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatic candidate generation') is the object of the preposition 'using', depending on 'collected'. Entity 2 ('manual judgement') is also the object of the preposition 'using', depending on 'collected'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the prepositional phrase 'using automatic candidate generation and manual judgement' that modifies the verb 'collected'.\""
    },
    {
        "raw_sentence": "The purpose of this research is to test the efficacy of applying automated evaluation techniques , originally devised for the evaluation of human language learners , to the output of machine translation -LRB- MT -RRB- systems .",
        "ner_pair": [
            [
                "automated evaluation techniques",
                "Method"
            ],
            [
                "evaluation of human language learners",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automated evaluation techniques') is the object of the preposition 'of', depending on 'efficacy'. Entity 2 ('evaluation of human language learners') is the object of the preposition 'for', depending on 'devised'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence, with Entity 1 being the subject of the testing and Entity 2 being the original context for which these techniques were developed.\"",
        "sdp_path_text": "techniques → devised → for → evaluation",
        "sentence": "Automated evaluation techniques were devised for the evaluation of human language learners.",
        "sentence_llm_dp_info": "\"Entity 1 ('automated evaluation techniques') is the subject, depending on the passive verb 'were devised'. Entity 2 ('evaluation of human language learners') is the object of the preposition 'for', depending on 'for' in the phrase 'for the evaluation of human language learners'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "The purpose of this research is to test the efficacy of applying automated evaluation techniques , originally devised for the evaluation of human language learners , to the output of machine translation -LRB- MT -RRB- systems .",
        "ner_pair": [
            [
                "automated evaluation techniques",
                "Method"
            ],
            [
                "machine translation -LRB- MT -RRB- systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automated evaluation techniques') is the object of the preposition 'of', depending on 'efficacy'. Entity 2 ('machine translation -LRB- MT -RRB- systems') is the object of the preposition 'to', depending on 'to' in the phrase 'to the output of machine translation -LRB- MT -RRB- systems'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and both are related to the main verb 'test' through the structure of the sentence.\"",
        "sdp_path_text": "techniques → applying → to → output → of → systems",
        "sentence": "Automated evaluation techniques are applied to the output of machine translation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('automated evaluation techniques') is the subject, depending on the verb 'are applied'. Entity 2 ('machine translation systems') is the object of the preposition 'of', depending on 'output' in the phrase 'output of machine translation systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are applied' and the prepositional phrase 'to the output of'.\""
    },
    {
        "raw_sentence": "The purpose of this research is to test the efficacy of applying automated evaluation techniques , originally devised for the evaluation of human language learners , to the output of machine translation -LRB- MT -RRB- systems .",
        "ner_pair": [
            [
                "evaluation of human language learners",
                "Task"
            ],
            [
                "machine translation -LRB- MT -RRB- systems",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation of human language learners') is the object of the preposition 'for', depending on 'devised'. Entity 2 ('machine translation -LRB- MT -RRB- systems') is the object of the preposition 'to', depending on 'applying'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence, which involves applying techniques originally devised for one (Entity 1) to another (Entity 2).\"",
        "sdp_path_text": "evaluation → for → devised → techniques → applying → to → output → of → systems",
        "sentence": "Automated evaluation techniques devised for human language learners are applied to machine translation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation of human language learners') is the object of the verb 'devised', depending on 'techniques'. Entity 2 ('machine translation (MT) systems') is the object of the verb 'applied', depending on 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'techniques' devised for one are applied to the other.\""
    },
    {
        "raw_sentence": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems .",
        "ner_pair": [
            [
                "evaluation techniques",
                "Generic"
            ],
            [
                "human language learning process",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation techniques') is the subject complement, depending on 'provide' with 'will provide'. Entity 2 ('human language learning process') is the object of the preposition 'about', depending on 'about' in the phrase 'about both the human language learning process'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provide' and the preposition 'about'.\"",
        "sdp_path_text": "techniques → provide → information → about → process",
        "sentence": "Evaluation techniques provide information about the human language learning process.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation techniques') is the subject, depending on the verb 'provide'. Entity 2 ('human language learning process') is the object of the preposition 'about', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provide' and the preposition 'about'.\""
    },
    {
        "raw_sentence": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems .",
        "ner_pair": [
            [
                "evaluation techniques",
                "Generic"
            ],
            [
                "translation process",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation techniques') is the subject complement, depending on 'provide' with 'will provide'. Entity 2 ('translation process') is part of the compound object of the preposition 'about', depending on 'about' in the phrase 'about both the human language learning process, the translation process and the development of machine translation systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provide' and the preposition 'about'.\"",
        "sdp_path_text": "techniques → provide → information → about → process → process",
        "sentence": "Evaluation techniques provide information about the translation process.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation techniques') is the subject, depending on the verb 'provide'. Entity 2 ('translation process') is the object of the preposition 'about', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provide' and the preposition 'about'.\""
    },
    {
        "raw_sentence": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems .",
        "ner_pair": [
            [
                "evaluation techniques",
                "Generic"
            ],
            [
                "machine translation systems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation techniques') is the subject, depending on 'will provide' with 'techniques'. Entity 2 ('machine translation systems') is part of the compound object, depending on 'of' in the phrase 'of machine translation systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'will provide' and the preposition 'of'.\"",
        "sdp_path_text": "techniques → provide → information → about → process → process → development → of → systems",
        "sentence": "Evaluation techniques will provide information about the development of machine translation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation techniques') is the subject, depending on the verb 'will provide'. Entity 2 ('machine translation systems') is the object of the preposition 'of', depending on 'development'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provide' and the prepositional phrase 'about the development of'.\""
    },
    {
        "raw_sentence": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems .",
        "ner_pair": [
            [
                "human language learning process",
                "Task"
            ],
            [
                "translation process",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('human language learning process') is part of the object complement, depending on the preposition 'about' which modifies 'information'. Entity 2 ('translation process') is also part of the object complement, depending on the same preposition 'about'. There is no direct dependency between Entity 1 and Entity 2; both are connected to the preposition 'about' which is part of the phrase 'information about'.\"",
        "sdp_path_text": "process → process",
        "sentence": "Evaluation techniques provide information about the human language learning process and the translation process.",
        "sentence_llm_dp_info": "\"Entity 1 ('human language learning process') is the object of the preposition 'about', depending on 'information'. Entity 2 ('translation process') is also the object of the preposition 'about', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but both are connected to 'information' through the preposition 'about'.\""
    },
    {
        "raw_sentence": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems .",
        "ner_pair": [
            [
                "human language learning process",
                "Task"
            ],
            [
                "machine translation systems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('human language learning process') is part of the object complement, depending on 'about' with 'information'. Entity 2 ('machine translation systems') is also part of the object complement, depending on 'of' with 'development'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items described by the information provided.\"",
        "sdp_path_text": "process → process → development → of → systems",
        "sentence": "These evaluation techniques will provide information about the human language learning process and the development of machine translation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('human language learning process') is the object of the preposition 'about', depending on 'information'. Entity 2 ('machine translation systems') is the object of the preposition 'of', depending on 'development'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'provide' through their respective prepositional phrases.\""
    },
    {
        "raw_sentence": "We believe that these evaluation techniques will provide information about both the human language learning process , the translation process and the development of machine translation systems .",
        "ner_pair": [
            [
                "translation process",
                "Task"
            ],
            [
                "machine translation systems",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('translation process') is the object of the preposition 'about', depending on 'information'. Entity 2 ('machine translation systems') is also the object of the preposition 'about', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'about' in the context of providing information.\"",
        "sdp_path_text": "process → development → of → systems",
        "sentence": "These evaluation techniques will provide information about the development of machine translation systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('translation process') is not directly mentioned in the sentence, so it does not have any dependencies within this context. Entity 2 ('machine translation systems') is the object of the preposition 'of', depending on 'development'. There is no direct dependency between Entity 1 and Entity 2, as Entity 1 is not present in the sentence.\"\n\nHowever, if you intended to analyze \"development\" as Entity 1 and \"machine translation systems\" as Entity 2, the answer would be:\n\n\"Entity 1 ('development') is the object of the preposition 'about', depending on 'information'. Entity 2 ('machine translation systems') is the object of the preposition 'of', depending on 'development'. There is a direct dependency between Entity 1 and Entity 2, as 'machine translation systems' modifies 'development'.\""
    },
    {
        "raw_sentence": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words .",
        "ner_pair": [
            [
                "language learning",
                "Task"
            ],
            [
                "assessors",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('language learning') is part of the noun phrase 'A language learning experiment', acting as a modifier to 'experiment', depending on 'experiment'. Entity 2 ('assessors') is the subject of the clause, depending on 'can' which is the modal verb of the main predicate 'differentiate'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'assessors' are the subjects performing an action related to the context set by the 'language learning experiment'.\"",
        "sdp_path_text": "learning → experiment → showed → differentiate → assessors",
        "sentence": "A language learning experiment showed that assessors can differentiate.",
        "sentence_llm_dp_info": "\"Entity 1 ('language learning') is part of the noun phrase 'A language learning experiment', acting as the modifier of 'experiment', depending on 'experiment'. Entity 2 ('assessors') is the subject of the clause 'assessors can differentiate', depending on the verb 'can differentiate'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words .",
        "ner_pair": [
            [
                "language learning",
                "Task"
            ],
            [
                "non-native language essays",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('language learning') is part of the compound noun 'language learning experiment', which is the subject, depending on the verb 'showed'. Entity 2 ('non-native language essays') is the object of the preposition 'from', depending on 'differentiate'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where the experiment's results involve differentiating between types of essays.\"",
        "sdp_path_text": "learning → experiment → showed → differentiate → essays",
        "sentence": "A language learning experiment showed that assessors can differentiate non-native language essays.",
        "sentence_llm_dp_info": "\"Entity 1 ('language learning') is part of a compound noun, depending on 'experiment' as a modifier. Entity 2 ('non-native language essays') is the object, depending on 'differentiate' with 'assessors'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the context provided by the sentence.\""
    },
    {
        "raw_sentence": "A language learning experiment showed that assessors can differentiate native from non-native language essays in less than 100 words .",
        "ner_pair": [
            [
                "assessors",
                "Generic"
            ],
            [
                "non-native language essays",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('assessors') is the subject, depending on the verb 'can differentiate'. Entity 2 ('non-native language essays') is the object, depending on 'differentiate' with 'assessors'. There is a direct dependency between Entity 1 and Entity 2, as 'non-native language essays' is one of the objects being differentiated by 'assessors'.\"",
        "sdp_path_text": "assessors → differentiate → essays",
        "sentence": "Assessors can differentiate non-native language essays.",
        "sentence_llm_dp_info": "\"Entity 1 ('assessors') is the subject, depending on the verb 'can differentiate'. Entity 2 ('non-native language essays') is the object, depending on 'differentiate' with 'assessors'. There is a direct dependency between Entity 1 and Entity 2, as 'assessors' are the ones performing the action of differentiating 'non-native language essays'.\""
    },
    {
        "raw_sentence": "Some of the extracts were expert human translations , others were machine translation outputs .",
        "ner_pair": [
            [
                "machine translation outputs",
                "OtherScientificTerm"
            ],
            [
                "expert human translations",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine translation outputs') is the subject, depending on the verb 'were'. Entity 2 ('expert human translations') is also the subject, depending on the verb 'were'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of the same clause, linked by the coordinating conjunction 'and'.\"",
        "sdp_path_text": "outputs → were → were → translations",
        "sentence": "{\n  \"Simplified sentence\": \"Machine translation outputs were expert human translations.\"\n} \n\nHowever, this simplification might not accurately reflect the original meaning since the original sentence indicates a contrast between the two types of translations. A more accurate simplification would be:\n\n{\n  \"Simplified sentence\": \"Some extracts were machine translation outputs, others were expert human translations.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('machine translation outputs') is the subject complement, depending on the copula 'were'. Entity 2 ('expert human translations') is also a subject complement, depending on the copula 'were'. There is no direct dependency between Entity 1 and Entity 2; both are independently linked to the copula 'were'.\""
    },
    {
        "raw_sentence": "The subjects were given three minutes per extract to determine whether they believed the sample output to be an expert human translation or a machine translation .",
        "ner_pair": [
            [
                "expert human translation",
                "OtherScientificTerm"
            ],
            [
                "machine translation",
                "OtherScientificTerm"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expert human translation') is the object of the clause 'the sample output to be an expert human translation', depending on 'be' as part of the infinitive construction. Entity 2 ('machine translation') is also the object of the clause 'the sample output to be a machine translation', depending on 'be' as part of the infinitive construction. There is no direct dependency between Entity 1 and Entity 2; both are potential outcomes of the subjects' determination.\"",
        "sdp_path_text": "translation → translation",
        "sentence": "The subjects determined whether the sample output was an expert human translation or a machine translation.",
        "sentence_llm_dp_info": "\"Entity 1 ('expert human translation') is the complement of the verb 'was', depending on 'was' in the phrase 'was an expert human translation'. Entity 2 ('machine translation') is also the complement of the verb 'was', depending on 'was' in the phrase 'was a machine translation'. There is no direct dependency between Entity 1 and Entity 2; both are complements of the same verb 'was'.\""
    },
    {
        "raw_sentence": "This paper presents a machine learning approach to bare slice disambiguation in dialogue .",
        "ner_pair": [
            [
                "machine learning approach",
                "Method"
            ],
            [
                "bare slice disambiguation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning approach') is the object, depending on 'presents' with 'This paper'. Entity 2 ('bare slice disambiguation') is the object of the preposition 'to', depending on 'to' in the phrase 'to bare slice disambiguation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\"",
        "sdp_path_text": "approach → to → disambiguation",
        "sentence": "This paper presents a machine learning approach to bare slice disambiguation.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning approach') is the subject complement, depending on 'presents' with 'This paper'. Entity 2 ('bare slice disambiguation') is the object of the preposition 'to', depending on 'to' in the phrase 'to bare slice disambiguation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "This paper presents a machine learning approach to bare slice disambiguation in dialogue .",
        "ner_pair": [
            [
                "machine learning approach",
                "Method"
            ],
            [
                "dialogue",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning approach') is the object of the verb 'presents', depending on 'presents' in the clause 'presents a machine learning approach'. Entity 2 ('dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence.\"",
        "sdp_path_text": "approach → to → disambiguation → in → dialogue",
        "sentence": "A machine learning approach is presented for disambiguation in dialogue.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning approach') is the subject, depending on the verb 'presented'. Entity 2 ('dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in dialogue'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "This paper presents a machine learning approach to bare slice disambiguation in dialogue .",
        "ner_pair": [
            [
                "dialogue",
                "Material"
            ],
            [
                "bare slice disambiguation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in dialogue'. Entity 2 ('bare slice disambiguation') is the object of the preposition 'to', depending on 'to' in the phrase 'to bare slice disambiguation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different parts of the main clause.\"",
        "sdp_path_text": "dialogue → in → disambiguation",
        "sentence": "This paper presents an approach to bare slice disambiguation in dialogue.",
        "sentence_llm_dp_info": "\"Entity 1 ('dialogue') is the object of the preposition 'in', depending on 'in' in the phrase 'in dialogue'. Entity 2 ('bare slice disambiguation') is the object of the preposition 'to', depending on 'to' in the phrase 'to bare slice disambiguation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying different parts of the sentence.\""
    },
    {
        "raw_sentence": "We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses .",
        "ner_pair": [
            [
                "corpus-based sample",
                "Material"
            ],
            [
                "heuristic principles",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpus-based sample') is the object of the preposition 'from', depending on 'extract' with 'We'. Entity 2 ('heuristic principles') is the direct object, depending on 'extract' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'extract'.\"",
        "sdp_path_text": "sample → from → extract → set → of → principles",
        "sentence": "We extract heuristic principles from a corpus-based sample.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpus-based sample') is the object, depending on the preposition 'from' which modifies the verb 'extract'. Entity 2 ('heuristic principles') is the direct object, depending on the verb 'extract'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause where 'heuristic principles' are extracted from the 'corpus-based sample'.\""
    },
    {
        "raw_sentence": "We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses .",
        "ner_pair": [
            [
                "probabilistic Horn clauses",
                "OtherScientificTerm"
            ],
            [
                "heuristic principles",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('probabilistic Horn clauses') is the object of the verb 'formulate', depending on the verb 'formulate' with 'them'. Entity 2 ('heuristic principles') is the object of the verb 'extract', depending on the verb 'extract' with 'a set of'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the sequence of actions described in the sentence, where 'heuristic principles' are extracted and then formulated as 'probabilistic Horn clauses'.\"",
        "sdp_path_text": "clauses → as → formulate → extract → set → of → principles",
        "sentence": "We extract heuristic principles and formulate them as probabilistic Horn clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('probabilistic Horn clauses') is the object, depending on 'formulate' with 'them'. Entity 2 ('heuristic principles') is the object, depending on 'extract' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of actions performed by the subject 'We'.\""
    },
    {
        "raw_sentence": "We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses .",
        "ner_pair": [
            [
                "corpus-based sample",
                "Material"
            ],
            [
                "probabilistic Horn clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpus-based sample') is the object of the preposition 'from', depending on 'extract' with 'We'. Entity 2 ('probabilistic Horn clauses') is the object of the preposition 'as', depending on 'formulate' with 'them'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'extract' and 'formulate' which describe actions performed on these entities.\"",
        "sdp_path_text": "sample → from → extract → formulate → as → clauses",
        "sentence": "We extract principles from a corpus-based sample and formulate them as probabilistic Horn clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpus-based sample') is the object of the preposition 'from', depending on 'extract' with 'We'. Entity 2 ('probabilistic Horn clauses') is the complement of the preposition 'as', depending on 'formulate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to actions performed by the subject ('We').\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "clauses",
                "OtherScientificTerm"
            ],
            [
                "domain independent features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('domain independent features') is the object of the verb 'create', depending on 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence of actions described in the sentence, where the predicates of the clauses are used to create the domain independent features.\"",
        "sdp_path_text": "clauses → of → predicates → use → create → set → of → features",
        "sentence": "We use the predicates of clauses to create a set of domain independent features.",
        "sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('domain independent features') is the object of the verb 'create', depending on 'create'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'clauses' contributes to the creation of 'domain independent features'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "clauses",
                "OtherScientificTerm"
            ],
            [
                "machine learning algorithms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('machine learning algorithms') is the object of the verb 'run'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "clauses → of → predicates → use → run → algorithms",
        "sentence": "Predicates of clauses are used to run machine learning algorithms.",
        "sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('machine learning algorithms') is the object of the verb 'run', depending on 'run'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'predicates of clauses' are used to 'run machine learning algorithms'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "clauses",
                "OtherScientificTerm"
            ],
            [
                "SLIPPER",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('SLIPPER') is part of a coordination, depending on 'algorithms' as a member of the list of algorithms being run. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "clauses → of → predicates → use → run → algorithms → SLIPPER",
        "sentence": "Predicates of clauses are used to run algorithms including SLIPPER.",
        "sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'Predicates'. Entity 2 ('SLIPPER') is part of a compound noun, depending on 'algorithms' with 'including'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "clauses",
                "OtherScientificTerm"
            ],
            [
                "rule-based learning algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('rule-based learning algorithm') is part of a compound noun, depending on 'algorithms' with the appositive 'SLIPPER'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "clauses → of → predicates → use → run → algorithms → SLIPPER → algorithm",
        "sentence": "Predicates of clauses are used to run a rule-based learning algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('rule-based learning algorithm') is the object of the verb 'run'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'predicates of clauses' are the subject and 'run a rule-based learning algorithm' is the predicate.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "clauses",
                "OtherScientificTerm"
            ],
            [
                "TiMBL",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('TiMBL') is the object of the preposition 'and', part of a list introduced by 'algorithms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "clauses → of → predicates → use → run → algorithms → SLIPPER → TiMBL",
        "sentence": "Predicates of clauses are used to run algorithms including TiMBL.",
        "sentence_llm_dp_info": "\"Entity 1 ('clauses') is part of the noun phrase 'predicates of clauses', where it depends on 'predicates' as the object of the preposition 'of'. Entity 2 ('TiMBL') is part of the noun phrase 'algorithms including TiMBL', where it depends on 'including' as the object of the preposition 'including'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "clauses",
                "OtherScientificTerm"
            ],
            [
                "memory-based system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('memory-based system') is the appositive, depending on 'TiMBL'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "clauses → of → predicates → use → run → algorithms → SLIPPER → TiMBL → system",
        "sentence": "Predicates of clauses are used to run a memory-based system.",
        "sentence_llm_dp_info": "\"Entity 1 ('clauses') is the object of the preposition 'of', depending on 'predicates'. Entity 2 ('memory-based system') is the object, depending on the verb 'run'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'predicates of clauses' are used to perform an action on the 'memory-based system'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "domain independent features",
                "OtherScientificTerm"
            ],
            [
                "machine learning algorithms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object of the verb 'create', depending on the verb 'create' with 'predicates'. Entity 2 ('machine learning algorithms') is the subject complement, depending on the verb 'run' with 'run'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described in the sentence, where the features are used to annotate a dataset that is then processed by the algorithms.\"",
        "sdp_path_text": "features → of → set → create → use → run → algorithms",
        "sentence": "Domain independent features are used to run machine learning algorithms.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the subject, depending on the verb 'used'. Entity 2 ('machine learning algorithms') is the object, depending on the verb 'run'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the purpose clause introduced by 'to run'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "domain independent features",
                "OtherScientificTerm"
            ],
            [
                "SLIPPER",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object of the verb 'create', depending on 'create' with 'predicates'. Entity 2 ('SLIPPER') is part of a coordination, depending on 'run' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "features → of → set → create → use → run → algorithms → SLIPPER",
        "sentence": "We use domain independent features to run SLIPPER.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object of the verb 'use', depending on 'use' with 'We'. Entity 2 ('SLIPPER') is the object of the preposition 'to', depending on 'to' in the phrase 'to run SLIPPER'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "domain independent features",
                "OtherScientificTerm"
            ],
            [
                "rule-based learning algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object, depending on 'create' with 'predicates'. Entity 2 ('rule-based learning algorithm') is part of the appositive, depending on 'algorithms' with 'SLIPPER'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "features → of → set → create → use → run → algorithms → SLIPPER → algorithm",
        "sentence": "Domain independent features are used to run a rule-based learning algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the subject, depending on the verb 'used'. Entity 2 ('rule-based learning algorithm') is the object of the verb 'run', depending on 'run' in the phrase 'to run a rule-based learning algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'used' and 'run'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "domain independent features",
                "OtherScientificTerm"
            ],
            [
                "TiMBL",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object of the verb 'create', depending on 'create' with 'predicates'. Entity 2 ('TiMBL') is the appositive, depending on 'algorithms' with 'and'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "features → of → set → create → use → run → algorithms → SLIPPER → TiMBL",
        "sentence": "Domain independent features are used to run TiMBL.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the subject, depending on the verb 'used'. Entity 2 ('TiMBL') is the object of the preposition 'to', depending on 'run' in the phrase 'to run TiMBL'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "domain independent features",
                "OtherScientificTerm"
            ],
            [
                "memory-based system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object, depending on 'create' with 'predicates'. Entity 2 ('memory-based system') is the appositive, depending on 'TiMBL' which itself is part of a list introduced by 'algorithms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "features → of → set → create → use → run → algorithms → SLIPPER → TiMBL → system",
        "sentence": "We use domain independent features to run a memory-based system.",
        "sentence_llm_dp_info": "\"Entity 1 ('domain independent features') is the object of the verb 'use', depending on 'use' with 'We'. Entity 2 ('memory-based system') is the object of the verb 'run', depending on 'run' which is part of the infinitive phrase 'to run'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing actions performed on or with these entities.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "machine learning algorithms",
                "Method"
            ],
            [
                "SLIPPER",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning algorithms') is the object of the verb 'run', depending on 'run' with 'we'. Entity 2 ('SLIPPER') is the first element in a list of appositives, specifying the type of 'machine learning algorithms'. There is a direct dependency between Entity 1 and Entity 2, as 'SLIPPER' is listed as an example of 'machine learning algorithms'.\"",
        "sdp_path_text": "algorithms → SLIPPER",
        "sentence": "Machine learning algorithms include SLIPPER.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning algorithms') is the subject, depending on the verb 'include'. Entity 2 ('SLIPPER') is the object, depending on 'include' with 'machine learning algorithms'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is included as part of Entity 1.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "rule-based learning algorithm",
                "Method"
            ],
            [
                "machine learning algorithms",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based learning algorithm') is the appositive, depending on 'algorithms' with the conjunction 'and'. Entity 2 ('machine learning algorithms') is the direct object, depending on the verb 'run'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where Entity 1 specifies a type of Entity 2.\"",
        "sdp_path_text": "algorithm → SLIPPER → algorithms",
        "sentence": "SLIPPER, a rule-based learning algorithm, is one of the machine learning algorithms used.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based learning algorithm') is the appositive, depending on the noun 'SLIPPER'. Entity 2 ('machine learning algorithms') is the object of the preposition 'of', depending on 'one' in the phrase 'one of the machine learning algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same nominal structure describing SLIPPER.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "machine learning algorithms",
                "Method"
            ],
            [
                "TiMBL",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine learning algorithms') is the object of the verb 'run', depending on 'run' with 'we'. Entity 2 ('TiMBL') is the appositive, depending on 'algorithms' with 'and'. There is a direct dependency between Entity 1 and Entity 2, as 'TiMBL' specifies one of the 'machine learning algorithms' being run.\"",
        "sdp_path_text": "algorithms → SLIPPER → TiMBL",
        "sentence": "We run two machine learning algorithms: SLIPPER and TiMBL.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine learning algorithms') is the object, depending on the verb 'run'. Entity 2 ('TiMBL') is an appositive, specifying one of the 'machine learning algorithms'. There is a direct dependency between Entity 1 and Entity 2, as 'TiMBL' is listed as one of the specific algorithms referred to by 'machine learning algorithms'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "memory-based system",
                "Method"
            ],
            [
                "machine learning algorithms",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('memory-based system') is the appositive, depending on the noun 'algorithms' in the phrase 'machine learning algorithms'. Entity 2 ('machine learning algorithms') is the object of the verb 'run', depending on 'run'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 specifies one of the types of Entity 2.\"",
        "sdp_path_text": "system → TiMBL → SLIPPER → algorithms",
        "sentence": "A memory-based system is one of the machine learning algorithms used.",
        "sentence_llm_dp_info": "\"Entity 1 ('memory-based system') is the subject, depending on the verb 'is'. Entity 2 ('machine learning algorithms') is the object of the preposition 'of', depending on 'one' in the phrase 'one of the machine learning algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'one of the machine learning algorithms'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "SLIPPER",
                "Generic"
            ],
            [
                "rule-based learning algorithm",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('SLIPPER') is the appositive, depending on the conjunction 'and' with 'TiMBL'. Entity 2 ('rule-based learning algorithm') is the appositive, depending on the noun 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but both are part of a list describing different machine learning algorithms.\"",
        "sdp_path_text": "SLIPPER → algorithm",
        "sentence": "SLIPPER is a rule-based learning algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('SLIPPER') is the subject, depending on the verb 'is'. Entity 2 ('rule-based learning algorithm') is the predicate nominative, depending on 'is' with 'SLIPPER'. There is a direct dependency between Entity 1 and Entity 2, as 'rule-based learning algorithm' directly renames or describes 'SLIPPER'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "SLIPPER",
                "Generic"
            ],
            [
                "TiMBL",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('SLIPPER') is the appositive, depending on the noun 'algorithms' with the conjunction 'and'. Entity 2 ('TiMBL') is also an appositive, depending on the noun 'algorithms' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both listed as examples of the algorithms being used.\"",
        "sdp_path_text": "SLIPPER → TiMBL",
        "sentence": "SLIPPER and TiMBL are used as machine learning algorithms.",
        "sentence_llm_dp_info": "\"Entity 1 ('SLIPPER') is the subject, depending on the verb 'are used'. Entity 2 ('TiMBL') is also the subject, coordinated with 'SLIPPER' and depending on the same verb 'are used'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in a coordinate structure.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "SLIPPER",
                "Generic"
            ],
            [
                "memory-based system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('SLIPPER') is the object, depending on 'run' with 'algorithms'. Entity 2 ('memory-based system') is the object, depending on 'is' with 'TiMBL'. There is no direct dependency between Entity 1 and Entity 2; both are listed as objects of the verb 'run' and are part of a list of machine learning algorithms.\"",
        "sdp_path_text": "SLIPPER → TiMBL → system",
        "sentence": "SLIPPER and TiMBL are different machine learning algorithms, with TiMBL being a memory-based system.",
        "sentence_llm_dp_info": "\"Entity 1 ('SLIPPER') is a noun, depending on the conjunction 'and' with 'TiMBL'. Entity 2 ('memory-based system') is the complement of 'being', which modifies 'TiMBL'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a list of entities described in the sentence.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "rule-based learning algorithm",
                "Method"
            ],
            [
                "TiMBL",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based learning algorithm') is the appositive, depending on 'SLIPPER' with the relation 'appositive'. Entity 2 ('TiMBL') is the subject, depending on 'run' with the relation 'nsubj'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of items that are run as machine learning algorithms.\"",
        "sdp_path_text": "algorithm → SLIPPER → TiMBL",
        "sentence": "SLIPPER is a rule-based learning algorithm, and TiMBL is a memory-based system.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based learning algorithm') is the complement of the copula 'is', depending on 'SLIPPER'. Entity 2 ('TiMBL') is the subject, depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses joined by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "rule-based learning algorithm",
                "Method"
            ],
            [
                "memory-based system",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based learning algorithm') is the appositive, depending on the noun 'algorithms'. Entity 2 ('memory-based system') is also an appositive, depending on the same noun 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both appositives of the noun 'algorithms'.\"",
        "sdp_path_text": "algorithm → SLIPPER → TiMBL → system",
        "sentence": "SLIPPER is a rule-based learning algorithm, and TiMBL is a memory-based system.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based learning algorithm') is the complement, depending on the copula 'is' with 'SLIPPER'. Entity 2 ('memory-based system') is the complement, depending on the copula 'is' with 'TiMBL'. There is no direct dependency between Entity 1 and Entity 2, but they are both complements in similar structures within the sentence.\""
    },
    {
        "raw_sentence": "We then use the predicates of such clauses to create a set of domain independent features to annotate an input dataset , and run two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system .",
        "ner_pair": [
            [
                "TiMBL",
                "Generic"
            ],
            [
                "memory-based system",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TiMBL') is the subject, depending on the verb 'run' with 'algorithms'. Entity 2 ('memory-based system') is the appositive, depending on 'TiMBL' to provide additional information about it. There is a direct dependency between Entity 1 and Entity 2, where 'memory-based system' serves as an appositive to 'TiMBL'.\"",
        "sdp_path_text": "TiMBL → system",
        "sentence": "TiMBL is a memory-based system.",
        "sentence_llm_dp_info": "\"Entity 1 ('TiMBL') is the subject, depending on the verb 'is'. Entity 2 ('memory-based system') is the predicate nominative, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'memory-based system' directly describes what 'TiMBL' is.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "heuristic principles",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'have' with 'significant predictive power'. Entity 2 ('heuristic principles') is the object of the preposition 'of', depending on 'formulate' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formulate' where 'features' are used to formulate 'heuristic principles'.\"",
        "sdp_path_text": "features → formulate → principles",
        "sentence": "Features are used to formulate heuristic principles.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'used'. Entity 2 ('heuristic principles') is the object, depending on the verb 'formulate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'used' and 'formulate'.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "rules",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the subject of the clause 'features in terms of which we formulate our heuristic principles', depending on 'formulate' with 'principles'. It also serves as the object of the preposition 'of' in the phrase 'the accuracy of a term aggregation system'. Entity 2 ('rules') is the subject of the clause 'rules that closely resemble our Horn clauses', depending on 'resemble' with 'clauses'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the larger context describing the formulation of heuristic principles and the learning of rules from these features.\" \n\nHowever, to more accurately reflect the sentence structure and dependencies:\n\n\"Entity 1 ('features') is the object of the preposition 'in terms of', depending on 'formulate' with 'principles'. Entity 2 ('rules') is the subject of the clause 'rules that closely resemble our Horn clauses', depending on 'resemble' with 'clauses'. There is no direct dependency between Entity 1 and Entity 2, but they are both key elements in the description of the heuristic principles and the rules derived from these features.\"",
        "sdp_path_text": "features → have → learnt → rules",
        "sentence": "Features have predictive power, and rules can be learnt from them.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'have' in the clause 'Features have predictive power'. Entity 2 ('rules') is the subject of the second clause, depending on the verb 'can be learnt' in the clause 'rules can be learnt from them'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the conjunction 'and' and the prepositional phrase 'from them' which refers back to 'features'.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "Horn clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the object of the preposition 'in', depending on 'formulate'. Entity 2 ('Horn clauses') is the object of the preposition 'of', depending on 'resemble'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the formulation of heuristic principles and the learning of rules, respectively.\"",
        "sdp_path_text": "features → have → learnt → rules → resemble → clauses",
        "sentence": "Features have predictive power, and rules resembling Horn clauses can be learnt from them.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'have' with 'predictive power'. Entity 2 ('Horn clauses') is the object of the preposition 'resembling', depending on 'resembling' in the phrase 'resembling Horn clauses'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'features' influence what can be 'learnt', which includes 'rules resembling Horn clauses'.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "heuristic principles",
                "Method"
            ],
            [
                "rules",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('heuristic principles') is the object of the preposition 'which', depending on 'formulate'. Entity 2 ('rules') is the subject of the clause 'rules that closely resemble our Horn clauses can be learnt', depending on the verb 'resemble'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context provided by the sentence, where 'heuristic principles' are formulated and 'rules' are described as being learnable from certain features.\"",
        "sdp_path_text": "principles → formulate → features → have → learnt → rules",
        "sentence": "Heuristic principles formulated using features that can be used to learn rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('heuristic principles') is the subject, depending on 'formulated'. Entity 2 ('rules') is the object, depending on 'learn'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'formulated' and 'learn' which describe actions related to the entities.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "heuristic principles",
                "Method"
            ],
            [
                "Horn clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('heuristic principles') is the object of the preposition 'which', depending on 'formulate'. Entity 2 ('Horn clauses') is the object of the preposition 'of', depending on 'resemble'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause structure describing aspects of the research findings.\"",
        "sdp_path_text": "principles → formulate → features → have → learnt → rules → resemble → clauses",
        "sentence": "Heuristic principles formulated using features can lead to rules resembling Horn clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('heuristic principles') is the subject, depending on the verb 'formulated'. Entity 2 ('Horn clauses') is the object of the preposition 'resembling', depending on 'resembling' in the phrase 'resembling Horn clauses'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'lead' and the preposition 'resembling'.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "heuristic principles",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'have' in the clause 'have significant predictive power'. Entity 2 ('heuristic principles') is the object of the preposition 'of', depending on 'formulate' in the phrase 'formulate our heuristic principles'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formulate' and the preposition 'of'.\"",
        "sdp_path_text": "features → formulate → principles",
        "sentence": "The features are used to formulate heuristic principles.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'are used'. Entity 2 ('heuristic principles') is the object of the verb 'formulate', which is part of the infinitive phrase 'to formulate heuristic principles'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formulate' in the context of the sentence.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "Horn clauses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the subject, depending on the verb 'resemble' in the clause 'that closely resemble our Horn clauses'. Entity 2 ('Horn clauses') is the object, depending on the verb 'resemble' in the same clause. There is a direct dependency between Entity 1 and Entity 2, as 'Horn clauses' is the object of the verb 'resemble' which has 'rules' as its subject.\"",
        "sdp_path_text": "rules → resemble → clauses",
        "sentence": "Rules closely resemble Horn clauses.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the subject, depending on the verb 'resemble'. Entity 2 ('Horn clauses') is the complement, depending on 'resemble' with 'rules'. There is a direct dependency between Entity 1 and Entity 2, as 'Horn clauses' is the direct object of the verb 'resemble' which is governed by 'rules'.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the subject of the clause, depending on 'resemble' with 'our Horn clauses'. Entity 2 ('features') is the object of the preposition 'from', depending on 'learnt' in the phrase 'learnt automatically from these features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'learnt' and the preposition 'from'.\"",
        "sdp_path_text": "rules → learnt → have → features",
        "sentence": "Rules can be learnt from features.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the subject, depending on the verb 'can be learnt'. Entity 2 ('features') is the object of the preposition 'from', depending on 'from' in the phrase 'from features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from these features .",
        "ner_pair": [
            [
                "Horn clauses",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Horn clauses') is the object of the preposition 'of', depending on 'resemble' with 'rules'. Entity 2 ('features') is the object of the preposition 'from', depending on 'learnt' with 'can be'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'resemble' and the preposition 'from'.\"",
        "sdp_path_text": "clauses → resemble → rules → learnt → have → features",
        "sentence": "Horn clauses can be learnt from features.",
        "sentence_llm_dp_info": "\"Entity 1 ('Horn clauses') is the subject, depending on the verb 'can be learnt'. Entity 2 ('features') is the object of the preposition 'from', depending on 'from' in the phrase 'from features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We suggest a new goal and evaluation criterion for word similarity measures .",
        "ner_pair": [
            [
                "evaluation criterion",
                "Metric"
            ],
            [
                "word similarity measures",
                "Metric"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation criterion') is the object of the preposition 'for', depending on 'for' in the phrase 'for word similarity measures'. Entity 2 ('word similarity measures') is the object of the preposition 'for', depending on 'for' in the same phrase. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for word similarity measures'.\"",
        "sdp_path_text": "criterion → goal → for → measures",
        "sentence": "We suggest a new evaluation criterion for word similarity measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation criterion') is the object of the preposition 'for', depending on 'suggest' in the phrase 'suggest a new evaluation criterion'. Entity 2 ('word similarity measures') is the object of the preposition 'for', depending on 'criterion' in the phrase 'criterion for word similarity measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "The new criterion -- meaning-entailing substitutability -- fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement .",
        "ner_pair": [
            [
                "criterion",
                "Generic"
            ],
            [
                "meaning-entailing substitutability",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('criterion') is the subject, depending on the verb 'fits'. Entity 2 ('meaning-entailing substitutability') is the appositive, depending on 'criterion'. There is a direct dependency between Entity 1 and Entity 2, as 'meaning-entailing substitutability' renames or describes 'criterion'.\"",
        "sdp_path_text": "criterion → entailing",
        "sentence": "{\n  \"Simplified sentence\": \"The new criterion fits the needs of semantic-oriented NLP applications and can be evaluated at a good level of human agreement.\"\n}\n\nHowever, focusing strictly on the relationship between \"criterion\" and \"meaning-entailing substitutability\" as per the SDP, a more concise version would be:\n\n{\n  \"Simplified sentence\": \"The new criterion is meaning-entailing substitutability.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('criterion') is the subject, depending on the copula 'is'. Entity 2 ('meaning-entailing substitutability') is the predicate nominative, directly linked to 'criterion' through the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, where 'criterion' is identified as being 'meaning-entailing substitutability'.\""
    },
    {
        "raw_sentence": "The new criterion -- meaning-entailing substitutability -- fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement .",
        "ner_pair": [
            [
                "criterion",
                "Generic"
            ],
            [
                "semantic-oriented NLP applications",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('criterion') is the subject, depending on the verb 'fits'. Entity 2 ('semantic-oriented NLP applications') is the object of the preposition 'of', depending on 'needs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'the needs of semantic-oriented NLP applications'.\"",
        "sdp_path_text": "criterion → fits → needs → of → applications",
        "sentence": "The new criterion fits the needs of semantic-oriented NLP applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('criterion') is the subject, depending on the verb 'fits'. Entity 2 ('semantic-oriented NLP applications') is the object of the preposition 'of', depending on 'needs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'fits' and the prepositional phrase 'of semantic-oriented NLP applications'.\""
    },
    {
        "raw_sentence": "The new criterion -- meaning-entailing substitutability -- fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement .",
        "ner_pair": [
            [
                "criterion",
                "Generic"
            ],
            [
                "human agreement",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('criterion') is the subject, depending on the verb 'fits'. Entity 2 ('human agreement') is part of a prepositional phrase, depending on 'level' in 'level of human agreement'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "criterion → fits → evaluated → at → level → of → agreement",
        "sentence": "The new criterion fits the needs and can be evaluated at a good level of human agreement.",
        "sentence_llm_dp_info": "\"Entity 1 ('criterion') is the subject, depending on the verb 'fits'. Entity 2 ('human agreement') is part of a noun phrase, depending on 'level' with the prepositional phrase 'of human agreement'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The new criterion -- meaning-entailing substitutability -- fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement .",
        "ner_pair": [
            [
                "meaning-entailing substitutability",
                "Metric"
            ],
            [
                "semantic-oriented NLP applications",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('meaning-entailing substitutability') is the appositive, depending on 'criterion' with 'The new criterion'. Entity 2 ('semantic-oriented NLP applications') is the object of the preposition 'of', depending on 'needs' in the phrase 'the needs of semantic-oriented NLP applications'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context provided by the sentence, where Entity 1 describes a criterion that fits the needs of Entity 2.\"",
        "sdp_path_text": "entailing → criterion → fits → needs → of → applications",
        "sentence": "Meaning-entailing substitutability fits the needs of semantic-oriented NLP applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('meaning-entailing substitutability') is the subject, depending on the verb 'fits'. Entity 2 ('semantic-oriented NLP applications') is the object, depending on 'fits' with 'the needs of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'fits' and the prepositional phrase 'the needs of'.\""
    },
    {
        "raw_sentence": "The new criterion -- meaning-entailing substitutability -- fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement .",
        "ner_pair": [
            [
                "human agreement",
                "Metric"
            ],
            [
                "meaning-entailing substitutability",
                "Metric"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('human agreement') is the object of the preposition 'of', depending on 'level'. Entity 2 ('meaning-entailing substitutability') is the appositive, depending on 'criterion'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "agreement → of → level → at → evaluated → fits → criterion → entailing",
        "sentence": "The criterion of meaning-entailing substitutability fits the needs and can be evaluated at a good level of human agreement.",
        "sentence_llm_dp_info": "\"Entity 1 ('human agreement') is the object of the preposition 'of', depending on 'level'. Entity 2 ('meaning-entailing substitutability') is the subject, depending on 'fits' with 'criterion'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'meaning-entailing substitutability' is the subject of the main verb 'fits' and 'human agreement' is part of the object complement.\""
    },
    {
        "raw_sentence": "The new criterion -- meaning-entailing substitutability -- fits the needs of semantic-oriented NLP applications and can be evaluated directly -LRB- independent of an application -RRB- at a good level of human agreement .",
        "ner_pair": [
            [
                "semantic-oriented NLP applications",
                "Task"
            ],
            [
                "human agreement",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic-oriented NLP applications') is the object of the preposition 'of', depending on 'fits' in the phrase 'fits the needs of semantic-oriented NLP applications'. Entity 2 ('human agreement') is part of a prepositional phrase, depending on 'level' in 'level of human agreement'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "applications → of → needs → fits → evaluated → at → level → of → agreement",
        "sentence": "The new criterion fits the needs of semantic-oriented NLP applications and can be evaluated at a good level of human agreement.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic-oriented NLP applications') is the object of the preposition 'of', depending on 'needs'. Entity 2 ('human agreement') is the object of the preposition 'of', depending on 'level'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger sentence structure, where 'semantic-oriented NLP applications' relates to what the criterion fits, and 'human agreement' relates to the evaluation level.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "semantic criterion",
                "Metric"
            ],
            [
                "distributional word feature vectors",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'motivated'. Entity 2 ('distributional word feature vectors') is the subject, depending on 'analyze'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'semantic criterion' motivates the action of analyzing 'distributional word feature vectors'.\"",
        "sdp_path_text": "criterion → by → Motivated → analyze → quality → of → vectors",
        "sentence": "Motivated by the semantic criterion, we analyze the quality of distributional word feature vectors.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'Motivated'. Entity 2 ('distributional word feature vectors') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure that describes the motivation and the focus of the analysis.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "semantic criterion",
                "Metric"
            ],
            [
                "word similarity",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'motivated'. Entity 2 ('word similarity') is part of the compound noun 'word similarity results', which is the object of the preposition 'on', depending on 'impact'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the broader context of the sentence through the verbs 'analyze' and 'proposing'.\"",
        "sdp_path_text": "criterion → by → Motivated → analyze → quality → impact → on → results → similarity",
        "sentence": "Motivated by the semantic criterion, we analyze the impact on word similarity results.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'motivated'. Entity 2 ('word similarity') is part of the compound noun 'word similarity results', acting as the modifier of 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the structure of the sentence, with 'semantic criterion' influencing the motivation for the action and 'word similarity' being part of the result being analyzed.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "semantic criterion",
                "Metric"
            ],
            [
                "measure",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'Motivated'. Entity 2 ('measure') is the object of the verb 'proposing', depending on 'proposing'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence, contributing to the motivation and the outcome of the analysis described.\"",
        "sdp_path_text": "criterion → by → Motivated → analyze → proposing → measure",
        "sentence": "Motivated by the semantic criterion, we propose a measure for analyzing feature vector quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'motivated'. Entity 2 ('measure') is the object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'semantic criterion' influences the context in which 'measure' is proposed.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "semantic criterion",
                "Metric"
            ],
            [
                "feature vector quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'motivated'. Entity 2 ('feature vector quality') is the object of the preposition 'for', depending on 'measure'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence, which discusses the motivation for analyzing and evaluating certain aspects of word features.\"",
        "sdp_path_text": "criterion → by → Motivated → analyze → proposing → measure → for → evaluating → quality",
        "sentence": "Motivated by the semantic criterion, a measure for evaluating feature vector quality is proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic criterion') is the object of the preposition 'by', depending on 'Motivated'. Entity 2 ('feature vector quality') is the object of the preposition 'for', depending on 'evaluating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what is proposed.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "distributional word feature vectors",
                "OtherScientificTerm"
            ],
            [
                "word similarity",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distributional word feature vectors') is the object of the preposition 'of', depending on 'quality'. Entity 2 ('word similarity') is the object of the preposition 'on', depending on 'impact'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the analysis and its impact.\"",
        "sdp_path_text": "vectors → of → quality → impact → on → results → similarity",
        "sentence": "Distributional word feature vectors impact word similarity results.",
        "sentence_llm_dp_info": "\"Entity 1 ('distributional word feature vectors') is the subject, depending on the verb 'impact'. Entity 2 ('word similarity') is part of the compound noun 'word similarity results', which is the direct object of the verb 'impact'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'impact' and the noun 'results'.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "distributional word feature vectors",
                "OtherScientificTerm"
            ],
            [
                "measure",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distributional word feature vectors') is the object of the preposition 'of', depending on 'quality'. Entity 2 ('measure') is the object, depending on 'proposing' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of analyzing and proposing methods related to word features and evaluation.\"",
        "sdp_path_text": "vectors → of → quality → analyze → proposing → measure",
        "sentence": "We analyze the quality of distributional word feature vectors, proposing a measure.",
        "sentence_llm_dp_info": "\"Entity 1 ('distributional word feature vectors') is the object of the preposition 'of', depending on 'quality'. Entity 2 ('measure') is the object, depending on 'proposing'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what is analyzed and proposed in the sentence.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "distributional word feature vectors",
                "OtherScientificTerm"
            ],
            [
                "feature vector quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distributional word feature vectors') is the object of the preposition 'of', depending on 'quality'. Entity 2 ('feature vector quality') is the object of the preposition 'for', depending on 'measure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of the sentence, where Entity 1 influences Entity 2 in terms of evaluation.\"",
        "sdp_path_text": "vectors → of → quality → analyze → proposing → measure → for → evaluating → quality",
        "sentence": "We analyze the quality of distributional word feature vectors, proposing a measure for evaluating feature vector quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('distributional word feature vectors') is the object of the preposition 'of', depending on 'quality'. Entity 2 ('feature vector quality') is the object, depending on 'evaluating' with 'measure'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where both are discussed in the scope of the analysis and the proposed measure.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "word similarity",
                "Task"
            ],
            [
                "measure",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word similarity') is part of the noun phrase 'word similarity results', which is the object of the preposition 'on', depending on 'impact'. Entity 2 ('measure') is the object of the preposition 'for', depending on 'proposing'. There is no direct dependency between Entity 1 and Entity 2; however, they are both related to the context of evaluating and analyzing aspects of word features and their effects.\"",
        "sdp_path_text": "similarity → results → on → impact → quality → analyze → proposing → measure",
        "sentence": "We analyze the impact of word similarity results on feature vector quality, proposing a measure.",
        "sentence_llm_dp_info": "\"Entity 1 ('word similarity') is part of the noun phrase 'word similarity results', which acts as the object of the preposition 'of', depending on 'impact'. Entity 2 ('measure') is the object of the gerund-participle verb 'proposing', depending on 'proposing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the analysis and the proposal of a measure.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "word similarity",
                "Task"
            ],
            [
                "feature vector quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word similarity') is the object of the preposition 'on', depending on 'impact' in the phrase 'its impact on word similarity results'. Entity 2 ('feature vector quality') is the object of the preposition 'for', depending on 'measure' in the phrase 'an objective measure for evaluating feature vector quality'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of analyzing the impact of distributional word feature vectors.\"",
        "sdp_path_text": "similarity → results → on → impact → quality → analyze → proposing → measure → for → evaluating → quality",
        "sentence": "We analyze the impact of feature vector quality on word similarity results and propose a measure for evaluating quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('word similarity') is part of the compound noun 'word similarity results', which is the object of the preposition 'on', depending on 'impact'. Entity 2 ('feature vector quality') is the object of the preposition 'of', depending on 'impact'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the impact being analyzed.\""
    },
    {
        "raw_sentence": "Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .",
        "ner_pair": [
            [
                "measure",
                "Generic"
            ],
            [
                "feature vector quality",
                "Metric"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('measure') is the object, depending on the verb 'proposing' with 'we'. Entity 2 ('feature vector quality') is the object of the preposition 'for', depending on 'for' in the phrase 'for evaluating feature vector quality'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluating' which links 'measure' to 'feature vector quality'.\"",
        "sdp_path_text": "measure → for → evaluating → quality",
        "sentence": "A measure is proposed for evaluating feature vector quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('measure') is the subject, depending on the verb 'proposed'. Entity 2 ('feature vector quality') is the object of the preposition 'for', depending on 'for' in the phrase 'for evaluating feature vector quality'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance .",
        "ner_pair": [
            [
                "feature weighting and selection function",
                "Method"
            ],
            [
                "feature vectors",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature weighting and selection function') is the subject, depending on the verb 'presented'. Entity 2 ('feature vectors') is the object of the preposition 'vectors', depending on 'yields' in the phrase 'yields superior feature vectors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields'.\"",
        "sdp_path_text": "function → yields → vectors",
        "sentence": "A feature weighting and selection function yields superior feature vectors.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature weighting and selection function') is the subject, depending on the verb 'yields'. Entity 2 ('feature vectors') is the object, depending on the verb 'yields'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the agent that produces Entity 2.\""
    },
    {
        "raw_sentence": "Finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance .",
        "ner_pair": [
            [
                "feature weighting and selection function",
                "Method"
            ],
            [
                "word similarity",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature weighting and selection function') is the subject, depending on the verb 'presented'. Entity 2 ('word similarity') is part of a compound noun, depending on 'performance' with 'better'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the outcomes of presenting the function.\"",
        "sdp_path_text": "function → yields → vectors → performance → similarity",
        "sentence": "A feature weighting and selection function yields better word similarity performance.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature weighting and selection function') is the subject, depending on the verb 'yields'. Entity 2 ('word similarity') is part of the object, depending on 'performance' with the adjective 'better'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields' which indicates that Entity 1 results in an improvement of Entity 2.\""
    },
    {
        "raw_sentence": "Finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance .",
        "ner_pair": [
            [
                "feature vectors",
                "OtherScientificTerm"
            ],
            [
                "word similarity",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature vectors') is the object, depending on 'yields' with 'function'. Entity 2 ('word similarity') is part of a compound noun, depending on 'performance' in the phrase 'word similarity performance'. There is no direct dependency between Entity 1 and Entity 2, but both are outcomes of the function that is presented.\"",
        "sdp_path_text": "vectors → performance → similarity",
        "sentence": "Feature vectors yield better word similarity performance.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature vectors') is the subject, depending on the verb 'yield'. Entity 2 ('word similarity') is part of the compound noun 'word similarity performance', which is the direct object of the verb 'yield'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yield' and the compound noun structure.\""
    },
    {
        "raw_sentence": "Reflections in image sequences consist of several layers superimposed over each other .",
        "ner_pair": [
            [
                "Reflections",
                "OtherScientificTerm"
            ],
            [
                "image sequences",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Reflections') is the subject, depending on the verb 'consist'. Entity 2 ('image sequences') is the object, depending on 'in' in the prepositional phrase 'in image sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in image sequences'.\"",
        "sdp_path_text": "Reflections → in → sequences",
        "sentence": "Reflections are in image sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('Reflections') is the subject, depending on the verb 'are'. Entity 2 ('image sequences') is the object of the preposition 'in', depending on 'in' in the phrase 'in image sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'in'.\""
    },
    {
        "raw_sentence": "This phenomenon causes many image processing techniques to fail as they assume the presence of only one layer at each examined site e.g. motion estimation and object recognition .",
        "ner_pair": [
            [
                "image processing techniques",
                "Method"
            ],
            [
                "motion estimation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image processing techniques') is the object of the verb 'causes', depending on 'phenomenon'. Entity 2 ('motion estimation') is part of a list, depending on 'and' with 'object recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of techniques and processes that can fail due to the phenomenon described.\"",
        "sdp_path_text": "techniques → fail → causes → assume → estimation",
        "sentence": "Image processing techniques fail because they assume conditions that do not hold for motion estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('image processing techniques') is the subject, depending on the verb 'fail'. Entity 2 ('motion estimation') is the object of the preposition 'for', depending on 'hold'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the causal relationship described in the sentence, where the failure of Entity 1 is attributed to assumptions that do not apply to Entity 2.\""
    },
    {
        "raw_sentence": "This phenomenon causes many image processing techniques to fail as they assume the presence of only one layer at each examined site e.g. motion estimation and object recognition .",
        "ner_pair": [
            [
                "image processing techniques",
                "Method"
            ],
            [
                "object recognition",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image processing techniques') is the object of the verb 'causes', depending on 'phenomenon'. Entity 2 ('object recognition') is part of a list, depending on 'and' which connects it to 'motion estimation', and both are objects of the verb 'assume'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where both are affected by the phenomenon causing them to fail.\"",
        "sdp_path_text": "techniques → fail → causes → assume → estimation → recognition",
        "sentence": "Image processing techniques fail due to assumptions affecting object recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('image processing techniques') is the subject, depending on the verb 'fail'. Entity 2 ('object recognition') is the object of the preposition 'affecting', depending on 'assumptions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the causal relationship expressed by 'fail due to assumptions affecting'.\""
    },
    {
        "raw_sentence": "This phenomenon causes many image processing techniques to fail as they assume the presence of only one layer at each examined site e.g. motion estimation and object recognition .",
        "ner_pair": [
            [
                "motion estimation",
                "Task"
            ],
            [
                "object recognition",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('motion estimation') is part of a coordination, depending on 'and' which connects it with 'object recognition'. Entity 2 ('object recognition') is also part of a coordination, depending on 'and' which connects it with 'motion estimation'. There is no direct dependency between Entity 1 and Entity 2; they are both coordinated elements in the list of techniques that assume the presence of only one layer at each examined site.\"",
        "sdp_path_text": "estimation → recognition",
        "sentence": "Motion estimation and object recognition are affected by this phenomenon.",
        "sentence_llm_dp_info": "\"Entity 1 ('motion estimation') is a conjunct, depending on 'and' with 'object recognition'. Entity 2 ('object recognition') is also a conjunct, depending on 'and' with 'motion estimation'. Both are subjects, depending on the verb 'are affected'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and share the same predicate 'are affected'.\""
    },
    {
        "raw_sentence": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "detecting reflections in image sequences",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the object, depending on 'presents' with 'This work'. Entity 2 ('detecting reflections in image sequences') is the complement of the preposition 'for', depending on 'for' in the phrase 'for detecting reflections in image sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "technique → for → detecting",
        "sentence": "This work presents a technique for detecting reflections in image sequences.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'presents' with 'This work'. Entity 2 ('detecting reflections in image sequences') is the object of the preposition 'for', depending on 'for' in the phrase 'for detecting reflections in image sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points .",
        "ner_pair": [
            [
                "motion trajectories",
                "OtherScientificTerm"
            ],
            [
                "technique",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('motion trajectories') is the object of the preposition 'of', depending on 'analyzing'. Entity 2 ('technique') is the object, depending on 'presents' with 'This work'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'analyzing' which describes part of the process used by the technique.\"",
        "sdp_path_text": "trajectories → analyzing → by → detecting → for → technique",
        "sentence": "The technique detects reflections by analyzing motion trajectories.",
        "sentence_llm_dp_info": "\"Entity 1 ('motion trajectories') is the object, depending on the verb 'analyzing'. Entity 2 ('technique') is the subject, depending on the verb 'detects'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'detects' and the prepositional phrase 'by analyzing motion trajectories'.\""
    },
    {
        "raw_sentence": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "feature points",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on 'presents' with 'This work'. Entity 2 ('feature points') is the object, depending on 'trajectories' with 'motion'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'technique' is described as being used for detecting reflections by analyzing the motion trajectories of 'feature points'.\"",
        "sdp_path_text": "technique → for → detecting → by → analyzing → trajectories → of → points",
        "sentence": "The technique detects reflections by analyzing trajectories of feature points.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'detects'. Entity 2 ('feature points') is the object of the preposition 'of', depending on 'trajectories'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'detects' and the prepositional phrase 'of feature points'.\""
    },
    {
        "raw_sentence": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points .",
        "ner_pair": [
            [
                "detecting reflections in image sequences",
                "Task"
            ],
            [
                "motion trajectories",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detecting reflections in image sequences') is the object of the preposition 'for', depending on 'technique'. Entity 2 ('motion trajectories') is the object of the preposition 'of', depending on 'analyzing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger process described in the sentence.\"",
        "sdp_path_text": "detecting → by → analyzing → trajectories",
        "sentence": "Detecting reflections in image sequences is achieved by analyzing motion trajectories.",
        "sentence_llm_dp_info": "\"Entity 1 ('detecting reflections in image sequences') is the subject, depending on the verb 'is achieved'. Entity 2 ('motion trajectories') is the object of the preposition 'by', depending on 'analyzing' in the phrase 'by analyzing motion trajectories'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieved' and the prepositional phrase 'by analyzing'.\""
    },
    {
        "raw_sentence": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points .",
        "ner_pair": [
            [
                "detecting reflections in image sequences",
                "Task"
            ],
            [
                "feature points",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detecting reflections in image sequences') is the object of the preposition 'for', depending on 'technique'. Entity 2 ('feature points') is the object of the preposition 'of', depending on 'trajectories'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the technique's purpose and method.\"",
        "sdp_path_text": "detecting → by → analyzing → trajectories → of → points",
        "sentence": "Detecting reflections in image sequences is done by analyzing the trajectories of feature points.",
        "sentence_llm_dp_info": "\"Entity 1 ('detecting reflections in image sequences') is the subject, depending on the verb 'is done'. Entity 2 ('feature points') is the object of the preposition 'of', depending on 'trajectories'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'analyzing' and the prepositional phrase 'the trajectories of feature points'.\""
    },
    {
        "raw_sentence": "This work presents an automated technique for detecting reflections in image sequences by analyzing motion trajectories of feature points .",
        "ner_pair": [
            [
                "feature points",
                "OtherScientificTerm"
            ],
            [
                "motion trajectories",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature points') is the object of the preposition 'of', depending on 'motion trajectories'. Entity 2 ('motion trajectories') is the object of the preposition 'of', depending on the verb phrase 'analyzing motion trajectories'. There is a direct dependency between Entity 1 and Entity 2, where 'feature points' modifies 'motion trajectories'.\"",
        "sdp_path_text": "points → of → trajectories",
        "sentence": "Feature points have motion trajectories analyzed in this technique.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature points') is the subject, depending on the verb 'have'. Entity 2 ('motion trajectories') is the object, depending on 'have' with 'feature points'. There is a direct dependency between Entity 1 and Entity 2, as 'motion trajectories' is the object of the verb 'have' that is associated with 'feature points'.\""
    },
    {
        "raw_sentence": "It models reflection as regions containing two different layers moving over each other .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "reflection",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'models'. Entity 2 ('reflection') is the object, depending on 'models' with 'It'. There is a direct dependency between Entity 1 and Entity 2, where 'It' models 'reflection'.\"",
        "sdp_path_text": "It → models → reflection",
        "sentence": "It models reflection.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'models'. Entity 2 ('reflection') is the object, depending on the verb 'models'. There is a direct dependency between Entity 1 and Entity 2, as 'It' is the subject that performs the action of modeling 'reflection'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "priors",
                "OtherScientificTerm"
            ],
            [
                "sparse and dense detection maps",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the verb 'use', depending on 'We'. Entity 2 ('sparse and dense detection maps') is the object of the verb 'generate', depending on 'We'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "priors → use → generate → maps",
        "sentence": "We use novel priors to generate sparse and dense detection maps.",
        "sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the verb 'use', depending on 'use' in the phrase 'use novel priors'. Entity 2 ('sparse and dense detection maps') is the object of the infinitive 'to generate', depending on 'generate' in the phrase 'to generate sparse and dense detection maps'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the infinitive 'to generate'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "priors",
                "OtherScientificTerm"
            ],
            [
                "detection rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the verb 'use', depending on 'We'. Entity 2 ('detection rate') is the object of the preposition 'with', depending on 'show' in the phrase 'show high detection rate'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence describing different aspects of the process and outcomes.\"",
        "sdp_path_text": "priors → use → show → rate",
        "sentence": "The use of novel priors shows a high detection rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the preposition 'of', depending on 'use'. Entity 2 ('detection rate') is the subject complement, depending on 'shows' with 'priors'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'shows'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "priors",
                "OtherScientificTerm"
            ],
            [
                "pathological motion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the verb 'use', depending on 'use' in the clause 'We use novel priors'. Entity 2 ('pathological motion') is part of a prepositional phrase, depending on 'rejection' in the phrase 'rejection to pathological motion and occlusion'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "priors → use → show → rate → with → rejection → to → motion",
        "sentence": "Our use of novel priors shows high detection rate with rejection to pathological motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the preposition 'of', depending on 'use'. Entity 2 ('pathological motion') is the object of the preposition 'to', depending on 'rejection'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the outcome of the use of novel priors.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "priors",
                "OtherScientificTerm"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the verb 'use', depending on 'We'. Entity 2 ('occlusion') is the object of the preposition 'to', part of the phrase 'rejection to pathological motion and occlusion', which modifies 'high detection rate'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "priors → use → show → rate → with → rejection → to → motion → occlusion",
        "sentence": "Our use of novel priors shows high detection rate with rejection to occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('priors') is the object of the preposition 'of', depending on 'use'. Entity 2 ('occlusion') is the object of the preposition 'to', depending on 'rejection'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the outcome of the use of novel priors.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "sparse and dense detection maps",
                "OtherScientificTerm"
            ],
            [
                "detection rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sparse and dense detection maps') is the object, depending on 'generate' with 'We'. Entity 2 ('detection rate') is the object, depending on 'show' with 'results'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "maps → generate → use → show → rate",
        "sentence": "Sparse and dense detection maps show a high detection rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('sparse and dense detection maps') is the subject, depending on the verb 'show'. Entity 2 ('detection rate') is the object, depending on the verb 'show'. There is a direct dependency between Entity 1 and Entity 2, as 'sparse and dense detection maps' shows 'a high detection rate'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "sparse and dense detection maps",
                "OtherScientificTerm"
            ],
            [
                "pathological motion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sparse and dense detection maps') is the object, depending on 'generate' with 'We'. Entity 2 ('pathological motion') is part of the prepositional phrase 'to pathological motion', depending on 'rejection'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "maps → generate → use → show → rate → with → rejection → to → motion",
        "sentence": "Detection maps show high detection rate with rejection to pathological motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('sparse and dense detection maps') is the subject, depending on the verb 'show'. Entity 2 ('pathological motion') is the object of the preposition 'to', depending on 'rejection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'show' and the prepositional phrase 'with rejection to'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "sparse and dense detection maps",
                "OtherScientificTerm"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sparse and dense detection maps') is the object, depending on 'generate' with 'We'. Entity 2 ('occlusion') is the object of the preposition 'to', depending on 'rejection' in the phrase 'rejection to pathological motion and occlusion'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "maps → generate → use → show → rate → with → rejection → to → motion → occlusion",
        "sentence": "Sparse and dense detection maps show rejection to occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('sparse and dense detection maps') is the subject, depending on the verb 'show'. Entity 2 ('occlusion') is the object of the preposition 'to', depending on 'rejection'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the predicate 'show rejection to'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "detection rate",
                "Metric"
            ],
            [
                "pathological motion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection rate') is the object, depending on 'show' with 'results'. Entity 2 ('pathological motion') is part of the prepositional phrase 'to pathological motion', which modifies 'rejection'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "rate → with → rejection → to → motion",
        "sentence": "The detection rate shows rejection to pathological motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection rate') is the subject, depending on the verb 'shows'. Entity 2 ('pathological motion') is the object, depending on the verb 'rejection'. There is a direct dependency between Entity 1 and Entity 2, as 'pathological motion' is the object of the action 'rejection' that is shown by 'detection rate'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "detection rate",
                "Metric"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('detection rate') is the object of the preposition 'with', depending on 'show' in the clause 'results show high detection rate'. Entity 2 ('occlusion') is the object of the preposition 'to', depending on 'rejection' in the phrase 'rejection to pathological motion and occlusion'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "rate → with → rejection → to → motion → occlusion",
        "sentence": "Detection rate shows high performance with rejection to occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('detection rate') is the subject, depending on 'shows' with 'high performance'. Entity 2 ('occlusion') is the object of the preposition 'to', depending on 'rejection'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'with rejection to occlusion'.\""
    },
    {
        "raw_sentence": "We use novel priors , generate sparse and dense detection maps and our results show high detection rate with rejection to pathological motion and occlusion .",
        "ner_pair": [
            [
                "pathological motion",
                "OtherScientificTerm"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pathological motion') is part of a coordination, depending on 'rejection' with 'to'. Entity 2 ('occlusion') is also part of the same coordination, depending on 'to' with 'rejection'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'to' in the phrase 'rejection to pathological motion and occlusion'.\"",
        "sdp_path_text": "motion → occlusion",
        "sentence": "Our results show rejection to pathological motion and occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('pathological motion') is part of a conjunction, depending on 'and' with 'occlusion'. Entity 2 ('occlusion') is also part of the same conjunction, depending on 'and' with 'pathological motion'. Both are objects of the preposition 'to', which depends on 'rejection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and their shared role as objects of the preposition 'to'.\""
    },
    {
        "raw_sentence": "This paper considers the problem of reconstructing the motion of a 3D articulated tree from 2D point correspondences subject to some temporal prior .",
        "ner_pair": [
            [
                "2D point correspondences",
                "OtherScientificTerm"
            ],
            [
                "reconstructing the motion of a 3D articulated tree",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('2D point correspondences') is the object of the preposition 'from', depending on 'from' in the phrase 'from 2D point correspondences'. Entity 2 ('reconstructing the motion of a 3D articulated tree') is the object of the preposition 'of', depending on 'problem' in the phrase 'the problem of reconstructing the motion of a 3D articulated tree'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the problem being considered.\"",
        "sdp_path_text": "correspondences → from → reconstructing",
        "sentence": "2D point correspondences are used for reconstructing the motion of a 3D articulated tree.",
        "sentence_llm_dp_info": "\"Entity 1 ('2D point correspondences') is the subject, depending on the verb 'are used'. Entity 2 ('reconstructing the motion of a 3D articulated tree') is the complement, depending on the verb 'are used' through the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are used' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper considers the problem of reconstructing the motion of a 3D articulated tree from 2D point correspondences subject to some temporal prior .",
        "ner_pair": [
            [
                "reconstructing the motion of a 3D articulated tree",
                "Task"
            ],
            [
                "temporal prior",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstructing the motion of a 3D articulated tree') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('temporal prior') is the object of the preposition 'to', depending on 'subject'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the problem considered in the paper.\"",
        "sdp_path_text": "reconstructing → from → correspondences → subject → to → prior",
        "sentence": "Reconstructing the motion of a 3D articulated tree is subject to a temporal prior.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstructing the motion of a 3D articulated tree') is the subject, depending on the verb 'is'. Entity 2 ('temporal prior') is the object of the preposition 'to', depending on 'to' in the phrase 'to a temporal prior'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "This paper considers the problem of reconstructing the motion of a 3D articulated tree from 2D point correspondences subject to some temporal prior .",
        "ner_pair": [
            [
                "2D point correspondences",
                "OtherScientificTerm"
            ],
            [
                "temporal prior",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('2D point correspondences') is the object of the preposition 'from', depending on 'reconstructing'. Entity 2 ('temporal prior') is the object of the preposition 'to', depending on 'subject'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the problem being considered.\"",
        "sdp_path_text": "correspondences → subject → to → prior",
        "sentence": "2D point correspondences are subject to a temporal prior.",
        "sentence_llm_dp_info": "\"Entity 1 ('2D point correspondences') is the subject, depending on the verb 'are'. Entity 2 ('temporal prior') is the object of the preposition 'to', depending on 'to' in the phrase 'to a temporal prior'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'to'.\""
    },
    {
        "raw_sentence": "Hitherto , smooth motion has been encouraged using a trajectory basis , yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames .",
        "ner_pair": [
            [
                "trajectory basis",
                "OtherScientificTerm"
            ],
            [
                "smooth motion",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trajectory basis') is the object of the preposition 'using', depending on 'encouraged'. Entity 2 ('smooth motion') is the subject, depending on the auxiliary verb 'has been' in the phrase 'has been encouraged'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'encouraged' and the preposition 'using'.\"",
        "sdp_path_text": "basis → using → encouraged → motion",
        "sentence": "Using a trajectory basis encourages smooth motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('trajectory basis') is the object of the preposition 'Using', depending on 'Using'. Entity 2 ('smooth motion') is the complement of the verb 'encourages', depending on 'encourages'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'encourages' which indicates that Entity 1 influences Entity 2.\""
    },
    {
        "raw_sentence": "Hitherto , smooth motion has been encouraged using a trajectory basis , yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames .",
        "ner_pair": [
            [
                "smooth motion",
                "OtherScientificTerm"
            ],
            [
                "hard combinatorial problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smooth motion') is the subject, depending on the verb 'encouraged'. Entity 2 ('hard combinatorial problem') is the subject complement, depending on the verb 'yielding'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the causal relationship described by the verbs 'encouraged' and 'yielding'.\"",
        "sdp_path_text": "motion → encouraged → yielding → problem",
        "sentence": "Smooth motion encouraged yields a hard combinatorial problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('smooth motion') is the subject, depending on the verb 'encouraged'. Entity 2 ('hard combinatorial problem') is the subject complement, depending on the verb 'yields'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'encouraged' and 'yields' which describe the relationship where the encouragement of smooth motion leads to a hard combinatorial problem.\""
    },
    {
        "raw_sentence": "Hitherto , smooth motion has been encouraged using a trajectory basis , yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames .",
        "ner_pair": [
            [
                "smooth motion",
                "OtherScientificTerm"
            ],
            [
                "time complexity",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('smooth motion') is the subject, depending on the verb 'encouraged'. Entity 2 ('time complexity') is the subject of the clause 'time complexity growing exponentially', depending on the verb 'growing'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "motion → encouraged → yielding → problem → with → growing → complexity",
        "sentence": "Smooth motion encouragement yields a problem with growing time complexity.",
        "sentence_llm_dp_info": "\"Entity 1 ('smooth motion') is part of a compound noun, depending on 'encouragement' with 'motion encouragement'. Entity 2 ('time complexity') is the object of the preposition 'with', depending on 'with' in the phrase 'with growing time complexity'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the outcome of the encouragement.\""
    },
    {
        "raw_sentence": "Hitherto , smooth motion has been encouraged using a trajectory basis , yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames .",
        "ner_pair": [
            [
                "trajectory basis",
                "OtherScientificTerm"
            ],
            [
                "hard combinatorial problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trajectory basis') is the object of the preposition 'using', depending on the verb 'encouraged'. Entity 2 ('hard combinatorial problem') is the subject complement, depending on the verb 'yielding'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, connected through the verbs 'encouraged' and 'yielding'.\"",
        "sdp_path_text": "basis → using → encouraged → yielding → problem",
        "sentence": "Using a trajectory basis yields a hard combinatorial problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('trajectory basis') is the subject, depending on the verb 'yields'. Entity 2 ('hard combinatorial problem') is the direct object, depending on the verb 'yields'. There is a direct dependency between Entity 1 and Entity 2, as 'trajectory basis' directly yields 'a hard combinatorial problem'.\""
    },
    {
        "raw_sentence": "Hitherto , smooth motion has been encouraged using a trajectory basis , yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames .",
        "ner_pair": [
            [
                "trajectory basis",
                "OtherScientificTerm"
            ],
            [
                "time complexity",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trajectory basis') is the object of the preposition 'using', depending on 'encouraged'. Entity 2 ('time complexity') is the subject of the clause, depending on 'growing'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger context where 'trajectory basis' contributes to the problem that affects 'time complexity'.\"",
        "sdp_path_text": "basis → using → encouraged → yielding → problem → with → growing → complexity",
        "sentence": "Using a trajectory basis yields a problem with growing time complexity.",
        "sentence_llm_dp_info": "\"Entity 1 ('trajectory basis') is the subject, depending on the verb 'yields'. Entity 2 ('time complexity') is the object of the preposition 'with', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'yields' and the prepositional phrase 'with growing time complexity'.\""
    },
    {
        "raw_sentence": "Hitherto , smooth motion has been encouraged using a trajectory basis , yielding a hard combinatorial problem with time complexity growing exponentially in the number of frames .",
        "ner_pair": [
            [
                "time complexity",
                "Metric"
            ],
            [
                "hard combinatorial problem",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('time complexity') is the subject complement, depending on the verb 'growing'. Entity 2 ('hard combinatorial problem') is the object, depending on the verb 'yielding'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the outcome of using a trajectory basis.\"",
        "sdp_path_text": "complexity → growing → with → problem",
        "sentence": "Time complexity grows with the hard combinatorial problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('time complexity') is the subject, depending on the verb 'grows'. Entity 2 ('hard combinatorial problem') is the object of the preposition 'with', depending on 'with' in the phrase 'with the hard combinatorial problem'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Branch and bound strategies have previously attempted to curb this complexity whilst maintaining global optimality .",
        "ner_pair": [
            [
                "Branch and bound strategies",
                "Method"
            ],
            [
                "complexity",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Branch and bound strategies') is the subject, depending on the verb 'have attempted'. Entity 2 ('complexity') is the object of the verb 'curb', depending on 'curb' in the phrase 'to curb this complexity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'curb' which is part of the action that Entity 1 attempts to perform.\"",
        "sdp_path_text": "strategies → attempted → curb → complexity",
        "sentence": "Branch and bound strategies have attempted to curb complexity.",
        "sentence_llm_dp_info": "\"Entity 1 ('Branch and bound strategies') is the subject, depending on the verb 'have attempted'. Entity 2 ('complexity') is the object, depending on the verb 'curb'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action 'have attempted to curb'.\""
    },
    {
        "raw_sentence": "Branch and bound strategies have previously attempted to curb this complexity whilst maintaining global optimality .",
        "ner_pair": [
            [
                "global optimality",
                "OtherScientificTerm"
            ],
            [
                "Branch and bound strategies",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('global optimality') is the object of the gerund-participle 'maintaining', depending on 'maintaining'. Entity 2 ('Branch and bound strategies') is the subject, depending on the verb 'have attempted'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'whilst maintaining global optimality'.\"",
        "sdp_path_text": "optimality → maintaining → curb → attempted → strategies",
        "sentence": "Branch and bound strategies attempt to maintain global optimality while curbing complexity.",
        "sentence_llm_dp_info": "\"Entity 1 ('global optimality') is the object, depending on 'maintain' with 'strategies'. Entity 2 ('Branch and bound strategies') is the subject, depending on the verb 'attempt'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'maintain'.\""
    },
    {
        "raw_sentence": "Branch and bound strategies have previously attempted to curb this complexity whilst maintaining global optimality .",
        "ner_pair": [
            [
                "complexity",
                "Generic"
            ],
            [
                "global optimality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('complexity') is the object of the verb 'curb', depending on 'curb' in the phrase 'to curb this complexity'. Entity 2 ('global optimality') is the object of the gerund 'maintaining', depending on 'maintaining' in the phrase 'maintaining global optimality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the actions taken by 'branch and bound strategies'.\"",
        "sdp_path_text": "complexity → curb → maintaining → optimality",
        "sentence": "Branch and bound strategies attempt to curb complexity while maintaining global optimality.",
        "sentence_llm_dp_info": "\"Entity 1 ('complexity') is the object of the verb 'curb', depending on 'curb' in the phrase 'curb complexity'. Entity 2 ('global optimality') is the object of the gerund 'maintaining', depending on 'maintaining' in the phrase 'maintaining global optimality'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "However , they provide no guarantee of being more efficient than exhaustive search .",
        "ner_pair": [
            [
                "they",
                "Generic"
            ],
            [
                "exhaustive search",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('they') is the subject, depending on the verb 'provide'. Entity 2 ('exhaustive search') is the complement of the preposition 'than', depending on 'than' in the phrase 'than exhaustive search'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure involving the verb 'provide' and the preposition 'than'.\"",
        "sdp_path_text": "they → provide → guarantee → of → being → efficient → than → search",
        "sentence": "They provide no guarantee of being more efficient than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('they') is the subject, depending on the verb 'provide'. Entity 2 ('exhaustive search') is the complement, depending on the comparative adjective 'efficient'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparison established by 'more efficient than'.\""
    },
    {
        "raw_sentence": "Inspired by recent work which reconstructs general trajectories using compact high-pass filters , we develop a dynamic programming approach which scales linearly in the number of frames , leveraging the intrinsically local nature of filter interactions .",
        "ner_pair": [
            [
                "compact high-pass filters",
                "Method"
            ],
            [
                "dynamic programming approach",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compact high-pass filters') is the object of the preposition 'using', depending on 'reconstructs'. Entity 2 ('dynamic programming approach') is the object of the verb 'develop', depending on the pronoun 'we'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the sentence, linked by the context of the development inspired by the work mentioned.\"",
        "sdp_path_text": "filters → using → reconstructs → work → by → Inspired → develop → approach",
        "sentence": "Inspired by work using compact high-pass filters, we develop a dynamic programming approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('compact high-pass filters') is the object of the preposition 'by', depending on 'Inspired'. Entity 2 ('dynamic programming approach') is the object, depending on the verb 'develop'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure influenced by the main clause 'we develop'.\""
    },
    {
        "raw_sentence": "Inspired by recent work which reconstructs general trajectories using compact high-pass filters , we develop a dynamic programming approach which scales linearly in the number of frames , leveraging the intrinsically local nature of filter interactions .",
        "ner_pair": [
            [
                "compact high-pass filters",
                "Method"
            ],
            [
                "filter interactions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compact high-pass filters') is the object of the preposition 'using', depending on 'reconstructs' in the clause 'which reconstructs general trajectories using compact high-pass filters'. Entity 2 ('filter interactions') is the object of the preposition 'of', depending on 'nature' in the phrase 'the intrinsically local nature of filter interactions'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence describing methods and properties related to filtering and interaction.\"",
        "sdp_path_text": "filters → using → reconstructs → work → by → Inspired → develop → approach → scales → leveraging → nature → of → interactions",
        "sentence": "We develop an approach inspired by work using compact high-pass filters, leveraging the local nature of filter interactions.",
        "sentence_llm_dp_info": "\"Entity 1 ('compact high-pass filters') is the object of the preposition 'by', depending on 'inspired'. Entity 2 ('filter interactions') is the object of the preposition 'of', depending on 'nature'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the inspiration and characteristics of the developed approach.\""
    },
    {
        "raw_sentence": "Inspired by recent work which reconstructs general trajectories using compact high-pass filters , we develop a dynamic programming approach which scales linearly in the number of frames , leveraging the intrinsically local nature of filter interactions .",
        "ner_pair": [
            [
                "dynamic programming approach",
                "Method"
            ],
            [
                "filter interactions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dynamic programming approach') is the subject, depending on the verb 'develop' with 'we'. Entity 2 ('filter interactions') is the object of the preposition 'of', depending on 'nature' in the phrase 'the intrinsically local nature of filter interactions'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause.\"",
        "sdp_path_text": "approach → scales → leveraging → nature → of → interactions",
        "sentence": "The dynamic programming approach scales leveraging the nature of filter interactions.",
        "sentence_llm_dp_info": "\"Entity 1 ('dynamic programming approach') is the subject, depending on the verb 'scales'. Entity 2 ('filter interactions') is the object of the preposition 'of', depending on 'nature'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'leveraging the nature of filter interactions'.\""
    },
    {
        "raw_sentence": "Extension to affine projection enables reconstruction without estimating cameras .",
        "ner_pair": [
            [
                "affine projection",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine projection') is the object of the preposition 'to', depending on 'Extension'. Entity 2 ('reconstruction') is the subject complement, depending on the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the enabling action described by the verb 'enables'.\"",
        "sdp_path_text": "projection → to → Extension → enables → reconstruction",
        "sentence": "Extension to affine projection enables reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine projection') is the object of the preposition 'to', depending on 'Extension'. Entity 2 ('reconstruction') is the object, depending on the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables', which indicates that the extension to 'affine projection' facilitates 'reconstruction'.\""
    },
    {
        "raw_sentence": "Extension to affine projection enables reconstruction without estimating cameras .",
        "ner_pair": [
            [
                "affine projection",
                "Method"
            ],
            [
                "estimating cameras",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine projection') is part of the noun phrase 'extension to affine projection', where it depends on 'to' as the object of the preposition. Entity 2 ('estimating cameras') is the complement of the preposition 'without', indicating an action that is not required for the reconstruction. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through prepositional phrases.\"",
        "sdp_path_text": "projection → to → Extension → enables → without → estimating",
        "sentence": "Extension to affine projection enables reconstruction without estimating cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine projection') is the object of the preposition 'to', depending on 'Extension'. Entity 2 ('estimating cameras') is the complement of the preposition 'without', depending on 'without'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Extension to affine projection enables reconstruction without estimating cameras .",
        "ner_pair": [
            [
                "reconstruction",
                "Task"
            ],
            [
                "estimating cameras",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is the object, depending on 'enables' with 'Extension to affine projection'. Entity 2 ('estimating cameras') is the complementizer, depending on 'without' in the phrase 'without estimating cameras'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the extension enables.\"",
        "sdp_path_text": "reconstruction → enables → without → estimating",
        "sentence": "Reconstruction is enabled without estimating cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is the subject, depending on the verb 'is enabled'. Entity 2 ('estimating cameras') is the complementizer, depending on the negation 'without'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the negation 'without'.\""
    },
    {
        "raw_sentence": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .",
        "ner_pair": [
            [
                "Topical blog post retrieval",
                "Task"
            ],
            [
                "ranking blog posts",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Topical blog post retrieval') is the subject, depending on the verb 'is'. Entity 2 ('ranking blog posts') is the object, depending on the preposition 'of' in the phrase 'the task of ranking blog posts'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate 'is the task of'.\"",
        "sdp_path_text": "retrieval → is → task → of → ranking",
        "sentence": "Topical blog post retrieval is the task of ranking blog posts.",
        "sentence_llm_dp_info": "\"Entity 1 ('Topical blog post retrieval') is the subject, depending on the verb 'is'. Entity 2 ('ranking blog posts') is the complement, depending on the noun 'task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' and the noun 'task' which defines what the task is.\""
    },
    {
        "raw_sentence": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .",
        "ner_pair": [
            [
                "Topical blog post retrieval",
                "Task"
            ],
            [
                "blog posts",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Topical blog post retrieval') is the subject, depending on the verb 'is'. Entity 2 ('blog posts') is the object, depending on 'ranking' with the preposition 'of' in the phrase 'of ranking blog posts'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'blog posts' are part of the task described by 'Topical blog post retrieval'.\"",
        "sdp_path_text": "retrieval → is → task → of → ranking → posts",
        "sentence": "Topical blog post retrieval is the task of ranking blog posts.",
        "sentence_llm_dp_info": "\"Entity 1 ('Topical blog post retrieval') is the subject, depending on the verb 'is'. Entity 2 ('blog posts') is the object, depending on 'ranking' with the preposition 'of' in the phrase 'ranking of blog posts'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate 'is the task of ranking'.\""
    },
    {
        "raw_sentence": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .",
        "ner_pair": [
            [
                "Topical blog post retrieval",
                "Task"
            ],
            [
                "relevance",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Topical blog post retrieval') is the subject, depending on the verb 'is'. Entity 2 ('relevance') is the object of the preposition 'for', depending on 'for' in the phrase 'for a given topic'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'with respect to their relevance for a given topic'.\"",
        "sdp_path_text": "retrieval → is → task → of → ranking → with → respect → to → relevance",
        "sentence": "Topical blog post retrieval ranks posts based on relevance.",
        "sentence_llm_dp_info": "\"Entity 1 ('Topical blog post retrieval') is the subject, depending on the verb 'ranks'. Entity 2 ('relevance') is the object of the preposition 'based on', depending on 'based' in the phrase 'based on relevance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on relevance'.\""
    },
    {
        "raw_sentence": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .",
        "ner_pair": [
            [
                "ranking blog posts",
                "Task"
            ],
            [
                "relevance",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ranking blog posts') is the object of the preposition 'of', depending on 'task'. Entity 2 ('relevance') is the object of the preposition 'to', depending on 'for' in the phrase 'for a given topic'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the description of the task.\"",
        "sdp_path_text": "ranking → with → respect → to → relevance",
        "sentence": "Ranking blog posts is based on their relevance.",
        "sentence_llm_dp_info": "\"Entity 1 ('ranking blog posts') is the subject, depending on the verb 'is'. Entity 2 ('relevance') is the object of the preposition 'on', depending on 'based' in the phrase 'based on'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .",
        "ner_pair": [
            [
                "relevance",
                "Metric"
            ],
            [
                "blog posts",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relevance') is the object of the preposition 'for', depending on 'for' in the phrase 'for a given topic'. Entity 2 ('blog posts') is the subject of the clause, depending on 'ranking' with 'task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'blog posts' are ranked based on their 'relevance'.\"",
        "sdp_path_text": "relevance → to → respect → with → ranking → posts",
        "sentence": "Relevance of blog posts is determined by their ranking.",
        "sentence_llm_dp_info": "\"Entity 1 ('relevance') is the subject, depending on the verb 'is determined'. Entity 2 ('blog posts') is the object of the preposition 'of', depending on 'relevance' in the phrase 'relevance of blog posts'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process .",
        "ner_pair": [
            [
                "textual credibility indicators",
                "OtherScientificTerm"
            ],
            [
                "topical blog post retrieval",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('textual credibility indicators') is the object, depending on 'incorporate' with 'we'. Entity 2 ('topical blog post retrieval') is the object of the preposition 'for', depending on 'improve' in the phrase 'to improve topical blog post retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose and method of the improvement.\"",
        "sdp_path_text": "indicators → incorporate → improve → retrieval",
        "sentence": "Textual credibility indicators are incorporated to improve topical blog post retrieval.",
        "sentence_llm_dp_info": "\"Entity 1 ('textual credibility indicators') is the subject, depending on the verb 'incorporated'. Entity 2 ('topical blog post retrieval') is the object of the preposition 'to', depending on 'to' in the phrase 'to improve topical blog post retrieval'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'improve'.\""
    },
    {
        "raw_sentence": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process .",
        "ner_pair": [
            [
                "topical blog post retrieval",
                "Task"
            ],
            [
                "retrieval process",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('topical blog post retrieval') is the object of the preposition 'To', depending on the verb 'improve'. Entity 2 ('retrieval process') is the object of the preposition 'in', depending on 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the improvement and incorporation actions.\"",
        "sdp_path_text": "retrieval → improve → incorporate → in → process",
        "sentence": "To improve topical blog post retrieval, we incorporate indicators in the retrieval process.",
        "sentence_llm_dp_info": "\"Entity 1 ('topical blog post retrieval') is the object of the preposition 'To', depending on the verb 'improve'. Entity 2 ('retrieval process') is the object, depending on the verb 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the purpose and action described in the sentence.\""
    },
    {
        "raw_sentence": "To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process .",
        "ner_pair": [
            [
                "textual credibility indicators",
                "OtherScientificTerm"
            ],
            [
                "retrieval process",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('textual credibility indicators') is the object, depending on 'incorporate' with 'we'. Entity 2 ('retrieval process') is the object of the preposition 'in', depending on 'in' in the phrase 'in the retrieval process'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporate'.\"",
        "sdp_path_text": "indicators → incorporate → in → process",
        "sentence": "Textual credibility indicators are incorporated in the retrieval process.",
        "sentence_llm_dp_info": "\"Entity 1 ('textual credibility indicators') is the subject, depending on the verb 'are incorporated'. Entity 2 ('retrieval process') is the object of the preposition 'in', depending on 'in' in the phrase 'in the retrieval process'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We consider two groups of indicators : post level -LRB- determined using information about individual blog posts only -RRB- and blog level -LRB- determined using information from the underlying blogs -RRB- .",
        "ner_pair": [
            [
                "indicators",
                "Generic"
            ],
            [
                "blog posts",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object, depending on the verb 'consider' with 'We'. Entity 2 ('blog posts') is part of a modifying phrase, depending on 'determined' within the clause 'determined using information about individual blog posts only'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'blog posts' is part of the definition or description of one type of 'indicators'.\"",
        "sdp_path_text": "indicators → of → groups → level → determined → using → information → about → posts",
        "sentence": "Indicators are determined using information about blog posts.",
        "sentence_llm_dp_info": "\"Entity 1 ('indicators') is the subject, depending on the verb 'determined'. Entity 2 ('blog posts') is the object of the preposition 'about', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'using information about blog posts'.\""
    },
    {
        "raw_sentence": "We consider two groups of indicators : post level -LRB- determined using information about individual blog posts only -RRB- and blog level -LRB- determined using information from the underlying blogs -RRB- .",
        "ner_pair": [
            [
                "indicators",
                "Generic"
            ],
            [
                "blogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object of the verb 'consider', depending on 'We' as the subject. Entity 2 ('blogs') is part of a compound noun, depending on 'level' in the phrase 'blog level'. There is no direct dependency between Entity 1 and Entity 2; they are related through the structure of the sentence where both are discussed as types of indicators.\"",
        "sdp_path_text": "indicators → of → groups → level → level → determined → using → information → from → blogs",
        "sentence": "Indicators are determined using information from blogs.",
        "sentence_llm_dp_info": "\"Entity 1 ('indicators') is the subject, depending on the verb 'determined'. Entity 2 ('blogs') is the object of the preposition 'from', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from' and the noun 'information'.\""
    },
    {
        "raw_sentence": "We consider two groups of indicators : post level -LRB- determined using information about individual blog posts only -RRB- and blog level -LRB- determined using information from the underlying blogs -RRB- .",
        "ner_pair": [
            [
                "blog posts",
                "Material"
            ],
            [
                "blogs",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('blog posts') is part of a modifying clause, depending on 'information' through the preposition 'about' in the phrase 'information about individual blog posts only'. Entity 2 ('blogs') is also part of a modifying clause, depending on 'information' through the preposition 'from' in the phrase 'information from the underlying blogs'. There is no direct dependency between Entity 1 and Entity 2; both are related to the concept of 'information' but in different contexts (post level vs. blog level).\"",
        "sdp_path_text": "posts → about → information → using → determined → level → level → determined → using → information → from → blogs",
        "sentence": "Information about blog posts determines post level, while information from blogs determines blog level.",
        "sentence_llm_dp_info": "\"Entity 1 ('blog posts') is the object of the preposition 'about', depending on 'information'. It also modifies 'post level' through the verb 'determines'. Entity 2 ('blogs') is the object of the preposition 'from', depending on 'information'. It modifies 'blog level' through the verb 'determines'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the determination of levels through similar structures involving the verb 'determines'.\""
    },
    {
        "raw_sentence": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .",
        "ner_pair": [
            [
                "indicators",
                "Generic"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object, depending on 'estimate' with 'how to estimate these indicators'. Entity 2 ('them') is a pronoun, depending on 'integrate' with 'how to integrate them into a retrieval approach'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers back to 'indicators'.\"",
        "sdp_path_text": "indicators → estimate → integrate → them",
        "sentence": "We describe how to estimate indicators and integrate them into a retrieval approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object, depending on 'estimate' with 'how to estimate'. Entity 2 ('them') is a pronoun, referring back to 'indicators' and acting as the object of 'integrate' in the clause 'integrate them into a retrieval approach'. There is a direct dependency between Entity 1 and Entity 2, where 'them' refers back to 'indicators'.\""
    },
    {
        "raw_sentence": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .",
        "ner_pair": [
            [
                "indicators",
                "Generic"
            ],
            [
                "retrieval approach",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object of the verb 'estimate', depending on 'estimate' in the clause 'how to estimate these indicators'. Entity 2 ('retrieval approach') is the object of the preposition 'into', depending on 'integrate' in the clause 'how to integrate them into a retrieval approach'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the clauses describing actions (estimation and integration) that are related to the main verb 'describe'.\"",
        "sdp_path_text": "indicators → estimate → integrate → into → approach",
        "sentence": "Indicators are estimated and integrated into a retrieval approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('indicators') is the subject, depending on the verb 'estimated'. Entity 2 ('retrieval approach') is the object of the preposition 'into', depending on 'integrated'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'integrated' and the preposition 'into'.\""
    },
    {
        "raw_sentence": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .",
        "ner_pair": [
            [
                "indicators",
                "Generic"
            ],
            [
                "language models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object of the verb 'estimate', depending on 'estimate' in the phrase 'estimate these indicators'. Entity 2 ('language models') is the object of the preposition 'on', depending on 'based' in the phrase 'based on language models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing different aspects of the retrieval approach.\"",
        "sdp_path_text": "indicators → estimate → integrate → into → approach → based → on → models",
        "sentence": "We describe how to estimate indicators and integrate them into an approach based on language models.",
        "sentence_llm_dp_info": "\"Entity 1 ('indicators') is the object of the verb 'estimate', depending on 'estimate' in the phrase 'estimate indicators'. Entity 2 ('language models') is the object of the preposition 'on', depending on 'based' in the phrase 'based on language models'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing different aspects of the approach.\""
    },
    {
        "raw_sentence": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "retrieval approach",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'integrate', depending on 'integrate' in the clause 'how to integrate them'. Entity 2 ('retrieval approach') is the object of the preposition 'into', depending on 'into' in the phrase 'into a retrieval approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'integrate'.\"",
        "sdp_path_text": "them → integrate → into → approach",
        "sentence": "We describe how to integrate them into a retrieval approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on the verb 'integrate'. Entity 2 ('retrieval approach') is the object of the preposition 'into', depending on 'into' in the phrase 'into a retrieval approach'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'integrate'.\""
    },
    {
        "raw_sentence": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .",
        "ner_pair": [
            [
                "language models",
                "Method"
            ],
            [
                "them",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('language models') is the object of the preposition 'based on', depending on 'based'. Entity 2 ('them') is the object of the verb 'integrate', depending on 'integrate'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as 'them' refers back to 'indicators' which are integrated into an approach that is based on 'language models'.\"",
        "sdp_path_text": "models → on → based → approach → into → integrate → them",
        "sentence": "Integrate them into a retrieval approach based on language models.",
        "sentence_llm_dp_info": "\"Entity 1 ('language models') is the object of the preposition 'based on', depending on 'approach'. Entity 2 ('them') is the object of the verb 'integrate', depending on 'integrate'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'them' is integrated into an 'approach' that is based on 'language models'.\""
    },
    {
        "raw_sentence": "We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .",
        "ner_pair": [
            [
                "retrieval approach",
                "Method"
            ],
            [
                "language models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('retrieval approach') is the object of the preposition 'into', depending on 'integrate' with 'how to integrate them into a retrieval approach'. Entity 2 ('language models') is the complement of the preposition 'based', depending on 'approach' in the phrase 'a retrieval approach based on language models'. There is a direct dependency between Entity 1 and Entity 2, as 'language models' modifies 'retrieval approach'.\"",
        "sdp_path_text": "approach → based → on → models",
        "sentence": "The retrieval approach is based on language models.",
        "sentence_llm_dp_info": "\"Entity 1 ('retrieval approach') is the subject, depending on the verb 'is'. Entity 2 ('language models') is the object of the preposition 'on', depending on 'based' in the phrase 'based on language models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' and the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them .",
        "ner_pair": [
            [
                "TREC Blog track test set",
                "Material"
            ],
            [
                "credibility indicators",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TREC Blog track test set') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('credibility indicators') is the subject, depending on the verb 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the scope of the experiments described.\"",
        "sdp_path_text": "set → on → Experiments → show → improve → groups → of → indicators",
        "sentence": "Experiments on the TREC Blog track test set show that credibility indicators improve retrieval effectiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('TREC Blog track test set') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('credibility indicators') is the subject, depending on 'improve'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the context and the effect of the experiments.\""
    },
    {
        "raw_sentence": "Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them .",
        "ner_pair": [
            [
                "TREC Blog track test set",
                "Material"
            ],
            [
                "retrieval effectiveness",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TREC Blog track test set') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('retrieval effectiveness') is the object, depending on 'improve' with 'indicators'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where experiments conducted on the TREC Blog track test set lead to improvements in retrieval effectiveness.\"",
        "sdp_path_text": "set → on → Experiments → show → improve → effectiveness",
        "sentence": "Experiments on the TREC Blog track test set show improvement in retrieval effectiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('TREC Blog track test set') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('retrieval effectiveness') is the object of the preposition 'in', depending on 'show'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure describing the context and outcome of the experiments.\""
    },
    {
        "raw_sentence": "Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them .",
        "ner_pair": [
            [
                "retrieval effectiveness",
                "Metric"
            ],
            [
                "credibility indicators",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('retrieval effectiveness') is the object, depending on 'improve' with 'indicators'. Entity 2 ('credibility indicators') is the subject, depending on 'improve' with 'retrieval effectiveness'. There is a direct dependency between Entity 1 and Entity 2, as 'credibility indicators' directly influences 'retrieval effectiveness' through the verb 'improve'.\"",
        "sdp_path_text": "effectiveness → improve → groups → of → indicators",
        "sentence": "Credibility indicators significantly improve retrieval effectiveness.",
        "sentence_llm_dp_info": "\"Entity 1 ('retrieval effectiveness') is the object, depending on the verb 'improve'. Entity 2 ('credibility indicators') is the subject, depending on the verb 'improve'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the agent that performs the action of improving Entity 1.\""
    },
    {
        "raw_sentence": "We investigate the problem of learning to predict moves in the board game of Go from game records of expert players .",
        "ner_pair": [
            [
                "game records of expert players",
                "Material"
            ],
            [
                "board game of Go",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('game records of expert players') is the object, depending on the preposition 'from', which modifies the verb 'predict'. Entity 2 ('board game of Go') is the object of the preposition 'in', depending on 'in' in the phrase 'in the board game of Go'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the investigation into predicting moves.\"",
        "sdp_path_text": "records → from → predict → moves → in → game",
        "sentence": "We investigate predicting moves in the board game of Go from game records of expert players.",
        "sentence_llm_dp_info": "\"Entity 1 ('game records of expert players') is the object, depending on the preposition 'from', which modifies the verb 'investigate'. Entity 2 ('board game of Go') is the object of the preposition 'in', which is part of the larger noun phrase 'moves in the board game of Go', functioning as the direct object of the verb 'predicting'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is being investigated.\""
    },
    {
        "raw_sentence": "This distribution has numerous applications in computer Go , including serving as an efficient stand-alone Go player .",
        "ner_pair": [
            [
                "distribution",
                "Generic"
            ],
            [
                "computer Go",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distribution') is the subject, depending on 'has' with 'This'. Entity 2 ('computer Go') is the object of the preposition 'in', depending on 'in' in the phrase 'in computer Go'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "distribution → has → applications → in → Go",
        "sentence": "This distribution has applications in computer Go.",
        "sentence_llm_dp_info": "\"Entity 1 ('distribution') is the subject, depending on the verb 'has'. Entity 2 ('computer Go') is the object of the preposition 'in', depending on 'applications'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'applications' which is the object of the verb 'has'.\""
    },
    {
        "raw_sentence": "This distribution has numerous applications in computer Go , including serving as an efficient stand-alone Go player .",
        "ner_pair": [
            [
                "distribution",
                "Generic"
            ],
            [
                "stand-alone Go player",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distribution') is the subject, depending on 'has' with 'This'. Entity 2 ('stand-alone Go player') is the object, depending on 'as' within the prepositional phrase 'as an efficient stand-alone Go player'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating one of the applications of the distribution.\"",
        "sdp_path_text": "distribution → has → including → serving → as → player",
        "sentence": "This distribution serves as a stand-alone Go player.",
        "sentence_llm_dp_info": "\"Entity 1 ('distribution') is the subject, depending on the verb 'serves'. Entity 2 ('stand-alone Go player') is the complement, depending on 'as' in the phrase 'as a stand-alone Go player'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'.\""
    },
    {
        "raw_sentence": "This distribution has numerous applications in computer Go , including serving as an efficient stand-alone Go player .",
        "ner_pair": [
            [
                "computer Go",
                "OtherScientificTerm"
            ],
            [
                "stand-alone Go player",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer Go') is the object of the preposition 'in', depending on 'applications'. Entity 2 ('stand-alone Go player') is the object of the preposition 'as', depending on 'serving'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the applications of the distribution.\"",
        "sdp_path_text": "Go → in → applications → has → including → serving → as → player",
        "sentence": "Computer Go has applications including serving as a stand-alone Go player.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer Go') is the subject, depending on the verb 'has'. Entity 2 ('stand-alone Go player') is the object of the preposition 'as', depending on 'serving' in the phrase 'serving as a stand-alone Go player'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has' and the prepositional phrase 'including serving as'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "move selector",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('move selector') is the complement of the preposition 'as', depending on 'effective'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'would be effective as'.\"",
        "sdp_path_text": "It → be → as → selector",
        "sentence": "It would be effective as a move selector.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('move selector') is the complement, depending on the verb 'be' in the phrase 'be effective as a move selector'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'be effective as'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "move sorter",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('move sorter') is part of a compound noun, depending on 'and' in the phrase 'selector and move sorter'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'would be effective as'.\"",
        "sdp_path_text": "It → be → as → selector → sorter",
        "sentence": "It would be effective as a move sorter.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the modal verb 'would' which leads to the adjective 'effective'. Entity 2 ('move sorter') is the complement, depending on the preposition 'as' which indicates the role or function that 'It' would serve. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'as a move sorter'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "game tree search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'be' with 'would also be effective'. Entity 2 ('game tree search') is the object of the preposition 'for', depending on 'for' in the phrase 'for game tree search'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as a move selector and move sorter for game tree search'.\"",
        "sdp_path_text": "It → be → as → selector → for → search",
        "sentence": "It would be effective as a selector for game tree search.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the adjective 'effective'. Entity 2 ('game tree search') is the object of the preposition 'for', depending on 'selector'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'as a selector for game tree search'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "training tool",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('training tool') is part of the compound object, depending on the preposition 'as' in the phrase 'as a training tool'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'be' and the preposition 'as'.\"",
        "sdp_path_text": "It → be → as → as → tool",
        "sentence": "It would be effective as a training tool.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('training tool') is the complement, depending on 'be' with 'effective'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'be effective as'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "Go players",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'for' in the phrase 'for Go players'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for Go players'.\"",
        "sdp_path_text": "It → be → as → as → tool → for → players",
        "sentence": "It would be effective as a training tool for Go players.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'would be'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'for' in the phrase 'for Go players'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move selector",
                "Method"
            ],
            [
                "move sorter",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move selector') is a conjunct, depending on 'and' with 'move sorter'. Entity 2 ('move sorter') is also a conjunct, depending on 'and' with 'move selector'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated by the conjunction 'and'.\"",
        "sdp_path_text": "selector → sorter",
        "sentence": "It would be effective as a move selector and move sorter.",
        "sentence_llm_dp_info": "\"Entity 1 ('move selector') is the complement of the preposition 'as', depending on 'as' in the phrase 'as a move selector'. Entity 2 ('move sorter') is also the complement of the preposition 'as', depending on 'as' in the phrase 'and move sorter'. There is no direct dependency between Entity 1 and Entity 2, but they are both complements of the same preposition 'as'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move selector",
                "Method"
            ],
            [
                "game tree search",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move selector') is part of a compound noun, depending on 'effective' with 'as'. Entity 2 ('game tree search') is the object of the preposition 'for', depending on 'for' in the phrase 'for game tree search'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the conjunction 'and'.\"",
        "sdp_path_text": "selector → for → search",
        "sentence": "It would be effective as a move selector for game tree search.",
        "sentence_llm_dp_info": "\"Entity 1 ('move selector') is the object of the preposition 'as', depending on 'effective'. Entity 2 ('game tree search') is the object of the preposition 'for', depending on 'selector'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrases 'as a move selector' and 'for game tree search'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move selector",
                "Method"
            ],
            [
                "training tool",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move selector') is part of a compound noun, depending on 'effective' as a complement. Entity 2 ('training tool') is also part of a compound noun, depending on 'effective' as a complement. There is no direct dependency between Entity 1 and Entity 2; both are complements of 'effective'.\"",
        "sdp_path_text": "selector → as → as → tool",
        "sentence": "It would be effective as a move selector and a training tool.",
        "sentence_llm_dp_info": "\"Entity 1 ('move selector') is the complement of the preposition 'as', depending on 'effective'. Entity 2 ('training tool') is also the complement of the preposition 'as', depending on 'effective'. There is no direct dependency between Entity 1 and Entity 2; both are independently related to the predicate 'effective' through the preposition 'as'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move selector",
                "Method"
            ],
            [
                "Go players",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move selector') is part of a compound noun, depending on the preposition 'as' with 'effective'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of roles or functions described for the subject of the sentence.\"",
        "sdp_path_text": "selector → as → as → tool → for → players",
        "sentence": "It would be effective as a move selector and training tool for Go players.",
        "sentence_llm_dp_info": "\"Entity 1 ('move selector') is part of the compound object, depending on the preposition 'as' with 'effective'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what the subject (It) would be effective as.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move sorter",
                "Method"
            ],
            [
                "game tree search",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move sorter') is part of a compound noun, depending on 'and' which connects it with 'move selector'. Both 'move selector' and 'move sorter' are objects of the preposition 'as', depending on 'effective'. Entity 2 ('game tree search') is the object of the preposition 'for', depending on 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what the subject is effective as or for.\"",
        "sdp_path_text": "sorter → selector → for → search",
        "sentence": "It would be effective as a move sorter for game tree search.",
        "sentence_llm_dp_info": "\"Entity 1 ('move sorter') is the object of the preposition 'as', depending on 'effective'. Entity 2 ('game tree search') is the object of the preposition 'for', depending on 'sorter'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrases 'as a move sorter' and 'for game tree search'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move sorter",
                "Method"
            ],
            [
                "training tool",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move sorter') is part of a coordinated list, depending on 'and' which connects it with 'move selector'. Entity 2 ('training tool') is also part of a coordinated list, depending on 'and' which connects it with the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of functions or roles described for the subject of the sentence.\"",
        "sdp_path_text": "sorter → selector → as → as → tool",
        "sentence": "It can be used as a move sorter and a training tool.",
        "sentence_llm_dp_info": "\"Entity 1 ('move sorter') is the complement of the preposition 'as', depending on 'used'. Entity 2 ('training tool') is also the complement of the preposition 'as', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but both are connected through the preposition 'as' and the verb 'used'.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "move sorter",
                "Method"
            ],
            [
                "Go players",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('move sorter') is part of a compound noun, depending on the conjunction 'and' with 'move selector'. Both are objects of the preposition 'as', which depends on the verb 'be'. Entity 2 ('Go players') is the object of the preposition 'for', which depends on 'tool'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "sorter → selector → as → as → tool → for → players",
        "sentence": "It would be effective as a move sorter and training tool for Go players.",
        "sentence_llm_dp_info": "\"Entity 1 ('move sorter') is part of a compound noun, depending on the conjunction 'and' with 'training tool'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'for' in the phrase 'for Go players'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger noun phrase that serves as the complement of the preposition 'as' and 'for' respectively.\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "game tree search",
                "Method"
            ],
            [
                "training tool",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('game tree search') is the object of the preposition 'for', depending on 'selector and move sorter'. Entity 2 ('training tool') is the object of the preposition 'for', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of prepositions that modify different parts of the sentence.\"",
        "sdp_path_text": "search → for → selector → as → as → tool",
        "sentence": "It would be effective as a move selector for game tree search and as a training tool.",
        "sentence_llm_dp_info": "\"Entity 1 ('game tree search') is the object of the preposition 'for', depending on 'selector'. Entity 2 ('training tool') is the object of the preposition 'as', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the noun 'selector' through different prepositions ('for' and 'as').\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "game tree search",
                "Method"
            ],
            [
                "Go players",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('game tree search') is the object of the preposition 'for', depending on 'selector and move sorter'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'training tool'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of prepositions that describe the uses of the subject ('It').\"",
        "sdp_path_text": "search → for → selector → as → as → tool → for → players",
        "sentence": "It would be effective as a move selector for game tree search and as a training tool for Go players.",
        "sentence_llm_dp_info": "\"Entity 1 ('game tree search') is the object of the preposition 'for', depending on 'selector'. Entity 2 ('Go players') is also the object of the preposition 'for', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2; both are objects of prepositions that describe different purposes of the subject ('move selector' and 'training tool').\""
    },
    {
        "raw_sentence": "It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players .",
        "ner_pair": [
            [
                "training tool",
                "Task"
            ],
            [
                "Go players",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training tool') is the object of the preposition 'as', depending on the verb 'be'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'for' in the phrase 'for Go players'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "tool → for → players",
        "sentence": "It serves as a training tool for Go players.",
        "sentence_llm_dp_info": "\"Entity 1 ('training tool') is the complement, depending on the preposition 'as' with 'serves'. Entity 2 ('Go players') is the object of the preposition 'for', depending on 'for' in the phrase 'for Go players'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our method has two major components : a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context .",
        "ner_pair": [
            [
                "pattern extraction scheme",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pattern extraction scheme') is the object of the preposition 'for', depending on the verb 'harvesting'. Entity 2 ('method') is the subject, depending on the verb 'has'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the structure where 'pattern extraction scheme' is one of the components of the 'method'.\"",
        "sdp_path_text": "scheme → -RRB- → components → has → method",
        "sentence": "The method includes a pattern extraction scheme.",
        "sentence_llm_dp_info": "\"Entity 1 ('pattern extraction scheme') is the object, depending on the verb 'includes'. Entity 2 ('method') is the subject, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is included in Entity 2.\""
    },
    {
        "raw_sentence": "Our method has two major components : a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context .",
        "ner_pair": [
            [
                "Bayesian learning algorithm",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian learning algorithm') is part of the list item 'b', which is a component of the subject 'method'. It depends on 'components' through the preposition 'and' in the phrase 'and b -RRB- a Bayesian learning algorithm'. Entity 2 ('method') is the subject, depending on the verb 'has'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where Entity 1 is described as one of the components of Entity 2.\"",
        "sdp_path_text": "algorithm → -RRB- → -RRB- → components → has → method",
        "sentence": "Our method includes a Bayesian learning algorithm as one of its components.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian learning algorithm') is the object of the preposition 'as', depending on 'includes' in the phrase 'includes a Bayesian learning algorithm'. Entity 2 ('method') is the object, depending on 'includes' with 'Our'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is part of what Entity 2 includes.\""
    },
    {
        "raw_sentence": "Our method has two major components : a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "local pattern context",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'has' in the phrase 'Our method has two major components'. Entity 2 ('local pattern context') is the object of the preposition 'based on', depending on 'based' in the phrase 'based on the local pattern context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence, where 'local pattern context' influences the 'Bayesian learning algorithm' which is one of the components of the 'method'.\"",
        "sdp_path_text": "method → has → components → -RRB- → -RRB- → algorithm → learns → distribution → over → values → of → move → given → position → based → on → context",
        "sentence": "Our method includes an algorithm that learns a distribution over move values based on local pattern context.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'includes'. Entity 2 ('local pattern context') is the object of the preposition 'on', depending on 'based' in the phrase 'based on local pattern context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on local pattern context'.\""
    },
    {
        "raw_sentence": "Our method has two major components : a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context .",
        "ner_pair": [
            [
                "pattern extraction scheme",
                "Method"
            ],
            [
                "Bayesian learning algorithm",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pattern extraction scheme') is the object of the preposition 'a', which is part of the list of components of 'method'. It depends on 'components' through the preposition 'a'. Entity 2 ('Bayesian learning algorithm') is also an object of the preposition 'b', another component of the same 'method', and it depends on 'components' through the preposition 'b'. There is no direct dependency between Entity 1 and Entity 2; both are listed as separate components of the method.\"",
        "sdp_path_text": "scheme → -RRB- → -RRB- → algorithm",
        "sentence": "Our method includes a pattern extraction scheme and a Bayesian learning algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('pattern extraction scheme') is part of a compound noun, depending on 'includes' with 'method'. Entity 2 ('Bayesian learning algorithm') is also part of a compound noun, depending on 'includes' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but both are listed as objects included by the method.\""
    },
    {
        "raw_sentence": "Our method has two major components : a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context .",
        "ner_pair": [
            [
                "pattern extraction scheme",
                "Method"
            ],
            [
                "local pattern context",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pattern extraction scheme') is the subject of the clause 'for efficiently harvesting patterns of given size and shape from expert game records', depending on the verb 'harvesting'. Entity 2 ('local pattern context') is the object of the preposition 'based on', depending on 'based' in the phrase 'based on the local pattern context'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence.\"",
        "sdp_path_text": "scheme → -RRB- → -RRB- → algorithm → learns → distribution → over → values → of → move → given → position → based → on → context",
        "sentence": "The pattern extraction scheme contributes to a learning algorithm that learns a distribution over move values based on local pattern context.",
        "sentence_llm_dp_info": "\"Entity 1 ('pattern extraction scheme') is the subject, depending on the verb 'contributes'. Entity 2 ('local pattern context') is the object of the preposition 'on', depending on 'based' in the phrase 'based on local pattern context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'contributes' and the prepositional phrase 'based on local pattern context'.\""
    },
    {
        "raw_sentence": "Our method has two major components : a -RRB- a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b -RRB- a Bayesian learning algorithm -LRB- in two variants -RRB- that learns a distribution over the values of a move given a board position based on the local pattern context .",
        "ner_pair": [
            [
                "Bayesian learning algorithm",
                "Method"
            ],
            [
                "local pattern context",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian learning algorithm') is part of a list item, depending on the conjunction 'and' within the components of the method. It also depends on the preposition 'that' which introduces a clause describing what the algorithm does. Entity 2 ('local pattern context') is the object of the preposition 'based on', depending on the verb 'learns' within the clause describing the function of the Bayesian learning algorithm. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause where Entity 2 serves as the basis for what Entity 1 learns.\"",
        "sdp_path_text": "algorithm → learns → distribution → over → values → of → move → given → position → based → on → context",
        "sentence": "The Bayesian learning algorithm learns a distribution over move values based on the local pattern context.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian learning algorithm') is the subject, depending on the verb 'learns'. Entity 2 ('local pattern context') is the object of the preposition 'based on', depending on 'based' in the phrase 'based on the local pattern context'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'based on'.\""
    },
    {
        "raw_sentence": "The system is trained on 181,000 expert games and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34 % of test positions .",
        "ner_pair": [
            [
                "expert games",
                "Material"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expert games') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('system') is the subject, depending on the verb 'is trained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on 181,000 expert games'.\"",
        "sdp_path_text": "games → on → trained → system",
        "sentence": "The system is trained on expert games.",
        "sentence_llm_dp_info": "\"Entity 1 ('expert games') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('system') is the subject, depending on the verb 'is trained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' in the phrase 'trained on expert games'.\""
    },
    {
        "raw_sentence": "We present a novel approach for automatically acquiring English topic signatures .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "automatically acquiring English topic signatures",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject complement, depending on 'present' with 'We'. Entity 2 ('automatically acquiring English topic signatures') is the object of the preposition 'for', depending on 'for' in the phrase 'for automatically acquiring English topic signatures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose of the approach.\"",
        "sdp_path_text": "approach → for → acquiring",
        "sentence": "{\n  \"Simplified sentence\": \"We present a novel approach for automatically acquiring English topic signatures.\"\n} \n\nHowever, to strictly adhere to the guidelines and focus only on the relationship indicated by the SDP, a more refined version would be:\n\n{\n  \"Simplified sentence\": \"The approach is for automatically acquiring English topic signatures.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('automatically acquiring English topic signatures') is the object of the preposition 'for', depending on 'for' in the phrase 'for automatically acquiring English topic signatures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Given a particular concept , or word sense , a topic signature is a set of words that tend to co-occur with it .",
        "ner_pair": [
            [
                "concept",
                "OtherScientificTerm"
            ],
            [
                "word sense",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('concept') is the object of the preposition 'a', depending on the verb 'Given'. Entity 2 ('word sense') is the second item in a coordination, depending on 'concept' with the conjunction 'or'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated as part of the same prepositional phrase.\"",
        "sdp_path_text": "concept → sense",
        "sentence": "A concept is associated with a word sense.",
        "sentence_llm_dp_info": "\"Entity 1 ('concept') is the subject, depending on the verb 'is'. Entity 2 ('word sense') is the object of the preposition 'with', depending on 'with' in the phrase 'with a word sense'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Given a particular concept , or word sense , a topic signature is a set of words that tend to co-occur with it .",
        "ner_pair": [
            [
                "concept",
                "OtherScientificTerm"
            ],
            [
                "topic signature",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('concept') is the object of the preposition 'Given', depending on 'Given' in the phrase 'Given a particular concept'. Entity 2 ('topic signature') is the subject, depending on the verb 'is' in the clause 'a topic signature is a set of words'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the explanation provided in the sentence.\"",
        "sdp_path_text": "concept → Given → is → signature",
        "sentence": "A topic signature is a set of words that co-occur with a concept.",
        "sentence_llm_dp_info": "\"Entity 1 ('concept') is the object, depending on the verb 'co-occur'. Entity 2 ('topic signature') is the subject, depending on the copula 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate describing the relationship where 'topic signature' is defined as a set of words that co-occur with 'concept'.\""
    },
    {
        "raw_sentence": "Given a particular concept , or word sense , a topic signature is a set of words that tend to co-occur with it .",
        "ner_pair": [
            [
                "word sense",
                "OtherScientificTerm"
            ],
            [
                "topic signature",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word sense') is part of a prepositional phrase, depending on 'Given' as an object of the preposition. Entity 2 ('topic signature') is the subject, depending on 'is' as its predicate. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause, where 'word sense' is mentioned as one of the elements for which a 'topic signature' can be defined.\"",
        "sdp_path_text": "sense → concept → Given → is → signature",
        "sentence": "A topic signature is a set of words that co-occur with a word sense.",
        "sentence_llm_dp_info": "\"Entity 1 ('word sense') is the object, depending on the verb 'co-occur'. Entity 2 ('topic signature') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'co-occur' which indicates their association within the sentence.\""
    },
    {
        "raw_sentence": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications , such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation .",
        "ner_pair": [
            [
                "Topic signatures",
                "OtherScientificTerm"
            ],
            [
                "Natural Language Processing -LRB- NLP -RRB- applications",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Topic signatures') is the subject, depending on the verb 'can be'. Entity 2 ('Natural Language Processing -LRB- NLP -RRB- applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in a number of Natural Language Processing -LRB- NLP -RRB- applications'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase that describes where 'Topic signatures' can be useful.\"",
        "sdp_path_text": "signatures → be → in → number → of → applications",
        "sentence": "Topic signatures can be useful in Natural Language Processing applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('Topic signatures') is the subject, depending on the verb 'can be'. Entity 2 ('Natural Language Processing -LRB- NLP -RRB- applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in Natural Language Processing applications'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that indicates the context in which 'Topic signatures' can be useful.\""
    },
    {
        "raw_sentence": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications , such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation .",
        "ner_pair": [
            [
                "Topic signatures",
                "OtherScientificTerm"
            ],
            [
                "Word Sense Disambiguation -LRB- WSD -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Topic signatures') is the subject, depending on the verb 'can be'. Entity 2 ('Word Sense Disambiguation -LRB- WSD -RRB-') is part of the list of examples, depending on the conjunction 'such as' and the preposition 'as' in the phrase 'such as Word Sense Disambiguation -LRB- WSD -RRB-'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "signatures → be → in → number → of → applications → as → -RRB-",
        "sentence": "Topic signatures can be useful in applications such as Word Sense Disambiguation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Topic signatures') is the subject, depending on the verb 'can be'. Entity 2 ('Word Sense Disambiguation -LRB- WSD -RRB-') is the object of the preposition 'such as', depending on 'applications'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the prepositional phrase 'in applications such as'.\""
    },
    {
        "raw_sentence": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications , such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation .",
        "ner_pair": [
            [
                "Topic signatures",
                "OtherScientificTerm"
            ],
            [
                "Text Summarisation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Topic signatures') is the subject, depending on the verb 'can be' and modified by the adjective 'useful'. Entity 2 ('Text Summarisation') is part of a list of examples introduced by 'such as', which depends on 'applications'. There is no direct dependency between Entity 1 and Entity 2; both are related through the context of being useful in NLP applications.\"",
        "sdp_path_text": "signatures → be → in → number → of → applications → as → -RRB- → Summarisation",
        "sentence": "Topic signatures can be useful in applications such as Text Summarisation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Topic signatures') is the subject, depending on the verb 'can be'. Entity 2 ('Text Summarisation') is the object of the preposition 'such as', depending on 'applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in applications such as'.\""
    },
    {
        "raw_sentence": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications , such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation .",
        "ner_pair": [
            [
                "Word Sense Disambiguation -LRB- WSD -RRB-",
                "Task"
            ],
            [
                "Natural Language Processing -LRB- NLP -RRB- applications",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Word Sense Disambiguation -LRB- WSD -RRB-') is the appositive, depending on 'such as' which introduces examples of 'applications'. Entity 2 ('Natural Language Processing -LRB- NLP -RRB- applications') is the object of the preposition 'in', depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where Entity 1 serves as an example of Entity 2.\"",
        "sdp_path_text": "-RRB- → as → applications",
        "sentence": "Word Sense Disambiguation is an application of Natural Language Processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('Word Sense Disambiguation -LRB- WSD -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('Natural Language Processing -LRB- NLP -RRB- applications') is the complement of the preposition 'of', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2; however, they are related through the structure where Entity 1 is described as an instance or part of the set defined by Entity 2.\""
    },
    {
        "raw_sentence": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications , such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation .",
        "ner_pair": [
            [
                "Text Summarisation",
                "Task"
            ],
            [
                "Natural Language Processing -LRB- NLP -RRB- applications",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Text Summarisation') is part of a list, depending on the conjunction 'and', which connects it to another item in the list ('Word Sense Disambiguation'). Entity 2 ('Natural Language Processing -LRB- NLP -RRB- applications') is the object of the preposition 'in', depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger structure where Entity 1 is an example of the type of Entity 2.\"",
        "sdp_path_text": "Summarisation → -RRB- → as → applications",
        "sentence": "Text Summarisation is an application of Natural Language Processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('Text Summarisation') is the subject, depending on the verb 'is'. Entity 2 ('Natural Language Processing') is part of a nominal compound, depending on 'application' with 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the copular verb 'is' and the prepositional phrase 'an application of'.\""
    },
    {
        "raw_sentence": "Topic signatures can be useful in a number of Natural Language Processing -LRB- NLP -RRB- applications , such as Word Sense Disambiguation -LRB- WSD -RRB- and Text Summarisation .",
        "ner_pair": [
            [
                "Word Sense Disambiguation -LRB- WSD -RRB-",
                "Task"
            ],
            [
                "Text Summarisation",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Word Sense Disambiguation -LRB- WSD -RRB-') is part of a coordination, depending on 'such' in the phrase 'such as Word Sense Disambiguation'. Entity 2 ('Text Summarisation') is also part of the same coordination, depending on 'and' in the phrase 'WSD and Text Summarisation'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated elements listed as examples of applications where topic signatures can be useful.\"",
        "sdp_path_text": "-RRB- → Summarisation",
        "sentence": "Word Sense Disambiguation and Text Summarisation are applications of topic signatures.",
        "sentence_llm_dp_info": "\"Entity 1 ('Word Sense Disambiguation -LRB- WSD -RRB-') is the first element in a conjunction, depending on the conjunction 'and' with 'Text Summarisation'. Entity 2 ('Text Summarisation') is the second element in the conjunction, also depending on the conjunction 'and' with 'Word Sense Disambiguation -LRB- WSD -RRB-'. There is a direct dependency between Entity 1 and Entity 2, as they are both part of the same conjunctive structure and together form the subject of the sentence, which is linked to the predicate 'are applications of topic signatures'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "word senses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes'. Entity 2 ('word senses') is part of the object of the preposition 'of', depending on 'way'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'the different way in which word senses are lexicalised'.\"",
        "sdp_path_text": "method → takes → of → way → lexicalised → senses",
        "sentence": "Our method takes advantage of how word senses are lexicalised.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes'. Entity 2 ('word senses') is the object of the preposition 'of', depending on 'lexicalised' in the phrase 'how word senses are lexicalised'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of how word senses are lexicalised'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes'. Entity 2 ('English') is part of a prepositional phrase, depending on 'lexicalised' with 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing how word senses are lexicalised in different languages.\"",
        "sdp_path_text": "method → takes → of → way → lexicalised → in → English",
        "sentence": "Our method takes advantage of the way word senses are lexicalised in English.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes'. Entity 2 ('English') is the object of the preposition 'in', depending on 'lexicalised'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in English' which modifies 'lexicalised'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "Chinese",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'takes' with 'Our'. Entity 2 ('Chinese') is the object of the preposition 'in', depending on 'in' in the phrase 'in Chinese'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in Chinese' which is part of a larger clause describing how the method works.\"",
        "sdp_path_text": "method → takes → of → way → lexicalised → in → English → Chinese",
        "sentence": "Our method takes advantage of the different way word senses are lexicalised in Chinese.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes'. Entity 2 ('Chinese') is the object of the preposition 'in', depending on 'lexicalised' in the phrase 'in Chinese'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'takes' and the prepositional phrase 'in Chinese'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "Chinese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'takes' in the phrase 'takes advantage'. Entity 2 ('Chinese text') is the object, depending on 'exploits' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'exploits' which indicates that the method uses or benefits from the Chinese text.\"",
        "sdp_path_text": "method → takes → exploits → amount → of → text",
        "sentence": "Our method exploits the amount of Chinese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('Chinese text') is the object, depending on 'amount' with 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the noun 'amount'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "corpora",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes' in the phrase 'takes advantage'. Entity 2 ('corpora') is part of the compound noun phrase 'corpora and on the Web', depending on 'available' as its complement. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "method → takes → exploits → amount → of → text → available → in → corpora",
        "sentence": "Our method exploits the amount of text available in corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'exploits'. Entity 2 ('corpora') is the object, depending on the preposition 'in' within the phrase 'in corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in corpora'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'takes'. Entity 2 ('Web') is part of a prepositional phrase, depending on 'available' with 'on'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "method → takes → exploits → amount → of → text → available → in → on → Web",
        "sentence": "Our method exploits the amount of text available on the Web.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'exploits' with 'Our'. Entity 2 ('Web') is the object of the preposition 'on', depending on 'on' in the phrase 'on the Web'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "word senses",
                "OtherScientificTerm"
            ],
            [
                "English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word senses') is the object of the preposition 'of', depending on 'way'. Entity 2 ('English') is part of a compound noun, depending on 'lexicalised' with 'in'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'are lexicalised' and the preposition 'in'.\"",
        "sdp_path_text": "senses → lexicalised → in → English",
        "sentence": "Word senses are lexicalised differently in English.",
        "sentence_llm_dp_info": "\"Entity 1 ('word senses') is the subject, depending on the verb 'are'. Entity 2 ('English') is the object of the preposition 'in', depending on 'in' in the phrase 'in English'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in English'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "word senses",
                "OtherScientificTerm"
            ],
            [
                "Chinese",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word senses') is the object of the preposition 'of', depending on 'way'. Entity 2 ('Chinese') is the object of the preposition 'in', depending on 'lexicalised'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing how word senses are lexicalized differently in English and Chinese.\"",
        "sdp_path_text": "senses → lexicalised → in → English → Chinese",
        "sentence": "Word senses are lexicalised differently in Chinese.",
        "sentence_llm_dp_info": "\"Entity 1 ('word senses') is the subject, depending on the passive verb 'are lexicalised'. Entity 2 ('Chinese') is the adverbial modifier, depending on 'differently' in the phrase 'in Chinese'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are lexicalised' and the adverbial phrase 'differently in Chinese'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "word senses",
                "OtherScientificTerm"
            ],
            [
                "Chinese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word senses') is the object of the preposition 'of', depending on 'way'. Entity 2 ('Chinese text') is the object of the preposition 'of', depending on 'amount'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger clauses that describe aspects of the method's operation.\"",
        "sdp_path_text": "senses → lexicalised → way → of → takes → exploits → amount → of → text",
        "sentence": "Word senses are lexicalised differently in Chinese, and our method exploits Chinese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('word senses') is the subject, depending on 'are' as the main verb. Entity 2 ('Chinese text') is the object, depending on 'exploits' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the clause that discusses how word senses are treated in Chinese and how the method uses Chinese text.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "word senses",
                "OtherScientificTerm"
            ],
            [
                "corpora",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word senses') is the object of the preposition 'of', depending on 'way'. Entity 2 ('corpora') is part of the compound noun 'corpora and Web', depending on 'available' as an object complement. There is no direct dependency between Entity 1 and Entity 2; both are parts of separate clauses within the sentence.\"",
        "sdp_path_text": "senses → lexicalised → way → of → takes → exploits → amount → of → text → available → in → corpora",
        "sentence": "Our method exploits how word senses are lexicalized in corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('word senses') is the subject complement, depending on the verb 'are' with 'lexicalized'. Entity 2 ('corpora') is the object of the preposition 'in', depending on 'in' in the phrase 'in corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'lexicalized' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "word senses",
                "OtherScientificTerm"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word senses') is the object of the preposition 'of', depending on 'way'. Entity 2 ('Web') is part of a prepositional phrase, depending on 'available' in the phrase 'on the Web'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "senses → lexicalised → way → of → takes → exploits → amount → of → text → available → in → on → Web",
        "sentence": "Our method exploits the different ways word senses are lexicalised in text available on the Web.",
        "sentence_llm_dp_info": "\"Entity 1 ('word senses') is the object, depending on 'lexicalised' with 'are'. Entity 2 ('Web') is the object of the preposition 'on', depending on 'available' in the phrase 'on the Web'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "Chinese",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'in', depending on 'lexicalised'. Entity 2 ('Chinese') is also the object of the preposition 'in', depending on 'lexicalised'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'lexicalised' through the preposition 'in'.\"",
        "sdp_path_text": "English → Chinese",
        "sentence": "The method exploits differences in lexicalisation between English and Chinese.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'between', depending on 'between' in the phrase 'between English and Chinese'. Entity 2 ('Chinese') is also the object of the preposition 'between', depending on 'between' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrase 'between English and Chinese' that modifies 'differences'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "Chinese text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is part of a coordination, depending on 'way' with 'in which word senses are lexicalised'. Entity 2 ('Chinese text') is the object of the preposition 'of', depending on 'amount'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of language resources and their utilization in the method described.\"",
        "sdp_path_text": "English → in → lexicalised → way → of → takes → exploits → amount → of → text",
        "sentence": "Our method exploits the different ways word senses are lexicalised in English and Chinese text.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'in', depending on 'lexicalised'. Entity 2 ('Chinese text') is also the object of the preposition 'in', depending on 'lexicalised'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the prepositional phrase 'in English and Chinese text' which modifies 'lexicalised'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "corpora",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is part of a compound noun, depending on 'way' with the preposition 'in'. Entity 2 ('corpora') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, specifically through the conjunction 'and' that links the two clauses describing different aspects of the method.\"",
        "sdp_path_text": "English → in → lexicalised → way → of → takes → exploits → amount → of → text → available → in → corpora",
        "sentence": "Our method exploits the way word senses are lexicalised in English and the amount of text available in corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is the object of the preposition 'in', depending on 'lexicalised'. Entity 2 ('corpora') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing what the method exploits.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "English",
                "Material"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English') is part of the compound noun 'way in which word senses are lexicalised in English', depending on 'lexicalised' as an adverbial modifier. Entity 2 ('Web') is part of the prepositional phrase 'on the Web', functioning as an adverbial modifier of location for the verb 'exploits'. There is no direct dependency between Entity 1 and Entity 2; they are both part of larger phrases that describe different aspects of the method's approach.\"",
        "sdp_path_text": "English → in → lexicalised → way → of → takes → exploits → amount → of → text → available → in → on → Web",
        "sentence": "Our method exploits the different way word senses are lexicalised in English and the large amount of text available on the Web.",
        "sentence_llm_dp_info": "\"Entity 1 ('English') is part of the prepositional phrase 'in English', depending on 'lexicalised'. Entity 2 ('Web') is the object of the preposition 'on', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing what the method exploits.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "Chinese",
                "Material"
            ],
            [
                "corpora",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Chinese') is part of the compound noun 'Chinese text', depending on 'text' as a modifier. Entity 2 ('corpora') is the object of the preposition 'in', depending on 'available' in the phrase 'available in corpora'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "Chinese → English → in → lexicalised → way → of → takes → exploits → amount → of → text → available → in → corpora",
        "sentence": "Our method exploits the large amount of Chinese text available in corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('Chinese') is the modifier, depending on the noun 'text' with the relation 'amod'. Entity 2 ('corpora') is the object, depending on the preposition 'in' with the relation 'pobj'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same noun phrase 'Chinese text available in corpora'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "Chinese",
                "Material"
            ],
            [
                "Web",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Chinese') is part of a compound noun, depending on 'text' with the relation 'compound'. Entity 2 ('Web') is part of a prepositional phrase, depending on 'available' with the relation 'pobj' (prepositional object) in the phrase 'on the Web'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the availability of text in different contexts.\"",
        "sdp_path_text": "Chinese → English → in → lexicalised → way → of → takes → exploits → amount → of → text → available → in → on → Web",
        "sentence": "Our method exploits the large amount of Chinese text available on the Web.",
        "sentence_llm_dp_info": "\"Entity 1 ('Chinese') is an adjective, modifying 'text'. Entity 2 ('Web') is the object of the preposition 'on', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "Chinese text",
                "Material"
            ],
            [
                "corpora",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Chinese text') is the object, depending on 'exploits' with 'method'. Entity 2 ('corpora') is part of a prepositional phrase, depending on 'in' with 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what is being exploited.\"",
        "sdp_path_text": "text → available → in → corpora",
        "sentence": "Chinese text is available in corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('Chinese text') is the subject, depending on the verb 'is'. Entity 2 ('corpora') is the object of the preposition 'in', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'is' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "Chinese text",
                "Material"
            ],
            [
                "Web",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Chinese text') is the object, depending on 'exploits' with 'method'. Entity 2 ('Web') is the object of the preposition 'on', depending on 'available' in the phrase 'available in corpora and on the Web'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger phrase describing what is being exploited.\"",
        "sdp_path_text": "text → available → in → on → Web",
        "sentence": "Chinese text is available on the Web.",
        "sentence_llm_dp_info": "\"Entity 1 ('Chinese text') is the subject, depending on the verb 'is'. Entity 2 ('Web') is the object of the preposition 'on', depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on the Web'.\""
    },
    {
        "raw_sentence": "Our method takes advantage of the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web .",
        "ner_pair": [
            [
                "corpora",
                "Generic"
            ],
            [
                "Web",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('corpora') is part of a compound noun, depending on 'available' with 'text'. Entity 2 ('Web') is coordinated with 'corpora', also depending on 'available' with 'text'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same coordination structure, indicating that the text is available in both.\"",
        "sdp_path_text": "corpora → in → on → Web",
        "sentence": "The method exploits the large amount of Chinese text available in corpora and on the Web.",
        "sentence_llm_dp_info": "\"Entity 1 ('corpora') is the object of the preposition 'in', depending on 'available'. Entity 2 ('Web') is the object of the preposition 'on', also depending on 'available'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying 'available'.\""
    },
    {
        "raw_sentence": "We evaluated the topic signatures on a WSD task , where we trained a second-order vector cooccurrence algorithm on standard WSD datasets , with promising results .",
        "ner_pair": [
            [
                "WSD task",
                "Task"
            ],
            [
                "topic signatures",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WSD task') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('topic signatures') is the subject, depending on 'evaluated' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluated' and the preposition 'on'.\"",
        "sdp_path_text": "task → on → evaluated → signatures",
        "sentence": "Topic signatures were evaluated on the WSD task.",
        "sentence_llm_dp_info": "\"Entity 1 ('WSD task') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('topic signatures') is the subject, depending on the verb 'were evaluated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'evaluated' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "We evaluated the topic signatures on a WSD task , where we trained a second-order vector cooccurrence algorithm on standard WSD datasets , with promising results .",
        "ner_pair": [
            [
                "topic signatures",
                "OtherScientificTerm"
            ],
            [
                "second-order vector cooccurrence algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('topic signatures') is the object, depending on the verb 'evaluated'. Entity 2 ('second-order vector cooccurrence algorithm') is the object, depending on the verb 'trained'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the evaluation and training processes described in the sentence.\"",
        "sdp_path_text": "signatures → evaluated → on → task → trained → algorithm",
        "sentence": "Topic signatures were evaluated on a task where a second-order vector cooccurrence algorithm was trained.",
        "sentence_llm_dp_info": "\"Entity 1 ('topic signatures') is the subject, depending on the verb 'evaluated'. Entity 2 ('second-order vector cooccurrence algorithm') is the subject complement, depending on 'was' in the passive construction 'was trained'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the evaluation task described in the sentence.\""
    },
    {
        "raw_sentence": "We evaluated the topic signatures on a WSD task , where we trained a second-order vector cooccurrence algorithm on standard WSD datasets , with promising results .",
        "ner_pair": [
            [
                "topic signatures",
                "OtherScientificTerm"
            ],
            [
                "WSD datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('topic signatures') is the object of the verb 'evaluated', depending on 'evaluated' with 'We'. Entity 2 ('WSD datasets') is the object of the preposition 'on', depending on 'trained' within the clause 'we trained a second-order vector cooccurrence algorithm on standard WSD datasets'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses that are related through the context of the evaluation and training processes described in the sentence.\"",
        "sdp_path_text": "signatures → evaluated → on → task → trained → on → datasets",
        "sentence": "Topic signatures were evaluated on WSD datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('topic signatures') is the subject, depending on the verb 'were evaluated'. Entity 2 ('WSD datasets') is the object of the preposition 'on', depending on 'on' in the phrase 'on WSD datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the evaluation process described by the verb 'were evaluated'.\""
    },
    {
        "raw_sentence": "We evaluated the topic signatures on a WSD task , where we trained a second-order vector cooccurrence algorithm on standard WSD datasets , with promising results .",
        "ner_pair": [
            [
                "WSD task",
                "Task"
            ],
            [
                "second-order vector cooccurrence algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WSD task') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('second-order vector cooccurrence algorithm') is the subject complement, depending on 'trained'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same evaluative context within the sentence.\"",
        "sdp_path_text": "task → trained → algorithm",
        "sentence": "We trained a second-order vector cooccurrence algorithm on a WSD task.",
        "sentence_llm_dp_info": "\"Entity 1 ('WSD task') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('second-order vector cooccurrence algorithm') is the direct object, depending on the verb 'trained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'trained' where Entity 2 is what was trained and Entity 1 is the context or domain in which it was applied.\""
    },
    {
        "raw_sentence": "We evaluated the topic signatures on a WSD task , where we trained a second-order vector cooccurrence algorithm on standard WSD datasets , with promising results .",
        "ner_pair": [
            [
                "WSD task",
                "Task"
            ],
            [
                "WSD datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WSD task') is the object of the preposition 'on', depending on 'evaluated'. Entity 2 ('WSD datasets') is the object of the preposition 'on', depending on 'trained'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of evaluation and training in the sentence.\"",
        "sdp_path_text": "task → trained → on → datasets",
        "sentence": "We trained a WSD task on WSD datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('WSD task') is the object of the verb 'trained', depending on 'trained'. Entity 2 ('WSD datasets') is the object of the preposition 'on', depending on 'on' in the phrase 'on WSD datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'trained' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "We evaluated the topic signatures on a WSD task , where we trained a second-order vector cooccurrence algorithm on standard WSD datasets , with promising results .",
        "ner_pair": [
            [
                "WSD datasets",
                "Material"
            ],
            [
                "second-order vector cooccurrence algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WSD datasets') is the object of the preposition 'on', depending on 'trained'. Entity 2 ('second-order vector cooccurrence algorithm') is the object, depending on 'trained' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'trained'.\"",
        "sdp_path_text": "datasets → on → trained → algorithm",
        "sentence": "A second-order vector cooccurrence algorithm was trained on WSD datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('WSD datasets') is the object, depending on the preposition 'on', which itself depends on the verb 'trained'. Entity 2 ('second-order vector cooccurrence algorithm') is the subject, depending on the verb 'was trained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'trained' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices , with applications in signal processing and machine learning .",
        "ner_pair": [
            [
                "Joint matrix triangularization",
                "Task"
            ],
            [
                "joint eigenstructure",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Joint matrix triangularization') is the subject, depending on the verb 'is' (used). Entity 2 ('joint eigenstructure') is the object of the preposition 'for', depending on 'estimating' in the phrase 'for estimating the joint eigenstructure'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the purpose clause introduced by 'for'.\"",
        "sdp_path_text": "triangularization → used → for → estimating → eigenstructure",
        "sentence": "Joint matrix triangularization is used for estimating the joint eigenstructure.",
        "sentence_llm_dp_info": "\"Entity 1 ('Joint matrix triangularization') is the subject, depending on the verb 'is used'. Entity 2 ('joint eigenstructure') is the object, depending on the verb 'estimating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'for estimating the joint eigenstructure'.\""
    },
    {
        "raw_sentence": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices , with applications in signal processing and machine learning .",
        "ner_pair": [
            [
                "Joint matrix triangularization",
                "Task"
            ],
            [
                "signal processing",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Joint matrix triangularization') is the subject, depending on the verb 'is' (used). Entity 2 ('signal processing') is part of a prepositional phrase, depending on 'applications' through the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase that describes the application areas of the method.\"",
        "sdp_path_text": "triangularization → used → with → applications → in → processing",
        "sentence": "Joint matrix triangularization is used with applications in signal processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('Joint matrix triangularization') is the subject, depending on the verb 'is used'. Entity 2 ('signal processing') is the object of the preposition 'in', depending on 'in' in the phrase 'in signal processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in signal processing'.\""
    },
    {
        "raw_sentence": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices , with applications in signal processing and machine learning .",
        "ner_pair": [
            [
                "Joint matrix triangularization",
                "Task"
            ],
            [
                "machine learning",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Joint matrix triangularization') is the subject, depending on the verb 'is used'. Entity 2 ('machine learning') is part of a prepositional phrase, depending on 'in' within the phrase 'in signal processing and machine learning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates the application areas of the technique described by Entity 1.\"",
        "sdp_path_text": "triangularization → used → with → applications → in → processing → learning",
        "sentence": "Joint matrix triangularization is used with applications in machine learning.",
        "sentence_llm_dp_info": "\"Entity 1 ('Joint matrix triangularization') is the subject, depending on the verb 'is used'. Entity 2 ('machine learning') is the object of the preposition 'in', depending on 'applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'with applications in machine learning'.\""
    },
    {
        "raw_sentence": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices , with applications in signal processing and machine learning .",
        "ner_pair": [
            [
                "joint eigenstructure",
                "OtherScientificTerm"
            ],
            [
                "signal processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('joint eigenstructure') is the object of the gerund-participle 'estimating', depending on 'estimating' in the phrase 'estimating the joint eigenstructure'. Entity 2 ('signal processing') is part of a prepositional phrase, depending on 'applications' in the phrase 'with applications in signal processing and machine learning'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "eigenstructure → estimating → for → used → with → applications → in → processing",
        "sentence": "Estimating the joint eigenstructure is used with applications in signal processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('joint eigenstructure') is part of the subject complement, depending on 'estimating' in the phrase 'Estimating the joint eigenstructure'. Entity 2 ('signal processing') is the object of the preposition 'in', depending on 'applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the prepositional phrase 'with applications in signal processing'.\""
    },
    {
        "raw_sentence": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices , with applications in signal processing and machine learning .",
        "ner_pair": [
            [
                "joint eigenstructure",
                "OtherScientificTerm"
            ],
            [
                "machine learning",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('joint eigenstructure') is the object, depending on 'estimating' with the verb 'used'. Entity 2 ('machine learning') is part of a compound noun, depending on 'applications' with the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where 'joint eigenstructure' is estimated using a method that has applications in 'machine learning'.\"",
        "sdp_path_text": "eigenstructure → estimating → for → used → with → applications → in → processing → learning",
        "sentence": "Estimating the joint eigenstructure is used with applications in machine learning.",
        "sentence_llm_dp_info": "\"Entity 1 ('joint eigenstructure') is part of the noun phrase 'the joint eigenstructure', which is the object of the verb 'estimating'. Entity 2 ('machine learning') is the object of the preposition 'in', depending on 'in' in the phrase 'in machine learning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the prepositional phrase 'with applications in'.\""
    },
    {
        "raw_sentence": "Joint matrix triangularization is often used for estimating the joint eigenstructure of a set M of matrices , with applications in signal processing and machine learning .",
        "ner_pair": [
            [
                "signal processing",
                "Task"
            ],
            [
                "machine learning",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('signal processing') is part of a coordination, depending on 'and' with 'machine learning'. Entity 2 ('machine learning') is also part of a coordination, depending on 'and' with 'signal processing'. Both entities are the objects of the preposition 'in', which depends on 'applications'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the coordinating conjunction 'and' within the prepositional phrase 'in signal processing and machine learning'.\"",
        "sdp_path_text": "processing → learning",
        "sentence": "Signal processing and machine learning are application areas.",
        "sentence_llm_dp_info": "\"Entity 1 ('signal processing') is a conjunct, depending on 'are' with 'and'. Entity 2 ('machine learning') is also a conjunct, depending on 'are' with 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and the verb 'are'.\""
    },
    {
        "raw_sentence": "Our main result is a first-order upper bound on the distance between any approximate joint triangularizer of the matrices in M ' and any exact joint triangularizer of the matrices in M .",
        "ner_pair": [
            [
                "first-order upper bound",
                "OtherScientificTerm"
            ],
            [
                "approximate joint triangularizer",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('first-order upper bound') is the subject complement, depending on the copula 'is' with 'result'. Entity 2 ('approximate joint triangularizer') is the subject, depending on the preposition 'of' with 'bound'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on the distance between any approximate joint triangularizer of the matrices in M'.\"",
        "sdp_path_text": "bound → on → distance → between → triangularizer",
        "sentence": "The first-order upper bound is on the distance between any approximate joint triangularizer and any exact joint triangularizer.",
        "sentence_llm_dp_info": "\"Entity 1 ('first-order upper bound') is the subject, depending on the preposition 'on' which links it to 'distance'. Entity 2 ('approximate joint triangularizer') is the object of the preposition 'between', depending on 'between' in the phrase 'between any approximate joint triangularizer and any exact joint triangularizer'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional structure involving 'on' and 'between'.\""
    },
    {
        "raw_sentence": "Our main result is a first-order upper bound on the distance between any approximate joint triangularizer of the matrices in M ' and any exact joint triangularizer of the matrices in M .",
        "ner_pair": [
            [
                "first-order upper bound",
                "OtherScientificTerm"
            ],
            [
                "exact joint triangularizer",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('first-order upper bound') is the complement, depending on 'is' as part of the predicate 'is a first-order upper bound on the distance'. Entity 2 ('exact joint triangularizer') is the object of the preposition 'between', depending on 'between' in the phrase 'between any approximate joint triangularizer... and any exact joint triangularizer'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger structure describing the relationship involving 'distance'.\"",
        "sdp_path_text": "bound → on → distance → between → triangularizer → triangularizer",
        "sentence": "The first-order upper bound is on the distance between any approximate and exact joint triangularizers.",
        "sentence_llm_dp_info": "\"Entity 1 ('first-order upper bound') is the subject, depending on the preposition 'on' with 'distance'. Entity 2 ('exact joint triangularizer') is part of the compound noun phrase, depending on 'between' as one of the nouns in the phrase 'between any approximate and exact joint triangularizers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on the distance between any approximate and exact joint triangularizers'.\""
    },
    {
        "raw_sentence": "Our main result is a first-order upper bound on the distance between any approximate joint triangularizer of the matrices in M ' and any exact joint triangularizer of the matrices in M .",
        "ner_pair": [
            [
                "approximate joint triangularizer",
                "Method"
            ],
            [
                "exact joint triangularizer",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approximate joint triangularizer') is the object of the preposition 'between', depending on 'distance'. Entity 2 ('exact joint triangularizer') is also the object of the preposition 'between', depending on 'distance'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'between' in the context of the distance being measured.\"",
        "sdp_path_text": "triangularizer → triangularizer",
        "sentence": "The distance between an approximate joint triangularizer and an exact joint triangularizer is bounded.",
        "sentence_llm_dp_info": "\"Entity 1 ('approximate joint triangularizer') is the subject of the clause, depending on the preposition 'between'. Entity 2 ('exact joint triangularizer') is also part of the same prepositional phrase, depending on 'between'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'between'.\""
    },
    {
        "raw_sentence": "To our knowledge , this is the first a posteriori bound for joint matrix decomposition .",
        "ner_pair": [
            [
                "posteriori bound",
                "OtherScientificTerm"
            ],
            [
                "joint matrix decomposition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('posteriori bound') is the object, depending on 'bound' with 'a'. Entity 2 ('joint matrix decomposition') is the object of the preposition 'for', depending on 'for' in the phrase 'for joint matrix decomposition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "bound → for → decomposition",
        "sentence": "This is the first posteriori bound for joint matrix decomposition.",
        "sentence_llm_dp_info": "\"Entity 1 ('posteriori bound') is the complement, depending on the preposition 'for'. Entity 2 ('joint matrix decomposition') is the object of the preposition 'for', also depending on 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for joint matrix decomposition'.\""
    },
    {
        "raw_sentence": "The psycholinguistic literature provides evidence for syntactic priming , i.e. , the tendency to repeat structures .",
        "ner_pair": [
            [
                "psycholinguistic literature",
                "OtherScientificTerm"
            ],
            [
                "syntactic priming",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('psycholinguistic literature') is the subject, depending on the verb 'provides'. Entity 2 ('syntactic priming') is the object of the preposition 'for', depending on 'for' in the phrase 'for syntactic priming'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' and the preposition 'for'.\"",
        "sdp_path_text": "literature → provides → evidence → for → priming",
        "sentence": "The psycholinguistic literature provides evidence for syntactic priming.",
        "sentence_llm_dp_info": "\"Entity 1 ('psycholinguistic literature') is the subject, depending on the verb 'provides'. Entity 2 ('syntactic priming') is the object of the preposition 'for', depending on 'for' in the phrase 'for syntactic priming'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper describes a method for incorporating priming into an incremental probabilistic parser .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "priming",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on the verb 'describes' with 'This paper'. Entity 2 ('priming') is part of the prepositional phrase 'for incorporating priming', where it is the object of the preposition 'into'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the verb 'incorporating'.\"",
        "sdp_path_text": "method → for → incorporating → priming",
        "sentence": "This paper describes a method for incorporating priming.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'for', depending on 'describes' with 'This paper'. Entity 2 ('priming') is the object of the preposition 'for', depending on 'incorporating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for incorporating priming'.\""
    },
    {
        "raw_sentence": "This paper describes a method for incorporating priming into an incremental probabilistic parser .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "incremental probabilistic parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'describes' with 'This paper'. Entity 2 ('incremental probabilistic parser') is the object of the preposition 'into', depending on 'into' in the phrase 'into an incremental probabilistic parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'into'.\"",
        "sdp_path_text": "method → for → incorporating → into → parser",
        "sentence": "A method for incorporating priming into an incremental probabilistic parser is described.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'described'. Entity 2 ('incremental probabilistic parser') is the object of the preposition 'into', depending on 'incorporating'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for incorporating priming into an incremental probabilistic parser'.\""
    },
    {
        "raw_sentence": "This paper describes a method for incorporating priming into an incremental probabilistic parser .",
        "ner_pair": [
            [
                "priming",
                "OtherScientificTerm"
            ],
            [
                "incremental probabilistic parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priming') is the object of the preposition 'for', depending on 'incorporating'. Entity 2 ('incremental probabilistic parser') is the object, depending on the preposition 'into'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for incorporating priming into an incremental probabilistic parser'.\"",
        "sdp_path_text": "priming → incorporating → into → parser",
        "sentence": "The method incorporates priming into an incremental probabilistic parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('priming') is the object of the preposition 'into', depending on 'incorporates'. Entity 2 ('incremental probabilistic parser') is the object of the preposition 'into', also depending on 'incorporates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'into an incremental probabilistic parser'.\""
    },
    {
        "raw_sentence": "Three models are compared , which involve priming of rules between sentences , within sentences , and within coordinate structures .",
        "ner_pair": [
            [
                "priming",
                "OtherScientificTerm"
            ],
            [
                "rules",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priming') is part of the prepositional phrase 'of rules', acting as the object of the preposition 'of', and depends on 'involve'. Entity 2 ('rules') is the object of the preposition 'of', depending on 'priming' in the phrase 'priming of rules'. There is a direct dependency between Entity 1 and Entity 2, as 'rules' is the object that 'priming' acts upon.\"",
        "sdp_path_text": "priming → of → rules",
        "sentence": "Priming involves rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('priming') is the subject, depending on the verb 'involves'. Entity 2 ('rules') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as 'rules' is directly involved with 'priming' through the verb 'involves'.\""
    },
    {
        "raw_sentence": "Three models are compared , which involve priming of rules between sentences , within sentences , and within coordinate structures .",
        "ner_pair": [
            [
                "priming",
                "OtherScientificTerm"
            ],
            [
                "coordinate structures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priming') is part of a noun phrase, acting as the object of the preposition 'of', depending on 'involve' in the clause 'which involve priming'. Entity 2 ('coordinate structures') is also part of a noun phrase, acting as an object complement, depending on the preposition 'within' in the phrase 'within coordinate structures'. There is no direct dependency between Entity 1 and Entity 2; both are related through the verb 'involve' and the prepositions 'of' and 'within'.\"",
        "sdp_path_text": "priming → of → rules → between → within → within → structures",
        "sentence": "Priming of rules involves coordinate structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('priming') is part of the compound noun 'priming of rules', acting as the subject, depending on the verb 'involves'. Entity 2 ('coordinate structures') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as 'coordinate structures' is directly involved by 'priming of rules'.\""
    },
    {
        "raw_sentence": "Three models are compared , which involve priming of rules between sentences , within sentences , and within coordinate structures .",
        "ner_pair": [
            [
                "rules",
                "OtherScientificTerm"
            ],
            [
                "coordinate structures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rules') is the object of the preposition 'of', depending on 'priming'. Entity 2 ('coordinate structures') is the object of the preposition 'within', depending on the preposition 'within'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of items that priming involves.\"",
        "sdp_path_text": "rules → between → within → within → structures",
        "sentence": "Rules are compared between sentences, within sentences, and within coordinate structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('rules') is the subject, depending on the verb 'compared'. Entity 2 ('coordinate structures') is the object of the preposition 'within', depending on 'within' in the phrase 'within coordinate structures'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparison structure described in the sentence.\""
    },
    {
        "raw_sentence": "These models simulate the reading time advantage for parallel structures found in human data , and also yield a small increase in overall parsing accuracy .",
        "ner_pair": [
            [
                "parallel structures",
                "OtherScientificTerm"
            ],
            [
                "human data",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parallel structures') is the object of the preposition 'for', depending on 'simulate' with 'models'. Entity 2 ('human data') is the object of the preposition 'in', depending on 'found' with 'advantage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the models simulate.\"",
        "sdp_path_text": "structures → found → in → data",
        "sentence": "Parallel structures are found in human data.",
        "sentence_llm_dp_info": "\"Entity 1 ('parallel structures') is the subject, depending on the verb 'found'. Entity 2 ('human data') is the object, depending on 'in' with 'found'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "These models simulate the reading time advantage for parallel structures found in human data , and also yield a small increase in overall parsing accuracy .",
        "ner_pair": [
            [
                "parallel structures",
                "OtherScientificTerm"
            ],
            [
                "parsing accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parallel structures') is the object of the preposition 'for', depending on 'simulate' with 'models'. Entity 2 ('parsing accuracy') is the object of the preposition 'in', depending on 'increase' in the phrase 'increase in overall parsing accuracy'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the actions performed by 'models'.\"",
        "sdp_path_text": "structures → for → advantage → simulate → yield → increase → in → accuracy",
        "sentence": "Parallel structures simulate an advantage that yields an increase in parsing accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('parallel structures') is the subject, depending on the verb 'simulate'. Entity 2 ('parsing accuracy') is the object of the preposition 'in', depending on 'increase'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'yields' and the prepositional phrase 'in parsing accuracy'.\""
    },
    {
        "raw_sentence": "These models simulate the reading time advantage for parallel structures found in human data , and also yield a small increase in overall parsing accuracy .",
        "ner_pair": [
            [
                "human data",
                "Material"
            ],
            [
                "parsing accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('human data') is the object of the preposition 'in', depending on 'found'. Entity 2 ('parsing accuracy') is the object of the preposition 'in', depending on 'increase'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing what the models achieve.\"",
        "sdp_path_text": "data → in → found → structures → for → advantage → simulate → yield → increase → in → accuracy",
        "sentence": "These models simulate the advantage found in human data and yield an increase in parsing accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('human data') is the object of the preposition 'in', depending on 'found'. Entity 2 ('parsing accuracy') is the object of the preposition 'in', depending on 'increase'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the outcomes of the models' simulation and yield.\""
    },
    {
        "raw_sentence": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .",
        "ner_pair": [
            [
                "Learned confidence measures",
                "Method"
            ],
            [
                "outlier removal",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Learned confidence measures') is the subject, depending on the verb 'gain'. Entity 2 ('outlier removal') is part of the compound object of the preposition 'for', depending on 'for' in the phrase 'for outlier removal and quality improvement'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "measures → gain → importance → for → removal",
        "sentence": "Learned confidence measures gain importance for outlier removal.",
        "sentence_llm_dp_info": "\"Entity 1 ('Learned confidence measures') is the subject, depending on the verb 'gain'. Entity 2 ('outlier removal') is the object of the preposition 'for', depending on 'for' in the phrase 'for outlier removal'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for' which indicates the purpose or benefit of the subject gaining importance.\""
    },
    {
        "raw_sentence": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .",
        "ner_pair": [
            [
                "Learned confidence measures",
                "Method"
            ],
            [
                "quality improvement",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Learned confidence measures') is the subject, depending on the verb 'gain'. Entity 2 ('quality improvement') is part of a compound object, depending on 'and' which connects it with 'outlier removal', both being objects of the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'for outlier removal and quality improvement'.\"",
        "sdp_path_text": "measures → gain → importance → for → removal → improvement",
        "sentence": "Learned confidence measures gain importance for quality improvement.",
        "sentence_llm_dp_info": "\"Entity 1 ('Learned confidence measures') is the subject, depending on the verb 'gain'. Entity 2 ('quality improvement') is the object of the preposition 'for', depending on 'for' in the phrase 'for quality improvement'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .",
        "ner_pair": [
            [
                "Learned confidence measures",
                "Method"
            ],
            [
                "stereo vision",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Learned confidence measures') is the subject, depending on the verb 'gain'. Entity 2 ('stereo vision') is the object of the preposition 'in', depending on 'in' in the phrase 'in stereo vision'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the phrase 'in stereo vision' which specifies the domain where Entity 1 gains importance.\"",
        "sdp_path_text": "measures → gain → importance → for → removal → improvement → in → vision",
        "sentence": "Learned confidence measures gain importance for improvement in stereo vision.",
        "sentence_llm_dp_info": "\"Entity 1 ('Learned confidence measures') is the subject, depending on the verb 'gain'. Entity 2 ('stereo vision') is the object of the preposition 'for', depending on 'for' in the phrase 'for improvement in stereo vision'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for improvement in'.\""
    },
    {
        "raw_sentence": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .",
        "ner_pair": [
            [
                "outlier removal",
                "Task"
            ],
            [
                "quality improvement",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('outlier removal') is part of the compound object of the preposition 'for', depending on 'for' in the phrase 'for outlier removal and quality improvement'. Entity 2 ('quality improvement') is also part of the compound object of the preposition 'for', depending on 'for' in the same phrase. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'for'.\"",
        "sdp_path_text": "removal → improvement",
        "sentence": "Learned confidence measures gain importance for outlier removal and quality improvement.",
        "sentence_llm_dp_info": "\"Entity 1 ('outlier removal') is the object of the preposition 'for', depending on 'for' in the phrase 'for outlier removal'. Entity 2 ('quality improvement') is also the object of the preposition 'for', depending on 'for' in the phrase 'for quality improvement'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'for' in the context of what the learned confidence measures gain importance for.\""
    },
    {
        "raw_sentence": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .",
        "ner_pair": [
            [
                "outlier removal",
                "Task"
            ],
            [
                "stereo vision",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('outlier removal') is the object of the preposition 'for', depending on 'for' in the phrase 'for outlier removal'. Entity 2 ('stereo vision') is the object of the preposition 'in', depending on 'in' in the phrase 'in stereo vision'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence, where 'learned confidence measures' are gaining importance for purposes that include 'outlier removal' and 'quality improvement' in the domain of 'stereo vision'.\"",
        "sdp_path_text": "removal → improvement → in → vision",
        "sentence": "Learned confidence measures improve outlier removal in stereo vision.",
        "sentence_llm_dp_info": "\"Entity 1 ('outlier removal') is the object, depending on the verb 'improve'. Entity 2 ('stereo vision') is the object of the preposition 'in', depending on 'in' in the phrase 'in stereo vision'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'outlier removal' is improved within the context of 'stereo vision'.\""
    },
    {
        "raw_sentence": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .",
        "ner_pair": [
            [
                "quality improvement",
                "Task"
            ],
            [
                "stereo vision",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('quality improvement') is the object of the preposition 'for', depending on 'for' in the phrase 'for outlier removal and quality improvement'. Entity 2 ('stereo vision') is also the object of the preposition 'in', depending on 'in' in the phrase 'in stereo vision'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger prepositional phrases that modify the main clause.\"",
        "sdp_path_text": "improvement → in → vision",
        "sentence": "Quality improvement is important for stereo vision.",
        "sentence_llm_dp_info": "\"Entity 1 ('quality improvement') is the subject, depending on the verb 'is'. Entity 2 ('stereo vision') is the object of the preposition 'for', depending on 'important'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate 'is important for'.\""
    },
    {
        "raw_sentence": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes .",
        "ner_pair": [
            [
                "manual interaction",
                "OtherScientificTerm"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manual interaction') is part of a list of items, depending on 'involves' with 'task'. Entity 2 ('task') is the subject, depending on 'is' with 'acquiring the necessary training data'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves'.\"",
        "sdp_path_text": "interaction → involves → task",
        "sentence": "Manual interaction involves a task.",
        "sentence_llm_dp_info": "\"Entity 1 ('manual interaction') is the subject, depending on the verb 'involves'. Entity 2 ('task') is the object, depending on the verb 'involves'. There is a direct dependency between Entity 1 and Entity 2, as 'task' is directly involved by 'manual interaction'.\""
    },
    {
        "raw_sentence": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes .",
        "ner_pair": [
            [
                "active sensing devices",
                "OtherScientificTerm"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('active sensing devices') is part of a list, depending on the conjunction 'and/or' with 'synthetic scenes', which together are the objects of the preposition 'involves'. Entity 2 ('task') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'involves'.\"",
        "sdp_path_text": "devices → interaction → involves → task",
        "sentence": "Active sensing devices involve a tedious and time-consuming task.",
        "sentence_llm_dp_info": "\"Entity 1 ('active sensing devices') is the subject, depending on the verb 'involve'. Entity 2 ('task') is the object, depending on the verb 'involve'. There is a direct dependency between Entity 1 and Entity 2, as 'active sensing devices' directly involve the 'task'.\""
    },
    {
        "raw_sentence": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes .",
        "ner_pair": [
            [
                "synthetic scenes",
                "OtherScientificTerm"
            ],
            [
                "task",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic scenes') is the object of the preposition 'and/or', depending on 'devices'. Entity 2 ('task') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing aspects of the task.\"",
        "sdp_path_text": "scenes → devices → interaction → involves → task",
        "sentence": "Acquiring the necessary training data involves synthetic scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic scenes') is the object, depending on 'involves' with 'data'. Entity 2 ('task') is not directly mentioned in the sentence provided, so it does not have any dependencies within this context. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not part of the given sentence.\""
    },
    {
        "raw_sentence": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes .",
        "ner_pair": [
            [
                "manual interaction",
                "OtherScientificTerm"
            ],
            [
                "active sensing devices",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manual interaction') is part of a coordination, depending on the conjunction 'and' with 'active sensing devices'. Entity 2 ('active sensing devices') is also part of the same coordination, depending on the conjunction 'and' with 'manual interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements of a list that serves as the object of the verb 'involves'.\"",
        "sdp_path_text": "interaction → devices",
        "sentence": "Acquiring training data involves manual interaction and active sensing devices.",
        "sentence_llm_dp_info": "\"Entity 1 ('manual interaction') is part of a coordination, depending on the conjunction 'and' with 'active sensing devices'. Entity 2 ('active sensing devices') is also part of the same coordination, depending on the conjunction 'and' with 'manual interaction'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the object of the verb 'involves'.\""
    },
    {
        "raw_sentence": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes .",
        "ner_pair": [
            [
                "manual interaction",
                "OtherScientificTerm"
            ],
            [
                "synthetic scenes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manual interaction') is part of a list, depending on the verb 'involves'. Entity 2 ('synthetic scenes') is also part of the same list, depending on the conjunction 'and/or' which links it to 'active sensing devices'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list involved in the task described.\"",
        "sdp_path_text": "interaction → devices → scenes",
        "sentence": "Acquiring training data involves manual interaction and synthetic scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('manual interaction') is part of a coordination, depending on 'involves' with 'Acquiring training data'. Entity 2 ('synthetic scenes') is also part of the same coordination, depending on 'and' with 'manual interaction'. There is no direct dependency between Entity 1 and Entity 2, but they are both coordinated elements in the list of what 'involves' refers to.\""
    },
    {
        "raw_sentence": "However , acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction , active sensing devices and/or synthetic scenes .",
        "ner_pair": [
            [
                "active sensing devices",
                "OtherScientificTerm"
            ],
            [
                "synthetic scenes",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('active sensing devices') is part of a coordination, depending on 'and/or' with 'synthetic scenes'. Entity 2 ('synthetic scenes') is also part of the same coordination, depending on 'and/or' with 'active sensing devices'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together in the list of items that the task involves.\"",
        "sdp_path_text": "devices → scenes",
        "sentence": "Acquiring training data involves active sensing devices and synthetic scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('active sensing devices') is part of a conjunction, depending on 'involves' with the verb 'involves'. Entity 2 ('synthetic scenes') is also part of the same conjunction, depending on 'involves' with the verb 'involves'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the list of things that the process of acquiring training data involves.\""
    },
    {
        "raw_sentence": "To overcome this problem , we propose a new , flexible , and scalable way for generating training data that only requires a set of stereo images as input .",
        "ner_pair": [
            [
                "problem",
                "Generic"
            ],
            [
                "stereo images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('problem') is the object of the preposition 'this', depending on 'overcome' with 'To overcome this problem'. Entity 2 ('stereo images') is the object of the preposition 'of', depending on 'set' in the phrase 'a set of stereo images'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "problem → overcome → propose → way → requires → set → of → images",
        "sentence": "To overcome the problem, a way is proposed that requires a set of stereo images.",
        "sentence_llm_dp_info": "\"Entity 1 ('problem') is the object of the preposition 'the', depending on 'overcome'. Entity 2 ('stereo images') is the object, depending on 'requires'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the solution proposed to overcome the problem.\""
    },
    {
        "raw_sentence": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm .",
        "ner_pair": [
            [
                "view points",
                "OtherScientificTerm"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('view points') is the object of the preposition 'for', depending on 'use' in the phrase 'use different view points'. Entity 2 ('approach') is the subject complement, depending on 'is' in the phrase 'idea of our approach is'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'use' which is part of the main clause describing what the approach entails.\"",
        "sdp_path_text": "points → use → is → idea → of → approach",
        "sentence": "The approach uses different view points.",
        "sentence_llm_dp_info": "\"Entity 1 ('view points') is the object, depending on 'uses' with 'approach'. Entity 2 ('approach') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, where 'approach' is the subject that performs the action of using 'view points'.\""
    },
    {
        "raw_sentence": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "multiple depth maps",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'idea'. Entity 2 ('multiple depth maps') is the object of the preposition 'between', depending on 'reasoning'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verb 'reasoning'.\"",
        "sdp_path_text": "approach → of → idea → is → use → for → reasoning → about → contradictions → between → maps",
        "sentence": "The approach uses different viewpoints for reasoning about contradictions between multiple depth maps.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'uses'. Entity 2 ('multiple depth maps') is the object of the preposition 'between', depending on 'between' in the phrase 'between multiple depth maps'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'uses' and the prepositional phrase 'for reasoning about contradictions between'.\""
    },
    {
        "raw_sentence": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "stereo algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject complement, depending on 'is' with 'idea'. Entity 2 ('stereo algorithm') is the object of the preposition 'with', depending on 'generated' in the phrase 'generated with the same stereo algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'generated' and the preposition 'with'.\"",
        "sdp_path_text": "approach → of → idea → is → use → for → reasoning → about → contradictions → between → maps → generated → with → algorithm",
        "sentence": "The approach uses different viewpoints for reasoning about contradictions between depth maps generated with the same stereo algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'uses'. Entity 2 ('stereo algorithm') is the object of the preposition 'with', depending on 'generated' in the phrase 'generated with the same stereo algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'uses' and the prepositional phrase 'with the same stereo algorithm'.\""
    },
    {
        "raw_sentence": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm .",
        "ner_pair": [
            [
                "view points",
                "OtherScientificTerm"
            ],
            [
                "multiple depth maps",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('view points') is the object of the preposition 'for', depending on 'use'. Entity 2 ('multiple depth maps') is the object of the preposition 'between', depending on 'reasoning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the purpose and method of the approach.\"",
        "sdp_path_text": "points → use → for → reasoning → about → contradictions → between → maps",
        "sentence": "Different view points are used for reasoning about contradictions between multiple depth maps.",
        "sentence_llm_dp_info": "\"Entity 1 ('view points') is the object of the verb 'used', depending on 'are used'. Entity 2 ('multiple depth maps') is the object of the preposition 'between', depending on 'between' in the phrase 'between multiple depth maps'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reasoning' which indicates the action performed regarding the contradictions between them.\""
    },
    {
        "raw_sentence": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm .",
        "ner_pair": [
            [
                "view points",
                "OtherScientificTerm"
            ],
            [
                "stereo algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('view points') is the object of the preposition 'for', depending on 'use' in the phrase 'to use different view points'. Entity 2 ('stereo algorithm') is the object of the preposition 'with', depending on 'generated' in the phrase 'generated with the same stereo algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the method used in the approach.\"",
        "sdp_path_text": "points → use → for → reasoning → about → contradictions → between → maps → generated → with → algorithm",
        "sentence": "Different view points are used for reasoning about contradictions between depth maps generated with the same stereo algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('view points') is the subject, depending on the verb 'used'. Entity 2 ('stereo algorithm') is the object of the preposition 'with', depending on 'generated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the prepositional phrase 'with the same stereo algorithm'.\""
    },
    {
        "raw_sentence": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm .",
        "ner_pair": [
            [
                "multiple depth maps",
                "OtherScientificTerm"
            ],
            [
                "stereo algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple depth maps') is the object of the preposition 'between', depending on 'reasoning'. Entity 2 ('stereo algorithm') is the object of the preposition 'with', depending on 'generated'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the reasoning is about and how the depth maps are generated.\"",
        "sdp_path_text": "maps → generated → with → algorithm",
        "sentence": "Multiple depth maps are generated with the same stereo algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple depth maps') is the subject, depending on the verb 'generated'. Entity 2 ('stereo algorithm') is the object of the preposition 'with', depending on 'with' in the phrase 'with the same stereo algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'generated' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "learned confidence measures",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'demonstrate' with 'the potential of our approach'. Entity 2 ('learned confidence measures') is the object of the preposition 'of', depending on 'performance' with 'the performance of three learned confidence measures'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where the potential of the approach is demonstrated by improving the performance of the learned confidence measures.\"",
        "sdp_path_text": "approach → of → potential → demonstrate → by → boosting → performance → of → measures",
        "sentence": "We demonstrate the potential of our approach by boosting the performance of learned confidence measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential'. Entity 2 ('learned confidence measures') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing what the approach boosts.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "KITTI2012 dataset",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'demonstrate' with 'we'. Entity 2 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'measures'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and contribute to describing the context of the experiment.\"",
        "sdp_path_text": "approach → of → potential → demonstrate → by → boosting → performance → on → dataset",
        "sentence": "We demonstrate the potential of our approach by boosting performance on the KITTI2012 dataset.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential'. Entity 2 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the demonstration of the potential of the approach by improving performance on the specified dataset.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential' in the phrase 'the potential of our approach'. Entity 2 ('them') is the object of the preposition 'on', depending on 'training' in the phrase 'training them on a vast amount of automatically generated training data'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and contribute to describing the actions taken to boost performance.\"",
        "sdp_path_text": "approach → of → potential → demonstrate → by → boosting → by → training → them",
        "sentence": "We demonstrate the potential of our approach by boosting the performance of the measures by training them.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential'. Entity 2 ('them') is the object of the verb 'training', depending on 'training' in the phrase 'training them'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and contribute to the overall meaning of the sentence.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "automatically generated training data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'demonstrate' with 'we'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training' with 'them'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the method used to boost performance.\"",
        "sdp_path_text": "approach → of → potential → demonstrate → by → boosting → by → training → on → amount → of → data",
        "sentence": "We demonstrate the potential of our approach by training on automatically generated training data.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how the potential of the approach is demonstrated.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "laser ground truth data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential' in the phrase 'the potential of our approach'. Entity 2 ('laser ground truth data') is the object of the preposition 'of', depending on 'amount' in the phrase 'a limited amount of laser ground truth data'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing the method and data used in the experiment.\"",
        "sdp_path_text": "approach → of → potential → demonstrate → by → boosting → by → training → on → amount → amount → of → data",
        "sentence": "We demonstrate the potential of our approach by training on a vast amount of data rather than laser ground truth data.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'of', depending on 'potential'. Entity 2 ('laser ground truth data') is the object of the preposition 'than', depending on 'rather'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the demonstration of the potential of the approach.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "KITTI2012 dataset",
                "Material"
            ],
            [
                "learned confidence measures",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'on' in the phrase 'on the KITTI2012 dataset'. Entity 2 ('learned confidence measures') is the object of the preposition 'of', depending on 'of' in the phrase 'of three learned confidence measures'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the performance of Entity 2 is evaluated on Entity 1.\"",
        "sdp_path_text": "dataset → on → performance → of → measures",
        "sentence": "The performance of learned confidence measures was boosted on the KITTI2012 dataset.",
        "sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'boosted'. Entity 2 ('learned confidence measures') is the subject, depending on 'was boosted'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'was boosted' which indicates that the performance of Entity 2 was enhanced when evaluated on Entity 1.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "learned confidence measures",
                "Method"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learned confidence measures') is the object of the preposition 'of', depending on 'performance'. Entity 2 ('them') is a pronoun, referring back to 'learned confidence measures' and serving as the object of the verb 'training'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers to 'learned confidence measures'.\"",
        "sdp_path_text": "measures → of → performance → boosting → by → training → them",
        "sentence": "The performance of learned confidence measures was boosted by training them.",
        "sentence_llm_dp_info": "\"Entity 1 ('learned confidence measures') is the subject, depending on 'boosted' with 'was'. Entity 2 ('them') is the object, depending on 'training' with 'by'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers back to 'learned confidence measures' in the passive construction 'was boosted by training them'.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "learned confidence measures",
                "Method"
            ],
            [
                "automatically generated training data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learned confidence measures') is the object of the preposition 'of', depending on 'performance'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the performance of Entity 1 is improved by training on Entity 2.\"",
        "sdp_path_text": "measures → of → performance → boosting → by → training → on → amount → of → data",
        "sentence": "The performance of learned confidence measures is boosted by training on a vast amount of automatically generated training data.",
        "sentence_llm_dp_info": "\"Entity 1 ('learned confidence measures') is the subject of the clause, depending on the verb 'is boosted'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'boosted' and the prepositional phrase 'by training on'.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "learned confidence measures",
                "Method"
            ],
            [
                "laser ground truth data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learned confidence measures') is the object of the preposition 'of', depending on 'performance'. Entity 2 ('laser ground truth data') is the object of the preposition 'of', depending on 'amount'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context where the performance of the learned confidence measures is being improved by using a vast amount of automatically generated training data instead of a limited amount of laser ground truth data.\"",
        "sdp_path_text": "measures → of → performance → boosting → by → training → on → amount → amount → of → data",
        "sentence": "The performance of learned confidence measures is boosted by training on a vast amount of data rather than laser ground truth data.",
        "sentence_llm_dp_info": "\"Entity 1 ('learned confidence measures') is the subject of the clause, depending on the verb 'is boosted'. Entity 2 ('laser ground truth data') is the object of the preposition 'than', depending on 'rather than' in the comparative clause. There is no direct dependency between Entity 1 and Entity 2, but they are part of a comparative structure where the performance of Entity 1 is being compared to the use of Entity 2.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "KITTI2012 dataset",
                "Material"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'on' in the phrase 'on the KITTI2012 dataset'. Entity 2 ('them') is the object of the verb 'training', depending on 'training' in the phrase 'training them'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing the training and performance improvement of the confidence measures.\"",
        "sdp_path_text": "dataset → on → performance → boosting → by → training → them",
        "sentence": "The performance on the KITTI2012 dataset was boosted by training them.",
        "sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'performance'. Entity 2 ('them') is the object of the verb 'training', depending on 'by' in the phrase 'by training them'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "KITTI2012 dataset",
                "Material"
            ],
            [
                "automatically generated training data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'measures'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'boosting' and the preposition 'on'.\"",
        "sdp_path_text": "dataset → on → performance → boosting → by → training → on → amount → of → data",
        "sentence": "The performance on the KITTI2012 dataset was boosted by training on a vast amount of automatically generated training data.",
        "sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'performance'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where the performance improvement is described.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "KITTI2012 dataset",
                "Material"
            ],
            [
                "laser ground truth data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'measures'. Entity 2 ('laser ground truth data') is the object of the preposition 'than', depending on 'amount'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparison structure in the sentence, where the performance improvement is described relative to these two datasets.\"",
        "sdp_path_text": "dataset → on → performance → boosting → by → training → on → amount → amount → of → data",
        "sentence": "The performance on the KITTI2012 dataset was boosted by training on a vast amount of data rather than laser ground truth data.",
        "sentence_llm_dp_info": "\"Entity 1 ('KITTI2012 dataset') is the object of the preposition 'on', depending on 'performance'. Entity 2 ('laser ground truth data') is the object of the preposition 'than', depending on 'rather than'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparison structure in the sentence.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "automatically generated training data",
                "Material"
            ],
            [
                "them",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically generated training data') is the object of the preposition 'on', depending on 'training' with 'on'. Entity 2 ('them') is the object of the verb 'training', referring back to 'three learned confidence measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where 'them' (the measures) are trained on 'automatically generated training data'.\"",
        "sdp_path_text": "data → of → amount → on → training → them",
        "sentence": "We boost their performance by training them on a vast amount of automatically generated training data.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. Entity 2 ('them') is the object of the verb 'training', depending on 'boost'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'training' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "laser ground truth data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'on', depending on 'training' in the phrase 'training them'. Entity 2 ('laser ground truth data') is also the object of the preposition 'on', depending on 'amount' in the phrase 'a limited amount of laser ground truth data'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence structure, specifically to the preposition 'on'.\"",
        "sdp_path_text": "them → training → on → amount → amount → of → data",
        "sentence": "We boost their performance by training them on a vast amount of data rather than laser ground truth data.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'by', depending on 'training' in the phrase 'by training them'. Entity 2 ('laser ground truth data') is the object of the preposition 'than', depending on 'rather' in the phrase 'rather than laser ground truth data'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Among other experiments , we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data .",
        "ner_pair": [
            [
                "laser ground truth data",
                "Material"
            ],
            [
                "automatically generated training data",
                "Material"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('laser ground truth data') is the object, depending on 'rather than' which contrasts it with 'automatically generated training data'. Entity 2 ('automatically generated training data') is the object of the preposition 'on', depending on 'training'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted through the preposition 'rather than'.\"",
        "sdp_path_text": "data → of → amount → amount → of → data",
        "sentence": "The approach boosts performance using automatically generated training data instead of laser ground truth data.",
        "sentence_llm_dp_info": "\"Entity 1 ('laser ground truth data') is the complement, depending on 'instead of' which modifies 'using'. Entity 2 ('automatically generated training data') is the object of the preposition 'using', depending on 'boosts'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the method of boosting performance described in the sentence.\""
    },
    {
        "raw_sentence": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems .",
        "ner_pair": [
            [
                "learning in autonomous agents",
                "Task"
            ],
            [
                "domain-speciic models of actions",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learning in autonomous agents') is the subject complement, depending on 'area' with 'important area of'. Entity 2 ('domain-specific models of actions') is the object of the preposition 'of', depending on 'learn' in the phrase 'to learn domain-specific models of actions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what is learned in autonomous agents.\"",
        "sdp_path_text": "learning → of → area → is → ability → learn → models",
        "sentence": "Learning in autonomous agents involves the ability to learn domain-specific models of actions.",
        "sentence_llm_dp_info": "\"Entity 1 ('learning in autonomous agents') is the subject, depending on the verb 'involves'. Entity 2 ('domain-specific models of actions') is the object, depending on the preposition 'of' within the phrase 'models of actions'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'involves' and the prepositional phrase 'the ability to learn'.\""
    },
    {
        "raw_sentence": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems .",
        "ner_pair": [
            [
                "learning in autonomous agents",
                "Task"
            ],
            [
                "planning systems",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learning in autonomous agents') is the subject complement, depending on the verb 'is'. Entity 2 ('planning systems') is the object of the preposition 'by', depending on 'by' in the phrase 'to be used by planning systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'the ability to learn domain-specific models of actions to be used by planning systems'.\"",
        "sdp_path_text": "learning → of → area → is → ability → learn → models → used → by → systems",
        "sentence": "Learning in autonomous agents involves the ability to learn models used by planning systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('learning in autonomous agents') is the subject, depending on the verb 'involves'. Entity 2 ('planning systems') is the object of the preposition 'by', depending on 'used' in the phrase 'used by planning systems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'involves' and the prepositional phrase 'used by planning systems'.\""
    },
    {
        "raw_sentence": "An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems .",
        "ner_pair": [
            [
                "planning systems",
                "Task"
            ],
            [
                "domain-speciic models of actions",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('planning systems') is the object of the preposition 'by', depending on 'used'. Entity 2 ('domain-specific models of actions') is the object of the preposition 'to', depending on 'learn'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the preposition 'to'.\"",
        "sdp_path_text": "systems → by → used → models",
        "sentence": "Planning systems use domain-specific models of actions.",
        "sentence_llm_dp_info": "\"Entity 1 ('planning systems') is the subject, depending on the verb 'use'. Entity 2 ('domain-specific models of actions') is the object, depending on the verb 'use'. There is a direct dependency between Entity 1 and Entity 2, as 'planning systems' directly uses 'domain-specific models of actions'.\""
    },
    {
        "raw_sentence": "In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "action models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the direct object, depending on the verb 'present' with 'we'. Entity 2 ('action models') is the object of the preposition 'models', depending on 'learns' with 'agent'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is presented and learned.\"",
        "sdp_path_text": "methods → learns → models",
        "sentence": "Methods are presented for learning action models.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on the verb 'presented'. Entity 2 ('action models') is the object, depending on the preposition 'for' in the phrase 'for learning action models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for learning'.\""
    },
    {
        "raw_sentence": "In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "domain expert",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the object, depending on the verb 'present'. Entity 2 ('domain expert') is the object of the preposition 'of', depending on 'observation' in the phrase 'observation of a domain expert'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'present' and the prepositional phrase describing one of the sources from which the methods learn.\"",
        "sdp_path_text": "methods → learns → from → from → observation → of → expert",
        "sentence": "Methods involve learning from the observation of a domain expert.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on the verb 'involve'. Entity 2 ('domain expert') is the object of the preposition 'of', depending on 'observation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involve' and the prepositional phrase 'from the observation of a domain expert'.\""
    },
    {
        "raw_sentence": "In this paper , we present methods by which an agent learns action models from its own experience and from its observation of a domain expert .",
        "ner_pair": [
            [
                "action models",
                "Method"
            ],
            [
                "domain expert",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action models') is the object of the verb 'learns', depending on 'agent'. Entity 2 ('domain expert') is the object of the preposition 'of', depending on 'observation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the agent learns from.\"",
        "sdp_path_text": "models → learns → from → from → observation → of → expert",
        "sentence": "An agent learns action models from observing a domain expert.",
        "sentence_llm_dp_info": "\"Entity 1 ('action models') is the object, depending on the verb 'learns'. Entity 2 ('domain expert') is the object of the preposition 'from', depending on 'observing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'learns' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .",
        "ner_pair": [
            [
                "action model formalism",
                "Method"
            ],
            [
                "methods",
                "Metric"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action model formalism') is the object of the preposition 'of', depending on 'use'. Entity 2 ('methods') is the subject, depending on 'differ' with 'These'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the area in two ways: the use of an action model formalism...'.\"",
        "sdp_path_text": "formalism → of → use → ways → in → diier → methods",
        "sentence": "These methods differ in the use of an action model formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('action model formalism') is the object, depending on 'use' with 'the use of'. Entity 2 ('methods') is the subject, depending on 'differ' with 'These methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in the use of'.\""
    },
    {
        "raw_sentence": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .",
        "ner_pair": [
            [
                "methods",
                "Metric"
            ],
            [
                "re-active agent",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on 'differ' with 'These methods'. Entity 2 ('re-active agent') is the object of the preposition 'to', depending on 'suited' in the phrase 'better suited to the needs of a re-active agent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the characteristics of the methods that make them suitable for a re-active agent.\"",
        "sdp_path_text": "methods → diier → in → ways → use → of → formalism → is → suited → to → needs → of → agent",
        "sentence": "These methods differ in their use of a formalism better suited to the needs of a re-active agent.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on 'differ' as the main verb of the clause. Entity 2 ('re-active agent') is the object of the preposition 'of', depending on 'needs' in the phrase 'the needs of a re-active agent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase that modifies 'formalism'.\""
    },
    {
        "raw_sentence": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .",
        "ner_pair": [
            [
                "noise-handling mechanisms",
                "Method"
            ],
            [
                "methods",
                "Metric"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('noise-handling mechanisms') is the object of the preposition 'of', depending on 'implementation'. Entity 2 ('methods') is the subject, depending on 'differ' with 'These'. There is no direct dependency between Entity 1 and Entity 2; they are part of the same sentence but are not directly linked in terms of dependency.\"",
        "sdp_path_text": "mechanisms → of → implementation → use → ways → in → diier → methods",
        "sentence": "Methods differ from previous work through the implementation of noise-handling mechanisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('noise-handling mechanisms') is the object, depending on the preposition 'of' which is part of the prepositional phrase 'of noise-handling mechanisms', modifying the noun 'implementation'. Entity 2 ('methods') is the subject, depending on the verb 'differ'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'differ' and the prepositional phrase 'through the implementation of'.\""
    },
    {
        "raw_sentence": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .",
        "ner_pair": [
            [
                "action model formalism",
                "Method"
            ],
            [
                "re-active agent",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action model formalism') is the object of the preposition 'of', depending on 'use' in the phrase 'the use of an action model formalism'. Entity 2 ('re-active agent') is the object of the preposition 'to', depending on 'suited' in the phrase 'better suited to the needs of a re-active agent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrases 'of an action model formalism' and 'to the needs of a re-active agent'.\"",
        "sdp_path_text": "formalism → is → suited → to → needs → of → agent",
        "sentence": "The action model formalism is better suited to the needs of a re-active agent.",
        "sentence_llm_dp_info": "\"Entity 1 ('action model formalism') is the subject, depending on the verb 'is'. Entity 2 ('re-active agent') is the object of the preposition 'of', depending on 'needs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'better suited to the needs of'.\""
    },
    {
        "raw_sentence": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .",
        "ner_pair": [
            [
                "action model formalism",
                "Method"
            ],
            [
                "noise-handling mechanisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action model formalism') is part of a noun phrase, depending on 'use' with 'the use of an action model formalism'. Entity 2 ('noise-handling mechanisms') is the object of the preposition 'of', depending on 'implementation' in the phrase 'implementation of noise-handling mechanisms'. There is no direct dependency between Entity 1 and Entity 2; both are parts of separate clauses describing the two ways in which the methods differ from previous work.\"",
        "sdp_path_text": "formalism → of → use → implementation → of → mechanisms",
        "sentence": "The use of an action model formalism includes the implementation of noise-handling mechanisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('action model formalism') is the object of the preposition 'of', depending on 'use'. Entity 2 ('noise-handling mechanisms') is the object, depending on 'implementation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where the inclusion of Entity 2 is a result of the use of Entity 1.\""
    },
    {
        "raw_sentence": "These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .",
        "ner_pair": [
            [
                "re-active agent",
                "Method"
            ],
            [
                "noise-handling mechanisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('re-active agent') is the object of the preposition 'to', depending on 'suited' within the clause 'which is better suited to the needs of a re-active agent'. Entity 2 ('noise-handling mechanisms') is the object of the preposition 'of', depending on 'implementation' within the phrase 'successful implementation of noise-handling mechanisms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "agent → of → needs → to → suited → is → formalism → of → use → implementation → of → mechanisms",
        "sentence": "The use of an action model formalism suited to a re-active agent's needs and the implementation of noise-handling mechanisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('re-active agent') is the object of the preposition 'to', depending on 'suited' in the phrase 'suited to a re-active agent's needs'. Entity 2 ('noise-handling mechanisms') is the object of the preposition 'of', depending on 'implementation' in the phrase 'the implementation of noise-handling mechanisms'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Training instances are generated from experience and observation , and a variant of GOLEM is used to learn action models from these instances .",
        "ner_pair": [
            [
                "GOLEM",
                "Method"
            ],
            [
                "action models",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GOLEM') is part of a noun phrase, functioning as the object of the preposition 'of' in the phrase 'a variant of GOLEM'. Entity 2 ('action models') is the object, depending on 'learn' with 'GOLEM'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'learn' and the preposition 'of'.\"",
        "sdp_path_text": "GOLEM → of → variant → used → learn → models",
        "sentence": "A variant of GOLEM is used to learn action models.",
        "sentence_llm_dp_info": "\"Entity 1 ('GOLEM') is the object of the preposition 'of', depending on 'variant'. Entity 2 ('action models') is the object, depending on 'learn'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'GOLEM' is modified by 'variant' and 'action models' is the target of the learning process described.\""
    },
    {
        "raw_sentence": "The integrated learning system has been experimentally validated in simulated construction and ooce domains .",
        "ner_pair": [
            [
                "simulated construction",
                "Task"
            ],
            [
                "integrated learning system",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('simulated construction') is the object of the preposition 'in', depending on 'validated'. Entity 2 ('integrated learning system') is the subject, depending on the verb 'has been validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'validated' and the prepositional phrase 'in simulated construction and office domains'.\"",
        "sdp_path_text": "simulated → domains → in → validated → system",
        "sentence": "The integrated learning system has been validated in simulated construction domains.",
        "sentence_llm_dp_info": "\"Entity 1 ('simulated construction') is part of a noun phrase acting as the object of the preposition 'in', depending on 'validated'. Entity 2 ('integrated learning system') is the subject, depending on the auxiliary verb 'has been' in the phrase 'has been validated'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the validation process described in the sentence.\""
    },
    {
        "raw_sentence": "The integrated learning system has been experimentally validated in simulated construction and ooce domains .",
        "ner_pair": [
            [
                "ooce domains",
                "Task"
            ],
            [
                "integrated learning system",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ooce domains') is the object of the preposition 'in', depending on 'validated'. Entity 2 ('integrated learning system') is the subject, depending on the auxiliary verb 'has been' in the phrase 'has been validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the validation process described in the sentence.\"",
        "sdp_path_text": "domains → in → validated → system",
        "sentence": "The integrated learning system has been validated in office domains.",
        "sentence_llm_dp_info": "\"Entity 1 ('office domains') is the object, depending on 'in' which modifies the verb phrase 'has been validated'. Entity 2 ('integrated learning system') is the subject, depending on the verb 'has been validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' that indicates where the validation took place.\""
    },
    {
        "raw_sentence": "The integrated learning system has been experimentally validated in simulated construction and ooce domains .",
        "ner_pair": [
            [
                "simulated construction",
                "Task"
            ],
            [
                "ooce domains",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('simulated construction') is part of the compound object, depending on 'in' with the prepositional phrase 'in simulated construction and ooce domains'. Entity 2 ('ooce domains') is also part of the compound object, depending on 'and' with 'simulated construction'. There is no direct dependency between Entity 1 and Entity 2, but they are connected as parts of the same prepositional phrase.\"",
        "sdp_path_text": "simulated → domains",
        "sentence": "{\n  \"Simplified sentence\": \"The integrated learning system has been validated in simulated construction and office domains.\"\n} \n\nNote: The original sentence contained a typo (\"ooce\" instead of \"office\"). In the simplified sentence, this typo has been corrected to maintain clarity and readability.",
        "sentence_llm_dp_info": "\"Entity 1 ('simulated construction') is part of the compound object of the preposition 'in', depending on 'in' in the phrase 'in simulated construction and office domains'. Entity 2 ('office domains') is also part of the compound object of the preposition 'in', depending on 'in' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are elements of the compound object linked by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This paper describes FERRET , an interactive question-answering -LRB- Q/A -RRB- system designed to address the challenges of integrating automatic Q/A applications into real-world environments .",
        "ner_pair": [
            [
                "FERRET",
                "Method"
            ],
            [
                "interactive question-answering -LRB- Q/A -RRB- system",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the appositive, depending on 'describes' with 'This paper'. Entity 2 ('interactive question-answering -LRB- Q/A -RRB- system') is the appositive, also depending on 'describes' with 'This paper'. There is no direct dependency between Entity 1 and Entity 2, but they are both described by the same clause, indicating that Entity 1 is the name or identifier for Entity 2.\"",
        "sdp_path_text": "FERRET → system",
        "sentence": "FERRET is an interactive question-answering (Q/A) system.",
        "sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject, depending on the copula 'is'. Entity 2 ('interactive question-answering (Q/A) system') is the predicate nominative, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is what Entity 1 is described as being.\""
    },
    {
        "raw_sentence": "This paper describes FERRET , an interactive question-answering -LRB- Q/A -RRB- system designed to address the challenges of integrating automatic Q/A applications into real-world environments .",
        "ner_pair": [
            [
                "FERRET",
                "Method"
            ],
            [
                "integrating automatic Q/A applications into real-world environments",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject complement, depending on the verb 'describes' with 'This paper'. Entity 2 ('integrating automatic Q/A applications into real-world environments') is the object of the preposition 'for', depending on 'designed' in the phrase 'designed to address the challenges of integrating...'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where FERRET is described as a system addressing the challenges mentioned.\"",
        "sdp_path_text": "FERRET → system → designed → address → challenges → of → integrating",
        "sentence": "FERRET is a system designed to address the challenges of integrating automatic Q/A applications into real-world environments.",
        "sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject, depending on the verb 'is'. Entity 2 ('integrating automatic Q/A applications into real-world environments') is the object of the preposition 'to', depending on 'address' in the phrase 'designed to address'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'designed' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "This paper describes FERRET , an interactive question-answering -LRB- Q/A -RRB- system designed to address the challenges of integrating automatic Q/A applications into real-world environments .",
        "ner_pair": [
            [
                "interactive question-answering -LRB- Q/A -RRB- system",
                "Method"
            ],
            [
                "integrating automatic Q/A applications into real-world environments",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('interactive question-answering -LRB- Q/A -RRB- system') is the subject complement, depending on the verb 'describes' with 'This paper'. Entity 2 ('integrating automatic Q/A applications into real-world environments') is the object of the verb 'address', depending on 'address' in the phrase 'designed to address'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the purpose and nature of the system described in the paper.\"",
        "sdp_path_text": "system → designed → address → challenges → of → integrating",
        "sentence": "The interactive question-answering system is designed to address the challenges of integrating automatic Q/A applications into real-world environments.",
        "sentence_llm_dp_info": "\"Entity 1 ('interactive question-answering (Q/A) system') is the subject, depending on the verb 'is designed'. Entity 2 ('integrating automatic Q/A applications into real-world environments') is the object of the preposition 'to', depending on 'address' in the phrase 'to address the challenges of integrating...'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'address' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "FERRET",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'to', depending on 'utilizes' with 'FERRET'. Entity 2 ('FERRET') is the subject, depending on the verb 'utilizes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the preposition 'to'.\"",
        "sdp_path_text": "approach → utilizes → FERRET",
        "sentence": "FERRET utilizes a novel approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object, depending on 'utilizes' with 'FERRET'. Entity 2 ('FERRET') is the subject, depending on the verb 'utilizes'. There is a direct dependency between Entity 1 and Entity 2, where 'approach' is utilized by 'FERRET'.\""
    },
    {
        "raw_sentence": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .",
        "ner_pair": [
            [
                "FERRET",
                "Method"
            ],
            [
                "Q/A",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject, depending on the verb 'utilizes'. Entity 2 ('Q/A') is the object of the preposition 'to', depending on 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the prepositional phrase 'to Q/A'.\"",
        "sdp_path_text": "FERRET → utilizes → approach → to → Q",
        "sentence": "FERRET utilizes a novel approach to Q/A.",
        "sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject, depending on the verb 'utilizes'. Entity 2 ('Q/A') is the object of the preposition 'to', depending on 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .",
        "ner_pair": [
            [
                "FERRET",
                "Method"
            ],
            [
                "predictive questioning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject, depending on the verb 'utilizes'. Entity 2 ('predictive questioning') is the object of the relative clause, depending on 'known' in the phrase 'known as predictive questioning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the prepositional phrase 'to Q/A known as predictive questioning'.\"",
        "sdp_path_text": "FERRET → utilizes → approach → known → as → questioning",
        "sentence": "FERRET utilizes an approach known as predictive questioning.",
        "sentence_llm_dp_info": "\"Entity 1 ('FERRET') is the subject, depending on the verb 'utilizes'. Entity 2 ('predictive questioning') is the complement of the preposition 'as', depending on 'as' in the phrase 'known as predictive questioning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the prepositional phrase 'known as'.\""
    },
    {
        "raw_sentence": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "Q/A",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object, depending on 'utilizes' with 'FERRET'. Entity 2 ('Q/A') is the object of the preposition 'to', depending on 'to' in the phrase 'to Q/A'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\"",
        "sdp_path_text": "approach → to → Q",
        "sentence": "FERRET utilizes a novel approach to Q/A.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'to', depending on 'utilizes' with 'FERRET'. Entity 2 ('Q/A') is the object of the preposition 'to', depending on 'approach'. There is a direct dependency between Entity 1 and Entity 2, where 'Q/A' is part of the prepositional phrase that modifies 'approach'.\""
    },
    {
        "raw_sentence": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "predictive questioning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the verb 'utilizes', depending on 'utilizes' with 'FERRET'. Entity 2 ('predictive questioning') is the appositive, depending on 'known as' with 'approach'. There is a direct dependency between Entity 1 and Entity 2, as 'predictive questioning' provides a specific name or description for 'approach'.\"",
        "sdp_path_text": "approach → known → as → questioning",
        "sentence": "The approach is known as predictive questioning.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is' in the phrase 'is known'. Entity 2 ('predictive questioning') is the complement, depending on the verb 'known' in the phrase 'known as'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'known'.\""
    },
    {
        "raw_sentence": "FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions -LRB- and answers -RRB- that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .",
        "ner_pair": [
            [
                "Q/A",
                "Method"
            ],
            [
                "predictive questioning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Q/A') is part of a noun phrase, depending on 'approach' with the preposition 'to'. Entity 2 ('predictive questioning') is the subject complement, depending on 'known' which is part of the phrase 'known as predictive questioning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the novel approach utilized by FERRET.\"",
        "sdp_path_text": "Q → to → approach → known → as → questioning",
        "sentence": "Q/A utilizes an approach known as predictive questioning.",
        "sentence_llm_dp_info": "\"Entity 1 ('Q/A') is the subject, depending on the verb 'utilizes'. Entity 2 ('predictive questioning') is the object of the preposition 'as', depending on 'known'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the prepositional phrase 'known as predictive questioning'.\""
    },
    {
        "raw_sentence": "In order to build robust automatic abstracting systems , there is a need for better training resources than are currently available .",
        "ner_pair": [
            [
                "training resources",
                "Material"
            ],
            [
                "automatic abstracting systems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training resources') is the object, depending on 'need' with 'there is a need for'. Entity 2 ('automatic abstracting systems') is the object of the preposition 'for', depending on 'build' in the phrase 'to build robust automatic abstracting systems'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of building and improving systems.\"",
        "sdp_path_text": "resources → for → need → is → In → order → build → systems",
        "sentence": "Better training resources are needed to build robust automatic abstracting systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('training resources') is the subject complement, depending on the verb 'needed'. Entity 2 ('automatic abstracting systems') is the object of the preposition 'to', depending on 'build' in the phrase 'to build robust automatic abstracting systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'needed' and the purpose clause introduced by 'to build'.\""
    },
    {
        "raw_sentence": "In this paper , we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way .",
        "ner_pair": [
            [
                "annotation scheme",
                "Method"
            ],
            [
                "scientific articles",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('annotation scheme') is the object of the verb 'introduce', depending on 'introduce' with 'we'. Entity 2 ('scientific articles') is the object of the preposition 'for', depending on 'for' in the phrase 'for scientific articles'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "scheme → for → articles",
        "sentence": "An annotation scheme is introduced for scientific articles.",
        "sentence_llm_dp_info": "\"Entity 1 ('annotation scheme') is the subject, depending on the verb 'introduced'. Entity 2 ('scientific articles') is the object of the preposition 'for', depending on 'for' in the phrase 'for scientific articles'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way .",
        "ner_pair": [
            [
                "annotation scheme",
                "Method"
            ],
            [
                "resource",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('annotation scheme') is the object of the verb 'introduce', depending on 'introduce' with 'we'. Entity 2 ('resource') is the object of the relative clause 'which can be used to build such a resource', depending on 'build'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where the 'annotation scheme' is described as something that can be used to build the 'resource'.\"",
        "sdp_path_text": "scheme → used → build → resource",
        "sentence": "The annotation scheme can be used to build a resource.",
        "sentence_llm_dp_info": "\"Entity 1 ('annotation scheme') is the subject, depending on the verb 'can be used'. Entity 2 ('resource') is the object, depending on the verb 'build'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'build' which is part of the clause 'can be used to build a resource'.\""
    },
    {
        "raw_sentence": "In this paper , we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way .",
        "ner_pair": [
            [
                "scientific articles",
                "Material"
            ],
            [
                "resource",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scientific articles') is the object of the preposition 'for', depending on 'scheme'. Entity 2 ('resource') is the object of the relative clause, depending on 'build'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what the annotation scheme is for and what it enables.\"",
        "sdp_path_text": "articles → for → scheme → used → build → resource",
        "sentence": "An annotation scheme for scientific articles can be used to build a resource.",
        "sentence_llm_dp_info": "\"Entity 1 ('scientific articles') is the object of the preposition 'for', depending on 'scheme'. Entity 2 ('resource') is the object, depending on 'build'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the scheme for scientific articles is used to build a resource.\""
    },
    {
        "raw_sentence": "The seven categories of the scheme are based on rhetorical moves of argumentation .",
        "ner_pair": [
            [
                "rhetorical moves of argumentation",
                "Method"
            ],
            [
                "scheme",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rhetorical moves of argumentation') is the object of the preposition 'on', depending on 'based'. Entity 2 ('scheme') is the subject, depending on 'are' in the phrase 'the scheme are based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on rhetorical moves of argumentation'.\"",
        "sdp_path_text": "moves → on → based → categories → of → scheme",
        "sentence": "The scheme is based on rhetorical moves of argumentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('rhetorical moves of argumentation') is the object of the preposition 'on', depending on 'based'. Entity 2 ('scheme') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is part of the prepositional phrase that modifies Entity 2.\""
    },
    {
        "raw_sentence": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "automated segmentation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'of', depending on 'segmentation'. Entity 2 ('automated segmentation') is the subject, depending on the verb 'requires'. There is a direct dependency between Entity 1 and Entity 2, as 'images' is part of the noun phrase that modifies 'automated segmentation'.\"",
        "sdp_path_text": "images → of → segmentation",
        "sentence": "Automated segmentation of images requires shape information.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'of', depending on 'of' in the phrase 'of images'. Entity 2 ('automated segmentation') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of images' which modifies 'automated segmentation'.\""
    },
    {
        "raw_sentence": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal .",
        "ner_pair": [
            [
                "automated segmentation",
                "Task"
            ],
            [
                "shape information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automated segmentation') is the subject, depending on the verb 'requires'. Entity 2 ('shape information') is the object, depending on 'requires' with 'automated segmentation'. There is a direct dependency between Entity 1 and Entity 2, as 'automated segmentation' directly requires 'shape information'.\"",
        "sdp_path_text": "segmentation → requires → information",
        "sentence": "Automated segmentation requires shape information.",
        "sentence_llm_dp_info": "\"Entity 1 ('automated segmentation') is the subject, depending on the verb 'requires'. Entity 2 ('shape information') is the object, depending on the verb 'requires'. There is a direct dependency between Entity 1 and Entity 2, as 'automated segmentation' directly requires 'shape information'.\""
    },
    {
        "raw_sentence": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal .",
        "ner_pair": [
            [
                "automated segmentation",
                "Task"
            ],
            [
                "low-level feature analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automated segmentation') is part of the subject, depending on the verb 'requires'. Entity 2 ('low-level feature analysis') is the subject of the clause 'low-level feature analysis alone often fails', depending on the verb 'fails'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence, with Entity 1 being a requirement for achieving the goal and Entity 2 being noted for its limitations in reaching the same goal.\"",
        "sdp_path_text": "segmentation → requires → fails → analysis",
        "sentence": "Automated segmentation requires more than low-level feature analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('automated segmentation') is the subject, depending on the verb 'requires'. Entity 2 ('low-level feature analysis') is the object of the preposition 'than', depending on 'than' in the phrase 'more than low-level feature analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'more than'.\""
    },
    {
        "raw_sentence": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "shape information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'of', depending on 'segmentation'. Entity 2 ('shape information') is the object, depending on 'requires' with 'segmentation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires' which indicates that 'shape information' is necessary for the 'segmentation of images'.\"",
        "sdp_path_text": "images → of → segmentation → requires → information",
        "sentence": "The segmentation of images requires shape information.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'of', depending on 'segmentation'. Entity 2 ('shape information') is the object, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'requires' which indicates that 'shape information' is required for the 'segmentation of images'.\""
    },
    {
        "raw_sentence": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "low-level feature analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'of', depending on 'segmentation'. Entity 2 ('low-level feature analysis') is the subject, depending on 'fails' with 'often'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, which discusses the requirements for image segmentation.\"",
        "sdp_path_text": "images → of → segmentation → requires → fails → analysis",
        "sentence": "The segmentation of images requires more than low-level feature analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'of', depending on 'segmentation'. Entity 2 ('low-level feature analysis') is the complement, depending on 'than' in the comparative clause 'more than low-level feature analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure that describes the requirements for image segmentation.\""
    },
    {
        "raw_sentence": "The automated segmentation of images into semantically meaningful parts requires shape information since low-level feature analysis alone often fails to reach this goal .",
        "ner_pair": [
            [
                "shape information",
                "OtherScientificTerm"
            ],
            [
                "low-level feature analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('shape information') is the subject complement, depending on 'requires' with 'segmentation'. Entity 2 ('low-level feature analysis') is the subject, depending on 'fails' with 'often'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence, with Entity 1 being necessary for the process and Entity 2 being insufficient on its own.\"",
        "sdp_path_text": "information → requires → fails → analysis",
        "sentence": "Shape information is required because low-level feature analysis often fails.",
        "sentence_llm_dp_info": "\"Entity 1 ('shape information') is the subject, depending on 'is' with the verb 'required'. Entity 2 ('low-level feature analysis') is the subject, depending on 'fails' with the verb 'fails'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause explaining why shape information is required.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "method",
                "Method"
            ],
            [
                "shape constrained image segmentation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'introduce' with 'We'. Entity 2 ('shape constrained image segmentation') is the object of the preposition 'of', depending on 'of' in the phrase 'of shape constrained image segmentation'. There is a direct dependency between Entity 1 and Entity 2, as 'shape constrained image segmentation' specifies what the 'method' is about.\"",
        "sdp_path_text": "method → of → segmentation",
        "sentence": "We introduce a method of shape constrained image segmentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'introduce' with 'We'. Entity 2 ('shape constrained image segmentation') is the object of the preposition 'of', depending on 'of' in the phrase 'of shape constrained image segmentation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "mixtures of feature distributions",
                "OtherScientificTerm"
            ],
            [
                "method",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the object of the preposition 'on', depending on 'based' in the phrase 'based on mixtures of feature distributions'. Entity 2 ('method') is the direct object, depending on the verb 'introduce'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on mixtures of feature distributions'.\"",
        "sdp_path_text": "mixtures → on → based → method",
        "sentence": "The method is based on mixtures of feature distributions.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the object, depending on 'based' with 'is'. Entity 2 ('method') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the complement that specifies what the method is based on.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "method",
                "Method"
            ],
            [
                "color",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'introduce' with 'We'. Entity 2 ('color') is part of the compound noun, depending on 'distributions' with 'feature'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of feature distributions for color and texture'.\"",
        "sdp_path_text": "method → based → on → mixtures → of → distributions → for → color",
        "sentence": "The method is based on mixtures of distributions for color.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is' in the phrase 'is based'. Entity 2 ('color') is the object of the preposition 'for', depending on 'distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for color' which modifies 'distributions'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "method",
                "Method"
            ],
            [
                "texture",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'introduce' with 'We'. Entity 2 ('texture') is part of the object, depending on 'distributions' with 'feature distributions'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "method → based → on → mixtures → of → distributions → for → color → texture",
        "sentence": "The method is based on mixtures of feature distributions for color and texture.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is'. Entity 2 ('texture') is part of a prepositional phrase, depending on 'for' in the phrase 'for color and texture'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "method",
                "Method"
            ],
            [
                "probabilistic shape knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'introduce'. Entity 2 ('probabilistic shape knowledge') is part of a list of items that describe what the method is based on, depending on 'based' in the phrase 'is based on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the basis of the method.\"",
        "sdp_path_text": "method → based → on → mixtures → of → distributions → knowledge",
        "sentence": "The method is based on mixtures of feature distributions and probabilistic shape knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is' as part of the predicate. Entity 2 ('probabilistic shape knowledge') is the object of the preposition 'and', depending on 'and' in the phrase 'and probabilistic shape knowledge'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing what the method is based on.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "shape constrained image segmentation",
                "Task"
            ],
            [
                "mixtures of feature distributions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the object of the preposition 'of', depending on 'method'. Entity 2 ('mixtures of feature distributions') is the subject complement, depending on 'is' in the clause 'which is based on mixtures of feature distributions'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the description of the 'novel method'.\"",
        "sdp_path_text": "segmentation → of → method → based → on → mixtures",
        "sentence": "Shape constrained image segmentation is based on mixtures of feature distributions.",
        "sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the subject, depending on the verb 'is'. Entity 2 ('mixtures of feature distributions') is the complement, depending on the preposition 'on' which follows the verb 'based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "shape constrained image segmentation",
                "Task"
            ],
            [
                "color",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the object of the preposition 'of', depending on 'method'. Entity 2 ('color') is part of a compound noun, depending on 'distributions' with 'feature distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'feature distributions' within the sentence.\"",
        "sdp_path_text": "segmentation → of → method → based → on → mixtures → of → distributions → for → color",
        "sentence": "Shape constrained image segmentation is based on mixtures of feature distributions for color.",
        "sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the subject, depending on the verb 'is' which links it to the predicate. Entity 2 ('color') is the object of the preposition 'for', depending on 'distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for color' which modifies 'feature distributions'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "shape constrained image segmentation",
                "Task"
            ],
            [
                "texture",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the object of the preposition 'of', depending on 'method'. Entity 2 ('texture') is part of the compound noun 'feature distributions for color and texture', depending on 'distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the method introduced.\"",
        "sdp_path_text": "segmentation → of → method → based → on → mixtures → of → distributions → for → color → texture",
        "sentence": "Shape constrained image segmentation is based on mixtures of feature distributions for color and texture.",
        "sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the subject, depending on the verb 'is'. Entity 2 ('texture') is part of the compound object, depending on the preposition 'for' within the phrase 'for color and texture'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for color and texture'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "shape constrained image segmentation",
                "Task"
            ],
            [
                "probabilistic shape knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the object of the preposition 'of', depending on 'method'. Entity 2 ('probabilistic shape knowledge') is part of a list of items, depending on 'as well as' within the clause describing the components of the method. There is no direct dependency between Entity 1 and Entity 2; both are components or aspects described in the sentence but are connected through the overall structure of the method being introduced.\"",
        "sdp_path_text": "segmentation → of → method → based → on → mixtures → of → distributions → knowledge",
        "sentence": "Shape constrained image segmentation is based on mixtures of feature distributions and probabilistic shape knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('shape constrained image segmentation') is the subject, depending on 'is' as the main verb of the sentence. Entity 2 ('probabilistic shape knowledge') is part of the compound object, depending on 'and' which connects it to 'mixtures of feature distributions'. There is no direct dependency between Entity 1 and Entity 2; both are related through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "mixtures of feature distributions",
                "OtherScientificTerm"
            ],
            [
                "color",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the object of the preposition 'on', depending on 'based' in the phrase 'based on mixtures of feature distributions'. Entity 2 ('color') is the object of the preposition 'for', depending on 'distributions' in the phrase 'for color and texture'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "mixtures → of → distributions → for → color",
        "sentence": "Mixtures of feature distributions are used for color.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the subject, depending on the verb 'are used'. Entity 2 ('color') is the object of the preposition 'for', depending on 'for' in the phrase 'for color'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "mixtures of feature distributions",
                "OtherScientificTerm"
            ],
            [
                "texture",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the object of the preposition 'on', depending on 'based' in the phrase 'based on mixtures of feature distributions'. Entity 2 ('texture') is part of a coordination, depending on 'for' in the phrase 'for color and texture'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the conjunction 'and'.\"",
        "sdp_path_text": "mixtures → of → distributions → for → color → texture",
        "sentence": "Mixtures of feature distributions are used for color and texture.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the subject, depending on the verb 'are used'. Entity 2 ('texture') is part of a coordination, depending on 'and' with 'color'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'are used' which indicates that the mixtures are used for both color and texture.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "mixtures of feature distributions",
                "OtherScientificTerm"
            ],
            [
                "probabilistic shape knowledge",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is part of the prepositional phrase 'based on mixtures of feature distributions', depending on the preposition 'on'. Entity 2 ('probabilistic shape knowledge') is also part of the prepositional phrase, depending on the conjunction 'as well as'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same prepositional phrase modifying the noun 'method'.\"",
        "sdp_path_text": "mixtures → of → distributions → knowledge",
        "sentence": "Mixtures of feature distributions are used with probabilistic shape knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('mixtures of feature distributions') is the subject, depending on the verb 'are used'. Entity 2 ('probabilistic shape knowledge') is the object of the preposition 'with', depending on 'with' in the phrase 'with probabilistic shape knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "color",
                "OtherScientificTerm"
            ],
            [
                "texture",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('color') is the object of the preposition 'for', depending on 'distributions'. Entity 2 ('texture') is also the object of the preposition 'for', depending on 'distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'for color and texture'.\"",
        "sdp_path_text": "color → texture",
        "sentence": "The method uses color and texture features for image segmentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('color') is part of a conjunction, depending on 'and' with 'texture'. Entity 2 ('texture') is also part of a conjunction, depending on 'and' with 'color'. Both are objects of the preposition 'of', which modifies 'features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "color",
                "OtherScientificTerm"
            ],
            [
                "probabilistic shape knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('color') is part of a compound noun, depending on 'distributions' with the preposition 'for'. Entity 2 ('probabilistic shape knowledge') is the object of the preposition 'as', depending on 'as' in the phrase 'as well as probabilistic shape knowledge'. There is no direct dependency between Entity 1 and Entity 2; both are related to the method described in the sentence but through different prepositional phrases.\"",
        "sdp_path_text": "color → for → distributions → knowledge",
        "sentence": "Color distributions contribute to probabilistic shape knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('color') is part of the compound noun 'color distributions', which acts as the subject, depending on the verb 'contribute'. Entity 2 ('probabilistic shape knowledge') is the object, depending on the verb 'contribute'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contribute'.\""
    },
    {
        "raw_sentence": "We introduce a novel method of shape constrained image segmentation which is based on mixtures of feature distributions for color and texture as well as probabilistic shape knowledge .",
        "ner_pair": [
            [
                "texture",
                "OtherScientificTerm"
            ],
            [
                "probabilistic shape knowledge",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('texture') is part of a compound noun, depending on 'distributions' with 'feature'. Entity 2 ('probabilistic shape knowledge') is the object of the preposition 'as', depending on 'as' in the phrase 'as well as probabilistic shape knowledge'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of elements that the method is based on.\"",
        "sdp_path_text": "texture → color → for → distributions → knowledge",
        "sentence": "Texture and color distributions contribute to probabilistic shape knowledge.",
        "sentence_llm_dp_info": "\"Entity 1 ('texture') is part of a conjunction, depending on 'contribute' with 'and color distributions'. Entity 2 ('probabilistic shape knowledge') is the object, depending on 'contribute' with 'texture and color distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contribute'.\""
    },
    {
        "raw_sentence": "The combined approach is formulated in the framework of Bayesian statistics to account for the robust-ness requirement in image understanding .",
        "ner_pair": [
            [
                "Bayesian statistics",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian statistics') is the object of the preposition 'in', depending on 'formulated'. Entity 2 ('approach') is the subject, depending on 'is' in the phrase 'The combined approach is formulated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formulated'.\"",
        "sdp_path_text": "statistics → of → framework → in → formulated → approach",
        "sentence": "The approach is formulated in the framework of Bayesian statistics.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian statistics') is the object of the preposition 'in', depending on 'framework'. Entity 2 ('approach') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the framework of Bayesian statistics'.\""
    },
    {
        "raw_sentence": "The combined approach is formulated in the framework of Bayesian statistics to account for the robust-ness requirement in image understanding .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "robust-ness requirement in image understanding",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'formulated'. Entity 2 ('robust-ness requirement in image understanding') is the object of the preposition 'for', depending on 'account' in the phrase 'to account for the robust-ness requirement in image understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to account for'.\"",
        "sdp_path_text": "approach → formulated → account → for → requirement",
        "sentence": "The approach is formulated to account for the robustness requirement in image understanding.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'formulated'. Entity 2 ('robustness requirement in image understanding') is the object of the preposition 'for', depending on 'for' in the phrase 'for the robustness requirement in image understanding'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "The combined approach is formulated in the framework of Bayesian statistics to account for the robust-ness requirement in image understanding .",
        "ner_pair": [
            [
                "Bayesian statistics",
                "Method"
            ],
            [
                "robust-ness requirement in image understanding",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian statistics') is part of the prepositional phrase 'in the framework of Bayesian statistics', where it serves as the object of the preposition 'of', depending on 'framework'. Entity 2 ('robust-ness requirement in image understanding') is the object of the preposition 'for', depending on 'account'. There is no direct dependency between Entity 1 and Entity 2; both are parts of larger phrases that are connected through the main clause of the sentence.\"",
        "sdp_path_text": "statistics → of → framework → in → formulated → account → for → requirement",
        "sentence": "The approach is formulated in the Bayesian statistics framework to account for the robustness requirement in image understanding.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian statistics') is part of a noun phrase, depending on 'framework' with the preposition 'in'. Entity 2 ('robustness requirement in image understanding') is the object of the preposition 'for', depending on 'account' in the phrase 'to account for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause that describes the purpose of the approach being formulated.\""
    },
    {
        "raw_sentence": "The goal of this work is the enrichment of human-machine interactions in a natural language environment .",
        "ner_pair": [
            [
                "natural language environment",
                "OtherScientificTerm"
            ],
            [
                "human-machine interactions",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language environment') is the object of the preposition 'in', depending on 'enrichment'. Entity 2 ('human-machine interactions') is the object of the preposition 'of', depending on 'enrichment'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the noun 'enrichment'.\"",
        "sdp_path_text": "environment → in → enrichment → of → interactions",
        "sentence": "The goal is to enrich human-machine interactions in a natural language environment.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language environment') is the object of the preposition 'in', depending on 'enrich'. Entity 2 ('human-machine interactions') is the object, depending on 'enrich'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'enrich'.\""
    },
    {
        "raw_sentence": "These mistakes can lead to various kinds of misunderstandings between speaker and listener , including reference failures or failure to understand the speaker 's intention .",
        "ner_pair": [
            [
                "reference failures",
                "OtherScientificTerm"
            ],
            [
                "speaker 's intention",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reference failures') is part of a coordination, depending on 'including' with 'misunderstandings'. Entity 2 ('speaker's intention') is the object of the preposition 'of', depending on 'failure' in the phrase 'failure to understand the speaker's intention'. There is no direct dependency between Entity 1 and Entity 2, but they are both included under the list of possible outcomes introduced by 'including'.\"",
        "sdp_path_text": "failures → failure → understand → intention",
        "sentence": "Reference failures can lead to failure to understand the speaker's intention.",
        "sentence_llm_dp_info": "\"Entity 1 ('reference failures') is the subject, depending on the verb 'can lead'. Entity 2 ('speaker's intention') is the object of the preposition 'to', depending on 'understand' in the phrase 'failure to understand the speaker's intention'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'can lead' and the phrase 'failure to understand'.\""
    },
    {
        "raw_sentence": "Our goal is to recognize and isolate such miscommunications and circumvent them .",
        "ner_pair": [
            [
                "miscommunications",
                "Task"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('miscommunications') is the object of the verbs 'recognize' and 'isolate', depending on the conjunction 'and' within the phrase 'recognize and isolate such miscommunications'. Entity 2 ('them') is the object of the verb 'circumvent', referring back to 'miscommunications'. There is no direct dependency between Entity 1 and Entity 2, but 'them' serves as a pronoun that refers to 'miscommunications'.\"",
        "sdp_path_text": "miscommunications → isolate → circumvent → them",
        "sentence": "Our goal is to isolate and circumvent miscommunications.",
        "sentence_llm_dp_info": "\"Entity 1 ('miscommunications') is the object, depending on 'circumvent' with 'and'. Entity 2 ('them') is a pronoun, depending on 'circumvent' as its object. There is no direct dependency between Entity 1 and Entity 2, but 'them' likely refers back to 'miscommunications' in the context of the sentence.\""
    },
    {
        "raw_sentence": "This paper highlights a particular class of miscommunication -- reference problems -- by describing a case study and techniques for avoiding failures of reference .",
        "ner_pair": [
            [
                "reference problems",
                "Task"
            ],
            [
                "miscommunication",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reference problems') is the appositive, depending on the noun 'class' with the appositional modifier '-- reference problems --'. Entity 2 ('miscommunication') is the object of the preposition 'of', depending on 'class' in the phrase 'class of miscommunication'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure where 'reference problems' clarifies a type of 'miscommunication'.\"",
        "sdp_path_text": "problems → class → of → miscommunication",
        "sentence": "Reference problems are a class of miscommunication.",
        "sentence_llm_dp_info": "\"Entity 1 ('reference problems') is the subject, depending on the verb 'are'. Entity 2 ('miscommunication') is the complement, depending on the verb 'are' in the phrase 'a class of miscommunication'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are' and the prepositional phrase 'a class of'.\""
    },
    {
        "raw_sentence": "This paper highlights a particular class of miscommunication -- reference problems -- by describing a case study and techniques for avoiding failures of reference .",
        "ner_pair": [
            [
                "miscommunication",
                "Task"
            ],
            [
                "techniques",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('miscommunication') is part of a nominal compound, specifically modified by 'particular class of', and is the object of the verb 'highlights'. Entity 2 ('techniques') is the subject of the clause 'techniques for avoiding failures of reference', depending on the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of the larger structure of the sentence, connected through the main clause and the descriptive elements.\"",
        "sdp_path_text": "miscommunication → of → class → highlights → by → describing → study → techniques",
        "sentence": "This paper highlights miscommunication by describing techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('miscommunication') is the object of the verb 'highlights', depending on 'highlights' with 'This paper'. Entity 2 ('techniques') is the object of the verb 'describing', depending on 'describing' in the phrase 'describing techniques'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "This paper highlights a particular class of miscommunication -- reference problems -- by describing a case study and techniques for avoiding failures of reference .",
        "ner_pair": [
            [
                "miscommunication",
                "Task"
            ],
            [
                "failures of reference",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('miscommunication') is the object of the preposition 'of', depending on 'class' in the phrase 'class of miscommunication'. Entity 2 ('failures of reference') is the object of the preposition 'of', depending on 'avoiding' in the phrase 'techniques for avoiding failures of reference'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of communication issues discussed in the paper.\"",
        "sdp_path_text": "miscommunication → of → class → highlights → by → describing → study → techniques → for → avoiding → failures",
        "sentence": "This paper highlights miscommunication by describing techniques for avoiding failures of reference.",
        "sentence_llm_dp_info": "\"Entity 1 ('miscommunication') is the object, depending on 'highlights' with 'This paper'. Entity 2 ('failures of reference') is the object of the preposition 'of', depending on 'describing' in the phrase 'techniques for avoiding failures of reference'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the paper's focus on communication issues.\""
    },
    {
        "raw_sentence": "This paper highlights a particular class of miscommunication -- reference problems -- by describing a case study and techniques for avoiding failures of reference .",
        "ner_pair": [
            [
                "reference problems",
                "Task"
            ],
            [
                "techniques",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reference problems') is part of an appositive, depending on 'class' with 'a particular class of miscommunication'. Entity 2 ('techniques') is the object of the preposition 'for', depending on 'describing' in the phrase 'techniques for avoiding failures of reference'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence.\"",
        "sdp_path_text": "problems → class → highlights → by → describing → study → techniques",
        "sentence": "This paper highlights reference problems by describing techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('reference problems') is the object, depending on the verb 'highlights' with 'This paper'. Entity 2 ('techniques') is the object of the preposition 'by', depending on 'by' in the phrase 'by describing techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the action described by the verb 'highlights'.\""
    },
    {
        "raw_sentence": "This paper highlights a particular class of miscommunication -- reference problems -- by describing a case study and techniques for avoiding failures of reference .",
        "ner_pair": [
            [
                "reference problems",
                "Task"
            ],
            [
                "failures of reference",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reference problems') is the appositive, depending on 'class' with 'of'. Entity 2 ('failures of reference') is the object, depending on 'avoiding' with 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the topic of miscommunication discussed in the sentence.\"",
        "sdp_path_text": "problems → class → highlights → by → describing → study → techniques → for → avoiding → failures",
        "sentence": "This paper highlights reference problems by describing techniques for avoiding failures of reference.",
        "sentence_llm_dp_info": "\"Entity 1 ('reference problems') is the object, depending on 'highlights' with 'This paper'. Entity 2 ('failures of reference') is the object of the preposition 'of', depending on 'avoiding' in the phrase 'for avoiding failures of reference'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the theme of reference issues within the sentence.\""
    },
    {
        "raw_sentence": "This paper highlights a particular class of miscommunication -- reference problems -- by describing a case study and techniques for avoiding failures of reference .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "failures of reference",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('techniques') is the object of the preposition 'for', depending on 'describing' in the phrase 'describing a case study and techniques'. Entity 2 ('failures of reference') is the object of the preposition 'of', depending on 'avoiding' in the phrase 'avoiding failures of reference'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "techniques → for → avoiding → failures",
        "sentence": "Techniques for avoiding failures of reference are described.",
        "sentence_llm_dp_info": "\"Entity 1 ('techniques') is the subject, depending on the verb 'described'. Entity 2 ('failures of reference') is the object of the preposition 'for', depending on 'for' in the phrase 'for avoiding failures of reference'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for avoiding failures of reference'.\""
    },
    {
        "raw_sentence": "This paper examines the benefits of system combination for unsupervised WSD .",
        "ner_pair": [
            [
                "system combination",
                "Method"
            ],
            [
                "unsupervised WSD",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system combination') is the object of the preposition 'of', depending on 'benefits'. Entity 2 ('unsupervised WSD') is the complement of the preposition 'for', depending on 'for' in the phrase 'for unsupervised WSD'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify 'benefits'.\"",
        "sdp_path_text": "combination → of → benefits → for → WSD",
        "sentence": "System combination benefits unsupervised WSD.",
        "sentence_llm_dp_info": "\"Entity 1 ('system combination') is the subject, depending on the verb 'benefits'. Entity 2 ('unsupervised WSD') is the object, depending on the verb 'benefits'. There is a direct dependency between Entity 1 and Entity 2, where 'system combination' benefits 'unsupervised WSD'.\""
    },
    {
        "raw_sentence": "We investigate several voting - and arbiter-based combination strategies over a diverse pool of unsupervised WSD systems .",
        "ner_pair": [
            [
                "voting - and arbiter-based combination strategies",
                "Method"
            ],
            [
                "unsupervised WSD systems",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('voting - and arbiter-based combination strategies') is the object of the verb 'investigate', depending on 'We'. Entity 2 ('unsupervised WSD systems') is the object of the preposition 'over', depending on 'strategies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'over'.\"",
        "sdp_path_text": "strategies → investigate → over → pool → of → systems",
        "sentence": "We investigate voting and arbiter-based combination strategies over unsupervised WSD systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('voting and arbiter-based combination strategies') is the object, depending on the verb 'investigate' with 'We'. Entity 2 ('unsupervised WSD systems') is the object of the preposition 'over', depending on 'over' in the phrase 'over unsupervised WSD systems'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'over'.\""
    },
    {
        "raw_sentence": "Our combination methods rely on predominant senses which are derived automatically from raw text .",
        "ner_pair": [
            [
                "predominant senses",
                "OtherScientificTerm"
            ],
            [
                "combination methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('predominant senses') is the object, depending on 'rely' with 'combination methods'. Entity 2 ('combination methods') is the subject, depending on the verb 'rely'. There is a direct dependency between Entity 1 and Entity 2, as 'predominant senses' are what the 'combination methods' rely on.\"",
        "sdp_path_text": "senses → on → rely → methods",
        "sentence": "Combination methods rely on predominant senses.",
        "sentence_llm_dp_info": "\"Entity 1 ('predominant senses') is the object, depending on 'rely' with 'combination methods'. Entity 2 ('combination methods') is the subject, depending on the verb 'rely'. There is a direct dependency between Entity 1 and Entity 2, as 'combination methods' relies on 'predominant senses'.\""
    },
    {
        "raw_sentence": "Our combination methods rely on predominant senses which are derived automatically from raw text .",
        "ner_pair": [
            [
                "combination methods",
                "Method"
            ],
            [
                "raw text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('combination methods') is the subject, depending on the verb 'rely'. Entity 2 ('raw text') is the object, depending on the verb 'derived'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'derived' and the prepositional phrase 'from raw text'.\"",
        "sdp_path_text": "methods → rely → on → senses → derived → from → text",
        "sentence": "Combination methods rely on senses derived from raw text.",
        "sentence_llm_dp_info": "\"Entity 1 ('combination methods') is the subject, depending on the verb 'rely'. Entity 2 ('raw text') is the object, depending on the preposition 'from' in the phrase 'from raw text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'rely' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Our combination methods rely on predominant senses which are derived automatically from raw text .",
        "ner_pair": [
            [
                "raw text",
                "Material"
            ],
            [
                "predominant senses",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('raw text') is the object, depending on 'derived' with 'are derived'. Entity 2 ('predominant senses') is the subject, depending on 'rely' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'derived'.\"",
        "sdp_path_text": "text → from → derived → senses",
        "sentence": "Predominant senses are derived from raw text.",
        "sentence_llm_dp_info": "\"Entity 1 ('raw text') is the object, depending on 'derived' with 'are'. Entity 2 ('predominant senses') is the subject, depending on 'are' with 'derived'. There is a direct dependency between Entity 1 and Entity 2, where 'raw text' is the source from which 'predominant senses' are derived.\""
    },
    {
        "raw_sentence": "Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art .",
        "ner_pair": [
            [
                "SemCor and Senseval-3 data sets",
                "Material"
            ],
            [
                "ensembles",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('SemCor and Senseval-3 data sets') is the object of the preposition 'using', depending on 'Experiments'. Entity 2 ('ensembles') is the subject, depending on the verb 'yield'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the experiments and their outcomes.\"",
        "sdp_path_text": "sets → using → Experiments → demonstrate → yield → ensembles",
        "sentence": "Experiments using SemCor and Senseval-3 data sets demonstrate that ensembles yield better results.",
        "sentence_llm_dp_info": "\"Entity 1 ('SemCor and Senseval-3 data sets') is the object of the preposition 'using', depending on 'Experiments'. Entity 2 ('ensembles') is the subject, depending on the verb 'yield'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the experiments and their outcomes.\""
    },
    {
        "raw_sentence": "Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art .",
        "ner_pair": [
            [
                "SemCor and Senseval-3 data sets",
                "Material"
            ],
            [
                "state-of-the-art",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('SemCor and Senseval-3 data sets') is the object of the preposition 'using', depending on 'Experiments'. Entity 2 ('state-of-the-art') is the object of the preposition 'with', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "sets → using → Experiments → demonstrate → yield → compared → with → -",
        "sentence": "Experiments using SemCor and Senseval-3 data sets demonstrate better results compared to state-of-the-art.",
        "sentence_llm_dp_info": "\"Entity 1 ('SemCor and Senseval-3 data sets') is the object of the preposition 'using', depending on 'Experiments'. Entity 2 ('state-of-the-art') is the object of the preposition 'to', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the outcome of the experiments.\""
    },
    {
        "raw_sentence": "Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art .",
        "ner_pair": [
            [
                "ensembles",
                "Generic"
            ],
            [
                "state-of-the-art",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ensembles') is the subject, depending on 'yield' as the verb. Entity 2 ('state-of-the-art') is the object of the preposition 'with', depending on 'compared' in the phrase 'compared with state-of-the-art'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative clause 'when compared with'.\"",
        "sdp_path_text": "ensembles → yield → compared → with → -",
        "sentence": "Ensembles yield significantly better results compared with state-of-the-art.",
        "sentence_llm_dp_info": "\"Entity 1 ('ensembles') is the subject, depending on the verb 'yield'. Entity 2 ('state-of-the-art') is the object of the preposition 'with', depending on 'compared' in the phrase 'compared with state-of-the-art'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure involving 'compared with'.\""
    },
    {
        "raw_sentence": "The applicability of many current information extraction techniques is severely limited by the need for supervised training data .",
        "ner_pair": [
            [
                "supervised training data",
                "Material"
            ],
            [
                "information extraction techniques",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('supervised training data') is the object, depending on the preposition 'for', which modifies 'need'. Entity 2 ('information extraction techniques') is the subject, depending on the verb 'is' (from 'is limited'). There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where the need for Entity 1 limits the applicability of Entity 2.\"",
        "sdp_path_text": "data → for → need → by → limited → applicability → of → techniques",
        "sentence": "The applicability of information extraction techniques is limited by the need for supervised training data.",
        "sentence_llm_dp_info": "\"Entity 1 ('supervised training data') is the object of the preposition 'for', depending on 'need'. Entity 2 ('information extraction techniques') is the object of the preposition 'of', depending on 'applicability'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'limited' which indicates that the need for Entity 1 limits the applicability of Entity 2.\""
    },
    {
        "raw_sentence": "We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion .",
        "ner_pair": [
            [
                "classified advertisements",
                "Material"
            ],
            [
                "field structured extraction tasks",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classified advertisements') is part of a list, depending on the conjunction 'and' with 'bibliographic citations'. Entity 2 ('field structured extraction tasks') is the object of the preposition 'for', depending on 'demonstrate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context provided for the demonstration of the main clause.\"",
        "sdp_path_text": "advertisements → as → tasks",
        "sentence": "Classified advertisements are used as field structured extraction tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('classified advertisements') is the subject, depending on the verb 'are used'. Entity 2 ('field structured extraction tasks') is the object of the preposition 'as', depending on 'as' in the phrase 'as field structured extraction tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'as' which indicates the purpose or role of Entity 1 in the context of Entity 2.\""
    },
    {
        "raw_sentence": "We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion .",
        "ner_pair": [
            [
                "bibliographic citations",
                "Material"
            ],
            [
                "field structured extraction tasks",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bibliographic citations') is part of a list, depending on the conjunction 'and' with 'classified advertisements'. Entity 2 ('field structured extraction tasks') is the object of the preposition 'for', depending on 'demonstrate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context provided for the demonstration of the statement.\"",
        "sdp_path_text": "citations → advertisements → as → tasks",
        "sentence": "Bibliographic citations are used as field structured extraction tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('bibliographic citations') is the subject, depending on the verb 'are used'. Entity 2 ('field structured extraction tasks') is the object, depending on the preposition 'as', which itself depends on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'.\""
    },
    {
        "raw_sentence": "We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion .",
        "ner_pair": [
            [
                "prior knowledge",
                "OtherScientificTerm"
            ],
            [
                "field structured extraction tasks",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('prior knowledge') is the subject complement, depending on the verb 'can be used'. Entity 2 ('field structured extraction tasks') is the object of the preposition 'for', depending on 'demonstrate' through the prepositional phrase 'that for certain field structured extraction tasks'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence structure, where Entity 2 sets the domain in which Entity 1 is utilized.\"",
        "sdp_path_text": "knowledge → of → amounts → used → for → tasks",
        "sentence": "Prior knowledge can be used for field structured extraction tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('prior knowledge') is the subject, depending on the verb 'can be used'. Entity 2 ('field structured extraction tasks') is the object of the preposition 'for', depending on 'for' in the phrase 'for field structured extraction tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion .",
        "ner_pair": [
            [
                "classified advertisements",
                "Material"
            ],
            [
                "bibliographic citations",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classified advertisements') is the first item in a list, depending on 'such as' which introduces examples of 'field structured extraction tasks'. Entity 2 ('bibliographic citations') is the second item in the list, also depending on 'such as'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list introduced by 'such as'.\"",
        "sdp_path_text": "advertisements → citations",
        "sentence": "Classified advertisements and bibliographic citations are examples of field structured extraction tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('classified advertisements') is the first conjunct, depending on 'and' with Entity 2. Entity 2 ('bibliographic citations') is the second conjunct, also depending on 'and' with Entity 1. Both entities are part of the subject of the sentence, which is the compound noun 'classified advertisements and bibliographic citations', depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2 through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion .",
        "ner_pair": [
            [
                "classified advertisements",
                "Material"
            ],
            [
                "prior knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classified advertisements') is part of a list, depending on the preposition 'such as' which modifies 'tasks'. Entity 2 ('prior knowledge') is the subject complement, depending on the verb 'can be used'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of the sentence where 'classified advertisements' is an example of the type of tasks, and 'prior knowledge' is what can be used to learn effective models for these tasks.\"",
        "sdp_path_text": "advertisements → as → tasks → for → used → amounts → of → knowledge",
        "sentence": "Prior knowledge can be used for tasks such as classified advertisements.",
        "sentence_llm_dp_info": "\"Entity 1 ('classified advertisements') is the object of the preposition 'such as', depending on 'tasks'. Entity 2 ('prior knowledge') is the subject, depending on the modal verb 'can' and the verb 'be used'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'for tasks such as'.\""
    },
    {
        "raw_sentence": "We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion .",
        "ner_pair": [
            [
                "bibliographic citations",
                "Material"
            ],
            [
                "prior knowledge",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bibliographic citations') is part of a list, depending on the preposition 'such as' which modifies 'tasks'. Entity 2 ('prior knowledge') is the object of the preposition 'of', depending on the noun phrase 'amounts of prior knowledge'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing the types of tasks and the use of knowledge in learning models.\"",
        "sdp_path_text": "citations → advertisements → as → tasks → for → used → amounts → of → knowledge",
        "sentence": "Prior knowledge can be used to learn effective models for tasks such as bibliographic citations.",
        "sentence_llm_dp_info": "\"Entity 1 ('bibliographic citations') is the object of the preposition 'such as', depending on 'tasks'. Entity 2 ('prior knowledge') is the subject, depending on the verb 'can be used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence, where 'prior knowledge' is part of what can be used to learn effective models for tasks that include 'bibliographic citations'.\""
    },
    {
        "raw_sentence": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text , general unsupervised HMM learning fails to learn useful structure in either of our domains .",
        "ner_pair": [
            [
                "hidden Markov models -LRB- HMMs -RRB-",
                "Method"
            ],
            [
                "generative model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hidden Markov models -LRB- HMMs -RRB-') is the subject, depending on the verb 'provide'. Entity 2 ('generative model') is the object, depending on the verb 'provide' with 'hidden Markov models -LRB- HMMs -RRB-'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 provides Entity 2.\"",
        "sdp_path_text": "models → provide → model",
        "sentence": "Hidden Markov models provide a generative model.",
        "sentence_llm_dp_info": "\"Entity 1 ('hidden Markov models -LRB- HMMs -RRB-') is the subject, depending on the verb 'provide'. Entity 2 ('generative model') is the object, depending on 'provide' with 'hidden Markov models -LRB- HMMs -RRB-'. There is a direct dependency between Entity 1 and Entity 2, as 'hidden Markov models -LRB- HMMs -RRB-' provides 'a generative model'.\""
    },
    {
        "raw_sentence": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text , general unsupervised HMM learning fails to learn useful structure in either of our domains .",
        "ner_pair": [
            [
                "hidden Markov models -LRB- HMMs -RRB-",
                "Method"
            ],
            [
                "field structured text",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hidden Markov models -LRB- HMMs -RRB-') is the subject, depending on the verb 'provide'. Entity 2 ('field structured text') is the object of the preposition 'for', depending on 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for field structured text'.\"",
        "sdp_path_text": "models → provide → model → for → text",
        "sentence": "Hidden Markov models provide a suitable model for field structured text.",
        "sentence_llm_dp_info": "\"Entity 1 ('hidden Markov models -LRB- HMMs -RRB-') is the subject, depending on the verb 'provide'. Entity 2 ('field structured text') is the object of the preposition 'for', depending on 'for' in the phrase 'for field structured text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provide' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text , general unsupervised HMM learning fails to learn useful structure in either of our domains .",
        "ner_pair": [
            [
                "hidden Markov models -LRB- HMMs -RRB-",
                "Method"
            ],
            [
                "unsupervised HMM learning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hidden Markov models -LRB- HMMs -RRB-') is the subject, depending on the verb 'provide'. Entity 2 ('unsupervised HMM learning') is the subject of the clause 'general unsupervised HMM learning fails', depending on the verb 'fails'. There is no direct dependency between Entity 1 and Entity 2; however, both are related to the topic of HMMs in the context of the sentence.\"",
        "sdp_path_text": "models → provide → fails → learning",
        "sentence": "Hidden Markov models provide a generative model, but unsupervised HMM learning fails.",
        "sentence_llm_dp_info": "\"Entity 1 ('hidden Markov models (HMMs)') is the subject, depending on the verb 'provide'. Entity 2 ('unsupervised HMM learning') is the subject, depending on the verb 'fails'. There is no direct dependency between Entity 1 and Entity 2, but both are subjects of different clauses in the sentence.\""
    },
    {
        "raw_sentence": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text , general unsupervised HMM learning fails to learn useful structure in either of our domains .",
        "ner_pair": [
            [
                "generative model",
                "Method"
            ],
            [
                "field structured text",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generative model') is the object of the preposition 'for', depending on 'provide' with 'HMMs'. Entity 2 ('field structured text') is the object of the preposition 'for', also depending on 'provide' with 'HMMs'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'for' in the context provided by 'provide'.\"",
        "sdp_path_text": "model → for → text",
        "sentence": "A generative model provides a suitable framework for field structured text.",
        "sentence_llm_dp_info": "\"Entity 1 ('generative model') is the subject, depending on the verb 'provides'. Entity 2 ('field structured text') is the object, depending on the preposition 'for' within the phrase 'for field structured text'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text , general unsupervised HMM learning fails to learn useful structure in either of our domains .",
        "ner_pair": [
            [
                "generative model",
                "Method"
            ],
            [
                "unsupervised HMM learning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generative model') is the object of the preposition 'for', depending on 'provide' with 'HMMs'. Entity 2 ('unsupervised HMM learning') is the subject, depending on 'fails' with 'learning'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of Hidden Markov Models (HMMs).\"",
        "sdp_path_text": "model → provide → fails → learning",
        "sentence": "Generative model provision fails with unsupervised HMM learning.",
        "sentence_llm_dp_info": "\"Entity 1 ('generative model') is part of the noun compound 'generative model provision', which is the subject, depending on the verb 'fails'. Entity 2 ('unsupervised HMM learning') is the object of the preposition 'with', depending on 'with' in the phrase 'with unsupervised HMM learning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the failure of the provision.\""
    },
    {
        "raw_sentence": "Although hidden Markov models -LRB- HMMs -RRB- provide a suitable generative model for field structured text , general unsupervised HMM learning fails to learn useful structure in either of our domains .",
        "ner_pair": [
            [
                "field structured text",
                "Material"
            ],
            [
                "unsupervised HMM learning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('field structured text') is the object, depending on 'model' with the prepositional phrase 'for field structured text'. Entity 2 ('unsupervised HMM learning') is the subject, depending on 'fails' in the clause 'general unsupervised HMM learning fails to learn useful structure'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses and related through the context of the sentence.\"",
        "sdp_path_text": "text → for → model → provide → fails → learning",
        "sentence": "Unsupervised HMM learning fails to provide a useful model for field structured text.",
        "sentence_llm_dp_info": "\"Entity 1 ('field structured text') is the object, depending on 'provide' with 'model'. Entity 2 ('unsupervised HMM learning') is the subject, depending on the verb 'fails'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'fails' and the phrase 'to provide a useful model for'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "accuracies",
                "Metric"
            ],
            [
                "unsupervised methods",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on 'attain' with 'unsupervised methods'. Entity 2 ('unsupervised methods') is the subject, depending on 'can' which is part of the modal verb phrase indicating possibility. There is a direct dependency between Entity 1 and Entity 2, as 'unsupervised methods' is the agent that can attain 'accuracies'.\"",
        "sdp_path_text": "accuracies → attain → methods",
        "sentence": "Unsupervised methods can attain accuracies.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on 'attain' with 'methods'. Entity 2 ('unsupervised methods') is the subject, depending on the verb 'can attain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'attain'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unlabeled examples",
                "Material"
            ],
            [
                "unsupervised methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object, depending on 'with' in the phrase 'with 400 unlabeled examples'. Entity 2 ('unsupervised methods') is the subject, depending on 'can' in the clause 'unsupervised methods can attain accuracies'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the clause describing the capability of unsupervised methods to attain accuracies using a certain number of unlabeled examples.\"",
        "sdp_path_text": "examples → with → accuracies → attain → methods",
        "sentence": "Unsupervised methods can attain accuracies with unlabeled examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object, depending on 'with' in the phrase 'with unlabeled examples'. Entity 2 ('unsupervised methods') is the subject, depending on 'can' which is part of the modal verb phrase 'can attain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which indicates that 'unlabeled examples' are used by 'unsupervised methods' to achieve accuracies.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unsupervised methods",
                "Method"
            ],
            [
                "labeled examples",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unsupervised methods') is the subject, depending on the verb 'can attain'. Entity 2 ('labeled examples') is the object, depending on the preposition 'on' with 'supervised methods'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a larger comparative structure within the sentence.\"",
        "sdp_path_text": "methods → attain → accuracies → with → examples",
        "sentence": "Unsupervised methods can attain accuracies with unlabeled examples comparable to those attained by supervised methods on labeled examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('unsupervised methods') is the subject, depending on the verb 'can attain'. Entity 2 ('labeled examples') is the object of the preposition 'on', depending on 'on' in the phrase 'on labeled examples'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparison structure involving the verb 'attain' and the prepositional phrases 'with unlabeled examples' and 'on labeled examples'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unsupervised methods",
                "Method"
            ],
            [
                "semi-supervised methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unsupervised methods') is the subject, depending on 'can attain' with 'accuracies'. Entity 2 ('semi-supervised methods') is the subject, depending on 'can make' with 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects in different clauses of the same sentence, indicating parallel processes or findings.\"",
        "sdp_path_text": "methods → attain → make → methods",
        "sentence": "Unsupervised methods can attain accuracies comparable to those attained by supervised methods, and semi-supervised methods can make good use of small amounts of labeled data.",
        "sentence_llm_dp_info": "\"Entity 1 ('unsupervised methods') is the subject, depending on the verb 'can attain'. Entity 2 ('semi-supervised methods') is also a subject, depending on the verb 'can make'. There is no direct dependency between Entity 1 and Entity 2; both are independent subjects in the compound sentence.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unsupervised methods",
                "Method"
            ],
            [
                "labeled data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unsupervised methods') is the subject, depending on the verb 'can attain'. Entity 2 ('labeled data') is the object of the preposition 'of', depending on 'amounts'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'unsupervised methods' and 'supervised methods' (which uses 'labeled data') are compared.\"",
        "sdp_path_text": "methods → attain → make → use → of → amounts → of → data",
        "sentence": "Unsupervised methods can make good use of small amounts of labeled data.",
        "sentence_llm_dp_info": "\"Entity 1 ('unsupervised methods') is the subject, depending on the modal verb 'can' which leads to the main verb 'make'. Entity 2 ('labeled data') is the object, depending on the verb 'use' within the phrase 'make good use of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "accuracies",
                "Metric"
            ],
            [
                "unlabeled examples",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on 'attain' with 'methods'. Entity 2 ('unlabeled examples') is the object, depending on 'with' with 'attain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'attain' and the preposition 'with'.\"",
        "sdp_path_text": "accuracies → with → examples",
        "sentence": "Accuracies can be attained with unlabeled examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the subject, depending on the verb 'can be attained'. Entity 2 ('unlabeled examples') is the object of the preposition 'with', depending on 'with' in the phrase 'with unlabeled examples'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "accuracies",
                "Metric"
            ],
            [
                "supervised methods",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object of the verb 'attain', depending on 'methods'. Entity 2 ('supervised methods') is the subject complement, depending on 'by' in the phrase 'by supervised methods'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparative structure 'comparable to those attained by supervised methods'.\"",
        "sdp_path_text": "accuracies → attain → methods",
        "sentence": "Unsupervised methods can attain accuracies comparable to those attained by supervised methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on the verb 'attain'. Entity 2 ('supervised methods') is the object of the preposition 'by', depending on 'attained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure 'comparable to those attained by'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "accuracies",
                "Metric"
            ],
            [
                "labeled examples",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on 'attain' with 'methods'. Entity 2 ('labeled examples') is the object, depending on 'on' with 'supervised methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure of the sentence where 'accuracies' attained by 'unsupervised methods' are compared to those attained by 'supervised methods' on 'labeled examples'.\"",
        "sdp_path_text": "accuracies → with → examples",
        "sentence": "Accuracies can be attained with labeled examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the subject, depending on the verb 'can be attained'. Entity 2 ('labeled examples') is the object, depending on the preposition 'with' in the phrase 'with labeled examples'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'can be attained' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "accuracies",
                "Metric"
            ],
            [
                "semi-supervised methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object of the clause 'can attain accuracies', depending on the verb 'attain'. Entity 2 ('semi-supervised methods') is the subject of the clause 'semi-supervised methods can make good use', depending on the verb 'make'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same complex sentence describing different aspects of the study's findings.\"",
        "sdp_path_text": "accuracies → attain → make → methods",
        "sentence": "Semi-supervised methods can attain accuracies.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on the verb 'attain'. Entity 2 ('semi-supervised methods') is the subject, depending on the verb 'can attain'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'attain'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "accuracies",
                "Metric"
            ],
            [
                "labeled data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object of the verb 'attain', depending on 'can attain' with 'unsupervised methods'. Entity 2 ('labeled data') is the object of the preposition 'of', depending on 'amounts' in the phrase 'small amounts of labeled data'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the comparison structure of the sentence.\"",
        "sdp_path_text": "accuracies → attain → make → use → of → amounts → of → data",
        "sentence": "Unsupervised methods can attain accuracies comparable to those attained by supervised methods on labeled data.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracies') is the object, depending on 'attain' with 'methods'. Entity 2 ('labeled data') is the object, depending on 'on' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'attain' and the preposition 'on' in the context of the sentence.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unlabeled examples",
                "Material"
            ],
            [
                "supervised methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object, depending on 'with' which modifies 'attain accuracies'. Entity 2 ('supervised methods') is the subject, depending on 'by' which introduces the agent of the action 'attained'. There is no direct dependency between Entity 1 and Entity 2; they are related through the comparison structure in the sentence.\"",
        "sdp_path_text": "examples → with → accuracies → attain → methods",
        "sentence": "Unsupervised methods can attain accuracies with unlabeled examples comparable to those attained by supervised methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object, depending on 'with' in the phrase 'with unlabeled examples'. Entity 2 ('supervised methods') is the object of the preposition 'by', depending on 'attained'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparative structure in the sentence.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unlabeled examples",
                "Material"
            ],
            [
                "semi-supervised methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object, depending on 'with' in the phrase 'with 400 unlabeled examples'. Entity 2 ('semi-supervised methods') is the subject, depending on 'can' in the clause 'can make good use'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence, contributing to the overall meaning of the methods and examples used in the study.\"",
        "sdp_path_text": "examples → with → accuracies → attain → make → methods",
        "sentence": "Unlabeled examples can be used by semi-supervised methods to attain accuracies.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the subject, depending on 'used' with 'can be'. Entity 2 ('semi-supervised methods') is the agent, depending on 'used' with 'by'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction 'can be used by'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "unlabeled examples",
                "Material"
            ],
            [
                "labeled data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object, depending on the preposition 'with', which modifies 'attain accuracies'. Entity 2 ('labeled data') is the object, depending on the preposition 'on', which modifies 'attained by supervised methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of achieving certain levels of accuracy through different methods.\"",
        "sdp_path_text": "examples → with → accuracies → attain → make → use → of → amounts → of → data",
        "sentence": "Unsupervised methods can attain accuracies with unlabeled examples comparable to those attained by supervised methods on labeled data.",
        "sentence_llm_dp_info": "\"Entity 1 ('unlabeled examples') is the object of the preposition 'with', depending on 'attain'. Entity 2 ('labeled data') is the object of the preposition 'on', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of achieving similar accuracies through different types of data.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "labeled examples",
                "Material"
            ],
            [
                "supervised methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('labeled examples') is the object, depending on the preposition 'on', which modifies 'supervised methods'. Entity 2 ('supervised methods') is the subject, depending on the verb 'attained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on 50 labeled examples'.\"",
        "sdp_path_text": "examples → with → accuracies → attain → methods",
        "sentence": "Labeled examples can be used by supervised methods to attain accuracies.",
        "sentence_llm_dp_info": "\"Entity 1 ('labeled examples') is the subject, depending on the verb 'can be used'. Entity 2 ('supervised methods') is the agent, depending on the passive construction 'be used by'. There is a direct dependency between Entity 1 and Entity 2, where 'supervised methods' uses 'labeled examples'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "supervised methods",
                "Method"
            ],
            [
                "labeled data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('supervised methods') is the object of the preposition 'by', depending on 'attained'. Entity 2 ('labeled data') is the object of the preposition 'of', depending on 'amounts'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the performance of different methods in relation to the amount of labeled data used.\"",
        "sdp_path_text": "methods → attain → make → use → of → amounts → of → data",
        "sentence": "Supervised methods can make good use of labeled data.",
        "sentence_llm_dp_info": "\"Entity 1 ('supervised methods') is the subject, depending on the verb 'can make'. Entity 2 ('labeled data') is the object, depending on the verb phrase 'make good use of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can make good use of'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "labeled examples",
                "Material"
            ],
            [
                "semi-supervised methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('labeled examples') is the object, depending on 'on' with 'supervised methods'. Entity 2 ('semi-supervised methods') is the subject, depending on 'can' with 'make'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparative structure in the sentence.\"",
        "sdp_path_text": "examples → with → accuracies → attain → make → methods",
        "sentence": "Semi-supervised methods can make good use of labeled examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('labeled examples') is the object, depending on the verb 'use' in the phrase 'make good use of'. Entity 2 ('semi-supervised methods') is the subject, depending on the modal verb 'can' and the main verb 'make'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can make good use of'.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "labeled examples",
                "Material"
            ],
            [
                "labeled data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('labeled examples') is the object, depending on the preposition 'on', which is part of the phrase 'on 50 labeled examples'. Entity 2 ('labeled data') is the object, depending on the preposition 'of', which is part of the phrase 'small amounts of labeled data'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of labeling in the context of training methods.\"",
        "sdp_path_text": "examples → with → accuracies → attain → make → use → of → amounts → of → data",
        "sentence": "Labeled examples can be used to attain accuracies, and small amounts of labeled data can make good use of these examples.",
        "sentence_llm_dp_info": "\"Entity 1 ('labeled examples') is the subject, depending on the verb 'can be used'. Entity 2 ('labeled data') is the subject, depending on the verb 'can make'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of usage or application within the sentence.\""
    },
    {
        "raw_sentence": "In both domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .",
        "ner_pair": [
            [
                "labeled data",
                "Material"
            ],
            [
                "semi-supervised methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('labeled data') is the object, depending on 'use' with 'can make good use of'. Entity 2 ('semi-supervised methods') is the subject, depending on 'can' which is part of the verb phrase 'can make'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can make good use of'.\"",
        "sdp_path_text": "data → of → amounts → of → use → make → methods",
        "sentence": "Semi-supervised methods can make good use of small amounts of labeled data.",
        "sentence_llm_dp_info": "\"Entity 1 ('labeled data') is the object, depending on 'use' with the phrase 'make good use of'. Entity 2 ('semi-supervised methods') is the subject, depending on 'can' which is part of the modal verb phrase 'can make'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'make' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "This paper gives an overall account of a prototype natural language question answering system , called Chat-80 .",
        "ner_pair": [
            [
                "Chat-80",
                "Method"
            ],
            [
                "natural language question answering system",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Chat-80') is the appositive, depending on the noun 'system'. Entity 2 ('natural language question answering system') is the object of the preposition 'of', depending on 'account'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the appositive structure where 'Chat-80' renames or specifies 'system'.\"",
        "sdp_path_text": "Chat-80 → called → system",
        "sentence": "Chat-80 is a natural language question answering system.",
        "sentence_llm_dp_info": "\"Entity 1 ('Chat-80') is the subject, depending on the copula 'is'. Entity 2 ('natural language question answering system') is the predicative, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, linked through the copula 'is'.\""
    },
    {
        "raw_sentence": "The system is implemented entirely in Prolog , a programming language based on logic .",
        "ner_pair": [
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            [
                "system",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the object of the preposition 'in', depending on 'implemented' with 'system'. Entity 2 ('system') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in Prolog'.\"",
        "sdp_path_text": "Prolog → in → implemented → system",
        "sentence": "The system is implemented in Prolog.",
        "sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the object, depending on 'implemented' with 'is'. Entity 2 ('system') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'Prolog' specifies what the 'system' is implemented in.\""
    },
    {
        "raw_sentence": "The system is implemented entirely in Prolog , a programming language based on logic .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "programming language",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'is' (implemented). Entity 2 ('programming language') is the subject complement, depending on the verb 'based' in the phrase 'based on logic'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause that describes the implementation details of the system.\"",
        "sdp_path_text": "system → implemented → in → Prolog → language",
        "sentence": "The system is implemented in Prolog, a programming language.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'is implemented'. Entity 2 ('programming language') is the complement of the noun 'Prolog', depending on 'Prolog' in the appositive phrase 'a programming language'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The system is implemented entirely in Prolog , a programming language based on logic .",
        "ner_pair": [
            [
                "system",
                "Generic"
            ],
            [
                "logic",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'is implemented'. Entity 2 ('logic') is the object of the preposition 'based on', depending on 'language' in the phrase 'a programming language based on logic'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'implemented' and the prepositional phrase describing the programming language.\"",
        "sdp_path_text": "system → implemented → in → Prolog → language → based → on → logic",
        "sentence": "The system is implemented in Prolog, a language based on logic.",
        "sentence_llm_dp_info": "\"Entity 1 ('system') is the subject, depending on the verb 'is implemented'. Entity 2 ('logic') is the complement of the preposition 'on', depending on 'based' in the phrase 'based on logic'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in Prolog, a language based on logic'.\""
    },
    {
        "raw_sentence": "The system is implemented entirely in Prolog , a programming language based on logic .",
        "ner_pair": [
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            [
                "programming language",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the object of the preposition 'in', depending on 'implemented'. Entity 2 ('programming language') is the subject complement, depending on 'is' with the copula 'based on logic'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'a programming language based on logic' which describes 'Prolog'.\"",
        "sdp_path_text": "Prolog → language",
        "sentence": "Prolog is a programming language.",
        "sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the subject, depending on the copula 'is'. Entity 2 ('programming language') is the predicate nominal, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, connected through the copula 'is'.\""
    },
    {
        "raw_sentence": "The system is implemented entirely in Prolog , a programming language based on logic .",
        "ner_pair": [
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            [
                "logic",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the object of the preposition 'in', depending on 'implemented' in the phrase 'implemented entirely in Prolog'. Entity 2 ('logic') is the complement of the preposition 'based on', depending on 'language' in the phrase 'a programming language based on logic'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'Prolog' is described as a 'programming language' that is 'based on logic'.\"",
        "sdp_path_text": "Prolog → language → based → on → logic",
        "sentence": "Prolog is a programming language based on logic.",
        "sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the subject, depending on the verb 'is'. Entity 2 ('logic') is the object of the preposition 'on', depending on 'based' in the phrase 'based on logic'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on logic'.\""
    },
    {
        "raw_sentence": "The system is implemented entirely in Prolog , a programming language based on logic .",
        "ner_pair": [
            [
                "logic",
                "OtherScientificTerm"
            ],
            [
                "programming language",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logic') is the object, depending on 'based' with 'programming language'. Entity 2 ('programming language') is the subject, depending on 'is' with 'Prolog'. There is a direct dependency between Entity 1 and Entity 2, as 'programming language' is described as being 'based on logic'.\"",
        "sdp_path_text": "logic → on → based → language",
        "sentence": "Prolog, a programming language based on logic.",
        "sentence_llm_dp_info": "\"Entity 1 ('logic') is the object of the preposition 'based', depending on 'based' in the phrase 'based on logic'. Entity 2 ('programming language') is the complement of the relative clause, depending on 'is' with 'Prolog'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on logic'.\""
    },
    {
        "raw_sentence": "With the aid of a logic-based grammar formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic .",
        "ner_pair": [
            [
                "extraposition grammars",
                "Method"
            ],
            [
                "logic-based grammar formalism",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extraposition grammars') is the object of the preposition 'called', depending on 'formalism'. Entity 2 ('logic-based grammar formalism') is the object of the preposition 'of', depending on 'aid'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases that describe their relationship to the main clause.\"",
        "sdp_path_text": "grammars → called → formalism",
        "sentence": "Extraposition grammars are called a logic-based grammar formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('extraposition grammars') is the subject, depending on the verb 'are called'. Entity 2 ('logic-based grammar formalism') is the predicative complement, depending on the verb 'are called'. There is a direct dependency between Entity 1 and Entity 2, as 'logic-based grammar formalism' directly describes what 'extraposition grammars' are called.\""
    },
    {
        "raw_sentence": "With the aid of a logic-based grammar formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic .",
        "ner_pair": [
            [
                "logic-based grammar formalism",
                "Method"
            ],
            [
                "Chat-80",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logic-based grammar formalism') is the object of the preposition 'of', depending on 'aid'. Entity 2 ('Chat-80') is the subject, depending on the verb 'translates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence where Entity 1 aids in the functionality described for Entity 2.\"",
        "sdp_path_text": "formalism → of → aid → With → translates → Chat-80",
        "sentence": "Chat-80 translates English questions with the aid of a logic-based grammar formalism.",
        "sentence_llm_dp_info": "\"Entity 1 ('logic-based grammar formalism') is the object of the preposition 'of', depending on 'aid'. Entity 2 ('Chat-80') is the subject, depending on the verb 'translates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with the aid of a logic-based grammar formalism'.\""
    },
    {
        "raw_sentence": "With the aid of a logic-based grammar formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic .",
        "ner_pair": [
            [
                "logic-based grammar formalism",
                "Method"
            ],
            [
                "Prolog subset of logic",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logic-based grammar formalism') is the object of the preposition 'of', depending on 'aid'. Entity 2 ('Prolog subset of logic') is the object, depending on 'into' in the phrase 'into the Prolog subset of logic'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing what Chat-80 does.\"",
        "sdp_path_text": "formalism → of → aid → With → translates → into → subset",
        "sentence": "A logic-based grammar formalism aids in translating English questions into the Prolog subset of logic.",
        "sentence_llm_dp_info": "\"Entity 1 ('logic-based grammar formalism') is the subject, depending on the verb 'aids'. Entity 2 ('Prolog subset of logic') is the object of the preposition 'into', depending on 'into' in the phrase 'into the Prolog subset of logic'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'into'.\""
    },
    {
        "raw_sentence": "With the aid of a logic-based grammar formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic .",
        "ner_pair": [
            [
                "extraposition grammars",
                "Method"
            ],
            [
                "Chat-80",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extraposition grammars') is the object of the preposition 'called', depending on 'formalism'. Entity 2 ('Chat-80') is the subject, depending on the verb 'translates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the translation process.\"",
        "sdp_path_text": "grammars → called → formalism → of → aid → With → translates → Chat-80",
        "sentence": "Chat-80 translates English questions with the aid of extraposition grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('extraposition grammars') is the object of the preposition 'of', depending on 'aid'. Entity 2 ('Chat-80') is the subject, depending on the verb 'translates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with the aid of extraposition grammars'.\""
    },
    {
        "raw_sentence": "With the aid of a logic-based grammar formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic .",
        "ner_pair": [
            [
                "extraposition grammars",
                "Method"
            ],
            [
                "Prolog subset of logic",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('extraposition grammars') is the object of the preposition 'called', depending on 'formalism'. Entity 2 ('Prolog subset of logic') is the object of the preposition 'into', depending on 'translates'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "grammars → called → formalism → of → aid → With → translates → into → subset",
        "sentence": "Extraposition grammars aid in translating English questions into the Prolog subset of logic.",
        "sentence_llm_dp_info": "\"Entity 1 ('extraposition grammars') is the subject, depending on the verb 'aid'. Entity 2 ('Prolog subset of logic') is the object of the preposition 'into', depending on 'into' in the phrase 'into the Prolog subset of logic'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'into'.\""
    },
    {
        "raw_sentence": "With the aid of a logic-based grammar formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic .",
        "ner_pair": [
            [
                "Chat-80",
                "Method"
            ],
            [
                "Prolog subset of logic",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Chat-80') is the subject, depending on the verb 'translates'. Entity 2 ('Prolog subset of logic') is the object, depending on 'into' in the phrase 'into the Prolog subset of logic'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'translates' and the preposition 'into'.\"",
        "sdp_path_text": "Chat-80 → translates → into → subset",
        "sentence": "Chat-80 translates English questions into the Prolog subset of logic.",
        "sentence_llm_dp_info": "\"Entity 1 ('Chat-80') is the subject, depending on the verb 'translates'. Entity 2 ('Prolog subset of logic') is the object, depending on the verb 'translates'. There is a direct dependency between Entity 1 and Entity 2, as 'Chat-80' is performing the action of translating into 'Prolog subset of logic'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "planning algorithm",
                "Method"
            ],
            [
                "logical expression",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the subject, depending on the verb 'transformed'. Entity 2 ('logical expression') is the subject, depending on the verb 'is' (part of 'is transformed'). There is a direct dependency between Entity 1 and Entity 2, where 'planning algorithm' acts as the agent performing the transformation on 'logical expression'.\"",
        "sdp_path_text": "algorithm → by → transformed → expression",
        "sentence": "The planning algorithm transforms the logical expression.",
        "sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the subject, depending on the verb 'transforms'. Entity 2 ('logical expression') is the object, depending on 'transforms' with 'planning algorithm'. There is a direct dependency between Entity 1 and Entity 2, where 'planning algorithm' performs the action of transforming 'logical expression'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "logical expression",
                "OtherScientificTerm"
            ],
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical expression') is the subject, depending on the verb 'transformed'. Entity 2 ('Prolog') is the object of the preposition 'into', depending on 'transformed' in the phrase 'transformed into efficient Prolog'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the transformation process described by the verb 'transformed'.\"",
        "sdp_path_text": "expression → transformed → into → Prolog",
        "sentence": "The logical expression is transformed into Prolog.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical expression') is the subject, depending on the verb 'transformed'. Entity 2 ('Prolog') is the complement of the preposition 'into', depending on 'transformed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the transformation process described by the verb 'transformed'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "logical expression",
                "OtherScientificTerm"
            ],
            [
                "query optimisation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical expression') is the subject, depending on the verb 'is' and modified by 'resulting'. Entity 2 ('query optimisation') is the object of the preposition 'cf.', depending on 'cf.' in the phrase 'cf. query optimisation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence, which discusses transformations and optimizations in different contexts.\"",
        "sdp_path_text": "expression → transformed → cf → optimisation",
        "sentence": "The logical expression is transformed, relating to query optimisation.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical expression') is the subject, depending on the verb 'transformed'. Entity 2 ('query optimisation') is the object of the preposition 'to', depending on 'relating' in the phrase 'relating to query optimisation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "logical expression",
                "OtherScientificTerm"
            ],
            [
                "relational database",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical expression') is the subject, depending on the verb 'is' with 'resulting'. Entity 2 ('relational database') is the object of the preposition 'in', depending on 'optimisation'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence context, where the transformation of the logical expression is compared to query optimization in a relational database.\"",
        "sdp_path_text": "expression → transformed → cf → optimisation → in → database",
        "sentence": "The logical expression is transformed into an optimized form for a relational database.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical expression') is the subject, depending on the verb 'transformed'. Entity 2 ('relational database') is the object of the preposition 'for', depending on 'for' in the phrase 'for a relational database'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the transformation process described by the verb 'transformed' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "planning algorithm",
                "Method"
            ],
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the agent, depending on the verb 'transformed' with 'is'. Entity 2 ('Prolog') is the complement of the preposition 'into', depending on 'into' in the phrase 'into efficient Prolog'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the transformation process described by the verb 'transformed'.\"",
        "sdp_path_text": "algorithm → by → transformed → into → Prolog",
        "sentence": "The planning algorithm transforms the logical expression into Prolog.",
        "sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the subject, depending on the verb 'transforms'. Entity 2 ('Prolog') is the object, depending on the verb 'transforms'. There is a direct dependency between Entity 1 and Entity 2, as 'planning algorithm' is performing the action of transforming something into 'Prolog'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "planning algorithm",
                "Method"
            ],
            [
                "query optimisation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the agent, depending on 'transformed' with the logical expression. Entity 2 ('query optimisation') is the subject, depending on 'in' with 'relational database'. There is no direct dependency between Entity 1 and Entity 2, but both are related to processes of transformation or optimization in computational contexts.\"",
        "sdp_path_text": "algorithm → by → transformed → cf → optimisation",
        "sentence": "A planning algorithm transforms the logical expression, similar to query optimisation.",
        "sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the subject, depending on the verb 'transforms'. Entity 2 ('query optimisation') is the complement of the preposition 'similar to', depending on 'similar' in the phrase 'similar to query optimisation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'similar to'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "planning algorithm",
                "Method"
            ],
            [
                "relational database",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the agent, depending on the verb 'transformed' with 'is'. Entity 2 ('relational database') is the object of the preposition 'in', depending on 'in' in the phrase 'in a relational database'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence describing the transformation process and an analogy to query optimization.\"",
        "sdp_path_text": "algorithm → by → transformed → cf → optimisation → in → database",
        "sentence": "A planning algorithm transforms expressions, similar to query optimisation in a relational database.",
        "sentence_llm_dp_info": "\"Entity 1 ('planning algorithm') is the subject, depending on the verb 'transforms'. Entity 2 ('relational database') is the object of the preposition 'in', depending on 'in' in the phrase 'in a relational database'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the comparison made in the sentence.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            [
                "query optimisation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the object of the preposition 'into', depending on 'transformed' with 'is'. Entity 2 ('query optimisation') is the subject complement, depending on 'cf.' (compare) with 'in a relational database'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger clause describing the transformation process and a comparison, respectively.\"",
        "sdp_path_text": "Prolog → into → transformed → cf → optimisation",
        "sentence": "Prolog is transformed into an optimized form similar to query optimization.",
        "sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the subject, depending on the verb 'transformed'. Entity 2 ('query optimization') is the object of the preposition 'similar to', depending on 'similar' in the phrase 'similar to query optimization'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'similar to'.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "Prolog",
                "OtherScientificTerm"
            ],
            [
                "relational database",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the object of the preposition 'into', depending on 'transformed' with 'logical expression'. Entity 2 ('relational database') is the object of the preposition 'in', depending on 'optimisation'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of transformation and optimization processes in the context of the sentence.\"",
        "sdp_path_text": "Prolog → into → transformed → cf → optimisation → in → database",
        "sentence": "Prolog is transformed into an efficient form, similar to query optimisation in a relational database.",
        "sentence_llm_dp_info": "\"Entity 1 ('Prolog') is the subject, depending on the verb 'transformed'. Entity 2 ('relational database') is the object of the preposition 'in', depending on 'in' in the phrase 'in a relational database'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase that describes the context of the transformation.\""
    },
    {
        "raw_sentence": "The resulting logical expression is then transformed by a planning algorithm into efficient Prolog , cf. query optimisation in a relational database .",
        "ner_pair": [
            [
                "relational database",
                "Material"
            ],
            [
                "query optimisation",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('relational database') is the object of the preposition 'in', depending on 'in' in the phrase 'in a relational database'. Entity 2 ('query optimisation') is the subject complement, depending on the verb 'cf.' which is used here to indicate a comparison or reference point. There is no direct dependency between Entity 1 and Entity 2; they are connected through the comparative reference provided by 'cf.'. The phrase 'query optimisation in a relational database' serves as a point of comparison for the transformation process described earlier in the sentence.\"",
        "sdp_path_text": "database → in → optimisation",
        "sentence": "Query optimisation occurs in a relational database.",
        "sentence_llm_dp_info": "\"Entity 1 ('relational database') is the complement of the preposition 'in', depending on 'occurs'. Entity 2 ('query optimisation') is the subject, depending on the verb 'occurs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates where the action of Entity 2 takes place.\""
    },
    {
        "raw_sentence": "Human action recognition from well-segmented 3D skeleton data has been intensively studied and attracting an increasing attention .",
        "ner_pair": [
            [
                "well-segmented 3D skeleton data",
                "Material"
            ],
            [
                "Human action recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('well-segmented 3D skeleton data') is the object of the preposition 'from', depending on 'from' in the phrase 'from well-segmented 3D skeleton data'. Entity 2 ('Human action recognition') is the subject, depending on the verb 'has been'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'from well-segmented 3D skeleton data'.\"",
        "sdp_path_text": "data → from → recognition",
        "sentence": "Human action recognition from well-segmented 3D skeleton data has been studied.",
        "sentence_llm_dp_info": "\"Entity 1 ('well-segmented 3D skeleton data') is the object of the preposition 'from', depending on 'from' in the phrase 'from well-segmented 3D skeleton data'. Entity 2 ('Human action recognition') is the subject, depending on the verb 'has been studied'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "Online action detection goes one step further and is more challenging , which identifies the action type and localizes the action positions on the fly from the untrimmed stream .",
        "ner_pair": [
            [
                "Online action detection",
                "Task"
            ],
            [
                "action type",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Online action detection') is the subject, depending on the verb 'goes'. Entity 2 ('action type') is the object, depending on the verb 'identifies' within the relative clause 'which identifies the action type and localizes the action positions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause describing the capabilities of Entity 1.\"",
        "sdp_path_text": "detection → goes → is → identifies → type",
        "sentence": "Online action detection identifies the action type.",
        "sentence_llm_dp_info": "\"Entity 1 ('Online action detection') is the subject, depending on the verb 'identifies'. Entity 2 ('action type') is the object, depending on 'identifies' with 'Online action detection'. There is a direct dependency between Entity 1 and Entity 2, as 'action type' is directly identified by 'Online action detection'.\""
    },
    {
        "raw_sentence": "Online action detection goes one step further and is more challenging , which identifies the action type and localizes the action positions on the fly from the untrimmed stream .",
        "ner_pair": [
            [
                "Online action detection",
                "Task"
            ],
            [
                "action positions",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Online action detection') is the subject, depending on the verb 'goes'. Entity 2 ('action positions') is the object of the verb 'localizes', depending on 'localizes' in the clause 'which identifies the action type and localizes the action positions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same descriptive clause that elaborates on the capabilities of online action detection.\"",
        "sdp_path_text": "detection → goes → is → identifies → localizes → positions",
        "sentence": "Online action detection identifies and localizes action positions.",
        "sentence_llm_dp_info": "\"Entity 1 ('Online action detection') is the subject, depending on the verb 'identifies'. Entity 2 ('action positions') is the object, depending on 'localizes' with 'Online action detection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'identifies' and 'localizes' which describe the actions performed by Entity 1 on Entity 2.\""
    },
    {
        "raw_sentence": "Online action detection goes one step further and is more challenging , which identifies the action type and localizes the action positions on the fly from the untrimmed stream .",
        "ner_pair": [
            [
                "untrimmed stream",
                "Material"
            ],
            [
                "Online action detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('untrimmed stream') is the object, depending on the preposition 'from', which modifies the verb 'localizes'. Entity 2 ('Online action detection') is the subject, depending on the verb 'goes' and modified by the adverbial clause 'which identifies the action type and localizes the action positions on the fly'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the process described in the sentence where 'Online action detection' operates on the 'untrimmed stream'.\"",
        "sdp_path_text": "stream → from → localizes → identifies → is → goes → detection",
        "sentence": "Online action detection identifies and localizes actions from an untrimmed stream.",
        "sentence_llm_dp_info": "\"Entity 1 ('untrimmed stream') is the object, depending on 'from' in the prepositional phrase 'from an untrimmed stream'. Entity 2 ('Online action detection') is the subject, depending on the verb 'identifies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'localizes' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Online action detection goes one step further and is more challenging , which identifies the action type and localizes the action positions on the fly from the untrimmed stream .",
        "ner_pair": [
            [
                "action type",
                "OtherScientificTerm"
            ],
            [
                "action positions",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action type') is the object of the verb 'identifies', depending on the verb 'identifies' in the clause 'which identifies the action type'. Entity 2 ('action positions') is the object of the verb 'localizes', depending on the verb 'localizes' in the clause 'and localizes the action positions'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing actions performed on the fly from the untrimmed stream.\"",
        "sdp_path_text": "type → identifies → localizes → positions",
        "sentence": "The system identifies action type and localizes action positions.",
        "sentence_llm_dp_info": "\"Entity 1 ('action type') is the object, depending on the verb 'identifies' with 'system'. Entity 2 ('action positions') is the object, depending on the verb 'localizes' with 'system'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the subject 'system' through different verbs.\""
    },
    {
        "raw_sentence": "Online action detection goes one step further and is more challenging , which identifies the action type and localizes the action positions on the fly from the untrimmed stream .",
        "ner_pair": [
            [
                "action type",
                "OtherScientificTerm"
            ],
            [
                "untrimmed stream",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action type') is the object, depending on 'identifies' with 'which'. Entity 2 ('untrimmed stream') is the object, depending on 'from' with 'fly'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the online action detection does.\"",
        "sdp_path_text": "type → identifies → localizes → from → stream",
        "sentence": "Action type is identified and localized from the untrimmed stream.",
        "sentence_llm_dp_info": "\"Entity 1 ('action type') is the subject, depending on the verb 'is identified'. It also depends on the verb 'localized' through coordination. Entity 2 ('untrimmed stream') is the object of the preposition 'from', depending on 'localized'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'identified' and 'localized' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Online action detection goes one step further and is more challenging , which identifies the action type and localizes the action positions on the fly from the untrimmed stream .",
        "ner_pair": [
            [
                "action positions",
                "OtherScientificTerm"
            ],
            [
                "untrimmed stream",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action positions') is the object, depending on 'localizes' with 'which'. Entity 2 ('untrimmed stream') is the object, depending on 'from' with 'fly'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the characteristics of online action detection.\"",
        "sdp_path_text": "positions → localizes → from → stream",
        "sentence": "Action positions are localized from the untrimmed stream.",
        "sentence_llm_dp_info": "\"Entity 1 ('action positions') is the subject, depending on the verb 'localized'. Entity 2 ('untrimmed stream') is the source or origin, depending on the preposition 'from' with 'localized'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' indicating the source of the localization process.\""
    },
    {
        "raw_sentence": "In this paper , we study the problem of online action detection from the streaming skeleton data .",
        "ner_pair": [
            [
                "streaming skeleton data",
                "Material"
            ],
            [
                "online action detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('streaming skeleton data') is the object of the preposition 'from', depending on 'from' in the phrase 'from the streaming skeleton data'. Entity 2 ('online action detection') is the object of the preposition 'of', depending on 'problem' in the phrase 'the problem of online action detection'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "data → from → detection",
        "sentence": "The problem of online action detection from streaming skeleton data is studied.",
        "sentence_llm_dp_info": "\"Entity 1 ('streaming skeleton data') is the object of the preposition 'from', depending on 'from' in the phrase 'from streaming skeleton data'. Entity 2 ('online action detection') is part of the noun phrase that is the subject complement, depending on 'of' in the phrase 'of online action detection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' and the prepositional phrase 'of online action detection'.\""
    },
    {
        "raw_sentence": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information .",
        "ner_pair": [
            [
                "multi-task end-to-end Joint Classification-Regression Recurrent Neural Network",
                "Method"
            ],
            [
                "action type",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multi-task end-to-end Joint Classification-Regression Recurrent Neural Network') is the object, depending on the verb 'propose' with 'We'. Entity 2 ('action type') is part of the object complement, depending on 'explore' with 'better'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of the network described by the verb 'explore'.\"",
        "sdp_path_text": "Network → propose → explore → type",
        "sentence": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to explore action type.",
        "sentence_llm_dp_info": "\"Entity 1 ('multi-task end-to-end Joint Classification-Regression Recurrent Neural Network') is the object, depending on the verb 'propose' with 'We'. Entity 2 ('action type') is the object of the preposition 'to', depending on 'explore' in the phrase 'to explore action type'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'explore' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information .",
        "ner_pair": [
            [
                "multi-task end-to-end Joint Classification-Regression Recurrent Neural Network",
                "Method"
            ],
            [
                "temporal localiza-tion information",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multi-task end-to-end Joint Classification-Regression Recurrent Neural Network') is the object of the preposition 'a', depending on 'propose' with 'We'. Entity 2 ('temporal localization information') is the object of the preposition 'the', depending on 'explore' with 'better'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the network aims to explore.\"",
        "sdp_path_text": "Network → propose → explore → type → information",
        "sentence": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to explore temporal localization information.",
        "sentence_llm_dp_info": "\"Entity 1 ('multi-task end-to-end Joint Classification-Regression Recurrent Neural Network') is the object of the preposition 'a', depending on 'propose' with 'We'. Entity 2 ('temporal localization information') is the object of the verb 'explore', depending on 'explore' in the clause 'to explore temporal localization information'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same purpose clause introduced by 'to'.\""
    },
    {
        "raw_sentence": "We propose a multi-task end-to-end Joint Classification-Regression Recurrent Neural Network to better explore the action type and temporal localiza-tion information .",
        "ner_pair": [
            [
                "action type",
                "OtherScientificTerm"
            ],
            [
                "temporal localiza-tion information",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('action type') is the object of the preposition 'the', depending on 'explore' with 'better'. Entity 2 ('temporal localization information') is also the object of the preposition 'the', depending on 'explore' with 'better'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same prepositional phrase 'the action type and temporal localization information' which depends on 'explore'.\"",
        "sdp_path_text": "type → information",
        "sentence": "We propose a network to explore action type and temporal localization information.",
        "sentence_llm_dp_info": "\"Entity 1 ('action type') is the object of the preposition 'of', depending on 'information'. Entity 2 ('temporal localization information') is also an object of the preposition 'of', depending on 'information'. There is no direct dependency between Entity 1 and Entity 2; both are part of the compound object of the preposition 'to explore'.\""
    },
    {
        "raw_sentence": "By employing a joint classification and regression optimization objective , this network is capable of automatically localizing the start and end points of actions more accurately .",
        "ner_pair": [
            [
                "joint classification and regression optimization objective",
                "OtherScientificTerm"
            ],
            [
                "network",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('joint classification and regression optimization objective') is the object of the preposition 'by', depending on 'employing'. Entity 2 ('network') is the subject, depending on 'is' in the clause 'this network is capable'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'employing' and the subject 'network'.\"",
        "sdp_path_text": "objective → employing → By → is → network",
        "sentence": "The network employs a joint classification and regression optimization objective.",
        "sentence_llm_dp_info": "\"Entity 1 ('joint classification and regression optimization objective') is the object, depending on the verb 'employs'. Entity 2 ('network') is the subject, depending on the verb 'employs'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 (network) employs Entity 1 (joint classification and regression optimization objective).\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork",
                "Method"
            ],
            [
                "model",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork') is the object of the preposition 'of', depending on 'merits'. Entity 2 ('model') is the subject, depending on 'captures' with 'the proposed model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause describing the capabilities of the model that leverages the merits of the LSTM subnetwork.\"",
        "sdp_path_text": "subnetwork → of → merits → leveraging → by → captures → model",
        "sentence": "The model leverages the merits of the deep LSTM subnetwork to capture complex dynamics.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory (LSTM) subnetwork') is the object of the preposition 'of', depending on 'merits'. Entity 2 ('model') is the subject, depending on the verb 'leverages'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'merits' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork",
                "Method"
            ],
            [
                "long-range temporal dynamics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork') is the object of the preposition 'of', depending on 'merits'. Entity 2 ('long-range temporal dynamics') is the object of the verb 'captures', depending on 'captures' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause where the 'subnetwork' contributes to the 'model' that 'captures' the 'dynamics'.\"",
        "sdp_path_text": "subnetwork → of → merits → leveraging → by → captures → dynamics",
        "sentence": "The deep LSTM subnetwork captures long-range temporal dynamics.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory (LSTM) subnetwork') is the subject, depending on the verb 'captures'. Entity 2 ('long-range temporal dynamics') is the object, depending on 'captures' with 'subnetwork'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the agent performing the action of capturing Entity 2.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork",
                "Method"
            ],
            [
                "sliding window design",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork') is the object of the preposition 'of', depending on 'merits'. Entity 2 ('sliding window design') is the object of the preposition 'the', depending on 'avoids'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, connected through the logical flow of the model's capabilities described.\"",
        "sdp_path_text": "subnetwork → of → merits → leveraging → by → captures → avoids → design",
        "sentence": "The deep LSTM subnetwork leverages merits to capture dynamics and avoid the sliding window design.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory (LSTM) subnetwork') is the subject, depending on the verb 'leverages'. Entity 2 ('sliding window design') is the object of the verb 'avoid', depending on 'avoid' in the phrase 'avoid the sliding window design'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'leverages' and 'avoid' which describe the actions performed by the subnetwork.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork",
                "Method"
            ],
            [
                "computational efficiency",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork') is the object of the preposition 'of', depending on 'merits'. Entity 2 ('computational efficiency') is the object of the verb 'ensures', depending on 'ensures' in the clause 'ensures high computational efficiency'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure, where the subnetwork contributes to the overall process that leads to ensuring high computational efficiency.\"",
        "sdp_path_text": "subnetwork → of → merits → leveraging → by → captures → avoids → ensures → efficiency",
        "sentence": "Leveraging the merits of the deep LSTM subnetwork ensures high computational efficiency.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep Long Short-Term Memory (LSTM) subnetwork') is the subject, depending on the verb 'ensures'. Entity 2 ('computational efficiency') is the object, depending on 'ensures' with 'subnetwork'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 ensures Entity 2.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "long-range temporal dynamics",
                "OtherScientificTerm"
            ],
            [
                "model",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('long-range temporal dynamics') is the object, depending on 'captures' with 'model'. Entity 2 ('model') is the subject, depending on 'proposed' with 'the'. There is a direct dependency between Entity 1 and Entity 2, where 'model' is the agent that performs the action of capturing 'long-range temporal dynamics'.\"",
        "sdp_path_text": "dynamics → captures → model",
        "sentence": "The model captures long-range temporal dynamics.",
        "sentence_llm_dp_info": "\"Entity 1 ('long-range temporal dynamics') is the object, depending on the verb 'captures'. Entity 2 ('model') is the subject, depending on the verb 'captures'. There is a direct dependency between Entity 1 and Entity 2, as 'model' captures 'long-range temporal dynamics'.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "sliding window design",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'captures' with the phrase 'automatically captures the complex long-range temporal dynamics'. Entity 2 ('sliding window design') is the object, depending on the verb 'avoids' in the relative clause 'which naturally avoids the typical sliding window design'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the model's capabilities described in the sentence.\"",
        "sdp_path_text": "model → captures → avoids → design",
        "sentence": "The proposed model captures dynamics that avoid the sliding window design.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'captures'. Entity 2 ('sliding window design') is the object of the preposition 'the', depending on 'avoid' in the phrase 'avoid the sliding window design'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'captures' and the verb 'avoid'.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "computational efficiency",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on 'proposes' with 'the proposed'. Entity 2 ('computational efficiency') is the object, depending on 'ensures' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause 'which naturally avoids the typical sliding window design and thus ensures high computational efficiency'.\"",
        "sdp_path_text": "model → captures → avoids → ensures → efficiency",
        "sentence": "The model captures dynamics, avoids typical designs, and ensures computational efficiency.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'captures', 'avoids', and 'ensures'. Entity 2 ('computational efficiency') is the object, depending on 'ensures' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'ensures'.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "long-range temporal dynamics",
                "OtherScientificTerm"
            ],
            [
                "sliding window design",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('long-range temporal dynamics') is the object, depending on 'captures' with 'model'. Entity 2 ('sliding window design') is the object, depending on 'avoids' with 'which'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "dynamics → captures → avoids → design",
        "sentence": "The model captures long-range temporal dynamics, avoiding the sliding window design.",
        "sentence_llm_dp_info": "\"Entity 1 ('long-range temporal dynamics') is the object, depending on 'captures' with 'model'. Entity 2 ('sliding window design') is the object, depending on 'avoiding' with 'model'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "long-range temporal dynamics",
                "OtherScientificTerm"
            ],
            [
                "computational efficiency",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('long-range temporal dynamics') is the object, depending on 'captures' with 'model'. Entity 2 ('computational efficiency') is the object, depending on 'ensures' with 'thus'. There is no direct dependency between Entity 1 and Entity 2; both are related to the actions performed by the 'model'.\"",
        "sdp_path_text": "dynamics → captures → avoids → ensures → efficiency",
        "sentence": "The model captures long-range temporal dynamics, ensuring computational efficiency.",
        "sentence_llm_dp_info": "\"Entity 1 ('long-range temporal dynamics') is the object, depending on 'captures' with 'model'. Entity 2 ('computational efficiency') is the object, depending on 'ensuring' with 'dynamics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'ensuring' which indicates that capturing the dynamics helps ensure the efficiency.\""
    },
    {
        "raw_sentence": "Specifically , by leveraging the merits of the deep Long Short-Term Memory -LRB- LSTM -RRB- subnetwork , the proposed model automatically captures the complex long-range temporal dynamics , which naturally avoids the typical sliding window design and thus ensures high computational efficiency .",
        "ner_pair": [
            [
                "sliding window design",
                "Method"
            ],
            [
                "computational efficiency",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sliding window design') is the object of the verb 'avoids', depending on 'avoids' with 'which'. Entity 2 ('computational efficiency') is the object of the verb 'ensures', depending on 'ensures' with 'thus'. There is no direct dependency between Entity 1 and Entity 2; they are part of the same clause but connected through the logical flow described by 'avoids' and 'ensures'.\"",
        "sdp_path_text": "design → avoids → ensures → efficiency",
        "sentence": "Avoiding the sliding window design ensures high computational efficiency.",
        "sentence_llm_dp_info": "\"Entity 1 ('sliding window design') is the object of the verb 'Avoiding', depending on 'Avoiding' with the preposition 'the'. Entity 2 ('computational efficiency') is the subject complement, depending on 'ensures' with the adjective 'high'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the logical structure of the sentence where avoiding one leads to ensuring the other.\""
    },
    {
        "raw_sentence": "To evaluate our proposed model , we build a large streaming video dataset with annotations .",
        "ner_pair": [
            [
                "streaming video dataset",
                "Material"
            ],
            [
                "model",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('streaming video dataset') is the object, depending on the verb 'build' with 'we'. Entity 2 ('model') is the object of the possessive pronoun 'our', depending on 'proposed' in the phrase 'proposed model'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the purpose of evaluation.\"",
        "sdp_path_text": "dataset → build → evaluate → model",
        "sentence": "We build a streaming video dataset to evaluate the model.",
        "sentence_llm_dp_info": "\"Entity 1 ('streaming video dataset') is the object, depending on the verb 'build'. Entity 2 ('model') is the object of the preposition 'the', which is part of the larger noun phrase 'the model'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'evaluate', where 'streaming video dataset' is the means by which the evaluation is performed, and 'model' is the entity being evaluated.\""
    },
    {
        "raw_sentence": "The task of machine translation -LRB- MT -RRB- evaluation is closely related to the task of sentence-level semantic equivalence classification .",
        "ner_pair": [
            [
                "machine translation -LRB- MT -RRB- evaluation",
                "Task"
            ],
            [
                "sentence-level semantic equivalence classification",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('machine translation -LRB- MT -RRB- evaluation') is the subject, depending on the verb 'is'. Entity 2 ('sentence-level semantic equivalence classification') is the object of the preposition 'to', depending on 'to' in the phrase 'to the task of sentence-level semantic equivalence classification'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' which indicates a close relationship.\"",
        "sdp_path_text": "evaluation → of → task → related → to → task → of → classification",
        "sentence": "Machine translation evaluation is closely related to sentence-level semantic equivalence classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('machine translation (MT) evaluation') is the subject, depending on the verb 'is'. Entity 2 ('sentence-level semantic equivalence classification') is the complement, depending on the adjective 'related' in the phrase 'closely related to sentence-level semantic equivalence classification'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relational phrase 'is closely related to'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "MT evaluation methods",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is a member of a list, depending on 'methods' with 'MT evaluation methods'. Entity 2 ('MT evaluation methods') is the object of the preposition 'of', depending on 'utility' in the phrase 'the utility of applying standard MT evaluation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of methods.\"",
        "sdp_path_text": "BLEU → methods",
        "sentence": "BLEU is among the MT evaluation methods investigated.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is the subject, depending on the verb 'is'. Entity 2 ('MT evaluation methods') is the object of the preposition 'among', depending on 'among' in the phrase 'among the MT evaluation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'among the MT evaluation methods'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "NIST",
                "Metric"
            ],
            [
                "MT evaluation methods",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a list, depending on 'methods' through the conjunction 'and'. Entity 2 ('MT evaluation methods') is the object of the preposition 'of', depending on 'utility'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the list of methods that are part of the 'MT evaluation methods'.\"",
        "sdp_path_text": "NIST → BLEU → methods",
        "sentence": "NIST is one of the MT evaluation methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST') is the subject, depending on the copula 'is'. Entity 2 ('MT evaluation methods') is the complement, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'NIST' is identified as part of 'MT evaluation methods' through the copula 'is'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "WER",
                "Metric"
            ],
            [
                "MT evaluation methods",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WER') is part of a list, depending on the conjunction 'and' within the list of methods (-LRB- BLEU, NIST, WER and PER -RRB-). Entity 2 ('MT evaluation methods') is the object of the preposition 'of', depending on 'applying'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the list structure and the prepositional phrase 'of applying standard MT evaluation methods'.\"",
        "sdp_path_text": "WER → NIST → BLEU → methods",
        "sentence": "WER is one of the MT evaluation methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('WER') is the subject, depending on the copula 'is'. Entity 2 ('MT evaluation methods') is the complement, depending on the preposition 'of' in the phrase 'one of the MT evaluation methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'one of the'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "MT evaluation methods",
                "Metric"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is part of a list, depending on the conjunction 'and' with 'WER'. Entity 2 ('MT evaluation methods') is the object of the preposition 'of', depending on 'utility'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list within the phrase describing 'MT evaluation methods'.\"",
        "sdp_path_text": "paper → investigates → utility → of → applying → methods",
        "sentence": "This paper investigates the utility of applying PER to MT evaluation methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is the object of the preposition 'of', depending on 'applying'. Entity 2 ('MT evaluation methods') is the object of the preposition 'to', depending on 'applying'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'applying'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "MT evaluation methods",
                "Metric"
            ],
            [
                "classifiers",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT evaluation methods') is the object of the preposition 'of', depending on 'utility'. Entity 2 ('classifiers') is the object of the preposition 'to', depending on 'building'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being investigated in the paper.\"",
        "sdp_path_text": "methods → applying → to → classifiers",
        "sentence": "This paper investigates applying MT evaluation methods to classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT evaluation methods') is the object of the gerund 'applying', depending on 'applying' in the phrase 'applying MT evaluation methods'. Entity 2 ('classifiers') is the object of the preposition 'to', depending on 'to' in the phrase 'to classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applying' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "MT evaluation methods",
                "Metric"
            ],
            [
                "semantic equivalence",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT evaluation methods') is the object of the preposition 'of', depending on 'utility'. Entity 2 ('semantic equivalence') is part of the compound object, depending on 'predict' with 'classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the investigation described in the sentence.\"",
        "sdp_path_text": "methods → applying → predict → equivalence",
        "sentence": "MT evaluation methods are applied to predict semantic equivalence.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT evaluation methods') is the subject, depending on the verb 'applied'. Entity 2 ('semantic equivalence') is the object, depending on 'predict' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "MT evaluation methods",
                "Metric"
            ],
            [
                "entailment",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT evaluation methods') is the object of the preposition 'of', depending on 'utility'. Entity 2 ('entailment') is the object of the preposition 'to', part of the phrase 'to predict semantic equivalence and entailment'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence, where 'MT evaluation methods' are being investigated for their utility in predicting 'entailment'.\"",
        "sdp_path_text": "methods → applying → predict → equivalence → entailment",
        "sentence": "MT evaluation methods are applied to predict entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT evaluation methods') is the subject, depending on the verb 'are applied'. Entity 2 ('entailment') is the object, depending on 'predict' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'are applied' and 'predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "NIST",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is a conjunct, depending on 'methods' with the conjunction 'and'. Entity 2 ('NIST') is also a conjunct, depending on 'methods' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of methods.\"",
        "sdp_path_text": "BLEU → NIST",
        "sentence": "BLEU and NIST are standard MT evaluation methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is a conjunct, depending on 'are' with 'NIST'. Entity 2 ('NIST') is also a conjunct, depending on 'are' with 'BLEU'. There is no direct dependency between Entity 1 and Entity 2; both are part of a conjunction that serves as the subject of the sentence.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "WER",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a list, depending on the preposition 'of' within the phrase 'of applying standard MT evaluation methods'. Entity 2 ('WER') is also part of the same list, depending on the conjunction 'and' which connects it to the other items in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of standard MT evaluation methods.\"",
        "sdp_path_text": "BLEU → NIST → WER",
        "sentence": "This paper investigates the utility of applying BLEU, NIST, and WER to building classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a conjunct, depending on the preposition 'of' within the phrase 'the utility of applying BLEU, NIST, and WER'. Entity 2 ('WER') is also part of the same conjunct, depending on the coordinating conjunction 'and' which links it with 'BLEU' and 'NIST'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same conjunctive structure.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "PER",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a list, depending on the verb 'applying' within the phrase 'applying standard MT evaluation methods'. Entity 2 ('PER') is also part of the same list, depending on the verb 'applying' within the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of methods being applied.\"",
        "sdp_path_text": "BLEU → methods → applying → of → utility → investigates → paper",
        "sentence": "This paper investigates the utility of applying methods including BLEU and PER.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is the conjunct, depending on 'including' with 'methods'. Entity 2 ('PER') is the conjunct, also depending on 'including' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list introduced by 'including'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a list of methods, depending on the verb 'applying' through the preposition 'of'. Entity 2 ('classifiers') is the object of the preposition 'to', depending on the verb 'building'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the overall structure of the sentence where 'BLEU' is one of the methods being applied to the action of building 'classifiers'.\"",
        "sdp_path_text": "BLEU → methods → applying → to → classifiers",
        "sentence": "BLEU methods are applied to build classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a compound noun 'BLEU methods', which is the subject, depending on the verb 'are applied'. Entity 2 ('classifiers') is the object of the verb 'build', depending on 'to build' in the phrase 'to build classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' and the purpose clause 'to build classifiers'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "semantic equivalence",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a list, depending on the verb 'applying' as one of the objects of the preposition 'of'. Entity 2 ('semantic equivalence') is the object of the preposition 'to', depending on 'predict'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'BLEU' is part of the methods being applied to predict 'semantic equivalence'.\"",
        "sdp_path_text": "BLEU → methods → applying → predict → equivalence",
        "sentence": "BLEU, among other methods, is used to predict semantic equivalence.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is the subject, depending on the verb 'is used'. Entity 2 ('semantic equivalence') is the object, depending on 'predict' with 'to predict'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is used to predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "BLEU",
                "Metric"
            ],
            [
                "entailment",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('BLEU') is part of a list of methods, depending on the verb 'applying' through the preposition 'of'. Entity 2 ('entailment') is the object of the preposition 'to', depending on 'predict' in the phrase 'to predict semantic equivalence and entailment'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'BLEU' is one of the methods being applied to predict 'entailment'.\"",
        "sdp_path_text": "BLEU → methods → applying → predict → equivalence → entailment",
        "sentence": "BLEU, among other methods, is used to predict entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('BLEU') is the subject, depending on the verb 'is used'. Entity 2 ('entailment') is the object, depending on 'predict' with 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is used' and the purpose clause 'to predict entailment'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "NIST",
                "Metric"
            ],
            [
                "WER",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a list, depending on the conjunction 'and' with 'PER', which together form the object of the preposition 'of' in the phrase 'of applying standard MT evaluation methods'. Entity 2 ('WER') is also part of the same list, depending on the conjunction 'and' with 'PER', forming part of the object of the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of the same list connected through the conjunction 'and'.\"",
        "sdp_path_text": "NIST → WER",
        "sentence": "NIST and WER are used in this paper to evaluate semantic equivalence and entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST') is the first item in a conjunction, depending on 'used' with the conjunction 'and'. Entity 2 ('WER') is the second item in the conjunction, also depending on 'used' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same conjunction.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "NIST",
                "Metric"
            ],
            [
                "PER",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a coordination, depending on the conjunction 'and' with 'PER'. Entity 2 ('PER') is also part of a coordination, depending on the conjunction 'and' with 'NIST'. There is no direct dependency between Entity 1 and Entity 2; however, they are both elements of a list connected by the conjunction 'and'.\"",
        "sdp_path_text": "NIST → BLEU → methods → applying → of → utility → investigates → paper",
        "sentence": "This paper investigates the utility of applying methods including NIST and PER.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST') is the conjunct, depending on 'including' as part of the list of methods. Entity 2 ('PER') is also a conjunct, depending on 'including' as part of the same list of methods. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same coordination introduced by 'including'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "NIST",
                "Metric"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a list of methods, depending on the verb 'applying' through the conjunction 'and'. Entity 2 ('classifiers') is the object of the verb 'building', depending on 'to' in the phrase 'to building classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the application and purpose of the methods.\"",
        "sdp_path_text": "NIST → BLEU → methods → applying → to → classifiers",
        "sentence": "NIST and other methods are applied to build classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a coordination, depending on 'methods' with 'and'. Entity 2 ('classifiers') is the object, depending on 'build' which is part of the verb phrase 'are applied to build'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'are applied to build'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "NIST",
                "Metric"
            ],
            [
                "semantic equivalence",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a list of methods, depending on the preposition 'of' in the phrase 'of applying standard MT evaluation methods'. Entity 2 ('semantic equivalence') is the object of the preposition 'to' in the phrase 'to predict semantic equivalence and entailment', depending on 'predict'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "NIST → BLEU → methods → applying → predict → equivalence",
        "sentence": "NIST and other methods are applied to predict semantic equivalence.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of the compound subject, depending on 'are' with 'methods'. Entity 2 ('semantic equivalence') is the object, depending on 'predict' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'are applied' and the purpose 'to predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "NIST",
                "Metric"
            ],
            [
                "entailment",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a list, depending on the preposition 'of' within the phrase 'of applying standard MT evaluation methods'. Entity 2 ('entailment') is the object of the preposition 'to' in the phrase 'to predict semantic equivalence and entailment'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through different prepositional phrases.\"",
        "sdp_path_text": "NIST → BLEU → methods → applying → predict → equivalence → entailment",
        "sentence": "NIST and other methods are used to predict entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST') is part of a coordination, depending on 'are' with the verb 'used'. Entity 2 ('entailment') is the object, depending on 'predict' with the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'predict' and the structure of the sentence.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "WER",
                "Metric"
            ],
            [
                "PER",
                "Metric"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WER') is part of a list, depending on the conjunction 'and' with 'PER'. Entity 2 ('PER') is also part of a list, depending on the conjunction 'and' with 'WER'. There is a direct dependency between Entity 1 and Entity 2, connected through the conjunction 'and'.\"",
        "sdp_path_text": "WER → NIST → BLEU → methods → applying → of → utility → investigates → paper",
        "sentence": "This paper investigates the utility of applying methods including WER and PER.",
        "sentence_llm_dp_info": "\"Entity 1 ('WER') is the object of the preposition 'including', depending on 'including' in the phrase 'including WER'. Entity 2 ('PER') is also the object of the preposition 'including', depending on 'including' in the phrase 'including PER'. There is no direct dependency between Entity 1 and Entity 2; both are listed as objects of the same preposition 'including'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "WER",
                "Metric"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WER') is part of a list, depending on the verb 'applying' through the conjunction 'and'. Entity 2 ('classifiers') is the object of the preposition 'to', depending on 'building' in the phrase 'to building classifiers'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "WER → NIST → BLEU → methods → applying → to → classifiers",
        "sentence": "This paper investigates applying WER and other methods to build classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('WER') is part of a conjunction, depending on 'and' with 'other methods'. Entity 2 ('classifiers') is the object of the verb 'build', depending on 'build' in the phrase 'to build classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'build' and the conjunction 'and'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "WER",
                "Metric"
            ],
            [
                "semantic equivalence",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WER') is part of a list, depending on the verb 'applying' within the phrase 'applying standard MT evaluation methods'. Entity 2 ('semantic equivalence') is the object of the preposition 'to', depending on 'predict' in the phrase 'to predict semantic equivalence'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence, where 'WER' is one of the methods being applied to predict 'semantic equivalence'.\"",
        "sdp_path_text": "WER → NIST → BLEU → methods → applying → predict → equivalence",
        "sentence": "WER is used to predict semantic equivalence.",
        "sentence_llm_dp_info": "\"Entity 1 ('WER') is the subject, depending on the verb 'is used'. Entity 2 ('semantic equivalence') is the object, depending on the verb 'predict'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'predict' which indicates that 'WER' is used in the process of predicting 'semantic equivalence'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "WER",
                "Metric"
            ],
            [
                "entailment",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WER') is part of a list, depending on the verb 'applying' as one of the objects within the methods being applied. Entity 2 ('entailment') is the object of the preposition 'to', depending on 'predict' in the phrase 'to predict semantic equivalence and entailment'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what the methods are used for.\"",
        "sdp_path_text": "WER → NIST → BLEU → methods → applying → predict → equivalence → entailment",
        "sentence": "WER is used to predict entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('WER') is the subject, depending on the verb 'is used'. Entity 2 ('entailment') is the object, depending on 'predict' with 'WER'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "classifiers",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is part of a list of evaluation methods, depending on 'methods' through the conjunction 'and'. Entity 2 ('classifiers') is the object of the preposition 'to', depending on 'building' in the phrase 'to building classifiers'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "paper → investigates → utility → of → applying → to → classifiers",
        "sentence": "This paper investigates the utility of applying PER to classifiers.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is the object of the preposition 'of', depending on 'applying'. Entity 2 ('classifiers') is the object, depending on 'to' in the phrase 'to classifiers'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what is being investigated.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "semantic equivalence",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is part of a list, depending on 'methods' with the preposition 'of' in the phrase 'of applying standard MT evaluation methods -LRB- BLEU, NIST, WER and PER -RRB-'. Entity 2 ('semantic equivalence') is the object of the preposition 'to', depending on 'predict' in the phrase 'to predict semantic equivalence and entailment'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "paper → investigates → utility → of → applying → predict → equivalence",
        "sentence": "This paper investigates the utility of applying methods to predict semantic equivalence.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is not explicitly mentioned in the sentence, so it cannot be directly analyzed for dependencies. Entity 2 ('semantic equivalence') is the object, depending on 'predict' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, as Entity 1 is not present in the given sentence.\"\n\nNote: In this sentence, \"PER\" (which typically stands for a person or a specific individual) is not mentioned. If you intended to analyze a different entity or if there's additional context that should be considered, please provide further details."
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "entailment",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is part of a list of standard MT evaluation methods, depending on the verb 'applying' through the conjunction 'and'. Entity 2 ('entailment') is one of the objects that the classifiers aim to predict, depending on the verb 'predict'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the overall structure of the sentence, where 'PER' is an evaluation method being applied, and 'entailment' is a target of prediction.\"",
        "sdp_path_text": "paper → investigates → utility → of → applying → predict → equivalence → entailment",
        "sentence": "This paper investigates the utility of applying methods to predict entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is not directly mentioned in the sentence, so it does not have any explicit dependencies. Entity 2 ('entailment') is the object, depending on 'predict' with 'methods'. There is no direct dependency between Entity 1 and Entity 2, as Entity 1 is not present in the sentence.\"\n\nNote: Since \"PER\" (which typically stands for \"Person\" in named entity recognition tasks) is not mentioned in the provided sentence, it does not form any dependency within the context of this sentence. If you intended to use a different entity or if there's additional context, please clarify."
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "semantic equivalence",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the object of the preposition 'to', depending on 'building' in the phrase 'to building classifiers'. Entity 2 ('semantic equivalence') is part of a compound object, depending on 'predict' in the phrase 'to predict semantic equivalence and entailment'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger goal described in the sentence.\"",
        "sdp_path_text": "classifiers → to → applying → predict → equivalence",
        "sentence": "Classifiers are used to predict semantic equivalence.",
        "sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the subject, depending on the verb 'used'. Entity 2 ('semantic equivalence') is the object, depending on the verb 'predict'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'used' and 'predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "classifiers",
                "Method"
            ],
            [
                "entailment",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the object of the preposition 'to', depending on the verb 'building' in the phrase 'to building classifiers'. Entity 2 ('entailment') is the second item in a conjunction, depending on 'predict' with 'semantic equivalence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose of the investigation.\"",
        "sdp_path_text": "classifiers → to → applying → predict → equivalence → entailment",
        "sentence": "Classifiers are used to predict entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('classifiers') is the subject, depending on the verb 'used'. Entity 2 ('entailment') is the object, depending on 'predict' with 'to predict entailment'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'predict'.\""
    },
    {
        "raw_sentence": "This paper investigates the utility of applying standard MT evaluation methods -LRB- BLEU , NIST , WER and PER -RRB- to building classifiers to predict semantic equivalence and entailment .",
        "ner_pair": [
            [
                "semantic equivalence",
                "Task"
            ],
            [
                "entailment",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic equivalence') is the object of the preposition 'to', depending on 'predict'. Entity 2 ('entailment') is also the object of the preposition 'to', depending on 'predict'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'to' within the context of predicting.\"",
        "sdp_path_text": "equivalence → entailment",
        "sentence": "This paper investigates predicting semantic equivalence and entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic equivalence') is the object of the verb 'predicting', which is part of the verbal phrase 'investigates predicting'. Entity 2 ('entailment') is also an object of the verb 'predicting', coordinated with 'semantic equivalence' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of the same verbal phrase, connected by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "classification method",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is the object of the preposition 'based', depending on 'method'. Entity 2 ('classification method') is the direct object, depending on the verb 'introduce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on PER'.\"",
        "sdp_path_text": "PER → on → based → method",
        "sentence": "A classification method based on PER leverages part of speech information.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is the object of the preposition 'on', depending on 'based' in the phrase 'based on PER'. Entity 2 ('classification method') is the subject, depending on the verb 'leverages'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on PER' that modifies 'classification method'.\""
    },
    {
        "raw_sentence": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence .",
        "ner_pair": [
            [
                "classification method",
                "Method"
            ],
            [
                "part of speech information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classification method') is the object of the verb 'introduce', depending on 'introduce' with 'We'. Entity 2 ('part of speech information') is the object of the preposition 'of', depending on 'leverages'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leverages' and the preposition 'of'.\"",
        "sdp_path_text": "method → leverages → part",
        "sentence": "The classification method leverages part of speech information.",
        "sentence_llm_dp_info": "\"Entity 1 ('classification method') is the subject, depending on the verb 'leverages'. Entity 2 ('part of speech information') is the object, depending on 'leverages' with 'classification method'. There is a direct dependency between Entity 1 and Entity 2, as 'part of speech information' is what the 'classification method' leverages.\""
    },
    {
        "raw_sentence": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence .",
        "ner_pair": [
            [
                "classification method",
                "Method"
            ],
            [
                "word matches and non-matches",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classification method') is the subject, depending on 'introduce' with 'We'. Entity 2 ('word matches and non-matches') is the object, depending on 'matches' and 'non-matches' with 'contributes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'to the word matches and non-matches' which modifies the verb 'contributes'.\"",
        "sdp_path_text": "method → leverages → part → of → information → of → words → contributing → to → matches",
        "sentence": "The classification method leverages information of words contributing to word matches and non-matches.",
        "sentence_llm_dp_info": "\"Entity 1 ('classification method') is the subject, depending on the verb 'leverages'. Entity 2 ('word matches and non-matches') is the object of the preposition 'to', depending on 'contributing' in the phrase 'contributing to word matches and non-matches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leverages' and the prepositional phrase describing what the method leverages.\""
    },
    {
        "raw_sentence": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "part of speech information",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is the object of the preposition 'on', depending on 'based' in the phrase 'based on PER'. Entity 2 ('part of speech information') is the object, depending on 'leverages' with 'which'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the method introduced.\"",
        "sdp_path_text": "PER → on → based → method → leverages → part",
        "sentence": "PER-based method leverages part of speech information.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is part of a compound noun 'PER-based method', which acts as the subject, depending on the verb 'leverages'. Entity 2 ('part of speech information') is the object, depending on the verb 'leverages'. There is a direct dependency between Entity 1 and Entity 2, as both are part of the same clause where 'PER-based method' (including 'PER') leverages 'part of speech information'.\""
    },
    {
        "raw_sentence": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence .",
        "ner_pair": [
            [
                "PER",
                "Metric"
            ],
            [
                "word matches and non-matches",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PER') is the object of the preposition 'on', depending on 'based' in the phrase 'based on PER'. Entity 2 ('word matches and non-matches') is the object of the preposition 'to', depending on 'contributing' in the phrase 'contributing to the word matches and non-matches'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the method introduced.\"",
        "sdp_path_text": "PER → on → based → method → leverages → part → of → information → of → words → contributing → to → matches",
        "sentence": "PER leverages part of speech information of words contributing to word matches and non-matches.",
        "sentence_llm_dp_info": "\"Entity 1 ('PER') is the subject, depending on the verb 'leverages'. Entity 2 ('word matches and non-matches') is the object, depending on the preposition 'to', which is part of the phrase 'contributing to word matches and non-matches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leverages' and the phrase 'contributing to'.\""
    },
    {
        "raw_sentence": "We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches and non-matches in the sentence .",
        "ner_pair": [
            [
                "part of speech information",
                "OtherScientificTerm"
            ],
            [
                "word matches and non-matches",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('part of speech information') is the object, depending on 'leverages' with 'which'. Entity 2 ('word matches and non-matches') is the object of the preposition 'to', depending on 'to' in the phrase 'to the word matches and non-matches'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what the novel classification method leverages.\"",
        "sdp_path_text": "part → of → information → of → words → contributing → to → matches",
        "sentence": "Part of speech information contributes to word matches and non-matches.",
        "sentence_llm_dp_info": "\"Entity 1 ('part of speech information') is the subject, depending on the verb 'contributes'. Entity 2 ('word matches and non-matches') is the object, depending on the preposition 'to', in the phrase 'to word matches and non-matches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contributes' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment .",
        "ner_pair": [
            [
                "MT evaluation techniques",
                "Method"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT evaluation techniques') is the subject, depending on 'are' as the main verb of the clause. Entity 2 ('features') is the object, depending on 'produce' which is part of the verbal phrase 'able to produce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbal phrase 'able to produce'.\"",
        "sdp_path_text": "techniques → are → able → produce → features",
        "sentence": "MT evaluation techniques are able to produce features.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT evaluation techniques') is the subject, depending on the verb 'are able'. Entity 2 ('features') is the object, depending on the verb 'produce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produce' which indicates that Entity 1 can generate or create Entity 2.\""
    },
    {
        "raw_sentence": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment .",
        "ner_pair": [
            [
                "MT evaluation techniques",
                "Method"
            ],
            [
                "paraphrase classification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT evaluation techniques') is the subject, depending on 'are' with 'able'. Entity 2 ('paraphrase classification') is the object of the preposition 'for', depending on 'for' in the phrase 'for paraphrase classification'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'produce' and the preposition 'for'.\"",
        "sdp_path_text": "techniques → are → able → produce → features → for → classification",
        "sentence": "MT evaluation techniques are able to produce features for paraphrase classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT evaluation techniques') is the subject, depending on the verb 'are able'. Entity 2 ('paraphrase classification') is the object of the preposition 'for', depending on 'for' in the phrase 'for paraphrase classification'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment .",
        "ner_pair": [
            [
                "MT evaluation techniques",
                "Method"
            ],
            [
                "entailment",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT evaluation techniques') is the subject, depending on the verb 'are able'. Entity 2 ('entailment') is the object of the preposition 'for', depending on 'extent' in the phrase 'to a lesser extent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'produce' and the prepositional phrase 'for paraphrase classification and to a lesser extent entailment'.\"",
        "sdp_path_text": "techniques → are → able → produce → features → for → classification → entailment",
        "sentence": "MT evaluation techniques are able to produce features for entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT evaluation techniques') is the subject, depending on the verb 'are able'. Entity 2 ('entailment') is the object of the preposition 'for', depending on 'produce'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'produce' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "paraphrase classification",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the object, depending on 'produce' which is part of the verb phrase 'are able to produce'. Entity 2 ('paraphrase classification') is the object of the preposition 'for', depending on 'for' in the phrase 'for paraphrase classification'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produce' and the preposition 'for'.\"",
        "sdp_path_text": "features → for → classification",
        "sentence": "Features are useful for paraphrase classification.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'are'. Entity 2 ('paraphrase classification') is the complement of the preposition 'for', depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'are useful for'.\""
    },
    {
        "raw_sentence": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "entailment",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the object, depending on 'produce' with 'techniques'. Entity 2 ('entailment') is the object of the preposition 'for', depending on 'extent'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'features' are produced for both 'paraphrase classification' and 'entailment'.\"",
        "sdp_path_text": "features → for → classification → entailment",
        "sentence": "Features are useful for classification and to a lesser extent entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the subject, depending on the verb 'are'. Entity 2 ('entailment') is the object of the preposition 'for', depending on 'extent' in the phrase 'to a lesser extent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'features' are described as being useful for both 'classification' and 'entailment'.\""
    },
    {
        "raw_sentence": "Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to a lesser extent entailment .",
        "ner_pair": [
            [
                "paraphrase classification",
                "Task"
            ],
            [
                "entailment",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification') is the object of the preposition 'for', depending on 'produce'. Entity 2 ('entailment') is also an object of the preposition 'for', but it is part of a coordinated structure introduced by 'and to a lesser extent'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'produce' through the preposition 'for'.\"",
        "sdp_path_text": "classification → entailment",
        "sentence": "MT evaluation techniques are useful for paraphrase classification and entailment.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification') is the first object of the preposition 'for', depending on 'useful'. Entity 2 ('entailment') is the second object of the preposition 'for', also depending on 'useful'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'for'.\""
    },
    {
        "raw_sentence": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "paraphrase classification",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'gives'. Entity 2 ('paraphrase classification') is part of the object, depending on 'in' within the phrase 'in paraphrase classification accuracy'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives' and the prepositional phrase 'in paraphrase classification accuracy'.\"",
        "sdp_path_text": "technique → gives → improvement → in → accuracy → classification",
        "sentence": "Our technique gives a substantial improvement in paraphrase classification accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'gives'. Entity 2 ('paraphrase classification') is part of the object, depending on 'in' within the phrase 'in paraphrase classification accuracy'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'gives' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments .",
        "ner_pair": [
            [
                "paraphrase classification accuracy",
                "Metric"
            ],
            [
                "technique",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification accuracy') is the object of the preposition 'in', depending on 'improvement'. Entity 2 ('technique') is the subject, depending on the verb 'gives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives' and the prepositional phrase 'in paraphrase classification accuracy'.\"",
        "sdp_path_text": "accuracy → in → improvement → gives → technique",
        "sentence": "The technique gives an improvement in paraphrase classification accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification accuracy') is the object, depending on 'gives' with 'technique'. Entity 2 ('technique') is the subject, depending on the verb 'gives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives'.\""
    },
    {
        "raw_sentence": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "models",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'gives'. Entity 2 ('models') is part of a prepositional phrase, depending on 'over' in the phrase 'over all of the other models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives' and the preposition 'over'.\"",
        "sdp_path_text": "technique → gives → improvement → over → all → of → models",
        "sentence": "Our technique gives a substantial improvement over other models.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'gives'. Entity 2 ('models') is the object of the preposition 'over', depending on 'over' in the phrase 'over other models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'over'.\""
    },
    {
        "raw_sentence": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments .",
        "ner_pair": [
            [
                "paraphrase classification",
                "Task"
            ],
            [
                "models",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification') is part of the object, depending on the noun 'accuracy' with the preposition 'in'. Entity 2 ('models') is the object of the preposition 'over', depending on 'over' in the phrase 'over all of the other models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the improvement provided by the technique.\"",
        "sdp_path_text": "classification → accuracy → in → improvement → over → all → of → models",
        "sentence": "Our technique improves paraphrase classification accuracy over other models.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification') is part of the object complement, depending on 'improves' with 'technique'. Entity 2 ('models') is the object of the preposition 'over', depending on 'over' in the phrase 'over other models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing what the technique improves.\""
    },
    {
        "raw_sentence": "Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other models used in the experiments .",
        "ner_pair": [
            [
                "paraphrase classification accuracy",
                "Metric"
            ],
            [
                "models",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification accuracy') is the object of the preposition 'in', depending on 'improvement'. Entity 2 ('models') is the object of the preposition 'over', depending on 'over' in the phrase 'over all of the other models'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'improvement' is the main noun.\"",
        "sdp_path_text": "accuracy → in → improvement → over → all → of → models",
        "sentence": "Our technique improves paraphrase classification accuracy over all models.",
        "sentence_llm_dp_info": "\"Entity 1 ('paraphrase classification accuracy') is the object, depending on the verb 'improves'. Entity 2 ('models') is the object of the preposition 'over', depending on 'over' in the phrase 'over all models'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'improves' and the prepositional phrase 'over all models'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "object model",
                "Method"
            ],
            [
                "black-box measure of similarity",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object model') is part of the conjunction, depending on 'and' with 'black-box measure of similarity'. Entity 2 ('black-box measure of similarity') is also part of the conjunction, depending on 'and' with 'object model'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\"",
        "sdp_path_text": "model → measure",
        "sentence": "An object model and a black-box measure of similarity are considered in visual object tracking.",
        "sentence_llm_dp_info": "\"Entity 1 ('object model') is part of a coordination, depending on 'and' with 'black-box measure of similarity'. Entity 2 ('black-box measure of similarity') is also part of the coordination, depending on 'and' with 'object model'. Both Entity 1 and Entity 2 are subjects, depending on the verb 'are considered'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same subject role.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "object model",
                "Method"
            ],
            [
                "visual object tracking",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object model') is part of the prepositional phrase 'Given an object model', depending on 'Given'. Entity 2 ('visual object tracking') is the subject of the clause 'we consider visual object tracking as a numerical optimization problem', depending on 'consider'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence describing a method for visual object tracking that involves an object model.\"",
        "sdp_path_text": "model → Given → consider → tracking",
        "sentence": "An object model is considered in visual object tracking.",
        "sentence_llm_dp_info": "\"Entity 1 ('object model') is the subject, depending on the verb 'considered'. Entity 2 ('visual object tracking') is the object of the preposition 'in', depending on 'in' in the phrase 'in visual object tracking'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "object model",
                "Method"
            ],
            [
                "numerical optimization problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object model') is the object of the preposition 'Given', depending on 'Given'. Entity 2 ('numerical optimization problem') is the complement of the verb 'consider', depending on 'consider' in the phrase 'we consider visual object tracking as a numerical optimization problem'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'object model' is mentioned in the context that leads to considering 'visual object tracking' as a 'numerical optimization problem'.\"",
        "sdp_path_text": "model → Given → consider → as → problem",
        "sentence": "An object model is considered as a numerical optimization problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('object model') is the subject, depending on the verb 'considered'. Entity 2 ('numerical optimization problem') is the complement, depending on 'as' in the phrase 'as a numerical optimization problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as' which indicates that Entity 1 is being considered in the context of Entity 2.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "black-box measure of similarity",
                "Metric"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('black-box measure of similarity') is the object of the preposition 'between', depending on 'between' in the phrase 'between the model and candidate targets'. Entity 2 ('model') is the first item in the prepositional phrase, also depending on 'between'. There is no direct dependency between Entity 1 and Entity 2; both are part of the same prepositional phrase connected by 'between'.\"",
        "sdp_path_text": "measure → model",
        "sentence": "A black-box measure of similarity is used between the model and candidate targets.",
        "sentence_llm_dp_info": "\"Entity 1 ('black-box measure of similarity') is the subject, depending on the verb 'used'. Entity 2 ('model') is part of a prepositional phrase, depending on 'between' in the phrase 'between the model and candidate targets'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'between'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "black-box measure of similarity",
                "Metric"
            ],
            [
                "visual object tracking",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('black-box measure of similarity') is part of the object complement, depending on the conjunction 'and' connecting it to 'object model'. Entity 2 ('visual object tracking') is the subject of the clause, depending on the verb 'consider' in the phrase 'we consider visual object tracking'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence structure, where both are elements considered in the overall problem formulation.\"",
        "sdp_path_text": "measure → model → Given → consider → tracking",
        "sentence": "A black-box measure of similarity is considered in visual object tracking.",
        "sentence_llm_dp_info": "\"Entity 1 ('black-box measure of similarity') is the subject complement, depending on the verb 'considered'. Entity 2 ('visual object tracking') is the object of the preposition 'in', depending on 'in' in the phrase 'in visual object tracking'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "black-box measure of similarity",
                "Metric"
            ],
            [
                "numerical optimization problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('black-box measure of similarity') is part of the complement of the conjunction 'and', depending on 'and' which connects it to 'object model'. Entity 2 ('numerical optimization problem') is the object of the preposition 'as', depending on 'consider' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of the sentence where Entity 1 is used in the description of the input to the process, and Entity 2 is the outcome or perspective of that process.\"",
        "sdp_path_text": "measure → model → Given → consider → as → problem",
        "sentence": "A black-box measure of similarity between the model and candidate targets is considered in a numerical optimization problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('black-box measure of similarity') is the subject, depending on the verb 'considered'. Entity 2 ('numerical optimization problem') is the object of the preposition 'in', depending on 'in' in the phrase 'in a numerical optimization problem'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the verb 'considered' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "visual object tracking",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is part of a prepositional phrase, depending on 'between' with 'a black-box measure of similarity between the model and candidate targets'. Entity 2 ('visual object tracking') is the subject complement, depending on 'consider' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of the sentence, where the model is used in the process of visual object tracking.\"",
        "sdp_path_text": "model → Given → consider → tracking",
        "sentence": "We consider visual object tracking based on a given model.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'on', depending on 'based' in the phrase 'based on a given model'. Entity 2 ('visual object tracking') is the direct object, depending on 'consider' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on a given model' which modifies 'visual object tracking'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "numerical optimization problem",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is part of the prepositional phrase 'of similarity between the model and candidate targets', where it serves as the first object of the preposition 'between'. Entity 2 ('numerical optimization problem') is the complement of the preposition 'as', depending on 'consider' in the clause 'we consider visual object tracking as a numerical optimization problem'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "model → Given → consider → as → problem",
        "sentence": "The model is considered as a numerical optimization problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'is considered'. Entity 2 ('numerical optimization problem') is the complement, depending on 'as' in the phrase 'as a numerical optimization problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is considered' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Given an object model and a black-box measure of similarity between the model and candidate targets , we consider visual object tracking as a numerical optimization problem .",
        "ner_pair": [
            [
                "numerical optimization problem",
                "Task"
            ],
            [
                "visual object tracking",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('numerical optimization problem') is the complement of the preposition 'as', depending on 'consider' with 'we'. Entity 2 ('visual object tracking') is the subject, depending on 'consider' with 'we'. There is a direct dependency between Entity 1 and Entity 2, as 'visual object tracking' is considered 'as' a 'numerical optimization problem'.\"",
        "sdp_path_text": "problem → as → consider → tracking",
        "sentence": "We consider visual object tracking as a numerical optimization problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('numerical optimization problem') is the complement of the preposition 'as', depending on 'as' in the phrase 'as a numerical optimization problem'. Entity 2 ('visual object tracking') is the object of the verb 'consider', depending on 'consider' in the clause 'We consider visual object tracking'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'as' which equates 'visual object tracking' to 'a numerical optimization problem'.\""
    },
    {
        "raw_sentence": "During normal tracking conditions when the object is visible from frame to frame , local optimization is used to track the local mode of the similarity measure in a parameter space of translation , rotation and scale .",
        "ner_pair": [
            [
                "local optimization",
                "Method"
            ],
            [
                "local mode of the similarity measure",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local optimization') is the subject, depending on the verb 'is used'. Entity 2 ('local mode of the similarity measure') is the object of the preposition 'of', depending on 'track' in the phrase 'to track the local mode of the similarity measure'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'track' and the preposition 'of'.\"",
        "sdp_path_text": "optimization → used → track → mode",
        "sentence": "Local optimization is used to track the local mode of the similarity measure.",
        "sentence_llm_dp_info": "\"Entity 1 ('local optimization') is the subject, depending on the verb 'used'. Entity 2 ('local mode of the similarity measure') is the object of the preposition 'of', depending on 'track' in the phrase 'to track the local mode of the similarity measure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'track'.\""
    },
    {
        "raw_sentence": "During normal tracking conditions when the object is visible from frame to frame , local optimization is used to track the local mode of the similarity measure in a parameter space of translation , rotation and scale .",
        "ner_pair": [
            [
                "local optimization",
                "Method"
            ],
            [
                "parameter space of translation , rotation and scale",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local optimization') is the subject, depending on the verb 'is used'. Entity 2 ('parameter space of translation, rotation and scale') is the object of the preposition 'in', depending on 'in' in the phrase 'in a parameter space of translation, rotation and scale'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is used' and the preposition 'in'.\"",
        "sdp_path_text": "optimization → used → track → in → space",
        "sentence": "Local optimization is used to track the parameter space of translation, rotation, and scale.",
        "sentence_llm_dp_info": "\"Entity 1 ('local optimization') is the subject, depending on the verb 'is used'. Entity 2 ('parameter space of translation, rotation, and scale') is the object of the preposition 'of', depending on 'track'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'track' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "During normal tracking conditions when the object is visible from frame to frame , local optimization is used to track the local mode of the similarity measure in a parameter space of translation , rotation and scale .",
        "ner_pair": [
            [
                "parameter space of translation , rotation and scale",
                "OtherScientificTerm"
            ],
            [
                "local mode of the similarity measure",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parameter space of translation, rotation and scale') is the object of the preposition 'in', depending on 'track'. Entity 2 ('local mode of the similarity measure') is the object of the preposition 'of', depending on 'track'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where 'track' serves as the main verb.\"",
        "sdp_path_text": "space → in → track → mode",
        "sentence": "The parameter space of translation, rotation, and scale is used to track the local mode of the similarity measure.",
        "sentence_llm_dp_info": "\"Entity 1 ('parameter space of translation, rotation, and scale') is the subject, depending on the verb 'is used'. Entity 2 ('local mode of the similarity measure') is the object of the preposition 'of', depending on 'track' in the phrase 'to track the local mode of the similarity measure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'track' which indicates the purpose or action involving both entities.\""
    },
    {
        "raw_sentence": "However , when the object becomes partially or totally occluded , such local tracking is prone to failure , especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames .",
        "ner_pair": [
            [
                "local tracking",
                "Method"
            ],
            [
                "prediction techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local tracking') is the subject, depending on the verb 'is' in the phrase 'is prone to failure'. Entity 2 ('prediction techniques') is the object of the preposition 'like', depending on 'techniques' in the phrase 'like the Kalman filter'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing conditions under which 'local tracking' may fail.\"",
        "sdp_path_text": "tracking → is → provide → techniques",
        "sentence": "Local tracking is prone to failure when prediction techniques do not provide a good estimate.",
        "sentence_llm_dp_info": "\"Entity 1 ('local tracking') is the subject, depending on the verb 'is' with the adjective 'prone'. Entity 2 ('prediction techniques') is the subject, depending on the verb 'do' in the clause 'do not provide a good estimate'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the condition described by the clause 'when prediction techniques do not provide a good estimate'.\""
    },
    {
        "raw_sentence": "However , when the object becomes partially or totally occluded , such local tracking is prone to failure , especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames .",
        "ner_pair": [
            [
                "local tracking",
                "Method"
            ],
            [
                "Kalman filter",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local tracking') is the subject, depending on the verb 'is' with the adjective 'prone'. Entity 2 ('Kalman filter') is part of a noun phrase, depending on 'techniques' with the preposition 'like'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related through the discussion of tracking and prediction techniques.\"",
        "sdp_path_text": "tracking → is → provide → techniques → like → filter",
        "sentence": "Local tracking is prone to failure when techniques like the Kalman filter do not provide a good estimate.",
        "sentence_llm_dp_info": "\"Entity 1 ('local tracking') is the subject, depending on the verb 'is' with the adjective 'prone'. Entity 2 ('Kalman filter') is part of a prepositional phrase, depending on 'techniques' with the preposition 'like'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the condition described in the sentence.\""
    },
    {
        "raw_sentence": "However , when the object becomes partially or totally occluded , such local tracking is prone to failure , especially when common prediction techniques like the Kalman filter do not provide a good estimate of object parameters in future frames .",
        "ner_pair": [
            [
                "Kalman filter",
                "Method"
            ],
            [
                "prediction techniques",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kalman filter') is the object of the preposition 'like', depending on 'techniques'. Entity 2 ('prediction techniques') is the subject complement, depending on 'are' (understood from the context) with 'common'. There is a direct dependency between Entity 1 and Entity 2, where 'Kalman filter' is an example of 'prediction techniques'.\"",
        "sdp_path_text": "filter → like → techniques",
        "sentence": "The Kalman filter is a prediction technique.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kalman filter') is the subject, depending on the verb 'is'. Entity 2 ('prediction technique') is the predicate nominative, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'Kalman filter' is identified as being a type of 'prediction technique'.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "global optimization problem",
                "Task"
            ],
            [
                "object detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the complement of the preposition 'as', depending on 'consider' with 'we'. Entity 2 ('object detection') is the subject, depending on 'solve' with 'it'. There is a direct dependency between Entity 1 and Entity 2, as 'object detection' is considered 'as' a 'global optimization problem'.\"",
        "sdp_path_text": "problem → as → consider → detection",
        "sentence": "We consider object detection as a global optimization problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the complement, depending on the preposition 'as', which is part of the prepositional phrase 'as a global optimization problem'. Entity 2 ('object detection') is the object of the preposition 'as', also depending on 'as'. There is a direct dependency between Entity 1 and Entity 2, as they are both parts of the prepositional phrase 'as a global optimization problem', where 'object detection' is being considered equivalent to 'a global optimization problem'.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "object detection",
                "Task"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject, depending on the verb 'consider' with 'we'. Entity 2 ('it') is the subject, depending on the verb 'solve' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context where 'it' refers back to the problem of 'object detection' being considered as a global optimization problem.\"",
        "sdp_path_text": "detection → consider → recover → from → failures → inevitable",
        "sentence": "We consider object detection to recover from inevitable tracking failures.",
        "sentence_llm_dp_info": "\"Entity 1 ('object detection') is the object of the preposition 'to', depending on 'consider'. Entity 2 ('it') does not appear in the sentence provided. Therefore, there is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not present in the sentence.\"\n\nHowever, if you meant to use a different word for Entity 2 that is actually present in the sentence, please clarify or provide the correct entity. For example, if \"tracking failures\" was intended as Entity 2, the analysis would be different."
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "object detection",
                "Task"
            ],
            [
                "Adaptive Simulated Annealing -LRB- ASA -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject complement, depending on 'consider' with 'we'. Entity 2 ('Adaptive Simulated Annealing -LRB- ASA -RRB-') is the object, depending on 'solve' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'object detection' is considered as a problem and 'Adaptive Simulated Annealing -LRB- ASA -RRB-' is used to solve it.\"",
        "sdp_path_text": "detection → consider → solve → via → -RRB-",
        "sentence": "Object detection is solved via Adaptive Simulated Annealing (ASA).",
        "sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject, depending on the verb 'solved'. Entity 2 ('Adaptive Simulated Annealing (ASA)') is the means or method, depending on 'via' in the phrase 'via Adaptive Simulated Annealing (ASA)'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'solved' and the preposition 'via'.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "object detection",
                "Task"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject complement, depending on 'consider' with 'we'. Entity 2 ('method') is the subject, depending on 'is' with 'that'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the context of solving the optimization problem.\"",
        "sdp_path_text": "detection → consider → solve → via → -RRB- → method",
        "sentence": "Object detection is solved via a method that avoids local traps and is faster than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject, depending on the verb 'is solved'. Entity 2 ('method') is the subject complement, depending on the verb 'is' in the clause 'is solved via a method'. There is a direct dependency between Entity 1 and Entity 2, as 'method' is part of the clause that describes how 'object detection' is solved.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "object detection",
                "Task"
            ],
            [
                "exhaustive search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject, depending on 'consider' with 'we'. Entity 2 ('exhaustive search') is the complement, depending on the comparative adjective 'faster' with 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where 'object detection' is described as being solved via a method (Adaptive Simulated Annealing) that is compared to 'exhaustive search'.\"",
        "sdp_path_text": "detection → consider → solve → via → -RRB- → method → avoids → is → faster → than → search",
        "sentence": "Object detection is solved via a method that is faster than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('object detection') is the subject, depending on the verb 'is solved'. Entity 2 ('exhaustive search') is the object of comparison, depending on the comparative adjective 'faster'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicating that the method solving Entity 1 is faster than Entity 2.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "global optimization problem",
                "Task"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider' with 'we'. Entity 2 ('it') is the subject, depending on 'solve' with 'via Adaptive Simulated Annealing (ASA)'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the logical flow of the sentence where 'it' refers back to the 'global optimization problem'.\"",
        "sdp_path_text": "problem → as → consider → recover → from → failures → inevitable",
        "sentence": "We consider object detection as a global optimization problem to recover from inevitable tracking failures.",
        "sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider'. Entity 2 ('it') is the subject, depending on 'recover'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly related through the context of the sentence where 'it' refers back to the subject or another element in the discourse that is not explicitly mentioned in this sentence.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "global optimization problem",
                "Task"
            ],
            [
                "Adaptive Simulated Annealing -LRB- ASA -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider' with 'we'. Entity 2 ('Adaptive Simulated Annealing -LRB- ASA -RRB-') is the object of the preposition 'via', depending on 'solve' with 'it'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'object detection' is considered as a 'global optimization problem' and solved 'via Adaptive Simulated Annealing (ASA)'.",
        "sdp_path_text": "problem → as → consider → solve → via → -RRB-",
        "sentence": "We consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing (ASA).",
        "sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider' with 'We'. Entity 2 ('Adaptive Simulated Annealing (ASA)') is the object of the preposition 'via', depending on 'solve'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the method and its application.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "global optimization problem",
                "Task"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider' with 'we'. Entity 2 ('method') is the subject complement, depending on 'is' with 'ASA'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the approach to solving the problem of tracking failures.\"",
        "sdp_path_text": "problem → as → consider → solve → via → -RRB- → method",
        "sentence": "We consider the global optimization problem and solve it via a method.",
        "sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the verb 'consider', depending on 'consider' with 'We'. Entity 2 ('method') is the object of the preposition 'via', depending on 'solve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'solve' which takes Entity 1 as its object and uses Entity 2 as the means to achieve the action.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "global optimization problem",
                "Task"
            ],
            [
                "exhaustive search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider' with 'we'. Entity 2 ('exhaustive search') is the complement of the comparative adjective 'faster', depending on 'is'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the same clause describing different aspects of the method used for solving the object detection problem.\"",
        "sdp_path_text": "problem → as → consider → solve → via → -RRB- → method → avoids → is → faster → than → search",
        "sentence": "We consider object detection as a global optimization problem and solve it via a method that is faster than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('global optimization problem') is the object of the preposition 'as', depending on 'consider'. Entity 2 ('exhaustive search') is the complement of the comparative adjective 'faster', depending on 'than' in the phrase 'faster than'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "Adaptive Simulated Annealing -LRB- ASA -RRB-",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Adaptive Simulated Annealing -LRB- ASA -RRB-') is the object of the preposition 'via', depending on 'solve'. Entity 2 ('it') is the subject, depending on 'solve' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'it' refers to the problem being solved using the method mentioned (ASA).\"",
        "sdp_path_text": "-RRB- → via → solve → consider → recover → from → failures → inevitable",
        "sentence": "Adaptive Simulated Annealing (ASA) is used to solve the problem of recovering from inevitable tracking failures.",
        "sentence_llm_dp_info": "\"Entity 1 ('Adaptive Simulated Annealing (ASA)') is the subject, depending on the verb 'is used'. Entity 2 ('it') is the object of the preposition 'of', depending on 'problem'. There is no direct dependency between Entity 1 and Entity 2. However, 'it' refers back to 'Adaptive Simulated Annealing (ASA)' in the context, indicating a semantic relationship though not a syntactic one.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'solve' in the clause 'solve it via Adaptive Simulated Annealing (ASA)'. Entity 2 ('method') is the subject complement, depending on the verb 'is' in the clause 'a method that avoids becoming trapped at local modes'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same sentence, where 'it' refers to the problem being solved and 'method' describes ASA.\"",
        "sdp_path_text": "inevitable → failures → from → recover → consider → solve → via → -RRB- → method",
        "sentence": "We solve tracking failures via a method that avoids becoming trapped at local modes.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') does not appear in the sentence, so there are no dependencies for this entity. Entity 2 ('method') is the subject complement, depending on 'that' which introduces the relative clause 'that avoids becoming trapped at local modes'. There is no direct dependency between Entity 1 and Entity 2, as Entity 1 is not present in the sentence.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "exhaustive search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the object, depending on 'solve' with 'problem'. Entity 2 ('exhaustive search') is the complement, depending on the comparative adjective 'faster' with 'is'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause where 'it' refers to the problem being solved, and 'exhaustive search' is compared to the method used for solving the problem (ASA).\"",
        "sdp_path_text": "inevitable → failures → from → recover → consider → solve → via → -RRB- → method → avoids → is → faster → than → search",
        "sentence": "It solves the problem via a method that is faster than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'solves'. Entity 2 ('exhaustive search') is the complement of the comparative adjective 'faster', depending on 'faster' in the clause 'that is faster than exhaustive search'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "Adaptive Simulated Annealing -LRB- ASA -RRB-",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Adaptive Simulated Annealing -LRB- ASA -RRB-') is the object of the preposition 'via', depending on 'solve'. Entity 2 ('method') is the subject complement, depending on the verb 'is' in the clause 'a method that avoids becoming trapped at local modes and is much faster than exhaustive search'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing how the problem is solved.\"",
        "sdp_path_text": "-RRB- → method",
        "sentence": "Adaptive Simulated Annealing (ASA) is a method.",
        "sentence_llm_dp_info": "\"Entity 1 ('Adaptive Simulated Annealing (ASA)') is the subject, depending on the verb 'is'. Entity 2 ('method') is the complement, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, where 'method' describes what 'Adaptive Simulated Annealing (ASA)' is.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "Adaptive Simulated Annealing -LRB- ASA -RRB-",
                "Method"
            ],
            [
                "exhaustive search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Adaptive Simulated Annealing -LRB- ASA -RRB-') is the object of the preposition 'via', depending on 'solve'. Entity 2 ('exhaustive search') is the complement of the comparative adjective 'faster', depending on 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in the context of speed and effectiveness in solving the optimization problem.\"",
        "sdp_path_text": "-RRB- → method → avoids → is → faster → than → search",
        "sentence": "Adaptive Simulated Annealing (ASA) is faster than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('Adaptive Simulated Annealing (ASA)') is the subject, depending on the verb 'is'. Entity 2 ('exhaustive search') is the complement of the comparison, depending on 'than' in the comparative clause 'faster than exhaustive search'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicated by 'faster than'.\""
    },
    {
        "raw_sentence": "To recover from these inevitable tracking failures , we consider object detection as a global optimization problem and solve it via Adaptive Simulated Annealing -LRB- ASA -RRB- , a method that avoids becoming trapped at local modes and is much faster than exhaustive search .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "exhaustive search",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'is' with 'that avoids becoming trapped at local modes and is much faster than'. Entity 2 ('exhaustive search') is the complement, depending on 'than' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the preposition 'than'.\"",
        "sdp_path_text": "method → avoids → is → faster → than → search",
        "sentence": "The method avoids being trapped and is faster than exhaustive search.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'avoids'. Entity 2 ('exhaustive search') is the complement of the preposition 'than', depending on 'faster'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'faster than'.\""
    },
    {
        "raw_sentence": "As a Monte Carlo approach , ASA stochastically samples the parameter space , in contrast to local deterministic search .",
        "ner_pair": [
            [
                "ASA",
                "Method"
            ],
            [
                "Monte Carlo approach",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASA') is the subject, depending on the verb 'samples'. Entity 2 ('Monte Carlo approach') is the appositive, depending on 'ASA'. There is a direct dependency between Entity 1 and Entity 2, where 'Monte Carlo approach' provides additional information about 'ASA'.\"",
        "sdp_path_text": "ASA → samples → As → approach",
        "sentence": "ASA samples the parameter space as a Monte Carlo approach.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASA') is the subject, depending on the verb 'samples'. Entity 2 ('Monte Carlo approach') is the complement, depending on the preposition 'as', which itself depends on the verb 'samples'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as'.\""
    },
    {
        "raw_sentence": "As a Monte Carlo approach , ASA stochastically samples the parameter space , in contrast to local deterministic search .",
        "ner_pair": [
            [
                "Monte Carlo approach",
                "Method"
            ],
            [
                "parameter space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Monte Carlo approach') is the appositive, depending on 'ASA' with the preposition 'as'. Entity 2 ('parameter space') is the object, depending on 'samples' with 'stochastically'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the action performed by ASA.\"",
        "sdp_path_text": "approach → As → samples → space",
        "sentence": "The Monte Carlo approach samples the parameter space.",
        "sentence_llm_dp_info": "\"Entity 1 ('Monte Carlo approach') is the subject, depending on the verb 'samples'. Entity 2 ('parameter space') is the object, depending on the verb 'samples'. There is a direct dependency between Entity 1 and Entity 2, as 'Monte Carlo approach' performs the action (sampling) on 'parameter space'.\""
    },
    {
        "raw_sentence": "As a Monte Carlo approach , ASA stochastically samples the parameter space , in contrast to local deterministic search .",
        "ner_pair": [
            [
                "Monte Carlo approach",
                "Method"
            ],
            [
                "local deterministic search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Monte Carlo approach') is the appositive, depending on 'ASA' which it describes. Entity 2 ('local deterministic search') is the object of the preposition 'to', depending on 'contrast' in the phrase 'in contrast to local deterministic search'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted through the preposition 'to'.\"",
        "sdp_path_text": "approach → As → samples → in → contrast → to → search",
        "sentence": "The Monte Carlo approach samples the parameter space in contrast to local deterministic search.",
        "sentence_llm_dp_info": "\"Entity 1 ('Monte Carlo approach') is the subject, depending on the verb 'samples'. Entity 2 ('local deterministic search') is the complement of the preposition 'to', depending on 'contrast' in the phrase 'in contrast to'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted through the prepositional phrase 'in contrast to'.\""
    },
    {
        "raw_sentence": "As a Monte Carlo approach , ASA stochastically samples the parameter space , in contrast to local deterministic search .",
        "ner_pair": [
            [
                "ASA",
                "Method"
            ],
            [
                "parameter space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASA') is the subject, depending on the verb 'samples'. Entity 2 ('parameter space') is the object, depending on 'samples' with 'ASA'. There is a direct dependency between Entity 1 and Entity 2, as 'ASA' performs the action of sampling 'parameter space'.\"",
        "sdp_path_text": "ASA → samples → space",
        "sentence": "ASA stochastically samples the parameter space.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASA') is the subject, depending on the verb 'samples'. Entity 2 ('parameter space') is the object, depending on 'samples' with 'ASA'. There is a direct dependency between Entity 1 and Entity 2, as 'ASA' directly performs the action of sampling on 'parameter space'.\""
    },
    {
        "raw_sentence": "As a Monte Carlo approach , ASA stochastically samples the parameter space , in contrast to local deterministic search .",
        "ner_pair": [
            [
                "ASA",
                "Method"
            ],
            [
                "local deterministic search",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASA') is the subject, depending on 'samples' with the verb 'stochastically samples'. Entity 2 ('local deterministic search') is the object of the preposition 'to', depending on 'contrast' in the phrase 'in contrast to local deterministic search'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted in the sentence through the preposition 'to'.\"",
        "sdp_path_text": "ASA → samples → in → contrast → to → search",
        "sentence": "ASA samples the parameter space in contrast to local deterministic search.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASA') is the subject, depending on the verb 'samples'. Entity 2 ('local deterministic search') is the object of the preposition 'to', depending on 'contrast' in the phrase 'in contrast to'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' in the phrase 'in contrast to'.\""
    },
    {
        "raw_sentence": "As a Monte Carlo approach , ASA stochastically samples the parameter space , in contrast to local deterministic search .",
        "ner_pair": [
            [
                "parameter space",
                "OtherScientificTerm"
            ],
            [
                "local deterministic search",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parameter space') is the object, depending on 'samples' with 'ASA'. Entity 2 ('local deterministic search') is the complement of the preposition 'to', depending on 'contrast' in the phrase 'in contrast to local deterministic search'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "space → samples → in → contrast → to → search",
        "sentence": "ASA samples the parameter space in contrast to local deterministic search.",
        "sentence_llm_dp_info": "\"Entity 1 ('parameter space') is the object of the verb 'samples', depending on 'ASA'. Entity 2 ('local deterministic search') is the object of the preposition 'to', depending on 'in contrast to'. There is no direct dependency between Entity 1 and Entity 2, but they are contrasted within the sentence.\""
    },
    {
        "raw_sentence": "We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker .",
        "ner_pair": [
            [
                "cluster analysis",
                "Method"
            ],
            [
                "sampled parameter space",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cluster analysis') is the object of the verb 'apply', depending on 'We' as the subject. Entity 2 ('sampled parameter space') is the object of the preposition 'on', depending on 'cluster analysis'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 serves as the location or target of the action applied to Entity 1.\"",
        "sdp_path_text": "analysis → apply → on → space",
        "sentence": "We apply cluster analysis on the sampled parameter space.",
        "sentence_llm_dp_info": "\"Entity 1 ('cluster analysis') is the object of the verb 'apply', depending on 'apply' with 'We'. Entity 2 ('sampled parameter space') is the object of the preposition 'on', depending on 'on' in the phrase 'on the sampled parameter space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'apply' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker .",
        "ner_pair": [
            [
                "cluster analysis",
                "Method"
            ],
            [
                "local tracker",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cluster analysis') is the object of the preposition 'on', depending on 'apply' with 'We'. Entity 2 ('local tracker') is the object of the verb 'renew', depending on 'renew' in the phrase 'renew the local tracker'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\"",
        "sdp_path_text": "analysis → apply → redetect → renew → tracker",
        "sentence": "Cluster analysis is applied to redetect and renew the local tracker.",
        "sentence_llm_dp_info": "\"Entity 1 ('cluster analysis') is the subject, depending on the verb 'is applied'. Entity 2 ('local tracker') is the object, depending on the verbs 'redetect' and 'renew'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of the application described by the verbs 'redetect' and 'renew'.\""
    },
    {
        "raw_sentence": "We apply cluster analysis on the sampled parameter space to redetect the object and renew the local tracker .",
        "ner_pair": [
            [
                "sampled parameter space",
                "OtherScientificTerm"
            ],
            [
                "local tracker",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('sampled parameter space') is the object of the preposition 'on', depending on 'apply' with 'We'. Entity 2 ('local tracker') is the object of the verb 'renew', depending on 'renew' in the clause 'to redetect the object and renew the local tracker'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "space → on → apply → redetect → renew → tracker",
        "sentence": "We apply cluster analysis on the sampled parameter space to renew the local tracker.",
        "sentence_llm_dp_info": "\"Entity 1 ('sampled parameter space') is the object of the preposition 'on', depending on 'apply' with 'cluster analysis'. Entity 2 ('local tracker') is the object of the verb 'renew', depending on 'renew'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the actions described by 'apply' and 'renew'.\""
    },
    {
        "raw_sentence": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .",
        "ner_pair": [
            [
                "airborne videos",
                "Material"
            ],
            [
                "numerical hybrid local and global mode-seeking tracker",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('airborne videos') is the object of the preposition 'on', depending on 'validated'. Entity 2 ('numerical hybrid local and global mode-seeking tracker') is the subject, depending on the verb 'is validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the validation process described by the verb 'is validated'.\"",
        "sdp_path_text": "videos → on → validated → tracker",
        "sentence": "The numerical hybrid local and global mode-seeking tracker is validated on airborne videos.",
        "sentence_llm_dp_info": "\"Entity 1 ('airborne videos') is the object, depending on 'validated' with 'is validated on'. Entity 2 ('numerical hybrid local and global mode-seeking tracker') is the subject, depending on the verb 'validated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'validated'.\""
    },
    {
        "raw_sentence": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .",
        "ner_pair": [
            [
                "numerical hybrid local and global mode-seeking tracker",
                "Method"
            ],
            [
                "heavy occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('numerical hybrid local and global mode-seeking tracker') is the subject, depending on the verb 'validated'. Entity 2 ('heavy occlusion') is part of a list of adverbial modifiers, depending on 'with' in the phrase 'with heavy occlusion and large camera motions'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "tracker → validated → on → videos → with → occlusion",
        "sentence": "The numerical hybrid local and global mode-seeking tracker is validated on videos with heavy occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('numerical hybrid local and global mode-seeking tracker') is the subject, depending on the verb 'validated'. Entity 2 ('heavy occlusion') is part of the prepositional phrase 'with heavy occlusion', modifying the noun 'videos'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which modifies the noun 'videos'.\""
    },
    {
        "raw_sentence": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .",
        "ner_pair": [
            [
                "numerical hybrid local and global mode-seeking tracker",
                "Method"
            ],
            [
                "camera motions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('numerical hybrid local and global mode-seeking tracker') is the subject, depending on the verb 'validated'. Entity 2 ('camera motions') is part of a prepositional phrase, depending on the preposition 'with' in the phrase 'with heavy occlusion and large camera motions'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same sentence describing the conditions under which the tracker is validated.\"",
        "sdp_path_text": "tracker → validated → on → videos → with → occlusion → motions",
        "sentence": "The numerical hybrid local and global mode-seeking tracker is validated on videos with camera motions.",
        "sentence_llm_dp_info": "\"Entity 1 ('numerical hybrid local and global mode-seeking tracker') is the subject, depending on the verb 'validated'. Entity 2 ('camera motions') is the object of the preposition 'with', depending on 'with' in the phrase 'with camera motions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .",
        "ner_pair": [
            [
                "heavy occlusion",
                "OtherScientificTerm"
            ],
            [
                "airborne videos",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('heavy occlusion') is part of a prepositional phrase, depending on 'with' which modifies 'videos'. Entity 2 ('airborne videos') is the object of the preposition 'on', depending on 'validated'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger prepositional phrase that modifies the verb 'validated'.\"",
        "sdp_path_text": "occlusion → with → videos",
        "sentence": "Airborne videos feature heavy occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('heavy occlusion') is the object, depending on the verb 'feature'. Entity 2 ('airborne videos') is the subject, depending on the verb 'feature'. There is a direct dependency between Entity 1 and Entity 2, as 'heavy occlusion' is directly featured by 'airborne videos'.\""
    },
    {
        "raw_sentence": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .",
        "ner_pair": [
            [
                "camera motions",
                "OtherScientificTerm"
            ],
            [
                "airborne videos",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('camera motions') is part of the prepositional phrase 'with heavy occlusion and large camera motions', depending on the preposition 'with'. Entity 2 ('airborne videos') is the object of the preposition 'on', depending on 'validated' in the phrase 'validated on challenging airborne videos'. There is no direct dependency between Entity 1 and Entity 2; both are part of the context describing the conditions under which the tracker is validated.\"",
        "sdp_path_text": "motions → occlusion → with → videos",
        "sentence": "Camera motions and heavy occlusion are present in airborne videos.",
        "sentence_llm_dp_info": "\"Entity 1 ('camera motions') is part of the subject, depending on 'are' with 'present'. Entity 2 ('airborne videos') is the object of the preposition 'in', depending on 'in' in the phrase 'in airborne videos'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence.\""
    },
    {
        "raw_sentence": "Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .",
        "ner_pair": [
            [
                "heavy occlusion",
                "OtherScientificTerm"
            ],
            [
                "camera motions",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('heavy occlusion') is the object of the preposition 'with', depending on 'with' in the phrase 'with heavy occlusion'. Entity 2 ('camera motions') is also the object of the preposition 'with', depending on 'with' in the phrase 'with heavy occlusion and large camera motions'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of conditions or characteristics described by the preposition 'with'.\"",
        "sdp_path_text": "occlusion → motions",
        "sentence": "The tracker is validated on videos with heavy occlusion and large camera motions.",
        "sentence_llm_dp_info": "\"Entity 1 ('heavy occlusion') is part of a prepositional phrase, depending on 'with' which modifies 'videos'. Entity 2 ('camera motions') is also part of a prepositional phrase, depending on 'with' which modifies 'videos'. There is no direct dependency between Entity 1 and Entity 2; both are elements of the same prepositional phrase modifying 'videos'.\""
    },
    {
        "raw_sentence": "Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets .",
        "ner_pair": [
            [
                "state-of-the-art trackers",
                "Generic"
            ],
            [
                "approach",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('state-of-the-art trackers') is the object of the preposition 'on', depending on 'outperforms'. Entity 2 ('approach') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'outperforms'.\"",
        "sdp_path_text": "trackers → outperforms → approach",
        "sentence": "Our approach outperforms state-of-the-art trackers.",
        "sentence_llm_dp_info": "\"Entity 1 ('state-of-the-art trackers') is the object, depending on the verb 'outperforms'. Entity 2 ('approach') is the subject, depending on the possessive pronoun 'Our'. There is a direct dependency between Entity 1 and Entity 2, where 'approach' is the subject that performs the action of 'outperforming' the 'state-of-the-art trackers'.\""
    },
    {
        "raw_sentence": "Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets .",
        "ner_pair": [
            [
                "VIVID benchmark datasets",
                "Material"
            ],
            [
                "approach",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('VIVID benchmark datasets') is the object, depending on the preposition 'on', which modifies 'outperforms'. Entity 2 ('approach') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'outperforms' and the preposition 'on'.\"",
        "sdp_path_text": "datasets → on → trackers → outperforms → approach",
        "sentence": "Our approach outperforms trackers on the VIVID benchmark datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('VIVID benchmark datasets') is the object, depending on 'on' with 'trackers'. Entity 2 ('approach') is the subject, depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'outperforms' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets .",
        "ner_pair": [
            [
                "VIVID benchmark datasets",
                "Material"
            ],
            [
                "state-of-the-art trackers",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('VIVID benchmark datasets') is the object, depending on the preposition 'on', which itself depends on the verb 'outperforms'. Entity 2 ('state-of-the-art trackers') is the object, directly depending on the verb 'outperforms'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'outperforms'.\"",
        "sdp_path_text": "datasets → on → trackers",
        "sentence": "{\n  \"Simplified sentence\": \"Our approach outperforms state-of-the-art trackers on the VIVID benchmark datasets.\"\n} \n\nHowever, to better adhere to the instructions and remove extraneous information while focusing on the relationship between the two entities:\n\n{\n  \"Simplified sentence\": \"The VIVID benchmark datasets show our approach outperforming state-of-the-art trackers.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('VIVID benchmark datasets') is the subject, depending on the verb 'show'. Entity 2 ('state-of-the-art trackers') is the object of the verb 'outperforming', which is part of a gerund phrase acting as a complement to the verb 'show'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'outperforming' and the verb 'show'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "Techniques",
                "Generic"
            ],
            [
                "automatically training modules",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('automatically training modules') is the object of the preposition 'for', depending on 'for' in the phrase 'for automatically training modules'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "Techniques → for → training",
        "sentence": "Techniques for automatically training modules have been proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('automatically training modules') is the object, depending on the preposition 'for', which is part of the phrase 'for automatically training modules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "Techniques",
                "Generic"
            ],
            [
                "natural language generator",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the noun 'modules' which is part of the prepositional phrase 'modules of a natural language generator'.\"",
        "sdp_path_text": "Techniques → for → training → modules → of → generator",
        "sentence": "Techniques for training modules of a natural language generator have been proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for training modules of a natural language generator'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "Techniques",
                "Generic"
            ],
            [
                "quality of utterances",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('quality of utterances') is the subject of the clause 'is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches', depending on 'whether'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "Techniques → proposed → is → compete → quality",
        "sentence": "Techniques have been proposed to compete with the quality of utterances.",
        "sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'have been proposed'. Entity 2 ('quality of utterances') is the object of the preposition 'with', depending on 'compete' in the phrase 'to compete with the quality of utterances'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'to compete with'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "Techniques",
                "Generic"
            ],
            [
                "utterances",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('utterances') is the object of the preposition 'of', depending on 'quality' in the phrase 'the quality of utterances'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause structure where the discussion revolves around the techniques and their impact on the quality of utterances.\"",
        "sdp_path_text": "Techniques → proposed → is → compete → quality → of → utterances",
        "sentence": "Techniques proposed can compete with the quality of utterances.",
        "sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('utterances') is the object of the preposition 'with', depending on 'with' in the phrase 'with the quality of utterances'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'can compete with'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "Techniques",
                "Generic"
            ],
            [
                "trainable components",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('trainable components') is the object of the preposition 'with', depending on 'produced' in the phrase 'utterances produced with trainable components'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'produced' and the preposition 'with'.\"",
        "sdp_path_text": "Techniques → proposed → is → compete → quality → of → utterances → produced → with → components",
        "sentence": "Techniques for training components have been proposed to compete with other approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('trainable components') is the object of the preposition 'for', depending on 'for' in the phrase 'for training components'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "Techniques",
                "Generic"
            ],
            [
                "hand-crafted template-based or rule-based approaches",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the verb 'proposed'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object, depending on the comparative verb 'compete' in the clause 'can compete with hand-crafted template-based or rule-based approaches'. There is no direct dependency between Entity 1 and Entity 2; they are related through the context of comparison established by the verb 'compete'.\"",
        "sdp_path_text": "Techniques → proposed → is → compete → with → approaches",
        "sentence": "Techniques have been proposed to compete with hand-crafted template-based or rule-based approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('Techniques') is the subject, depending on the passive verb 'have been proposed'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object of the preposition 'with', depending on 'compete' in the phrase 'to compete with hand-crafted template-based or rule-based approaches'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with' and the verb 'compete'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "automatically training modules",
                "Method"
            ],
            [
                "natural language generator",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'techniques'. Entity 2 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same noun phrase where 'modules' modifies 'natural language generator'.\"",
        "sdp_path_text": "training → modules → of → generator",
        "sentence": "Techniques for automatically training modules of a natural language generator have been proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'for' in the phrase 'for automatically training modules'. Entity 2 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'for automatically training modules' and 'of a natural language generator'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "automatically training modules",
                "Method"
            ],
            [
                "quality of utterances",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'for' in the phrase 'for automatically training modules'. Entity 2 ('quality of utterances') is the subject complement, depending on 'is' with 'a fundamental concern'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of concerns and proposals in the sentence.\"",
        "sdp_path_text": "training → for → Techniques → proposed → is → compete → quality",
        "sentence": "Techniques for automatically training modules have been proposed, raising concerns about competing with the quality of utterances.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'techniques'. Entity 2 ('quality of utterances') is the object of the preposition 'with', depending on 'competing'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, connected through the verb 'raising' which indicates the consequence of the proposal.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "automatically training modules",
                "Method"
            ],
            [
                "utterances",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'techniques'. Entity 2 ('utterances') is the subject of the clause, depending on 'produced'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "training → for → Techniques → proposed → is → compete → quality → of → utterances",
        "sentence": "Techniques for automatically training modules can produce utterances that compete in quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'Techniques'. Entity 2 ('utterances') is the subject complement, depending on 'produce'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'produce'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "automatically training modules",
                "Method"
            ],
            [
                "trainable components",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'Techniques'. Entity 2 ('trainable components') is the subject complement, depending on 'with' in the phrase 'produced with trainable components'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of techniques and their application in natural language generation.\"",
        "sdp_path_text": "training → for → Techniques → proposed → is → compete → quality → of → utterances → produced → with → components",
        "sentence": "Techniques for training modules have been proposed to compete with the quality of utterances produced by trainable components.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'Techniques'. Entity 2 ('trainable components') is the object of the preposition 'by', depending on 'produced'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence describing different aspects of the techniques proposed.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "automatically training modules",
                "Method"
            ],
            [
                "hand-crafted template-based or rule-based approaches",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'techniques'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the complement of the preposition 'with', depending on 'produced'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses that are compared in the context of the sentence.\"",
        "sdp_path_text": "training → for → Techniques → proposed → is → compete → with → approaches",
        "sentence": "Techniques for automatically training modules have been proposed to compete with hand-crafted template-based or rule-based approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatically training modules') is the object of the preposition 'for', depending on 'proposes' with 'have been proposed'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object of the preposition 'with', depending on 'compete' in the phrase 'to compete with'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what the proposed techniques aim to compete against.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "natural language generator",
                "Method"
            ],
            [
                "quality of utterances",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. Entity 2 ('quality of utterances') is the subject, depending on 'is' in the clause 'is whether the quality of utterances...'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context discussing techniques and concerns related to the generation of natural language.\"",
        "sdp_path_text": "generator → of → modules → training → for → Techniques → proposed → is → compete → quality",
        "sentence": "Techniques for training modules of a natural language generator have been proposed to compete with the quality of utterances.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. Entity 2 ('quality of utterances') is the object of the preposition 'with', depending on 'compete'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'techniques' are proposed to compete with the 'quality of utterances' that can be produced by the 'natural language generator'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "natural language generator",
                "Method"
            ],
            [
                "utterances",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is part of the object of the preposition 'of', depending on 'modules'. Entity 2 ('utterances') is the object of the preposition 'of', depending on 'quality'. There is no direct dependency between Entity 1 and Entity 2; they are both part of larger phrases that describe different aspects of the techniques and concerns mentioned in the sentence.\"",
        "sdp_path_text": "generator → of → modules → training → for → Techniques → proposed → is → compete → quality → of → utterances",
        "sentence": "Techniques for training modules of a natural language generator aim to produce utterances that can compete in quality with other approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. Entity 2 ('utterances') is the object of the infinitive 'to produce', depending on 'aim'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'aim to produce utterances'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "natural language generator",
                "Method"
            ],
            [
                "trainable components",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is part of the object of the preposition 'of', depending on 'modules'. Entity 2 ('trainable components') is the object of the preposition 'with', depending on 'produced'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context discussing the techniques and concerns related to training parts of a natural language generation system.\"",
        "sdp_path_text": "generator → of → modules → training → for → Techniques → proposed → is → compete → quality → of → utterances → produced → with → components",
        "sentence": "Techniques for training modules of a natural language generator have been proposed, focusing on the quality of utterances produced with trainable components.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is the object of the preposition 'of', depending on 'modules'. Entity 2 ('trainable components') is the object of the preposition 'with', depending on 'produced'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the topic of training modules and their impact on the quality of utterances.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "natural language generator",
                "Method"
            ],
            [
                "hand-crafted template-based or rule-based approaches",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is part of the object of the preposition 'of', depending on 'modules'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the complement of the comparison, depending on 'compete'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of training methods and performance comparison in the sentence.\"",
        "sdp_path_text": "generator → of → modules → training → for → Techniques → proposed → is → compete → with → approaches",
        "sentence": "Techniques for training modules of a natural language generator have been proposed to compete with hand-crafted template-based or rule-based approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language generator') is part of the object of the preposition 'of', depending on 'modules'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object of the preposition 'with', depending on 'compete'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'compete' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "quality of utterances",
                "Metric"
            ],
            [
                "trainable components",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('quality of utterances') is the subject of the clause, depending on 'is' with 'concern'. Entity 2 ('trainable components') is the object of the preposition 'with', depending on 'produced' in the phrase 'produced with trainable components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produced' and the preposition 'with'.\"",
        "sdp_path_text": "quality → of → utterances → produced → with → components",
        "sentence": "The quality of utterances produced with trainable components is a concern.",
        "sentence_llm_dp_info": "\"Entity 1 ('quality of utterances') is the subject, depending on the verb 'is'. Entity 2 ('trainable components') is the object of the preposition 'with', depending on 'produced'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produced' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "quality of utterances",
                "Metric"
            ],
            [
                "hand-crafted template-based or rule-based approaches",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('quality of utterances') is the subject of the clause, depending on the verb 'can compete'. It is also part of a larger noun phrase where it depends on 'whether' as the head of the clause. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object, depending on 'compete' with 'quality of utterances'. There is a direct dependency between Entity 1 and Entity 2, as they are in a comparative relationship expressed by the verb 'can compete'.\"",
        "sdp_path_text": "quality → compete → with → approaches",
        "sentence": "The quality of utterances can compete with hand-crafted template-based or rule-based approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('quality of utterances') is the subject, depending on the verb 'can compete'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object, depending on the verb 'compete' in the phrase 'compete with hand-crafted template-based or rule-based approaches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'compete'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "utterances",
                "OtherScientificTerm"
            ],
            [
                "trainable components",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('utterances') is the subject, depending on the verb 'produced'. Entity 2 ('trainable components') is the object of the preposition 'with', depending on 'with' in the phrase 'with trainable components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produced' where 'utterances' are produced 'with trainable components'.\"",
        "sdp_path_text": "utterances → produced → with → components",
        "sentence": "Utterances are produced with trainable components.",
        "sentence_llm_dp_info": "\"Entity 1 ('utterances') is the subject, depending on the verb 'produced'. Entity 2 ('trainable components') is the object, depending on the preposition 'with' in the phrase 'with trainable components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produced' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "utterances",
                "OtherScientificTerm"
            ],
            [
                "hand-crafted template-based or rule-based approaches",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('utterances') is the subject, depending on the verb 'produced'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object of the comparison, depending on 'with' in the comparative clause 'can compete with hand-crafted template-based or rule-based approaches'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a comparative structure where the quality of Entity 1 is being compared to Entity 2.\"",
        "sdp_path_text": "utterances → of → quality → compete → with → approaches",
        "sentence": "The quality of utterances produced can compete with hand-crafted template-based or rule-based approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('utterances') is the object of the preposition 'of', depending on 'quality'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object of the preposition 'with', depending on 'compete'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the quality of utterances can compete with.\""
    },
    {
        "raw_sentence": "Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .",
        "ner_pair": [
            [
                "trainable components",
                "Method"
            ],
            [
                "hand-crafted template-based or rule-based approaches",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trainable components') is the object of the preposition 'with', depending on 'produced'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the complement of the verb 'compete', depending on 'compete'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that compares the quality of utterances produced with different methods.\"",
        "sdp_path_text": "components → with → produced → utterances → of → quality → compete → with → approaches",
        "sentence": "The quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches.",
        "sentence_llm_dp_info": "\"Entity 1 ('trainable components') is the object of the preposition 'with', depending on 'produced'. Entity 2 ('hand-crafted template-based or rule-based approaches') is the object of the preposition 'with', depending on 'compete'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the comparison structure within the sentence.\""
    },
    {
        "raw_sentence": "In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments .",
        "ner_pair": [
            [
                "trainable sentence planner",
                "Method"
            ],
            [
                "spoken dialogue system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the object of the preposition 'for', depending on 'evaluate'. Entity 2 ('spoken dialogue system') is also the object of the preposition 'for', depending on 'planner'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'evaluate' through the preposition 'for'.\"",
        "sdp_path_text": "planner → for → system",
        "sentence": "We evaluate a trainable sentence planner for a spoken dialogue system.",
        "sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('spoken dialogue system') is the object of the preposition 'for', depending on 'for' in the phrase 'for a spoken dialogue system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments .",
        "ner_pair": [
            [
                "subjective human judgments",
                "OtherScientificTerm"
            ],
            [
                "trainable sentence planner",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('subjective human judgments') is the object, depending on 'eliciting' with 'by'. Entity 2 ('trainable sentence planner') is the object of the preposition 'for', depending on 'for' in the phrase 'for a trainable sentence planner'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the evaluation process.\"",
        "sdp_path_text": "judgments → eliciting → by → evaluate → planner",
        "sentence": "We evaluate a trainable sentence planner by eliciting subjective human judgments.",
        "sentence_llm_dp_info": "\"Entity 1 ('subjective human judgments') is the object, depending on the verb 'eliciting'. Entity 2 ('trainable sentence planner') is the subject, depending on the verb 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of evaluation and elicitation described in the sentence.\""
    },
    {
        "raw_sentence": "In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments .",
        "ner_pair": [
            [
                "spoken dialogue system",
                "Method"
            ],
            [
                "subjective human judgments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spoken dialogue system') is the object of the preposition 'for', depending on 'planner'. Entity 2 ('subjective human judgments') is the object of the verb 'eliciting', depending on 'eliciting' in the phrase 'by eliciting subjective human judgments'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the evaluation process.\"",
        "sdp_path_text": "system → for → planner → evaluate → by → eliciting → judgments",
        "sentence": "A trainable sentence planner for a spoken dialogue system is evaluated by eliciting subjective human judgments.",
        "sentence_llm_dp_info": "\"Entity 1 ('spoken dialogue system') is the object of the preposition 'for', depending on 'planner'. Entity 2 ('subjective human judgments') is the object of the verb 'eliciting', depending on 'by'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "In order to perform an exhaustive comparison , we also evaluate a hand-crafted template-based generation component , two rule-based sentence planners , and two baseline sentence planners .",
        "ner_pair": [
            [
                "hand-crafted template-based generation component",
                "Method"
            ],
            [
                "rule-based sentence planners",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hand-crafted template-based generation component') is the object of the verb 'evaluate', depending on 'evaluate' with 'we'. Entity 2 ('rule-based sentence planners') is also an object of the verb 'evaluate', depending on 'evaluate' with 'we'. There is no direct dependency between Entity 1 and Entity 2; both are evaluated as part of the same list of components being compared.\"",
        "sdp_path_text": "component → planners",
        "sentence": "We evaluate a hand-crafted template-based generation component and rule-based sentence planners.",
        "sentence_llm_dp_info": "\"Entity 1 ('hand-crafted template-based generation component') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('rule-based sentence planners') is also an object, coordinated with Entity 1 through the conjunction 'and', both depending on 'evaluate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through their coordination as objects of the same verb 'evaluate'.\""
    },
    {
        "raw_sentence": "In order to perform an exhaustive comparison , we also evaluate a hand-crafted template-based generation component , two rule-based sentence planners , and two baseline sentence planners .",
        "ner_pair": [
            [
                "hand-crafted template-based generation component",
                "Method"
            ],
            [
                "baseline sentence planners",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hand-crafted template-based generation component') is the object of the verb 'evaluate', depending on 'evaluate' with 'we'. Entity 2 ('baseline sentence planners') is the object of the conjunction 'and', depending on 'and' which connects it to another object 'two rule-based sentence planners'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items being evaluated.\"",
        "sdp_path_text": "component → planners → planners",
        "sentence": "We evaluate a hand-crafted template-based generation component and baseline sentence planners.",
        "sentence_llm_dp_info": "\"Entity 1 ('hand-crafted template-based generation component') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('baseline sentence planners') is also an object, coordinated with 'and', depending on 'evaluate' with 'We'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same verb 'evaluate'.\""
    },
    {
        "raw_sentence": "In order to perform an exhaustive comparison , we also evaluate a hand-crafted template-based generation component , two rule-based sentence planners , and two baseline sentence planners .",
        "ner_pair": [
            [
                "rule-based sentence planners",
                "Method"
            ],
            [
                "baseline sentence planners",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based sentence planners') is part of a list, depending on the conjunction 'and' with 'hand-crafted template-based generation component'. Entity 2 ('baseline sentence planners') is also part of a list, depending on the conjunction 'and' with 'rule-based sentence planners'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same list.\"",
        "sdp_path_text": "planners → planners",
        "sentence": "We evaluate rule-based sentence planners and baseline sentence planners.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based sentence planners') is the object of the verb 'evaluate', depending on 'evaluate' with 'We'. Entity 2 ('baseline sentence planners') is also the object of the verb 'evaluate', depending on 'and' which connects it to 'rule-based sentence planners'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'evaluate'.\""
    },
    {
        "raw_sentence": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and as well as the hand-crafted system .",
        "ner_pair": [
            [
                "trainable sentence planner",
                "Method"
            ],
            [
                "rule-based systems",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the subject, depending on the verb 'performs' in the clause 'performs better'. Entity 2 ('rule-based systems') is the object of the preposition 'than', depending on 'than' in the comparative construction 'better than the rule-based systems'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicating performance comparison.\"",
        "sdp_path_text": "planner → performs → better → than → systems",
        "sentence": "The trainable sentence planner performs better than rule-based systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the subject, depending on the verb 'performs'. Entity 2 ('rule-based systems') is the complement of the preposition 'than', depending on 'than' in the phrase 'than rule-based systems'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the verb 'performs' and the preposition 'than'.\""
    },
    {
        "raw_sentence": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and as well as the hand-crafted system .",
        "ner_pair": [
            [
                "trainable sentence planner",
                "Method"
            ],
            [
                "baselines",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the subject complement, depending on the verb 'performs'. Entity 2 ('baselines') is the object of the preposition 'than', depending on 'than' in the phrase 'than the rule-based systems and the baselines'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicated by 'than'.\"",
        "sdp_path_text": "planner → performs → better → than → systems → baselines",
        "sentence": "The trainable sentence planner performs better than the baselines.",
        "sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the subject, depending on the verb 'performs'. Entity 2 ('baselines') is the object of the preposition 'than', depending on 'than' in the phrase 'than the baselines'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure indicated by 'than'.\""
    },
    {
        "raw_sentence": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and as well as the hand-crafted system .",
        "ner_pair": [
            [
                "trainable sentence planner",
                "Method"
            ],
            [
                "hand-crafted system",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the subject complement, depending on 'performs' which is part of the verb phrase 'performs better'. Entity 2 ('hand-crafted system') is the object of the preposition 'as', depending on 'as' in the phrase 'as well as the hand-crafted system'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the comparison described in the sentence.\"",
        "sdp_path_text": "planner → performs → better → than → systems → system",
        "sentence": "The trainable sentence planner performs better than the hand-crafted system.",
        "sentence_llm_dp_info": "\"Entity 1 ('trainable sentence planner') is the subject, depending on the verb 'performs'. Entity 2 ('hand-crafted system') is the complement of the preposition 'than', depending on 'than' in the phrase 'than the hand-crafted system'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the verb 'performs' and the preposition 'than'.\""
    },
    {
        "raw_sentence": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and as well as the hand-crafted system .",
        "ner_pair": [
            [
                "rule-based systems",
                "Method"
            ],
            [
                "baselines",
                "Generic"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based systems') is the object of the preposition 'than', depending on 'performs'. Entity 2 ('baselines') is also the object of the preposition 'than', depending on 'performs'. There is no direct dependency between Entity 1 and Entity 2, but they are both compared to the subject 'trainable sentence planner' through the preposition 'than'.\"",
        "sdp_path_text": "systems → baselines",
        "sentence": "The trainable sentence planner performs better than rule-based systems and baselines.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based systems') is the second element in a comparison, depending on the comparative adjective 'better' with the verb 'performs'. Entity 2 ('baselines') is the third element in the comparison, also depending on the comparative adjective 'better' with the verb 'performs'. There is no direct dependency between Entity 1 and Entity 2; both are part of the same comparison structure.\""
    },
    {
        "raw_sentence": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and as well as the hand-crafted system .",
        "ner_pair": [
            [
                "rule-based systems",
                "Method"
            ],
            [
                "hand-crafted system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rule-based systems') is the object of the preposition 'than', depending on 'performs'. Entity 2 ('hand-crafted system') is also the object of the preposition 'than', depending on 'performs'. There is no direct dependency between Entity 1 and Entity 2, but they are both compared to the subject 'trainable sentence planner' in terms of performance.\"",
        "sdp_path_text": "systems → system",
        "sentence": "The trainable sentence planner performs better than rule-based systems and the hand-crafted system.",
        "sentence_llm_dp_info": "\"Entity 1 ('rule-based systems') is the object of the preposition 'than', depending on 'performs'. Entity 2 ('hand-crafted system') is also the object of the preposition 'than', depending on 'performs'. There is no direct dependency between Entity 1 and Entity 2; both are compared to the subject 'trainable sentence planner' through the verb 'performs'.\""
    },
    {
        "raw_sentence": "We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and as well as the hand-crafted system .",
        "ner_pair": [
            [
                "baselines",
                "Generic"
            ],
            [
                "hand-crafted system",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('baselines') is the object of the preposition 'than', depending on 'performs' in the clause 'performs better than the rule-based systems and the baselines'. Entity 2 ('hand-crafted system') is the complement of the conjunction 'as well as', depending on 'and' in the phrase 'and as well as the hand-crafted system'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the comparison introduced by 'than' and extended by 'as well as'.\"",
        "sdp_path_text": "baselines → systems → system",
        "sentence": "The trainable sentence planner performs better than the baselines and the hand-crafted system.",
        "sentence_llm_dp_info": "\"Entity 1 ('baselines') is the object of the comparative clause, depending on 'than' with 'performs'. Entity 2 ('hand-crafted system') is also an object of the comparative clause, depending on 'and' with 'baselines'. There is no direct dependency between Entity 1 and Entity 2; both are part of the comparative structure introduced by 'than'.\""
    },
    {
        "raw_sentence": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "novel view generation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'proposed'. Entity 2 ('novel view generation') is the object of the preposition 'for', depending on 'for' in the phrase 'for novel view generation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "algorithm → proposed → for → generation",
        "sentence": "A new algorithm is proposed for novel view generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'proposed'. Entity 2 ('novel view generation') is the object of the preposition 'for', depending on 'for' in the phrase 'for novel view generation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "one-to-one teleconferencing applications",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'proposed'. Entity 2 ('one-to-one teleconferencing applications') is the object of the preposition 'in', depending on 'in' in the phrase 'in one-to-one teleconferencing applications'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the purpose of the algorithm being proposed for use in these applications.\"",
        "sdp_path_text": "algorithm → proposed → in → applications",
        "sentence": "A new algorithm is proposed for one-to-one teleconferencing applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'proposed'. Entity 2 ('one-to-one teleconferencing applications') is the object of the preposition 'for', depending on 'for' in the phrase 'for one-to-one teleconferencing applications'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications .",
        "ner_pair": [
            [
                "novel view generation",
                "Task"
            ],
            [
                "one-to-one teleconferencing applications",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('novel view generation') is the object of the preposition 'for', depending on 'proposed'. Entity 2 ('one-to-one teleconferencing applications') is the object of the preposition 'in', depending on 'generation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context in which the algorithm is proposed.\"",
        "sdp_path_text": "generation → for → proposed → in → applications",
        "sentence": "{\n  \"Simplified sentence\": \"A new algorithm is proposed for novel view generation in one-to-one teleconferencing applications.\"\n} \n\nHowever, to better reflect the instructions and focus on the relationship between the two entities while removing unnecessary information, a more refined version would be:\n\n{\n  \"Simplified sentence\": \"A new algorithm is proposed for novel view generation in teleconferencing applications.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('novel view generation') is the object of the preposition 'for', depending on 'proposed'. Entity 2 ('one-to-one teleconferencing applications') is the object of the preposition 'in', depending on 'generation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context in which the new algorithm is proposed.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "video streams",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired' in the phrase 'acquired by two cameras'. Entity 2 ('video streams') is the subject, depending on 'given' at the beginning of the sentence. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'acquired'.\"",
        "sdp_path_text": "cameras → by → acquired → streams",
        "sentence": "Cameras acquire video streams.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the subject, depending on the verb 'acquire'. Entity 2 ('video streams') is the direct object, depending on 'acquire' with 'cameras'. There is a direct dependency between Entity 1 and Entity 2, where 'cameras' acquires 'video streams'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "video streams",
                "Material"
            ],
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'acquired by', depending on 'acquired'. Entity 2 ('computer monitor') is the object of the preposition 'of', depending on 'side'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context provided by the sentence, where the 'video streams' are acquired by cameras placed relative to the 'computer monitor'.\"",
        "sdp_path_text": "streams → acquired → by → cameras → placed → on → side → of → monitor",
        "sentence": "Video streams are acquired by cameras placed on the sides of a computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('video streams') is the subject, depending on the passive verb 'are acquired'. Entity 2 ('computer monitor') is the object of the preposition 'of', depending on 'sides'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the sequence of relations involving 'cameras' and 'sides'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "video streams",
                "Material"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'acquired', depending on 'acquired' in the phrase 'acquired by two cameras'. Entity 2 ('algorithm') is the subject, depending on 'synthesises' in the phrase 'the proposed algorithm synthesises'. There is no direct dependency between Entity 1 and Entity 2; however, both are part of the broader context where the algorithm processes the video streams.\"",
        "sdp_path_text": "streams → Given → synthesises → algorithm",
        "sentence": "The algorithm synthesises images from video streams.",
        "sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object, depending on the preposition 'from', which itself depends on the verb 'synthesises'. Entity 2 ('algorithm') is the subject, depending on the verb 'synthesises'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'synthesises' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "video streams",
                "Material"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'from', depending on 'acquired'. Entity 2 ('images') is the object, depending on 'synthesises' with 'the proposed algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the process described by the sentence where the algorithm uses the 'video streams' to 'synthesise' the 'images'.\"",
        "sdp_path_text": "streams → Given → synthesises → images",
        "sentence": "The proposed algorithm synthesises images from video streams.",
        "sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'from', depending on 'synthesises'. Entity 2 ('images') is the direct object, depending on the verb 'synthesises'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'synthesises'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "video streams",
                "Material"
            ],
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'acquired', depending on 'acquired' with 'by two cameras'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' with 'the proposed algorithm'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described by the verb 'synthesises'.\"",
        "sdp_path_text": "streams → Given → synthesises → images → from → camera",
        "sentence": "Video streams are used to synthesise images from a virtual camera.",
        "sentence_llm_dp_info": "\"Entity 1 ('video streams') is the subject, depending on the verb 'used'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'from' in the phrase 'from a virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'synthesise' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "video streams",
                "Material"
            ],
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'Given', depending on 'acquired' with 'by two cameras'. Entity 2 ('arbitrary position') is the complement of the preposition 'from', depending on 'in' within the phrase 'in arbitrary position'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "streams → Given → synthesises → images → from → camera → in → -LRB- → position",
        "sentence": "Video streams are used to synthesise images from a camera in an arbitrary position.",
        "sentence_llm_dp_info": "\"Entity 1 ('video streams') is the subject, depending on the verb 'are used'. Entity 2 ('arbitrary position') is the object of the preposition 'in', depending on 'in' in the phrase 'in an arbitrary position'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are used' and the prepositional phrase 'from a camera in an arbitrary position'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "video streams",
                "Material"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('video streams') is the object of the preposition 'Given', depending on 'acquired' with 'by two cameras'. Entity 2 ('eye contact') is the object, depending on 'facilitate' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same context where the video streams are used by the algorithm to facilitate eye contact.\"",
        "sdp_path_text": "streams → Given → synthesises → facilitate → contact",
        "sentence": "Video streams are used to synthesise images that facilitate eye contact.",
        "sentence_llm_dp_info": "\"Entity 1 ('video streams') is the subject, depending on the verb 'used'. Entity 2 ('eye contact') is the object of the clause, depending on 'facilitate' with 'images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of dependencies involving 'used', 'synthesise', and 'facilitate'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired'. Entity 2 ('computer monitor') is the object of the preposition 'of', depending on 'side'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger prepositional phrase that describes the setup of the acquisition of video streams.\"",
        "sdp_path_text": "cameras → placed → on → side → of → monitor",
        "sentence": "Cameras are placed on either side of the computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the subject, depending on the verb 'are placed'. Entity 2 ('computer monitor') is the object of the preposition 'of', depending on 'side' in the phrase 'side of the computer monitor'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'on either side of the computer monitor'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired'. Entity 2 ('algorithm') is the subject, depending on 'synthesises' with 'the proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the process involving video streams and image synthesis.\"",
        "sdp_path_text": "cameras → by → acquired → streams → Given → synthesises → algorithm",
        "sentence": "The algorithm synthesises images from video streams acquired by cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object, depending on the preposition 'by' which modifies the past participle 'acquired'. Entity 2 ('algorithm') is the subject, depending on the verb 'synthesises'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'acquired' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired' in the phrase 'acquired by two cameras'. Entity 2 ('images') is the object, depending on 'synthesises' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the algorithm that processes the input from the cameras to generate the images.\"",
        "sdp_path_text": "cameras → by → acquired → streams → Given → synthesises → images",
        "sentence": "Cameras acquire video streams used to synthesise images.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the subject, depending on the verb 'acquire'. Entity 2 ('images') is the object, depending on 'synthesise'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'acquire' and 'synthesise' which describe the process from acquiring video streams to synthesising images.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described by the verb 'synthesises'.\"",
        "sdp_path_text": "cameras → by → acquired → streams → Given → synthesises → images → from → camera",
        "sentence": "The proposed algorithm synthesises images from a virtual camera using video streams acquired by cameras.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the subject, depending on the verb 'acquired'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' in the phrase 'from a virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the verb 'synthesises'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired' in the phrase 'acquired by two cameras'. Entity 2 ('arbitrary position') is the complement of the preposition 'in', depending on 'position' in the phrase 'in arbitrary position'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses that describe different aspects of the setup and functionality of the algorithm.\"",
        "sdp_path_text": "cameras → by → acquired → streams → Given → synthesises → images → from → camera → in → -LRB- → position",
        "sentence": "Cameras acquire video streams used to synthesise images from a camera in an arbitrary position.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the subject, depending on the verb 'acquire'. Entity 2 ('arbitrary position') is the object of the preposition 'from', depending on 'from' in the phrase 'from a camera in an arbitrary position'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'acquire' and 'synthesise' and the prepositional phrase 'from a camera in an arbitrary position'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "cameras",
                "OtherScientificTerm"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cameras') is the object of the preposition 'by', depending on 'acquired'. Entity 2 ('eye contact') is the object of the infinitive 'to facilitate', depending on 'facilitate'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the purpose of the algorithm.\"",
        "sdp_path_text": "cameras → by → acquired → streams → Given → synthesises → facilitate → contact",
        "sentence": "Cameras acquire streams used to synthesise images facilitating eye contact.",
        "sentence_llm_dp_info": "\"Entity 1 ('cameras') is the subject, depending on the verb 'acquire'. Entity 2 ('eye contact') is the object of the verb 'facilitating', depending on 'facilitating' in the phrase 'facilitating eye contact'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'acquire' and 'facilitating'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'on', depending on 'cameras'. Entity 2 ('algorithm') is the subject, depending on the verb 'synthesises'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same context where the algorithm processes video streams from cameras placed relative to the computer monitor.\"",
        "sdp_path_text": "monitor → of → side → on → placed → cameras → by → acquired → streams → Given → synthesises → algorithm",
        "sentence": "The algorithm synthesises images from a virtual camera based on video streams acquired by cameras placed on either side of a computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'of', depending on 'side'. Entity 2 ('algorithm') is the subject, depending on 'synthesises' with 'The'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'on either side of a computer monitor' which modifies the location from where the video streams are acquired by cameras used by the algorithm.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is part of a prepositional phrase 'on either side of a computer monitor', where it serves as the object of the preposition 'of', and it depends on 'cameras'. Entity 2 ('images') is the object of the verb 'synthesises', depending on 'algorithm'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context provided by the sentence, where the 'computer monitor' is mentioned in relation to the placement of cameras, and 'images' are synthesized to facilitate a view that might be related to the monitor's position.\"",
        "sdp_path_text": "monitor → of → side → on → placed → cameras → by → acquired → streams → Given → synthesises → images",
        "sentence": "The proposed algorithm synthesises images from a virtual camera positioned relative to a computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'to', depending on 'relative' in the phrase 'relative to a computer monitor'. Entity 2 ('images') is the direct object, depending on 'synthesises' in the clause 'synthesises images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'synthesises' and the prepositional phrase 'relative to a computer monitor'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'on', depending on 'placed' with 'cameras'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of the algorithm's function described in the sentence.\"",
        "sdp_path_text": "monitor → of → side → on → placed → cameras → by → acquired → streams → Given → synthesises → images → from → camera",
        "sentence": "The proposed algorithm synthesises images from a virtual camera based on video streams acquired by cameras placed on either side of a computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'of', depending on 'side' in the phrase 'on either side of a computer monitor'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' in the phrase 'synthesises images from a virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'on', depending on 'placed' in the phrase 'placed on either side of a computer monitor'. Entity 2 ('arbitrary position') is the complement of the preposition 'in', depending on 'synthesises' in the phrase 'synthesises images from a virtual camera in arbitrary position'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the context describing the setup for the synthesis of images.\"",
        "sdp_path_text": "monitor → of → side → on → placed → cameras → by → acquired → streams → Given → synthesises → images → from → camera → in → -LRB- → position",
        "sentence": "The algorithm synthesises images from a virtual camera in an arbitrary position relative to the computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'to', depending on 'position'. Entity 2 ('arbitrary position') is the noun modifier, depending on 'in' with 'synthesises'. There is a direct dependency between Entity 1 and Entity 2, as 'position' is described relative to the 'computer monitor'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "computer monitor",
                "OtherScientificTerm"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'of', depending on 'side' in the phrase 'either side of a computer monitor'. Entity 2 ('eye contact') is the object of the infinitive 'to facilitate', depending on 'facilitates' in the phrase 'to facilitate eye contact'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the overall structure of the sentence, where the placement of the cameras relative to the computer monitor influences the facilitation of eye contact.\"",
        "sdp_path_text": "monitor → of → side → on → placed → cameras → by → acquired → streams → Given → synthesises → facilitate → contact",
        "sentence": "The proposed algorithm synthesises images to facilitate eye contact with a computer monitor.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer monitor') is the object of the preposition 'with', depending on 'with' in the phrase 'with a computer monitor'. Entity 2 ('eye contact') is the object, depending on 'facilitate' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'facilitate' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('images') is the direct object, depending on 'synthesises' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, where 'algorithm' is the agent performing the action of synthesising 'images'.\"",
        "sdp_path_text": "algorithm → synthesises → images",
        "sentence": "The algorithm synthesises images.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('images') is the object, depending on the verb 'synthesises'. There is a direct dependency between Entity 1 and Entity 2, as 'images' is the direct object of the action performed by 'algorithm'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'from' in the phrase 'from a virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'synthesises' where the algorithm (Entity 1) is responsible for synthesising images from the virtual camera (Entity 2).\"",
        "sdp_path_text": "algorithm → synthesises → images → from → camera",
        "sentence": "The algorithm synthesises images from a virtual camera.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'from' in the phrase 'from a virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('arbitrary position') is the complement of the preposition 'in', which modifies 'virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in arbitrary position' that describes the location of the virtual camera, which is the object of the action performed by the algorithm.\"",
        "sdp_path_text": "algorithm → synthesises → images → from → camera → in → -LRB- → position",
        "sentence": "The algorithm synthesises images from a camera in an arbitrary position.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('arbitrary position') is the complement of the preposition 'in', depending on 'in' in the phrase 'in an arbitrary position'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'in an arbitrary position'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises' in the clause 'the proposed algorithm synthesises images'. Entity 2 ('eye contact') is the object, depending on the verb 'facilitate' in the infinitive phrase 'to facilitate eye contact'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of the algorithm's action, which is to facilitate eye contact.\"",
        "sdp_path_text": "algorithm → synthesises → facilitate → contact",
        "sentence": "The algorithm synthesises images to facilitate eye contact.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'synthesises'. Entity 2 ('eye contact') is the object, depending on 'facilitate' with 'images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of the algorithm synthesising images which facilitates eye contact.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            [
                "images",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' with 'the proposed algorithm'. Entity 2 ('images') is the direct object, depending on 'synthesises' with 'the proposed algorithm'. There is a direct dependency between Entity 1 and Entity 2, as 'images' are synthesized from the 'virtual camera'.\"",
        "sdp_path_text": "camera → from → images",
        "sentence": "The proposed algorithm synthesises images from a virtual camera.",
        "sentence_llm_dp_info": "\"Entity 1 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises'. Entity 2 ('images') is the direct object, depending on the verb 'synthesises'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'synthesises'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object, depending on the verb 'synthesises'. Entity 2 ('arbitrary position') is the complement of the preposition 'in', depending on 'position'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the clause describing what the algorithm does, with 'images' being synthesized from a virtual camera that can be placed in an 'arbitrary position'.\"",
        "sdp_path_text": "images → from → camera → in → -LRB- → position",
        "sentence": "The algorithm synthesises images from a camera in an arbitrary position.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object, depending on the verb 'synthesises' with 'algorithm'. Entity 2 ('arbitrary position') is the complement of the preposition 'in', depending on 'camera'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'from a camera in an arbitrary position'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object, depending on the verb 'synthesises' with 'the proposed algorithm'. Entity 2 ('eye contact') is the object, depending on the verb 'facilitate' with 'to facilitate'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and contribute to the overall purpose of the algorithm described in the sentence.\"",
        "sdp_path_text": "images → synthesises → facilitate → contact",
        "sentence": "The algorithm synthesises images to facilitate eye contact.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object, depending on 'synthesises' with 'algorithm'. Entity 2 ('eye contact') is the object, depending on 'facilitate' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the actions performed by the 'algorithm'.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('arbitrary position') is the complement of the preposition 'from', depending on 'from' in the phrase 'from a virtual camera in arbitrary position'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' in the clause 'the proposed algorithm synthesises images from a virtual camera'. There is a direct dependency between Entity 1 and Entity 2, as 'arbitrary position' modifies the location of the 'virtual camera'.\"",
        "sdp_path_text": "position → -LRB- → in → camera",
        "sentence": "The algorithm synthesises images from a virtual camera in an arbitrary position.",
        "sentence_llm_dp_info": "\"Entity 1 ('arbitrary position') is the complement of the preposition 'in', depending on 'in' within the phrase 'in an arbitrary position'. Entity 2 ('virtual camera') is the object of the preposition 'from', depending on 'from' within the phrase 'from a virtual camera'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing how the algorithm synthesizes images.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "virtual camera",
                "OtherScientificTerm"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('virtual camera') is the object of the preposition 'from', depending on 'synthesises' in the clause 'the proposed algorithm synthesises images from a virtual camera'. Entity 2 ('eye contact') is the object of the infinitive 'to facilitate', depending on 'facilitate' in the phrase 'to facilitate eye contact'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence where the purpose of synthesizing images from the virtual camera is to facilitate eye contact.\"",
        "sdp_path_text": "camera → from → images → synthesises → facilitate → contact",
        "sentence": "The algorithm synthesizes images from a virtual camera to facilitate eye contact.",
        "sentence_llm_dp_info": "\"Entity 1 ('virtual camera') is the object of the preposition 'from', depending on 'synthesizes' with 'algorithm'. Entity 2 ('eye contact') is the object of the infinitive 'to facilitate', depending on 'facilitate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the main clause where the algorithm's action of synthesizing images from the virtual camera facilitates eye contact.\""
    },
    {
        "raw_sentence": "Given the video streams acquired by two cameras placed on either side of a computer monitor , the proposed algorithm synthesises images from a virtual camera in arbitrary position -LRB- typically located within the monitor -RRB- to facilitate eye contact .",
        "ner_pair": [
            [
                "arbitrary position",
                "OtherScientificTerm"
            ],
            [
                "eye contact",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('arbitrary position') is the complement of the preposition 'in', depending on 'position'. Entity 2 ('eye contact') is the object of the infinitive 'to facilitate', depending on 'facilitate'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the purpose of the algorithm's function.\"",
        "sdp_path_text": "position → -LRB- → in → camera → from → images → synthesises → facilitate → contact",
        "sentence": "Images synthesized from a camera in an arbitrary position facilitate eye contact.",
        "sentence_llm_dp_info": "\"Entity 1 ('arbitrary position') is the object of the preposition 'from', depending on 'camera'. Entity 2 ('eye contact') is the object, depending on 'facilitate' with 'Images'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation .",
        "ner_pair": [
            [
                "dynamic-programming , stereo algorithm",
                "Method"
            ],
            [
                "technique",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dynamic-programming, stereo algorithm') is the object of the preposition 'on', depending on 'based' in the phrase 'based on an improved, dynamic-programming, stereo algorithm'. Entity 2 ('technique') is the subject, depending on the verb 'is' in the phrase 'Our technique is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' and the verb 'is'.\"",
        "sdp_path_text": "algorithm → on → based → technique",
        "sentence": "Our technique is based on a dynamic-programming stereo algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('dynamic-programming stereo algorithm') is the complement of the preposition 'on', depending on 'based'. Entity 2 ('technique') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is what the technique is based on.\""
    },
    {
        "raw_sentence": "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "novel-view generation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'is' which links it to the predicate 'based on an improved, dynamic-programming, stereo algorithm'. Entity 2 ('novel-view generation') is the object of the preposition 'for', depending on 'for' in the phrase 'for efficient novel-view generation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for efficient novel-view generation'.\"",
        "sdp_path_text": "technique → based → on → algorithm → for → generation",
        "sentence": "Our technique is based on an algorithm for novel-view generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'is'. Entity 2 ('novel-view generation') is the object of the preposition 'for', depending on 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'algorithm' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Our technique is based on an improved , dynamic-programming , stereo algorithm for efficient novel-view generation .",
        "ner_pair": [
            [
                "dynamic-programming , stereo algorithm",
                "Method"
            ],
            [
                "novel-view generation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dynamic-programming, stereo algorithm') is the object of the preposition 'on', depending on 'based' in the phrase 'based on an improved, dynamic-programming, stereo algorithm'. Entity 2 ('novel-view generation') is the object of the preposition 'for', depending on 'for' in the phrase 'for efficient novel-view generation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger prepositional phrases that modify different aspects of the main clause.\"",
        "sdp_path_text": "algorithm → for → generation",
        "sentence": "The dynamic-programming stereo algorithm is used for novel-view generation.",
        "sentence_llm_dp_info": "\"Entity 1 ('dynamic-programming stereo algorithm') is the subject, depending on the verb 'is used'. Entity 2 ('novel-view generation') is the object of the preposition 'for', depending on 'for' in the phrase 'for novel-view generation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose of using Entity 1.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "three-plane graph",
                "Method"
            ],
            [
                "dense-stereo dynamic-programming",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the object of the preposition 'for', depending on 'for' in the phrase 'for dense-stereo dynamic-programming'. Entity 2 ('dense-stereo dynamic-programming') is the object of the preposition 'for', acting as the target of the 'for' phrase that modifies 'three-plane graph'. There is a direct dependency between Entity 1 and Entity 2, as 'three-plane graph' is used for 'dense-stereo dynamic-programming'.\"",
        "sdp_path_text": "graph → for → programming",
        "sentence": "A new type of three-plane graph is used for dense-stereo dynamic-programming.",
        "sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the subject complement, depending on the verb 'is' in the clause 'is used'. Entity 2 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'for' in the phrase 'for dense-stereo dynamic-programming'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "three-plane graph",
                "Method"
            ],
            [
                "occlusion labeling",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the object of the preposition 'of', depending on 'type' in the phrase 'a new type of three-plane graph'. Entity 2 ('occlusion labeling') is the object of the preposition 'for', depending on 'encourages' in the phrase 'that encourages correct occlusion labeling'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'encourages' which describes the effect of the 'three-plane graph' on 'occlusion labeling'.\"",
        "sdp_path_text": "graph → of → type → encourages → labeling",
        "sentence": "A three-plane graph encourages correct occlusion labeling.",
        "sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the subject, depending on the verb 'encourages'. Entity 2 ('occlusion labeling') is the object, depending on 'encourages' with 'three-plane graph'. There is a direct dependency between Entity 1 and Entity 2, where 'three-plane graph' is the agent that encourages 'occlusion labeling'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "three-plane graph",
                "Method"
            ],
            [
                "compact geometric derivation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is part of a nominal modifier, depending on 'are' through the prepositional phrase 'for dense-stereo dynamic-programming'. Entity 2 ('compact geometric derivation') is also a nominal modifier, depending on 'are' through the prepositional phrase 'for novel-view synthesis'. There is no direct dependency between Entity 1 and Entity 2; both are independently linked to the verb 'are' and describe the contributions of the paper.\"",
        "sdp_path_text": "graph → of → type → -RRB- → -RRB- → derivation",
        "sentence": "The paper introduces a three-plane graph and a compact geometric derivation.",
        "sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the object of the verb 'introduces', depending on 'introduces' in the clause 'introduces a three-plane graph'. Entity 2 ('compact geometric derivation') is also an object of the verb 'introduces', depending on 'introduces' in the clause 'introduces a compact geometric derivation'. There is no direct dependency between Entity 1 and Entity 2; both are introduced by the same verb 'introduces'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "three-plane graph",
                "Method"
            ],
            [
                "novel-view synthesis",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is part of a noun phrase, acting as the object of the preposition 'for', which modifies the verb phrase 'a new type of...for dense-stereo dynamic-programming'. Entity 2 ('novel-view synthesis') is also part of a noun phrase, acting as the object of the preposition 'for', which modifies the verb phrase 'a compact geometric derivation for...by direct projection of the minimum-cost surface'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence through the preposition 'for'.\"",
        "sdp_path_text": "graph → of → type → -RRB- → -RRB- → derivation → for → synthesis",
        "sentence": "A new type of three-plane graph contributes to novel-view synthesis.",
        "sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the subject, depending on the verb 'contributes'. Entity 2 ('novel-view synthesis') is the object, depending on the preposition 'to', in the phrase 'to novel-view synthesis'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contributes' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "three-plane graph",
                "Method"
            ],
            [
                "direct projection of the minimum-cost surface",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is part of the object of the preposition 'for', depending on 'graph' in the phrase 'a new type of three-plane graph'. Entity 2 ('direct projection of the minimum-cost surface') is also an object of the preposition 'by', depending on 'projection' in the phrase 'direct projection of the minimum-cost surface'. There is no direct dependency between Entity 1 and Entity 2; both are parts of the list of contributions described in the sentence, each being an object of different prepositions ('for' and 'by').\"",
        "sdp_path_text": "graph → of → type → -RRB- → -RRB- → derivation → by → projection",
        "sentence": "A new type of three-plane graph contributes to the direct projection of the minimum-cost surface.",
        "sentence_llm_dp_info": "\"Entity 1 ('three-plane graph') is the subject, depending on the verb 'contributes'. Entity 2 ('direct projection of the minimum-cost surface') is the object, depending on 'to' in the phrase 'to the direct projection of the minimum-cost surface'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contributes' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "dense-stereo dynamic-programming",
                "Method"
            ],
            [
                "occlusion labeling",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('occlusion labeling') is the object of the relative clause introduced by 'that', depending on 'encourages'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where Entity 1 is part of the description of what the graph is for, and Entity 2 is what the graph encourages.\"",
        "sdp_path_text": "programming → for → graph → of → type → encourages → labeling",
        "sentence": "A new type of three-plane graph for dense-stereo dynamic-programming encourages correct occlusion labeling.",
        "sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('occlusion labeling') is the object, depending on 'encourages' with 'graph'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main subject 'graph'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "dense-stereo dynamic-programming",
                "Method"
            ],
            [
                "compact geometric derivation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('compact geometric derivation') is the object of the preposition 'for', depending on the second contribution 'ii -RRB-'. There is no direct dependency between Entity 1 and Entity 2, as they are part of different contributions described in the sentence.\"",
        "sdp_path_text": "programming → for → graph → of → type → -RRB- → -RRB- → derivation",
        "sentence": "A new type of graph for dense-stereo dynamic-programming contributes to a compact geometric derivation.",
        "sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('compact geometric derivation') is the object, depending on the verb 'contributes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contributes' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "dense-stereo dynamic-programming",
                "Method"
            ],
            [
                "novel-view synthesis",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('novel-view synthesis') is the object of the preposition 'for', depending on 'derivation'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of contributions described in the sentence.\"",
        "sdp_path_text": "programming → for → graph → of → type → -RRB- → -RRB- → derivation → for → synthesis",
        "sentence": "A new type of graph for dense-stereo dynamic-programming contributes to a compact geometric derivation for novel-view synthesis.",
        "sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('novel-view synthesis') is the object of the preposition 'for', depending on 'derivation'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where the graph contributes to the derivation.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "dense-stereo dynamic-programming",
                "Method"
            ],
            [
                "direct projection of the minimum-cost surface",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'graph'. Entity 2 ('direct projection of the minimum-cost surface') is the object of the preposition 'by', depending on 'derivation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of contributions described in the sentence.\"",
        "sdp_path_text": "programming → for → graph → of → type → -RRB- → -RRB- → derivation → by → projection",
        "sentence": "A new type of graph for dense-stereo dynamic-programming is used for the direct projection of the minimum-cost surface.",
        "sentence_llm_dp_info": "\"Entity 1 ('dense-stereo dynamic-programming') is the object of the preposition 'for', depending on 'for' in the phrase 'for dense-stereo dynamic-programming'. Entity 2 ('direct projection of the minimum-cost surface') is the object, depending on 'used' with 'is used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where 'a new type of graph' is used for both the purpose described by Entity 1 and the action described by Entity 2.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "occlusion labeling",
                "Task"
            ],
            [
                "compact geometric derivation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('occlusion labeling') is the object of the verb 'encourages', depending on 'encourages' within the clause 'that encourages correct occlusion labeling'. Entity 2 ('compact geometric derivation') is the object of the preposition 'for', depending on 'for' in the phrase 'a compact geometric derivation for novel-view synthesis'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the same sentence.\"",
        "sdp_path_text": "labeling → encourages → type → -RRB- → -RRB- → derivation",
        "sentence": "The paper contributes a type of graph that encourages correct occlusion labeling and a compact geometric derivation.",
        "sentence_llm_dp_info": "\"Entity 1 ('occlusion labeling') is the object of the relative clause 'that encourages correct occlusion labeling', depending on 'encourages'. Entity 2 ('compact geometric derivation') is the object of the conjunction 'and', depending on 'contributes' in the main clause. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of contributions made by the paper.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "occlusion labeling",
                "Task"
            ],
            [
                "novel-view synthesis",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('occlusion labeling') is the object of the verb 'encourages', depending on 'encourages' in the clause 'that encourages correct occlusion labeling'. Entity 2 ('novel-view synthesis') is the object of the preposition 'for', depending on 'derivation' in the phrase 'a compact geometric derivation for novel-view synthesis'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the same sentence.\"",
        "sdp_path_text": "labeling → encourages → type → -RRB- → -RRB- → derivation → for → synthesis",
        "sentence": "A type of three-plane graph encourages correct occlusion labeling, which is used in a derivation for novel-view synthesis.",
        "sentence_llm_dp_info": "\"Entity 1 ('occlusion labeling') is the object of the verb 'encourages', depending on 'graph'. Entity 2 ('novel-view synthesis') is the object of the preposition 'for', depending on 'derivation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'occlusion labeling' being influenced by the 'three-plane graph' and 'novel-view synthesis' being related to the 'derivation'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "occlusion labeling",
                "Task"
            ],
            [
                "direct projection of the minimum-cost surface",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('occlusion labeling') is the object, depending on 'encourages' with 'graph'. Entity 2 ('direct projection of the minimum-cost surface') is the object, depending on 'synthesis' with 'derivation'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of contributions described in the sentence.\"",
        "sdp_path_text": "labeling → encourages → type → -RRB- → -RRB- → derivation → by → projection",
        "sentence": "The new type of three-plane graph encourages correct occlusion labeling, while a compact geometric derivation is used for direct projection of the minimum-cost surface.",
        "sentence_llm_dp_info": "\"Entity 1 ('occlusion labeling') is the object, depending on the verb 'encourages' with 'three-plane graph'. Entity 2 ('direct projection of the minimum-cost surface') is the object, depending on the verb 'used' with 'derivation'. There is no direct dependency between Entity 1 and Entity 2; both are related to different actions described in the sentence.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "compact geometric derivation",
                "OtherScientificTerm"
            ],
            [
                "novel-view synthesis",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('compact geometric derivation') is the subject complement, depending on the verb 'are' with 'contributions'. Entity 2 ('novel-view synthesis') is the object of the preposition 'for', depending on 'for' in the phrase 'for novel-view synthesis'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of contributions described in the sentence.\"",
        "sdp_path_text": "derivation → for → synthesis",
        "sentence": "A compact geometric derivation is provided for novel-view synthesis.",
        "sentence_llm_dp_info": "\"Entity 1 ('compact geometric derivation') is the subject, depending on the verb 'provided'. Entity 2 ('novel-view synthesis') is the object of the preposition 'for', depending on 'for' in the phrase 'for novel-view synthesis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "direct projection of the minimum-cost surface",
                "Method"
            ],
            [
                "compact geometric derivation",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('direct projection of the minimum-cost surface') is the object of the preposition 'by', depending on 'synthesis'. Entity 2 ('compact geometric derivation') is the subject complement, depending on 'are' with 'contributions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of contributions described in the sentence.\"",
        "sdp_path_text": "projection → by → derivation",
        "sentence": "A compact geometric derivation provides direct projection of the minimum-cost surface.",
        "sentence_llm_dp_info": "\"Entity 1 ('direct projection of the minimum-cost surface') is the object, depending on the verb 'provides'. Entity 2 ('compact geometric derivation') is the subject, also depending on the verb 'provides'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 (the subject) provides Entity 1 (the object).\""
    },
    {
        "raw_sentence": "The two main contributions of this paper are : i -RRB- a new type of three-plane graph for dense-stereo dynamic-programming , that encourages correct occlusion labeling ; ii -RRB- a compact geometric derivation for novel-view synthesis by direct projection of the minimum-cost surface .",
        "ner_pair": [
            [
                "novel-view synthesis",
                "Task"
            ],
            [
                "direct projection of the minimum-cost surface",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('novel-view synthesis') is the object, depending on 'derivation' with 'a compact geometric derivation for'. Entity 2 ('direct projection of the minimum-cost surface') is the object of the preposition 'by', depending on 'by' in the phrase 'by direct projection of the minimum-cost surface'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'novel-view synthesis' is the target of the 'derivation' and 'direct projection of the minimum-cost surface' is the method used for achieving it.\"",
        "sdp_path_text": "synthesis → for → derivation → by → projection",
        "sentence": "Novel-view synthesis is achieved through direct projection of the minimum-cost surface.",
        "sentence_llm_dp_info": "\"Entity 1 ('novel-view synthesis') is the subject, depending on the verb 'achieved'. Entity 2 ('direct projection of the minimum-cost surface') is the object, depending on the preposition 'through' which modifies the verb 'achieved'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'through' indicating the method by which the achievement occurs.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "temporal maintenance of a background model",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'for', depending on 'presents' with 'this paper'. Entity 2 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 specifies the purpose or function of Entity 1.\"",
        "sdp_path_text": "algorithm → for → maintenance",
        "sentence": "The paper presents an algorithm for the temporal maintenance of a background model.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object, depending on the verb 'presents' with 'The paper'. Entity 2 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'for' in the phrase 'for the temporal maintenance of a background model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "rendering of occlusions",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'for', depending on 'presents' with 'this paper'. Entity 2 ('rendering of occlusions') is the object of the preposition 'of', depending on 'enhance' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enhance' and the preposition 'of'.\"",
        "sdp_path_text": "algorithm → enhance → rendering",
        "sentence": "The algorithm enhances the rendering of occlusions.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'enhances'. Entity 2 ('rendering of occlusions') is the object, depending on the verb 'enhances'. There is a direct dependency between Entity 1 and Entity 2, as 'algorithm' directly enhances 'rendering of occlusions'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "temporal artefacts -LRB- flicker -RRB-",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is part of the subject, depending on 'presents' with 'this paper'. Entity 2 ('temporal artefacts -LRB- flicker -RRB-') is the object of the verb 'reduce', depending on 'reduce' which is part of the purpose clause introduced by 'to enhance the rendering of occlusions and reduce'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause where the algorithm aims to reduce temporal artefacts.\"",
        "sdp_path_text": "algorithm → -RRB-",
        "sentence": "The algorithm enhances rendering and reduces temporal artefacts (flicker).",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'enhances' and also related to 'reduces'. Entity 2 ('temporal artefacts (flicker)') is the object, depending on the verb 'reduces'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reduces'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "three-dimensional matching cost space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object, depending on 'presents' with 'this paper'. It is also modified by the adjective 'novel' and further described by the prepositional phrase 'for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-'. Entity 2 ('three-dimensional matching cost space') is the object of the preposition 'on', depending on 'acts' in the clause 'that acts directly on our three-dimensional matching cost space'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same sentence and related through the context provided by the paper's content.\"",
        "sdp_path_text": "algorithm → algorithm → acts → on → space",
        "sentence": "An algorithm acts directly on the three-dimensional matching cost space.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'acts'. Entity 2 ('three-dimensional matching cost space') is the object, depending on the preposition 'on' with 'acts'. There is a direct dependency between Entity 1 and Entity 2, as 'algorithm' acts directly on 'three-dimensional matching cost space'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "temporal maintenance of a background model",
                "Task"
            ],
            [
                "rendering of occlusions",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'presents' with 'this paper'. Entity 2 ('rendering of occlusions') is the object of the verb 'enhance', depending on 'to enhance'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the purpose of Entity 1 is to enhance Entity 2.\"",
        "sdp_path_text": "maintenance → for → algorithm → enhance → rendering",
        "sentence": "Temporal maintenance of a background model enhances the rendering of occlusions.",
        "sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the subject, depending on the verb 'enhances'. Entity 2 ('rendering of occlusions') is the object, depending on the verb 'enhances'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is the agent that performs the action (enhancing) on Entity 2.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "temporal maintenance of a background model",
                "Task"
            ],
            [
                "temporal artefacts -LRB- flicker -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'presents' with 'this paper'. Entity 2 ('temporal artefacts -LRB- flicker -RRB-') is the object of the verb 'reduce', depending on 'reduce' in the clause 'to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the same sentence, connected through the conjunction 'and'.\"",
        "sdp_path_text": "maintenance → for → algorithm → -RRB-",
        "sentence": "The temporal maintenance of a background model reduces temporal artefacts (flicker).",
        "sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the subject, depending on the verb 'reduces'. Entity 2 ('temporal artefacts (flicker)') is the object, depending on the verb 'reduces'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is the agent performing the action that affects Entity 2.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "temporal maintenance of a background model",
                "Task"
            ],
            [
                "cost aggregation algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'presents' with 'this paper'. Entity 2 ('cost aggregation algorithm') is the subject complement, depending on 'is' in the clause 'a cost aggregation algorithm that acts'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the list of items presented in the sentence, connected through the conjunction 'and'.\"",
        "sdp_path_text": "maintenance → for → algorithm → algorithm",
        "sentence": "The paper presents an algorithm for the temporal maintenance of a background model and a cost aggregation algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'algorithm'. Entity 2 ('cost aggregation algorithm') is the second object of the conjunction 'and', depending on 'presents' in the clause 'presents an algorithm... and a cost aggregation algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects related to the verb 'presents'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "temporal maintenance of a background model",
                "Task"
            ],
            [
                "three-dimensional matching cost space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'presents' with 'this paper'. Entity 2 ('three-dimensional matching cost space') is the object of the preposition 'on', depending on 'acts' with 'cost aggregation algorithm'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence describing different algorithms presented in the paper.\"",
        "sdp_path_text": "maintenance → for → algorithm → algorithm → acts → on → space",
        "sentence": "The algorithm for the temporal maintenance of a background model acts on the three-dimensional matching cost space.",
        "sentence_llm_dp_info": "\"Entity 1 ('temporal maintenance of a background model') is the object of the preposition 'for', depending on 'algorithm'. Entity 2 ('three-dimensional matching cost space') is the object, depending on 'acts' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the 'algorithm' through different dependency relations.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "rendering of occlusions",
                "Task"
            ],
            [
                "temporal artefacts -LRB- flicker -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rendering of occlusions') is the object of the verb 'enhance', depending on 'to enhance'. Entity 2 ('temporal artefacts -LRB- flicker -RRB-') is the object of the verb 'reduce', depending on 'to reduce'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of outcomes of the algorithm described in the sentence.\"",
        "sdp_path_text": "rendering → enhance → algorithm → -RRB-",
        "sentence": "The algorithm enhances the rendering of occlusions and reduces temporal artefacts (flicker).",
        "sentence_llm_dp_info": "\"Entity 1 ('rendering of occlusions') is the object of the preposition 'of', depending on 'enhances' with 'the algorithm'. Entity 2 ('temporal artefacts (flicker)') is the object of the verb 'reduces', depending on 'reduces' with 'the algorithm'. There is no direct dependency between Entity 1 and Entity 2, but both are affected by actions performed by 'the algorithm'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "rendering of occlusions",
                "Task"
            ],
            [
                "cost aggregation algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rendering of occlusions') is part of the object complement, depending on 'enhance' which is part of the purpose clause introduced by 'to enhance'. Entity 2 ('cost aggregation algorithm') is the subject of the relative clause, depending on 'that' which introduces the clause describing what the algorithm does. There is no direct dependency between Entity 1 and Entity 2; they are both parts of different clauses within the same sentence.\"",
        "sdp_path_text": "rendering → enhance → algorithm → algorithm",
        "sentence": "A cost aggregation algorithm enhances the rendering of occlusions.",
        "sentence_llm_dp_info": "\"Entity 1 ('rendering of occlusions') is the object of the verb 'enhances', depending on 'enhances' with 'cost aggregation algorithm'. Entity 2 ('cost aggregation algorithm') is the subject, depending on the verb 'enhances'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 performs the action that affects Entity 1.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "rendering of occlusions",
                "Task"
            ],
            [
                "three-dimensional matching cost space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rendering of occlusions') is the object of the verb 'enhance', depending on 'to enhance' with 'algorithm'. Entity 2 ('three-dimensional matching cost space') is the object of the preposition 'on', depending on 'acts' in the phrase 'acts directly on'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different aspects of the algorithms described in the sentence.\"",
        "sdp_path_text": "rendering → enhance → algorithm → algorithm → acts → on → space",
        "sentence": "An algorithm enhances the rendering of occlusions and acts on the three-dimensional matching cost space.",
        "sentence_llm_dp_info": "\"Entity 1 ('rendering of occlusions') is the object of the preposition 'of', depending on 'enhances' with 'algorithm'. Entity 2 ('three-dimensional matching cost space') is the object, depending on 'acts' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but both are influenced by the actions described by the verb 'algorithm'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "temporal artefacts -LRB- flicker -RRB-",
                "OtherScientificTerm"
            ],
            [
                "cost aggregation algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('temporal artefacts -LRB- flicker -RRB-') is the object of the verb 'reduce', depending on the verb 'reduce' in the clause 'to reduce temporal artefacts -LRB- flicker -RRB-'. Entity 2 ('cost aggregation algorithm') is the subject, depending on 'presents' with 'this paper'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the contributions of the paper.\"",
        "sdp_path_text": "-RRB- → algorithm → algorithm",
        "sentence": "A cost aggregation algorithm reduces temporal artefacts (flicker).",
        "sentence_llm_dp_info": "\"Entity 1 ('temporal artefacts (flicker)') is the object, depending on the verb 'reduces'. Entity 2 ('cost aggregation algorithm') is the subject, depending on the verb 'reduces'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 performs the action of reducing Entity 1.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "temporal artefacts -LRB- flicker -RRB-",
                "OtherScientificTerm"
            ],
            [
                "three-dimensional matching cost space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('temporal artefacts -LRB- flicker -RRB-') is the object of the verb 'reduce', depending on 'reduce' in the clause 'to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB-'. Entity 2 ('three-dimensional matching cost space') is the object of the preposition 'on', depending on 'acts' in the phrase 'acts directly on our three-dimensional matching cost space'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "-RRB- → algorithm → algorithm → acts → on → space",
        "sentence": "An algorithm acts on the three-dimensional matching cost space to reduce temporal artefacts (flicker).",
        "sentence_llm_dp_info": "\"Entity 1 ('temporal artefacts (flicker)') is the object, depending on the verb 'reduce'. Entity 2 ('three-dimensional matching cost space') is the object of the preposition 'on', depending on 'acts' in the phrase 'acts on the three-dimensional matching cost space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'acts' and the purpose of reducing the 'temporal artefacts (flicker)'.\""
    },
    {
        "raw_sentence": "Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .",
        "ner_pair": [
            [
                "cost aggregation algorithm",
                "Method"
            ],
            [
                "three-dimensional matching cost space",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cost aggregation algorithm') is the subject, depending on 'presents' with 'this paper'. Entity 2 ('three-dimensional matching cost space') is the object of the preposition 'on', depending on 'acts' in the phrase 'acts directly on our three-dimensional matching cost space'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'acts' and the preposition 'on'.\"",
        "sdp_path_text": "algorithm → acts → on → space",
        "sentence": "The cost aggregation algorithm acts on the three-dimensional matching cost space.",
        "sentence_llm_dp_info": "\"Entity 1 ('cost aggregation algorithm') is the subject, depending on the verb 'acts'. Entity 2 ('three-dimensional matching cost space') is the object, depending on the preposition 'on' which is part of the verb phrase 'acts on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams .",
        "ner_pair": [
            [
                "robustness",
                "Metric"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object of the preposition 'the', depending on 'demonstrate' with 'that'. Entity 2 ('algorithm') is the object of the preposition 'of', depending on 'robustness'. There is a direct dependency between Entity 1 and Entity 2, where 'algorithm' modifies 'robustness' through the preposition 'of'.\"",
        "sdp_path_text": "robustness → of → algorithm",
        "sentence": "Examples demonstrate the robustness of the new algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object of the preposition 'of', depending on 'demonstrate' with 'Examples'. Entity 2 ('algorithm') is the object of the preposition 'of', depending on 'robustness'. There is a direct dependency between Entity 1 and Entity 2, where 'algorithm' modifies 'robustness' through the preposition 'of'.\""
    },
    {
        "raw_sentence": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams .",
        "ner_pair": [
            [
                "robustness",
                "Metric"
            ],
            [
                "spatial and temporal artefacts",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object of the preposition 'of', depending on 'demonstrate' with 'that'. Entity 2 ('spatial and temporal artefacts') is the object of the preposition 'to', depending on 'robustness'. There is a direct dependency between Entity 1 and Entity 2, as 'spatial and temporal artefacts' modifies 'robustness' to specify what the robustness is resistant to.\"",
        "sdp_path_text": "robustness → to → artefacts",
        "sentence": "The robustness of the new algorithm is demonstrated to spatial and temporal artefacts.",
        "sentence_llm_dp_info": "\"Entity 1 ('robustness') is the subject, depending on the verb 'demonstrated'. Entity 2 ('spatial and temporal artefacts') is the object of the preposition 'to', depending on 'to' in the phrase 'to spatial and temporal artefacts'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrated' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams .",
        "ner_pair": [
            [
                "robustness",
                "Metric"
            ],
            [
                "long stereo video streams",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robustness') is the object of the preposition 'the', depending on 'demonstrate' with 'that'. Entity 2 ('long stereo video streams') is the object of the preposition 'for', depending on 'for' in the phrase 'for long stereo video streams'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what is demonstrated about the algorithm's robustness.\"",
        "sdp_path_text": "robustness → to → artefacts → for → streams",
        "sentence": "The robustness of the new algorithm is demonstrated for long stereo video streams.",
        "sentence_llm_dp_info": "\"Entity 1 ('robustness') is the subject, depending on the verb 'demonstrated'. Entity 2 ('long stereo video streams') is the object of the preposition 'for', depending on 'for' in the phrase 'for long stereo video streams'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "spatial and temporal artefacts",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'of', depending on 'demonstrate' in the clause 'that demonstrate the robustness of the new algorithm'. Entity 2 ('spatial and temporal artefacts') is the object of the preposition 'to', depending on 'robustness' in the phrase 'the robustness of the new algorithm to spatial and temporal artefacts'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional structure describing the robustness.\"",
        "sdp_path_text": "algorithm → of → robustness → to → artefacts",
        "sentence": "The new algorithm demonstrates robustness to spatial and temporal artefacts.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'demonstrates'. Entity 2 ('spatial and temporal artefacts') is the object of the preposition 'to', depending on 'to' in the phrase 'to spatial and temporal artefacts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "long stereo video streams",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the preposition 'of', depending on 'demonstrate' with 'that'. Entity 2 ('long stereo video streams') is the object of the preposition 'for', depending on 'artefacts'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the examples demonstrate about the algorithm's robustness.\"",
        "sdp_path_text": "algorithm → of → robustness → to → artefacts → for → streams",
        "sentence": "The algorithm demonstrates robustness to artefacts for long stereo video streams.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'demonstrates'. Entity 2 ('long stereo video streams') is the object of the preposition 'for', depending on 'for' in the phrase 'for long stereo video streams'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Examples are given that demonstrate the robustness of the new algorithm to spatial and temporal artefacts for long stereo video streams .",
        "ner_pair": [
            [
                "spatial and temporal artefacts",
                "OtherScientificTerm"
            ],
            [
                "long stereo video streams",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spatial and temporal artefacts') is the object of the preposition 'to', depending on 'to' in the phrase 'to spatial and temporal artefacts'. Entity 2 ('long stereo video streams') is the object of the preposition 'for', depending on 'for' in the phrase 'for long stereo video streams'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the prepositional phrases modifying 'robustness'.\"",
        "sdp_path_text": "artefacts → for → streams",
        "sentence": "Spatial and temporal artefacts are demonstrated for long stereo video streams.",
        "sentence_llm_dp_info": "\"Entity 1 ('spatial and temporal artefacts') is the subject, depending on the verb 'demonstrated'. Entity 2 ('long stereo video streams') is the object of the preposition 'for', depending on 'for' in the phrase 'for long stereo video streams'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "These include demonstrations of synthesis of cyclopean views of extended conversational sequences .",
        "ner_pair": [
            [
                "cyclopean views",
                "OtherScientificTerm"
            ],
            [
                "extended conversational sequences",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cyclopean views') is the object of the preposition 'of', depending on 'demonstrations'. Entity 2 ('extended conversational sequences') is also the object of the preposition 'of', depending on 'views'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a larger prepositional structure describing what the demonstrations are about.\"",
        "sdp_path_text": "views → of → sequences",
        "sentence": "Cyclopean views of extended conversational sequences are demonstrated.",
        "sentence_llm_dp_info": "\"Entity 1 ('cyclopean views') is the subject, depending on the verb 'demonstrated'. Entity 2 ('extended conversational sequences') is the object of the preposition 'of', depending on 'views' in the phrase 'of extended conversational sequences'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "We further demonstrate synthesis from a freely translating virtual camera .",
        "ner_pair": [
            [
                "translating virtual camera",
                "OtherScientificTerm"
            ],
            [
                "synthesis",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('translating virtual camera') is the object of the preposition 'from', depending on 'from' in the phrase 'from a freely translating virtual camera'. Entity 2 ('synthesis') is the direct object, depending on the verb 'demonstrate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' which indicates that the synthesis is derived from the translating virtual camera.\"",
        "sdp_path_text": "camera → from → synthesis",
        "sentence": "Synthesis is demonstrated from a translating virtual camera.",
        "sentence_llm_dp_info": "\"Entity 1 ('translating virtual camera') is the complement of the preposition 'from', depending on 'demonstrated'. Entity 2 ('synthesis') is the subject, depending on the verb 'is demonstrated'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' which indicates the source or origin of the demonstration of synthesis.\""
    },
    {
        "raw_sentence": "To a large extent , these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities .",
        "ner_pair": [
            [
                "semantic constraints",
                "OtherScientificTerm"
            ],
            [
                "anaphora references",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic constraints') is part of the compound object of the verb 'reflect', depending on 'reflect' with 'statistics'. Entity 2 ('anaphora references') is the object of the verb 'disambiguate', depending on 'disambiguate' with 'used'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process described in the sentence.\"",
        "sdp_path_text": "constraints → reflect → used → disambiguate → references",
        "sentence": "Semantic constraints are used to disambiguate anaphora references.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic constraints') is the subject, depending on the verb 'are used'. Entity 2 ('anaphora references') is the object of the verb 'disambiguate', depending on 'disambiguate' in the clause 'to disambiguate anaphora references'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'disambiguate' which is part of the purpose clause.\""
    },
    {
        "raw_sentence": "To a large extent , these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities .",
        "ner_pair": [
            [
                "semantic constraints",
                "OtherScientificTerm"
            ],
            [
                "syntactic ambiguities",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic constraints') is the object of the preposition 'reflect', depending on 'reflect' in the phrase 'reflect semantic constraints'. Entity 2 ('syntactic ambiguities') is part of a coordination, depending on 'and' in the phrase 'anaphora references and syntactic ambiguities'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the list of items that the statistics are used to disambiguate.\"",
        "sdp_path_text": "constraints → reflect → used → disambiguate → references → ambiguities",
        "sentence": "Semantic constraints reflect and help disambiguate syntactic ambiguities.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic constraints') is the subject, depending on the verb 'reflect'. Entity 1 also depends on the verb 'help' as the subject. Entity 2 ('syntactic ambiguities') is the object of the verbs 'reflect' and 'disambiguate', depending on these verbs. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'reflect' and 'help disambiguate'.\""
    },
    {
        "raw_sentence": "To a large extent , these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities .",
        "ner_pair": [
            [
                "anaphora references",
                "OtherScientificTerm"
            ],
            [
                "syntactic ambiguities",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anaphora references') is part of the coordination, depending on 'disambiguate' with 'used'. Entity 2 ('syntactic ambiguities') is also part of the coordination, depending on 'disambiguate' with 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'disambiguate' within the same clause.\"",
        "sdp_path_text": "references → ambiguities",
        "sentence": "These statistics are used to disambiguate anaphora references and syntactic ambiguities.",
        "sentence_llm_dp_info": "\"Entity 1 ('anaphora references') is the object of the conjunction 'and', depending on 'disambiguate'. Entity 2 ('syntactic ambiguities') is also the object of the conjunction 'and', depending on 'disambiguate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the compound object of the verb 'disambiguate'.\""
    },
    {
        "raw_sentence": "The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool .",
        "ner_pair": [
            [
                "cooccurrence statistics",
                "OtherScientificTerm"
            ],
            [
                "semantic constraints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cooccurrence statistics') is the subject, depending on the verb 'reflect'. Entity 2 ('semantic constraints') is the object, depending on 'reflect' with 'cooccurrence statistics'. There is a direct dependency between Entity 1 and Entity 2, where 'cooccurrence statistics' reflects 'semantic constraints'.\"",
        "sdp_path_text": "statistics → reflect → constraints",
        "sentence": "Cooccurrence statistics reflect semantic constraints.",
        "sentence_llm_dp_info": "\"Entity 1 ('cooccurrence statistics') is the subject, depending on the verb 'reflect'. Entity 2 ('semantic constraints') is the object, depending on the verb 'reflect'. There is a direct dependency between Entity 1 and Entity 2, as 'cooccurrence statistics' reflects 'semantic constraints'.\""
    },
    {
        "raw_sentence": "The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool .",
        "ner_pair": [
            [
                "cooccurrence statistics",
                "OtherScientificTerm"
            ],
            [
                "disambiguation tool",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cooccurrence statistics') is the subject, depending on 'reflect' with the verb 'reflect'. Entity 2 ('disambiguation tool') is the object, depending on 'provide' with the verb 'provide'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'reflect' and 'provide' which describe how the statistics relate to the constraints and how these constraints support the tool.\"",
        "sdp_path_text": "statistics → reflect → provide → basis → for → tool",
        "sentence": "Cooccurrence statistics provide a basis for a disambiguation tool.",
        "sentence_llm_dp_info": "\"Entity 1 ('cooccurrence statistics') is the subject, depending on the verb 'provide'. Entity 2 ('disambiguation tool') is the object of the preposition 'for', depending on 'basis'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provide' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool .",
        "ner_pair": [
            [
                "semantic constraints",
                "OtherScientificTerm"
            ],
            [
                "disambiguation tool",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic constraints') is the object of the verb 'reflect', depending on 'indeed reflect' with 'statistics'. Entity 2 ('disambiguation tool') is the object of the preposition 'for', depending on 'provide' with 'basis'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the outcome of the experiment.\"",
        "sdp_path_text": "constraints → reflect → provide → basis → for → tool",
        "sentence": "Semantic constraints reflect and provide a basis for a disambiguation tool.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic constraints') is the subject, depending on the verb 'reflect' and also part of the compound subject with 'provide'. Entity 2 ('disambiguation tool') is the object of the preposition 'for', depending on 'provide' in the phrase 'provide a basis for a disambiguation tool'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provide' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present a novel method for discovering parallel sentences in comparable , non-parallel corpora .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "discovering parallel sentences",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on the verb 'present'. Entity 2 ('discovering parallel sentences') is the object of the preposition 'for', depending on 'for' in the phrase 'for discovering parallel sentences'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "method → for → discovering",
        "sentence": "We present a novel method for discovering parallel sentences.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'present' with 'We'. Entity 2 ('discovering parallel sentences') is the complement of the preposition 'for', depending on 'for' in the phrase 'for discovering parallel sentences'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present a novel method for discovering parallel sentences in comparable , non-parallel corpora .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "comparable , non-parallel corpora",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'present' with 'We'. Entity 2 ('comparable, non-parallel corpora') is the object of the preposition 'in', depending on 'in' in the phrase 'in comparable, non-parallel corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\"",
        "sdp_path_text": "method → for → discovering → in → corpora",
        "sentence": "We present a method for discovering in comparable, non-parallel corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the direct object, depending on the verb 'present' with 'We'. Entity 2 ('comparable, non-parallel corpora') is the object of the preposition 'in', depending on 'in' in the phrase 'in comparable, non-parallel corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'for discovering in'.\""
    },
    {
        "raw_sentence": "We present a novel method for discovering parallel sentences in comparable , non-parallel corpora .",
        "ner_pair": [
            [
                "comparable , non-parallel corpora",
                "Material"
            ],
            [
                "discovering parallel sentences",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('comparable, non-parallel corpora') is the object of the preposition 'in', depending on 'in' in the phrase 'in comparable, non-parallel corpora'. Entity 2 ('discovering parallel sentences') is the object of the preposition 'for', depending on 'for' in the phrase 'for discovering parallel sentences'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify the noun 'method'.\"",
        "sdp_path_text": "corpora → in → discovering",
        "sentence": "We present a method for discovering parallel sentences in comparable, non-parallel corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('comparable, non-parallel corpora') is the object of the preposition 'in', depending on 'in' in the phrase 'in comparable, non-parallel corpora'. Entity 2 ('discovering parallel sentences') is the complement of the preposition 'for', depending on 'for' in the phrase 'for discovering parallel sentences'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify the noun 'method'.\""
    },
    {
        "raw_sentence": "Using this approach , we extract parallel data from large Chinese , Arabic , and English non-parallel newspaper corpora .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "parallel data",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'using', depending on the verb 'extract'. Entity 2 ('parallel data') is the direct object, depending on the verb 'extract'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the action described by the verb 'extract'.\"",
        "sdp_path_text": "approach → Using → extract → data",
        "sentence": "This approach extracts parallel data.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'extracts'. Entity 2 ('parallel data') is the object, depending on the verb 'extracts'. There is a direct dependency between Entity 1 and Entity 2, as 'parallel data' is the direct object of the action performed by 'approach'.\""
    },
    {
        "raw_sentence": "Using this approach , we extract parallel data from large Chinese , Arabic , and English non-parallel newspaper corpora .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "Chinese , Arabic , and English non-parallel newspaper corpora",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object of the preposition 'Using', depending on the verb 'extract'. Entity 2 ('Chinese, Arabic, and English non-parallel newspaper corpora') is the object, depending on 'from' in the phrase 'from large Chinese, Arabic, and English non-parallel newspaper corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'extract' and the preposition 'from'.\"",
        "sdp_path_text": "approach → Using → extract → from → corpora",
        "sentence": "This approach extracts data from Chinese, Arabic, and English non-parallel newspaper corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'extracts'. Entity 2 ('Chinese, Arabic, and English non-parallel newspaper corpora') is the object, depending on 'from' in the prepositional phrase 'from Chinese, Arabic, and English non-parallel newspaper corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "Using this approach , we extract parallel data from large Chinese , Arabic , and English non-parallel newspaper corpora .",
        "ner_pair": [
            [
                "parallel data",
                "Material"
            ],
            [
                "Chinese , Arabic , and English non-parallel newspaper corpora",
                "Material"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parallel data') is the object, depending on the verb 'extract'. Entity 2 ('Chinese, Arabic, and English non-parallel newspaper corpora') is the object of the preposition 'from', depending on 'from' in the phrase 'from large Chinese, Arabic, and English non-parallel newspaper corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'extract' and the preposition 'from'.\"",
        "sdp_path_text": "data → extract → from → corpora",
        "sentence": "Parallel data is extracted from Chinese, Arabic, and English non-parallel newspaper corpora.",
        "sentence_llm_dp_info": "\"Entity 1 ('parallel data') is the subject, depending on the verb 'is extracted'. Entity 2 ('Chinese, Arabic, and English non-parallel newspaper corpora') is the object, depending on 'from' in the prepositional phrase 'from Chinese, Arabic, and English non-parallel newspaper corpora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "statistical machine translation system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on 'improves' as the verb. Entity 2 ('statistical machine translation system') is the object, depending on 'of' in the phrase 'of a state-of-the-art statistical machine translation system'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' and the prepositional phrase 'of a state-of-the-art statistical machine translation system'.\"",
        "sdp_path_text": "quality → evaluate → by → showing → improves → performance → of → system",
        "sentence": "It improves the performance of a statistical machine translation system.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'improves'. Entity 2 ('statistical machine translation system') is the object of the preposition 'of', depending on 'performance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' and the noun 'performance'.\""
    },
    {
        "raw_sentence": "We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus -LRB- 100,000 words -RRB- and exploiting a large non-parallel corpus .",
        "ner_pair": [
            [
                "parallel corpus",
                "Material"
            ],
            [
                "MT system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parallel corpus') is the object of the preposition 'with', depending on 'starting'. Entity 2 ('MT system') is the subject complement, depending on 'can be built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing the process of building the 'MT system' which involves 'starting with' the 'parallel corpus'.\"",
        "sdp_path_text": "corpus → with → starting → by → built → system",
        "sentence": "A good-quality MT system can be built starting with a parallel corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('parallel corpus') is the object of the preposition 'with', depending on the verb phrase 'can be built'. Entity 2 ('MT system') is the subject, depending on the verb 'can be built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can be built starting with'.\""
    },
    {
        "raw_sentence": "We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus -LRB- 100,000 words -RRB- and exploiting a large non-parallel corpus .",
        "ner_pair": [
            [
                "non-parallel corpus",
                "Material"
            ],
            [
                "MT system",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-parallel corpus') is the object, depending on the verb 'exploiting'. Entity 2 ('MT system') is the subject complement, depending on the verb 'can be built'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the process of building an 'MT system'.\"",
        "sdp_path_text": "corpus → exploiting → starting → by → built → system",
        "sentence": "A good-quality MT system can be built by exploiting a large non-parallel corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-parallel corpus') is the object of the preposition 'by', depending on 'exploiting'. Entity 2 ('MT system') is the subject complement, depending on the verb 'can be built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'built' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "Thus , our method can be applied with great benefit to language pairs for which only scarce resources are available .",
        "ner_pair": [
            [
                "scarce resources",
                "Material"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scarce resources') is the subject complement, depending on 'available' with 'are'. Entity 2 ('method') is the subject, depending on 'can be applied' with 'our'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause 'for which only scarce resources are available'.\"",
        "sdp_path_text": "resources → are → pairs → to → applied → method",
        "sentence": "The method can be applied to language pairs with scarce resources.",
        "sentence_llm_dp_info": "\"Entity 1 ('scarce resources') is the object of the preposition 'with', depending on 'with' in the phrase 'with scarce resources'. Entity 2 ('method') is the subject, depending on the modal verb 'can' which is part of the phrase 'can be applied'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'with scarce resources'.\""
    },
    {
        "raw_sentence": "In this paper , we describe a search procedure for statistical machine translation -LRB- MT -RRB- based on dynamic programming -LRB- DP -RRB- .",
        "ner_pair": [
            [
                "search procedure",
                "Generic"
            ],
            [
                "statistical machine translation -LRB- MT -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('search procedure') is the object of the verb 'describe', depending on 'we'. Entity 2 ('statistical machine translation -LRB- MT -RRB-') is the object of the preposition 'for', depending on 'for' in the phrase 'for statistical machine translation -LRB- MT -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "procedure → for → translation",
        "sentence": "A search procedure is described for statistical machine translation.",
        "sentence_llm_dp_info": "\"Entity 1 ('search procedure') is the subject, depending on the verb 'described'. Entity 2 ('statistical machine translation') is the object of the preposition 'for', depending on 'for' in the phrase 'for statistical machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , we describe a search procedure for statistical machine translation -LRB- MT -RRB- based on dynamic programming -LRB- DP -RRB- .",
        "ner_pair": [
            [
                "search procedure",
                "Generic"
            ],
            [
                "dynamic programming -LRB- DP -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('search procedure') is the object of the verb 'describe', depending on 'we'. Entity 2 ('dynamic programming -LRB- DP -RRB-') is the complement of the preposition 'based on', depending on 'based on' in the phrase 'based on dynamic programming -LRB- DP -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'based on'.\"",
        "sdp_path_text": "procedure → based → on → programming",
        "sentence": "The search procedure is based on dynamic programming.",
        "sentence_llm_dp_info": "\"Entity 1 ('search procedure') is the subject, depending on the verb 'is'. Entity 2 ('dynamic programming') is the complement, depending on the preposition 'on' in the phrase 'based on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' and the verb 'is'.\""
    },
    {
        "raw_sentence": "In this paper , we describe a search procedure for statistical machine translation -LRB- MT -RRB- based on dynamic programming -LRB- DP -RRB- .",
        "ner_pair": [
            [
                "dynamic programming -LRB- DP -RRB-",
                "Method"
            ],
            [
                "statistical machine translation -LRB- MT -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dynamic programming -LRB- DP -RRB-') is the complement of the preposition 'based on', depending on the verb 'describe'. Entity 2 ('statistical machine translation -LRB- MT -RRB-') is the object of the preposition 'for', depending on 'procedure'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the search procedure.\"",
        "sdp_path_text": "programming → on → based → procedure → for → translation",
        "sentence": "A search procedure based on dynamic programming is described for statistical machine translation.",
        "sentence_llm_dp_info": "\"Entity 1 ('dynamic programming (DP)') is part of a prepositional phrase, depending on 'based' with 'procedure'. Entity 2 ('statistical machine translation (MT)') is the object of the preposition 'for', depending on 'for' in the phrase 'for statistical machine translation'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause through the verb 'described'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "DP-based solution",
                "Method"
            ],
            [
                "traveling salesman problem",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the object of the preposition 'from', depending on 'Starting'. Entity 2 ('traveling salesman problem') is the object of the preposition 'to', depending on 'solution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' which indicates that the solution is applied to the problem.\"",
        "sdp_path_text": "solution → to → problem",
        "sentence": "A DP-based solution to the traveling salesman problem is presented.",
        "sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the subject, depending on the verb 'presented'. Entity 2 ('traveling salesman problem') is the object of the preposition 'to', depending on 'to' in the phrase 'to the traveling salesman problem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "DP-based solution",
                "Method"
            ],
            [
                "technique",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the object of the preposition 'from', depending on 'Starting'. Entity 2 ('technique') is the subject, depending on 'present' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of presenting a methodological advancement.\"",
        "sdp_path_text": "solution → from → Starting → present → technique",
        "sentence": "We present a technique starting from a DP-based solution.",
        "sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the object of the preposition 'from', depending on 'starting'. Entity 2 ('technique') is the direct object, depending on the verb 'present'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'starting' which indicates the origin or basis of the 'technique'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "DP-based solution",
                "Method"
            ],
            [
                "word reordering",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the object of the preposition 'from', depending on 'Starting'. Entity 2 ('word reordering') is the object of the preposition 'to', depending on 'restrict'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the technique presented.\"",
        "sdp_path_text": "solution → from → Starting → present → technique → restrict → reordering",
        "sentence": "A technique is presented to restrict word reordering starting from a DP-based solution.",
        "sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the object of the preposition 'from', depending on 'starting'. Entity 2 ('word reordering') is the object of the verb 'restrict', depending on 'restrict'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'DP-based solution' serves as the starting point for restricting 'word reordering'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "DP-based solution",
                "Method"
            ],
            [
                "search algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the object of the preposition 'from', depending on 'Starting'. Entity 2 ('search algorithm') is the object, depending on 'achieve' in the phrase 'to achieve an efficient search algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence describing different aspects of the presented technique.\"",
        "sdp_path_text": "solution → from → Starting → present → technique → restrict → in → order → achieve → algorithm",
        "sentence": "A DP-based solution is used to achieve an efficient search algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('DP-based solution') is the subject, depending on the verb 'used'. Entity 2 ('search algorithm') is the object, depending on the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'achieve' which indicates that the 'DP-based solution' is used to achieve the 'search algorithm'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "traveling salesman problem",
                "Method"
            ],
            [
                "technique",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('traveling salesman problem') is the object of the preposition 'to', depending on 'solution'. Entity 2 ('technique') is the subject, depending on the verb 'present'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the technique is presented as a method related to the solution to the traveling salesman problem.\"",
        "sdp_path_text": "problem → to → solution → from → Starting → present → technique",
        "sentence": "A novel technique is presented starting from a solution to the traveling salesman problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('traveling salesman problem') is the object of the preposition 'to', depending on 'solution'. Entity 2 ('technique') is the subject, depending on the verb 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'a solution to the traveling salesman problem' which modifies 'technique'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "traveling salesman problem",
                "Method"
            ],
            [
                "word reordering",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('traveling salesman problem') is the object of the preposition 'to', depending on 'solution'. Entity 2 ('word reordering') is the object of the preposition 'between', depending on 'restrict'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same discourse, connected through the context of the described technique.\"",
        "sdp_path_text": "problem → to → solution → from → Starting → present → technique → restrict → reordering",
        "sentence": "A technique is presented to restrict word reordering based on a solution to the traveling salesman problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('traveling salesman problem') is the object of the preposition 'to', depending on 'solution'. Entity 2 ('word reordering') is the object of the verb 'restrict', depending on 'restrict' in the phrase 'to restrict word reordering'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'restrict' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "traveling salesman problem",
                "Method"
            ],
            [
                "search algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('traveling salesman problem') is the object of the preposition 'to', depending on 'solution'. Entity 2 ('search algorithm') is the object of the preposition 'to', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure, connected through the main clause and the purpose clause introduced by 'in order to'.\"",
        "sdp_path_text": "problem → to → solution → from → Starting → present → technique → restrict → in → order → achieve → algorithm",
        "sentence": "A technique derived from a solution to the traveling salesman problem helps achieve an efficient search algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('traveling salesman problem') is the object of the preposition 'from', depending on 'derived'. Entity 2 ('search algorithm') is the object of the noun 'achieve', depending on 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps' which indicates that the technique derived from Entity 1 contributes to achieving Entity 2.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "word reordering",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'present' with 'we'. Entity 2 ('word reordering') is the object of the preposition 'between', depending on 'between' in the phrase 'between source and target language'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to restrict'.\"",
        "sdp_path_text": "technique → restrict → reordering",
        "sentence": "A novel technique restricts word reordering between languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'restricts'. Entity 2 ('word reordering') is the object, depending on 'restricts' with 'technique'. There is a direct dependency between Entity 1 and Entity 2, where 'technique' acts upon 'word reordering'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "technique",
                "Generic"
            ],
            [
                "search algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'present'. Entity 2 ('search algorithm') is the object, depending on the verb 'achieve'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'in order to'.\"",
        "sdp_path_text": "technique → restrict → in → order → achieve → algorithm",
        "sentence": "A novel technique restricts word reordering to achieve an efficient search algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('technique') is the subject, depending on the verb 'restricts'. Entity 2 ('search algorithm') is the object, depending on 'achieve' with 'technique'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'restricts' and 'achieve'.\""
    },
    {
        "raw_sentence": "Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .",
        "ner_pair": [
            [
                "word reordering",
                "OtherScientificTerm"
            ],
            [
                "search algorithm",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word reordering') is the object of the preposition 'between', depending on 'restrict' which is part of the clause 'to restrict the possible word reordering'. Entity 2 ('search algorithm') is the object of the preposition 'for', depending on 'achieve' which is part of the clause 'to achieve an efficient search algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same purpose clause introduced by 'in order to'.\"",
        "sdp_path_text": "reordering → restrict → in → order → achieve → algorithm",
        "sentence": "A novel technique restricts word reordering to achieve an efficient search algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('word reordering') is the object of the verb 'restricts', depending on 'technique'. Entity 2 ('search algorithm') is the object of the verb 'achieve', depending on 'technique'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the action performed by 'technique'.\""
    },
    {
        "raw_sentence": "The experimental tests are carried out on the Verbmobil task -LRB- German-English , 8000-word vocabulary -RRB- , which is a limited-domain spoken-language task .",
        "ner_pair": [
            [
                "Verbmobil task",
                "Material"
            ],
            [
                "German-English",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Verbmobil task') is the object of the preposition 'on', depending on 'carried out'. Entity 2 ('German-English') is part of an appositive, specifying the nature of the 'Verbmobil task', depending on 'task'. There is no direct dependency between Entity 1 and Entity 2, but Entity 2 provides additional information about Entity 1.\"",
        "sdp_path_text": "task → -LRB- → German",
        "sentence": "The Verbmobil task involves German-English translation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Verbmobil task') is the subject, depending on the verb 'involves'. Entity 2 ('German-English') is part of the noun phrase functioning as the object of the verb 'involves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' which indicates that the 'Verbmobil task' includes 'German-English translation'.\""
    },
    {
        "raw_sentence": "The experimental tests are carried out on the Verbmobil task -LRB- German-English , 8000-word vocabulary -RRB- , which is a limited-domain spoken-language task .",
        "ner_pair": [
            [
                "Verbmobil task",
                "Material"
            ],
            [
                "limited-domain spoken-language task",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Verbmobil task') is the object of the preposition 'on', depending on 'carried out'. Entity 2 ('limited-domain spoken-language task') is the complement of 'be', depending on 'is' in the clause 'which is a limited-domain spoken-language task'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the relative clause 'which is a limited-domain spoken-language task' that describes Entity 1.\"",
        "sdp_path_text": "task → is → task",
        "sentence": "The Verbmobil task is a limited-domain spoken-language task.",
        "sentence_llm_dp_info": "\"Entity 1 ('Verbmobil task') is the subject, depending on the copula 'is'. Entity 2 ('limited-domain spoken-language task') is the predicate nominal, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 renames or defines Entity 1.\""
    },
    {
        "raw_sentence": "The experimental tests are carried out on the Verbmobil task -LRB- German-English , 8000-word vocabulary -RRB- , which is a limited-domain spoken-language task .",
        "ner_pair": [
            [
                "German-English",
                "Material"
            ],
            [
                "limited-domain spoken-language task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('German-English') is part of an appositive construction, depending on the noun 'task' in the phrase 'Verbmobil task (German-English, 8000-word vocabulary)'. Entity 2 ('limited-domain spoken-language task') is the complement of the copula 'is', describing the 'Verbmobil task'. There is no direct dependency between Entity 1 and Entity 2; both are related to the 'Verbmobil task' but serve different syntactic roles.\"",
        "sdp_path_text": "German → -LRB- → task → is → task",
        "sentence": "The German-English task is a limited-domain spoken-language task.",
        "sentence_llm_dp_info": "\"Entity 1 ('German-English') is part of a compound noun, depending on 'task' as a modifier. Entity 2 ('limited-domain spoken-language task') is the subject complement, depending on the copula 'is'. There is no direct dependency between Entity 1 and Entity 2; however, they are both parts of the same noun phrase describing the task.\""
    },
    {
        "raw_sentence": "A purely functional implementation of LR-parsers is given , together with a simple correctness proof .",
        "ner_pair": [
            [
                "correctness proof",
                "Method"
            ],
            [
                "LR-parsers",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('correctness proof') is the object, depending on 'given' with 'is'. Entity 2 ('LR-parsers') is the object of the preposition 'of', depending on 'implementation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure described in the sentence.\"",
        "sdp_path_text": "proof → with → given → implementation → of → LR",
        "sentence": "A correctness proof is given with the implementation of LR-parsers.",
        "sentence_llm_dp_info": "\"Entity 1 ('correctness proof') is the subject, depending on the verb 'given'. Entity 2 ('LR-parsers') is the object of the preposition 'of', depending on 'implementation' in the phrase 'the implementation of LR-parsers'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'with the implementation of LR-parsers'.\""
    },
    {
        "raw_sentence": "It is presented as a generalization of the recursive descent parser .",
        "ner_pair": [
            [
                "recursive descent parser",
                "Method"
            ],
            [
                "It",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recursive descent parser') is the object of the preposition 'of', depending on 'of' in the phrase 'of the recursive descent parser'. Entity 2 ('It') is the subject, depending on the verb 'is presented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate structure where 'It' refers to something that is being generalized, which includes the 'recursive descent parser'.\"",
        "sdp_path_text": "parser → of → generalization → as → presented → It",
        "sentence": "It is presented as a generalization of the recursive descent parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('recursive descent parser') is the object of the preposition 'of', depending on 'of' in the phrase 'of the recursive descent parser'. Entity 2 ('It') is the subject, depending on the verb 'is presented'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of the recursive descent parser'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "non-LR grammars",
                "Method"
            ],
            [
                "time-complexity",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-LR grammars') is the subject complement, depending on the preposition 'for' which modifies the clause. Entity 2 ('time-complexity') is the subject, depending on the copula 'is' which links it to the predicate 'cubic'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same context where 'non-LR grammars' is a condition for the statement about 'time-complexity'.\"",
        "sdp_path_text": "grammars → For → is → time",
        "sentence": "For non-LR grammars, the time-complexity is cubic.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-LR grammars') is the subject complement, depending on the preposition 'for'. Entity 2 ('time-complexity') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "non-LR grammars",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parser') is the subject, depending on the verb 'is' which describes its time-complexity. Entity 2 ('non-LR grammars') is the object of the preposition 'for', indicating the context or condition under which the statement about the parser's time-complexity holds true. There is no direct dependency between Entity 1 and Entity 2; they are related through the prepositional phrase 'For non-LR grammars' which sets the condition for the parser's described characteristic.\"",
        "sdp_path_text": "parser → of → complexity → is → For → grammars",
        "sentence": "The parser's complexity is cubic for non-LR grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('parser') is part of the possessive noun phrase 'The parser's complexity', depending on 'complexity' with a possessive relation. Entity 2 ('non-LR grammars') is the object of the preposition 'for', depending on 'for' in the phrase 'for non-LR grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'complexity' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "parser",
                "Method"
            ],
            [
                "non-LR grammars",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parser') is the subject of the clause, depending on the verb 'is' which describes its time-complexity. Entity 2 ('non-LR grammars') is the object of the preposition 'For', indicating the context or condition under which the statement about the parser's time-complexity holds. There is no direct dependency between Entity 1 and Entity 2; they are connected through the contextual setup provided by the preposition 'For'.\"",
        "sdp_path_text": "parser → of → complexity → is → For → grammars",
        "sentence": "The parser's time-complexity is cubic for non-LR grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('parser') is part of the possessive noun phrase 'The parser's time-complexity', where it modifies 'time-complexity' as a possessor. Entity 2 ('non-LR grammars') is the complement of the preposition 'for', indicating the type of grammars for which the time-complexity applies. There is no direct dependency between Entity 1 and Entity 2; they are connected through the predicate 'is cubic for'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "non-LR grammars",
                "Method"
            ],
            [
                "memo-functions",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-LR grammars') is the subject complement, depending on 'grammars' with the preposition 'for'. Entity 2 ('memo-functions') is the appositive, depending on 'functions' with the conjunction 'i.e.'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing conditions and characteristics of the parser.\"",
        "sdp_path_text": "grammars → For → is → implemented → as → -",
        "sentence": "For non-LR grammars, the parser functions are implemented as memo-functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-LR grammars') is the object of the preposition 'For', depending on 'For' in the phrase 'For non-LR grammars'. Entity 2 ('memo-functions') is the complement of the verb 'implemented', depending on 'implemented' in the phrase 'are implemented as memo-functions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'non-LR grammars' sets the context for the implementation of 'memo-functions'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "time-complexity",
                "Metric"
            ],
            [
                "parser",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('time-complexity') is the subject, depending on the verb 'is'. Entity 2 ('parser') is the object of the preposition 'of', depending on 'of' in the phrase 'of our parser'. There is a direct dependency between Entity 1 and Entity 2, as 'time-complexity' is directly associated with 'parser' through the preposition 'of'.\"",
        "sdp_path_text": "time → is → complexity → of → parser",
        "sentence": "The time-complexity is cubic for the parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('time-complexity') is the subject, depending on the verb 'is'. Entity 2 ('parser') is the object of the preposition 'for', depending on 'for' in the phrase 'for the parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "time-complexity",
                "Metric"
            ],
            [
                "parser",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('time-complexity') is the subject, depending on 'is' with 'cubic'. Entity 2 ('parser') is the object of the preposition 'of', depending on 'of' in the phrase 'of our parser'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'.\"",
        "sdp_path_text": "time → is → complexity → of → parser",
        "sentence": "The time-complexity is of the parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('time-complexity') is the subject, depending on the copula 'is'. Entity 2 ('parser') is the complement of the preposition 'of', depending on 'of' in the phrase 'of the parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "time-complexity",
                "Metric"
            ],
            [
                "memo-functions",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('time-complexity') is the subject, depending on the verb 'is'. Entity 2 ('memo-functions') is the appositive, depending on the noun 'functions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'time-complexity' is described as being cubic under the condition that 'functions' (which are further specified as 'memo-functions') are used.\"",
        "sdp_path_text": "time → is → implemented → as → -",
        "sentence": "The time-complexity is implemented as memo-functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('time-complexity') is the subject, depending on the verb 'is implemented'. Entity 2 ('memo-functions') is the object, depending on 'is implemented' with 'time-complexity'. There is a direct dependency between Entity 1 and Entity 2, where 'time-complexity' is implemented as 'memo-functions'.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "memo-functions",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('memo-functions') is the complement of the relative clause, depending on 'implemented' with 'functions that constitute the parser'. Entity 2 ('parser') is the object of the preposition 'of', depending on 'time-complexity'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'implemented'.\"",
        "sdp_path_text": "- → as → implemented → is → complexity → of → parser",
        "sentence": "The parser's time-complexity is cubic if implemented as memo-functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('memo-functions') is the complement of the conditional clause, depending on 'if' with 'implemented'. Entity 2 ('parser') is the possessor, depending on the noun 'time-complexity' with 'The parser's'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the condition described in the sentence.\""
    },
    {
        "raw_sentence": "For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions , i.e. functions that memorize the results of previous invocations .",
        "ner_pair": [
            [
                "memo-functions",
                "Method"
            ],
            [
                "parser",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('memo-functions') is the complement of the noun 'functions', depending on 'functions' with the preposition 'as'. Entity 2 ('parser') is the object of the preposition 'of', depending on 'constitute' in the phrase 'that constitute the parser'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the clause describing the implementation of the functions that constitute the parser.\"",
        "sdp_path_text": "- → as → implemented → is → complexity → of → parser",
        "sentence": "The parser's time-complexity is cubic if implemented as memo-functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('memo-functions') is the complement of the conditional clause, depending on 'implemented'. Entity 2 ('parser') is the possessor, depending on 'time-complexity' with the possessive form 'parser's'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the conditional structure of the sentence.\""
    },
    {
        "raw_sentence": "Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest .",
        "ner_pair": [
            [
                "Memo-functions",
                "Method"
            ],
            [
                "parse forest",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Memo-functions') is the subject, depending on the verb 'facilitate'. Entity 2 ('parse forest') is the object of the preposition 'of', depending on 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun phrase 'compact representation of the parse forest'.\"",
        "sdp_path_text": "Memo → facilitate → way → construct → representation → of → forest",
        "sentence": "Memo-functions facilitate constructing a compact representation of the parse forest.",
        "sentence_llm_dp_info": "\"Entity 1 ('Memo-functions') is the subject, depending on the verb 'facilitate'. Entity 2 ('parse forest') is the object of the preposition 'of', depending on 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'facilitate' and the prepositional phrase 'of the parse forest'.\""
    },
    {
        "raw_sentence": "For LR -LRB- 0 -RRB- grammars , our algorithm is closely related to the recursive ascent parsers recently discovered by Kruse-man Aretz -LSB- 1 -RSB- and Roberts -LSB- 2 -RSB- .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "LR -LRB- 0 -RRB- grammars",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on 'is' as the main verb. Entity 2 ('LR -LRB- 0 -RRB- grammars') is the object of the preposition 'for', depending on 'For' at the beginning of the sentence. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause where the relationship between them is described through the predicate 'is closely related to the recursive ascent parsers'.\"",
        "sdp_path_text": "algorithm → related → For → grammars",
        "sentence": "Our algorithm is related to LR(0) grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'is'. Entity 2 ('LR(0) grammars') is the complement, depending on 'related' in the phrase 'related to LR(0) grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relational phrase 'is related to'.\""
    },
    {
        "raw_sentence": "For LR -LRB- 0 -RRB- grammars , our algorithm is closely related to the recursive ascent parsers recently discovered by Kruse-man Aretz -LSB- 1 -RSB- and Roberts -LSB- 2 -RSB- .",
        "ner_pair": [
            [
                "LR -LRB- 0 -RRB- grammars",
                "Method"
            ],
            [
                "recursive ascent parsers",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LR -LRB- 0 -RRB- grammars') is the subject complement, depending on the verb 'is' in the clause 'our algorithm is closely related to the recursive ascent parsers'. Entity 2 ('recursive ascent parsers') is the object of the preposition 'to', depending on 'related' in the same clause. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'is' and the preposition 'to'.\"",
        "sdp_path_text": "grammars → For → related → to → parsers",
        "sentence": "LR(0) grammars are closely related to recursive ascent parsers.",
        "sentence_llm_dp_info": "\"Entity 1 ('LR(0) grammars') is the subject, depending on the verb 'are'. Entity 2 ('recursive ascent parsers') is the object of the preposition 'to', depending on 'to' in the phrase 'to recursive ascent parsers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating their relationship.\""
    },
    {
        "raw_sentence": "For LR -LRB- 0 -RRB- grammars , our algorithm is closely related to the recursive ascent parsers recently discovered by Kruse-man Aretz -LSB- 1 -RSB- and Roberts -LSB- 2 -RSB- .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "recursive ascent parsers",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject complement, depending on 'is' with 'our'. Entity 2 ('recursive ascent parsers') is the object of the preposition 'to', depending on 'related' in the phrase 'related to the recursive ascent parsers'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is closely related to'.\"",
        "sdp_path_text": "algorithm → related → to → parsers",
        "sentence": "Our algorithm is related to recursive ascent parsers.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'is'. Entity 2 ('recursive ascent parsers') is the complement, depending on the preposition 'to', which itself depends on 'related'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "Extended CF grammars",
                "Method"
            ],
            [
                "regular expressions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Extended CF grammars') is the subject, depending on the verb 'can be parsed'. Entity 2 ('regular expressions') is part of the appositive modifier, depending on 'grammars' in the phrase 'grammars with regular expressions at the right hand side'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the appositive structure that describes a characteristic of Entity 1.\"",
        "sdp_path_text": "grammars → grammars → with → expressions",
        "sentence": "Extended CF grammars can be parsed with regular expressions.",
        "sentence_llm_dp_info": "\"Entity 1 ('Extended CF grammars') is the subject, depending on the verb 'can be parsed'. Entity 2 ('regular expressions') is the object, depending on the preposition 'with' in the phrase 'with regular expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'can be parsed' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "LR-parser",
                "Method"
            ],
            [
                "Extended CF grammars",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LR-parser') is the object of the preposition 'of', depending on 'modification'. Entity 2 ('Extended CF grammars') is the subject, depending on the modal verb 'can' and the verb 'be parsed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can be parsed with a simple modification of the LR-parser'.\"",
        "sdp_path_text": "- → of → modification → with → parsed → grammars → grammars",
        "sentence": "Extended CF grammars can be parsed with a modification of the LR-parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('LR-parser') is the object of the preposition 'of', depending on 'modification'. Entity 2 ('Extended CF grammars') is the subject, depending on the verb 'can be parsed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'parsed' and the prepositional phrase 'with a modification of the LR-parser'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "regular expressions",
                "OtherScientificTerm"
            ],
            [
                "grammars",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regular expressions') is the object of the preposition 'with', depending on 'grammars'. Entity 2 ('grammars') is the subject, depending on 'can be parsed'. There is a direct dependency between Entity 1 and Entity 2, as 'regular expressions' modifies 'grammars' in the phrase 'grammars with regular expressions at the right hand side'.\"",
        "sdp_path_text": "expressions → with → grammars → grammars",
        "sentence": "Regular expressions can be used with grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('regular expressions') is the subject, depending on the verb 'can be used'. Entity 2 ('grammars') is the object of the preposition 'with', depending on 'with' in the phrase 'with grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "grammars",
                "Method"
            ],
            [
                "LR-parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('grammars') is the subject, depending on the verb 'can be parsed'. Entity 2 ('LR-parser') is the object of the preposition 'with', depending on 'parsed' in the phrase 'with a simple modification of the LR-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'parsed' and the preposition 'with'.\"",
        "sdp_path_text": "grammars → grammars → parsed → with → modification → of → -",
        "sentence": "Extended grammars can be parsed with a modified LR-parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('grammars') is the subject, depending on the verb 'parsed'. Entity 2 ('LR-parser') is the object of the preposition 'with', depending on 'with' in the phrase 'with a modified LR-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'parsed' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "regular expressions",
                "OtherScientificTerm"
            ],
            [
                "LR-parser",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regular expressions') is the object of the preposition 'with', depending on the noun 'side'. Entity 2 ('LR-parser') is the object of the preposition 'with', depending on the verb 'parsed'. There is no direct dependency between Entity 1 and Entity 2; both are part of different prepositional phrases that modify the main clause.\"",
        "sdp_path_text": "expressions → with → grammars → parsed → with → modification → of → -",
        "sentence": "Regular expressions can be parsed with a modified LR-parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('regular expressions') is the subject, depending on the verb 'parsed'. Entity 2 ('LR-parser') is the object of the preposition 'with', depending on 'with' in the phrase 'with a modified LR-parser'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'parsed' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "regular expressions",
                "OtherScientificTerm"
            ],
            [
                "CF grammars",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regular expressions') is the object of the preposition 'with', depending on the noun 'grammars' within the appositive clause that modifies 'Extended CF grammars'. Entity 2 ('CF grammars') is the subject, depending on the verb 'can be parsed'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same appositive structure where 'regular expressions' describes a feature of 'CF grammars'.\"",
        "sdp_path_text": "expressions → with → grammars → grammars",
        "sentence": "Regular expressions can be used with CF grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('regular expressions') is the subject, depending on the verb 'can be used'. Entity 2 ('CF grammars') is the object of the preposition 'with', depending on 'with' in the phrase 'with CF grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Extended CF grammars -LRB- grammars with regular expressions at the right hand side -RRB- can be parsed with a simple modification of the LR-parser for normal CF grammars .",
        "ner_pair": [
            [
                "LR-parser",
                "Method"
            ],
            [
                "CF grammars",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LR-parser') is part of the object complement, depending on 'modification' with 'simple modification'. Entity 2 ('CF grammars') is the object of the preposition 'for', depending on 'for' in the phrase 'for normal CF grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what can be parsed with the modified LR-parser.\"",
        "sdp_path_text": "- → of → modification → with → parsed → grammars → grammars",
        "sentence": "Extended CF grammars can be parsed with a modified LR-parser.",
        "sentence_llm_dp_info": "\"Entity 1 ('LR-parser') is the object of the preposition 'with', depending on 'parsed'. Entity 2 ('CF grammars') is the subject, depending on the verb 'can be parsed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'parsed'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "theory",
                "Generic"
            ],
            [
                "discourse structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the preposition 'In' at the beginning of the sentence. Entity 2 ('discourse structure') is the subject complement, depending on the verb 'is composed of'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the clause that describes what the discourse structure is composed of, which is part of the information provided about the theory.\"",
        "sdp_path_text": "theory → In → composed → structure",
        "sentence": "In this theory, discourse structure is composed of components.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the preposition 'In' at the beginning of the sentence. Entity 2 ('discourse structure') is the subject of the clause, depending on the verb 'is composed of'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same sentence, where 'discourse structure' is described as part of what the 'theory' encompasses.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "theory",
                "Generic"
            ],
            [
                "components",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'is' in the clause 'discourse structure is composed of'. Entity 2 ('components') is the object of the preposition 'of', depending on 'composed' in the phrase 'composed of three separate but interrelated components'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the predicate 'is composed of'.\"",
        "sdp_path_text": "theory → In → composed → of → components",
        "sentence": "The theory is composed of components.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'is composed of'. Entity 2 ('components') is the object, depending on the verb 'is composed of'. There is a direct dependency between Entity 1 and Entity 2, as 'components' is directly linked to 'theory' through the verb 'is composed of'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "theory",
                "Generic"
            ],
            [
                "linguistic structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the copula 'is' in the clause 'discourse structure is composed of...'. Entity 2 ('linguistic structure') is the object of the preposition 'of', depending on 'components' in the phrase 'the structure of the sequence of utterances -LRB- called the linguistic structure -RRB-'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the description of the components of the discourse structure.\"",
        "sdp_path_text": "theory → In → composed → of → components → structure → called → structure",
        "sentence": "The theory is composed of components including the linguistic structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'is composed of'. Entity 2 ('linguistic structure') is part of the object complement, depending on 'including' within the phrase 'including the linguistic structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is composed of' and the preposition 'including'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "theory",
                "Generic"
            ],
            [
                "intentional structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'is' in the clause 'discourse structure is composed of'. Entity 2 ('intentional structure') is the object of the preposition 'of', depending on 'purposes' in the phrase 'a structure of purposes'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the larger structure described in the sentence.\"",
        "sdp_path_text": "theory → In → composed → of → components → structure → structure → called → structure",
        "sentence": "The theory is composed of components including the intentional structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'composed'. Entity 2 ('intentional structure') is part of the object of the preposition 'including', depending on 'including' in the phrase 'including the intentional structure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'including the intentional structure'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "theory",
                "Generic"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'is' in the clause 'discourse structure is composed of'. Entity 2 ('attentional state') is the object of the preposition 'of', depending on 'focus' in the phrase 'state of focus of attention'. There is no direct dependency between Entity 1 and Entity 2; they are part of a larger descriptive structure where 'theory' introduces the concept and 'attentional state' is one of the components described within that theory.\"",
        "sdp_path_text": "theory → In → composed → of → components → structure → structure → state → called → state",
        "sentence": "In this theory, the attentional state is one of the components of discourse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory') is the object of the preposition 'In', depending on the preposition 'In' in the phrase 'In this theory'. Entity 2 ('attentional state') is the subject complement, depending on the copula verb 'is' in the clause 'the attentional state is one of the components of discourse structure'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, with 'theory' setting the context for the statement about 'attentional state'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "components",
                "Generic"
            ],
            [
                "discourse structure",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('components') is the object, depending on the verb 'composed' with 'is'. Entity 2 ('discourse structure') is the subject, depending on the verb 'is' in the clause 'discourse structure is composed'. There is a direct dependency between Entity 1 and Entity 2, as 'components' is the object of the verb 'composed' which is part of the predicate describing 'discourse structure'.\"",
        "sdp_path_text": "components → of → composed → structure",
        "sentence": "Components of discourse structure are composed of the structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('components') is the subject, depending on the verb 'are composed'. Entity 2 ('discourse structure') is the object of the preposition 'of', depending on 'of' in the phrase 'of discourse structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "discourse structure",
                "OtherScientificTerm"
            ],
            [
                "linguistic structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse structure') is the subject, depending on the verb 'is composed of'. Entity 2 ('linguistic structure') is the object of the preposition 'of', part of the list of components that 'discourse structure' is composed of. There is no direct dependency between Entity 1 and Entity 2; they are connected through the list of components mentioned in the sentence.\"",
        "sdp_path_text": "structure → composed → of → components → structure → called → structure",
        "sentence": "Discourse structure is composed of components including the linguistic structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse structure') is the subject, depending on the verb 'is composed of'. Entity 2 ('linguistic structure') is part of the list of objects, depending on 'including' within the prepositional phrase 'including the linguistic structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating that the linguistic structure is one of the components included in the discourse structure.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "discourse structure",
                "OtherScientificTerm"
            ],
            [
                "intentional structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse structure') is the subject, depending on the verb 'is composed of'. Entity 2 ('intentional structure') is the object of the preposition 'of', depending on 'purposes' within the list of components that compose the 'discourse structure'. There is no direct dependency between Entity 1 and Entity 2; they are part of the same list of components described in the sentence.\"",
        "sdp_path_text": "structure → composed → of → components → structure → structure → called → structure",
        "sentence": "Discourse structure is composed of components including the intentional structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse structure') is the subject, depending on the verb 'is composed of'. Entity 2 ('intentional structure') is part of the object, depending on the preposition 'including' which modifies 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'including the intentional structure'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "discourse structure",
                "OtherScientificTerm"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse structure') is the subject, depending on the verb 'is' in the clause 'discourse structure is composed of'. Entity 2 ('attentional state') is the object, depending on 'called' within the list of components. There is no direct dependency between Entity 1 and Entity 2; they are part of a larger structure where Entity 1 is described as being composed of multiple parts, one of which is Entity 2.\"",
        "sdp_path_text": "structure → composed → of → components → structure → structure → state → called → state",
        "sentence": "Discourse structure is composed of components including the attentional state.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse structure') is the subject, depending on the verb 'is composed of'. Entity 2 ('attentional state') is part of a list of objects, depending on 'including' which modifies 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relationship established by 'is composed of' and 'including'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "linguistic structure",
                "OtherScientificTerm"
            ],
            [
                "components",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the appositive, depending on the noun 'components' through the preposition 'of'. Entity 2 ('components') is the object, depending on the verb 'composed' with 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the appositive relationship where 'linguistic structure' describes one of the 'components'.\"",
        "sdp_path_text": "structure → called → structure → components",
        "sentence": "The linguistic structure is one of the components.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the subject, depending on the verb 'is'. Entity 2 ('components') is the object of the preposition 'of', depending on 'one' in the phrase 'one of the components'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "intentional structure",
                "OtherScientificTerm"
            ],
            [
                "components",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intentional structure') is the object of the preposition 'of', depending on 'purposes'. It is part of a list of items that are described as 'components'. Entity 2 ('components') is the object, depending on the verb 'composed' with 'discourse structure'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 1 is one of the items listed as being part of Entity 2.\"",
        "sdp_path_text": "structure → called → structure → structure → components",
        "sentence": "The intentional structure is one of the components of discourse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('intentional structure') is the subject complement, depending on 'is' with 'The'. Entity 2 ('components') is the object of the preposition 'of', depending on 'of' in the phrase 'of discourse structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the components of discourse structure'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            [
                "components",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('attentional state') is the subject complement, depending on 'called' within the clause describing one of the components. Entity 2 ('components') is the object, depending on the verb 'composed' with 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same complex sentence where Entity 1 is listed as one of the three components described by Entity 2.\"",
        "sdp_path_text": "state → called → state → structure → structure → components",
        "sentence": "The attentional state is one of the components of discourse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('attentional state') is the subject complement, depending on the copula 'is'. Entity 2 ('components') is the object of the preposition 'of', depending on 'of' in the phrase 'of discourse structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the components of discourse structure'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "linguistic structure",
                "OtherScientificTerm"
            ],
            [
                "intentional structure",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the appositive, depending on 'structure' within the phrase 'the structure of the sequence of utterances'. Entity 2 ('intentional structure') is also an appositive, depending on 'structure' within the phrase 'a structure of purposes'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of components that compose the discourse structure.\"",
        "sdp_path_text": "structure → called → structure → structure → called → structure",
        "sentence": "The linguistic structure and the intentional structure are components of discourse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the subject, depending on the verb 'are'. Entity 2 ('intentional structure') is also a subject, depending on the conjunction 'and' which connects it to 'linguistic structure'. There is no direct dependency between Entity 1 and Entity 2; both are subjects in a compound subject linked by 'and'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "linguistic structure",
                "OtherScientificTerm"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the appositive, depending on the noun 'components'. Entity 2 ('attentional state') is also an appositive, depending on the noun 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of components described in the sentence.\"",
        "sdp_path_text": "structure → called → structure → structure → state → called → state",
        "sentence": "The linguistic structure and attentional state are components of discourse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the first conjunct, depending on 'are' as part of the compound subject. Entity 2 ('attentional state') is the second conjunct, also depending on 'are' as part of the compound subject. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same compound subject connected by 'and'.\""
    },
    {
        "raw_sentence": "In this theory , discourse structure is composed of three separate but interrelated components : the structure of the sequence of utterances -LRB- called the linguistic structure -RRB- , a structure of purposes -LRB- called the intentional structure -RRB- , and the state of focus of attention -LRB- called the attentional state -RRB- .",
        "ner_pair": [
            [
                "intentional structure",
                "OtherScientificTerm"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intentional structure') is the object of the preposition 'of', depending on 'purposes'. Entity 2 ('attentional state') is the object of the preposition 'of', depending on 'focus of attention'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a list of components that compose the discourse structure.\"",
        "sdp_path_text": "structure → called → structure → state → called → state",
        "sentence": "The intentional structure and the attentional state are components of discourse structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('intentional structure') is the subject, depending on the verb 'are'. Entity 2 ('attentional state') is coordinated with 'intentional structure' through the conjunction 'and', also depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in a coordinated structure.\""
    },
    {
        "raw_sentence": "The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate .",
        "ner_pair": [
            [
                "linguistic structure",
                "OtherScientificTerm"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the subject, depending on the verb 'consists'. Entity 2 ('discourse') is the object of the preposition 'of', depending on 'segments' in the phrase 'segments of the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of segments of the discourse'.\"",
        "sdp_path_text": "structure → consists → of → segments → of → discourse",
        "sentence": "The linguistic structure consists of segments of the discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic structure') is the subject, depending on the verb 'consists'. Entity 2 ('discourse') is the object of the preposition 'of', depending on 'segments'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of the discourse'.\""
    },
    {
        "raw_sentence": "The intentional structure captures the discourse-relevant purposes , expressed in each of the linguistic segments as well as relationships among them .",
        "ner_pair": [
            [
                "intentional structure",
                "OtherScientificTerm"
            ],
            [
                "discourse-relevant purposes",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intentional structure') is the subject, depending on the verb 'captures'. Entity 2 ('discourse-relevant purposes') is the object, depending on 'captures' with 'intentional structure'. There is a direct dependency between Entity 1 and Entity 2, as 'intentional structure' captures 'discourse-relevant purposes'.\"",
        "sdp_path_text": "structure → captures → purposes",
        "sentence": "The intentional structure captures discourse-relevant purposes.",
        "sentence_llm_dp_info": "\"Entity 1 ('intentional structure') is the subject, depending on the verb 'captures'. Entity 2 ('discourse-relevant purposes') is the object, depending on the verb 'captures'. There is a direct dependency between Entity 1 and Entity 2, as 'intentional structure' captures 'discourse-relevant purposes'.\""
    },
    {
        "raw_sentence": "The attentional state is an abstraction of the focus of attention of the participants as the discourse unfolds .",
        "ner_pair": [
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('attentional state') is the subject, depending on the verb 'is'. Entity 2 ('discourse') is the object of the preposition 'as', depending on 'unfolds' in the phrase 'as the discourse unfolds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'as the discourse unfolds'.\"",
        "sdp_path_text": "state → is → unfolds → discourse",
        "sentence": "The attentional state is an abstraction of the focus as the discourse unfolds.",
        "sentence_llm_dp_info": "\"Entity 1 ('attentional state') is the subject, depending on the verb 'is'. Entity 2 ('discourse') is the object of the preposition 'as', depending on 'unfolds' in the phrase 'as the discourse unfolds'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the description of how the 'attentional state' is an abstraction that changes as the 'discourse' progresses.\""
    },
    {
        "raw_sentence": "The attentional state , being dynamic , records the objects , properties , and relations that are salient at each point of the discourse .",
        "ner_pair": [
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('attentional state') is the subject, depending on the verb 'records'. Entity 2 ('discourse') is the object of the preposition 'of', depending on 'point'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'at each point of the discourse'.\"",
        "sdp_path_text": "state → records → objects → are → at → point → of → discourse",
        "sentence": "The attentional state records objects salient at points of the discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('attentional state') is the subject, depending on the verb 'records'. Entity 2 ('discourse') is the object of the preposition 'of', depending on 'points'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'at points of the discourse'.\""
    },
    {
        "raw_sentence": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases , referring expressions , and interruptions .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "discourse phenomena",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of a list, depending on 'of' in the phrase 'of such discourse phenomena as cue phrases'. Entity 2 ('discourse phenomena') is the object of the preposition 'of', depending on 'explanation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of' and the structure of the list.\"",
        "sdp_path_text": "phrases → as → phenomena",
        "sentence": "Cue phrases are a type of discourse phenomena.",
        "sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is the subject, depending on the copula 'are'. Entity 2 ('discourse phenomena') is the predicate nominative, also depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, as they are linked through the copula 'are' to form a complete predicate.\""
    },
    {
        "raw_sentence": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases , referring expressions , and interruptions .",
        "ner_pair": [
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            [
                "discourse phenomena",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('referring expressions') is part of a list, depending on the conjunction 'and' within the prepositional phrase 'of such discourse phenomena'. Entity 2 ('discourse phenomena') is the object of the preposition 'of', depending on 'explanation'. There is no direct dependency between Entity 1 and Entity 2; both are part of the same prepositional phrase, connected through the preposition 'of'.\"",
        "sdp_path_text": "expressions → phrases → as → phenomena",
        "sentence": "Referring expressions are part of discourse phenomena.",
        "sentence_llm_dp_info": "\"Entity 1 ('referring expressions') is the subject, depending on the verb 'are'. Entity 2 ('discourse phenomena') is the complement, depending on the verb 'are' in the phrase 'are part of discourse phenomena'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases , referring expressions , and interruptions .",
        "ner_pair": [
            [
                "interruptions",
                "OtherScientificTerm"
            ],
            [
                "discourse phenomena",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('interruptions') is part of a coordination, depending on 'phenomena' with the conjunction 'and'. Entity 2 ('discourse phenomena') is the object of the preposition 'of', depending on 'explanation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the list that defines 'discourse phenomena'.\"",
        "sdp_path_text": "interruptions → expressions → phrases → as → phenomena",
        "sentence": "Interruptions are considered as discourse phenomena.",
        "sentence_llm_dp_info": "\"Entity 1 ('interruptions') is the subject, depending on the verb 'are considered'. Entity 2 ('discourse phenomena') is the complement, depending on 'as' in the phrase 'as discourse phenomena'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are considered' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases , referring expressions , and interruptions .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of a list, depending on the preposition 'of' with 'explanation'. Entity 2 ('referring expressions') is also part of the same list, depending on the conjunction 'and' with 'cue phrases'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list that serves as the object of the preposition 'of'.\"",
        "sdp_path_text": "phrases → expressions",
        "sentence": "Cue phrases and referring expressions are discourse phenomena.",
        "sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is the subject, depending on the copula 'are'. Entity 2 ('referring expressions') is coordinated with 'cue phrases' as part of the compound subject, also depending on the copula 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same subject in the sentence.\""
    },
    {
        "raw_sentence": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases , referring expressions , and interruptions .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "interruptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of a list, depending on the preposition 'of' within the phrase 'explanation of such discourse phenomena as cue phrases'. Entity 2 ('interruptions') is also part of the same list, depending on the conjunction 'and' which links it to the other items in the list. There is no direct dependency between Entity 1 and Entity 2; they are both elements in a list of examples of discourse phenomena.\"",
        "sdp_path_text": "phrases → expressions → interruptions",
        "sentence": "Cue phrases and interruptions are examples of discourse phenomena.",
        "sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is the subject, depending on the copula 'are' as part of the subject-predicate structure. Entity 2 ('interruptions') is a conjunct, coordinated with 'cue phrases' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are connected as parts of a coordinated subject.\""
    },
    {
        "raw_sentence": "The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases , referring expressions , and interruptions .",
        "ner_pair": [
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            [
                "interruptions",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('referring expressions') is part of a list, depending on the preposition 'as', which is part of the prepositional phrase 'of such discourse phenomena as cue phrases, referring expressions, and interruptions'. Entity 2 ('interruptions') is also part of the same list, depending on the conjunction 'and' that links it to the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list of examples of discourse phenomena.\"",
        "sdp_path_text": "expressions → interruptions",
        "sentence": "Referring expressions and interruptions are discourse phenomena.",
        "sentence_llm_dp_info": "\"Entity 1 ('referring expressions') is the first conjunct, depending on the conjunction 'and' with 'interruptions'. Entity 2 ('interruptions') is the second conjunct, also depending on the conjunction 'and' with 'referring expressions'. Both entities are the subjects of the sentence, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "The theory of attention , intention , and aggregation of utterances is illustrated in the paper with a number of example discourses .",
        "ner_pair": [
            [
                "theory of attention , intention , and aggregation of utterances",
                "Method"
            ],
            [
                "discourses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory of attention, intention, and aggregation of utterances') is the subject, depending on the verb 'illustrated'. Entity 2 ('discourses') is the object of the preposition 'with', depending on 'with' in the phrase 'with a number of example discourses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'illustrated' and the preposition 'with'.\"",
        "sdp_path_text": "theory → illustrated → with → number → of → discourses",
        "sentence": "The theory of attention, intention, and aggregation of utterances is illustrated with discourses.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory of attention, intention, and aggregation of utterances') is the subject, depending on the verb 'illustrated'. Entity 2 ('discourses') is the object of the preposition 'with', depending on 'with' in the phrase 'with discourses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'illustrated' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Various properties of discourse are described , and explanations for the behaviour of cue phrases , referring expressions , and interruptions are explored .",
        "ner_pair": [
            [
                "discourse",
                "OtherScientificTerm"
            ],
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse') is the object of the preposition 'of', depending on 'properties'. Entity 2 ('cue phrases') is part of a list of items, depending on the verb 'explored' through the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the exploration of aspects of discourse.\"",
        "sdp_path_text": "discourse → of → properties → described → explored → explanations → for → behaviour → of → phrases",
        "sentence": "Properties of discourse, including the behavior of cue phrases, are explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse') is part of the noun phrase 'Properties of discourse', where it depends on 'Properties' as a prepositional object of 'of'. Entity 2 ('cue phrases') is the object of the preposition 'of' within the prepositional phrase 'of cue phrases', which modifies 'behavior'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of different prepositional phrases that describe what is being explored.\""
    },
    {
        "raw_sentence": "Various properties of discourse are described , and explanations for the behaviour of cue phrases , referring expressions , and interruptions are explored .",
        "ner_pair": [
            [
                "discourse",
                "OtherScientificTerm"
            ],
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse') is the object of the preposition 'of', depending on 'properties'. Entity 2 ('referring expressions') is part of a list of items, depending on the verb 'explored'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "discourse → of → properties → described → explored → explanations → for → behaviour → of → phrases → expressions",
        "sentence": "Properties of discourse, including the behavior of referring expressions, are explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse') is part of the noun phrase 'Properties of discourse', where it is the object of the preposition 'of', depending on 'Properties'. Entity 2 ('referring expressions') is the object of the preposition 'of' within the prepositional phrase 'of referring expressions', which modifies 'behavior'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger noun phrase that serves as the subject of the sentence.\""
    },
    {
        "raw_sentence": "Various properties of discourse are described , and explanations for the behaviour of cue phrases , referring expressions , and interruptions are explored .",
        "ner_pair": [
            [
                "discourse",
                "OtherScientificTerm"
            ],
            [
                "interruptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse') is the object of the preposition 'of', depending on 'properties'. Entity 2 ('interruptions') is part of a coordination, depending on 'and' in the phrase 'cue phrases, referring expressions, and interruptions'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "discourse → of → properties → described → explored → explanations → for → behaviour → of → phrases → expressions → interruptions",
        "sentence": "Explanations for the behavior of interruptions in discourse properties are explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse') is part of a compound noun, depending on 'properties' with 'discourse properties'. Entity 2 ('interruptions') is the object of the preposition 'of', depending on 'behavior'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger noun phrase 'the behavior of interruptions in discourse properties'.\""
    },
    {
        "raw_sentence": "Various properties of discourse are described , and explanations for the behaviour of cue phrases , referring expressions , and interruptions are explored .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of a list, depending on 'of' in the phrase 'of discourse'. Entity 2 ('referring expressions') is also part of the same list, depending on 'and' which connects it to 'cue phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements in a list of items being discussed in the sentence.\"",
        "sdp_path_text": "phrases → expressions",
        "sentence": "Explanations for the behavior of cue phrases and referring expressions are explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of a conjunction, depending on 'and' with 'referring expressions'. Entity 2 ('referring expressions') is also part of a conjunction, depending on 'and' with 'cue phrases'. Both entities are objects of the preposition 'of', which modifies the noun 'behavior'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "Various properties of discourse are described , and explanations for the behaviour of cue phrases , referring expressions , and interruptions are explored .",
        "ner_pair": [
            [
                "cue phrases",
                "OtherScientificTerm"
            ],
            [
                "interruptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of a list, depending on the preposition 'of' within the phrase 'for the behaviour of cue phrases'. Entity 2 ('interruptions') is also part of the same list, depending on the conjunction 'and' which links it with 'referring expressions' and 'cue phrases'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a list that serves as the object of the preposition 'of' in the phrase 'for the behaviour of...'\"",
        "sdp_path_text": "phrases → expressions → interruptions",
        "sentence": "Explanations for the behavior of cue phrases and interruptions are explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('cue phrases') is part of the compound noun phrase, depending on 'behavior' with the preposition 'of' in the phrase 'behavior of cue phrases'. Entity 2 ('interruptions') is also part of the compound noun phrase, depending on 'behavior' with the conjunction 'and' in the phrase 'cue phrases and interruptions'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements in the same noun phrase.\""
    },
    {
        "raw_sentence": "Various properties of discourse are described , and explanations for the behaviour of cue phrases , referring expressions , and interruptions are explored .",
        "ner_pair": [
            [
                "referring expressions",
                "OtherScientificTerm"
            ],
            [
                "interruptions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('referring expressions') is part of a list, depending on the conjunction 'and' with 'cue phrases' and 'interruptions'. Entity 2 ('interruptions') is also part of the same list, depending on the conjunction 'and' with 'cue phrases' and 'referring expressions'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a list that serves as the object of the verb 'explored'.\"",
        "sdp_path_text": "expressions → interruptions",
        "sentence": "The behavior of referring expressions and interruptions is explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('referring expressions') is the object of the preposition 'of', depending on 'behavior'. Entity 2 ('interruptions') is coordinated with 'referring expressions' through the conjunction 'and', both being objects of the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; they are part of a coordinate structure under the preposition 'of'.\""
    },
    {
        "raw_sentence": "This theory provides a framework for describing the processing of utterances in a discourse .",
        "ner_pair": [
            [
                "theory",
                "Generic"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'provides'. Entity 2 ('discourse') is the object of the preposition 'in', depending on 'in' in the phrase 'in a discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that specifies the context in which the theory's framework is applied.\"",
        "sdp_path_text": "theory → provides → framework → for → describing → processing → in → discourse",
        "sentence": "This theory provides a framework for describing the processing in a discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('theory') is the subject, depending on the verb 'provides'. Entity 2 ('discourse') is part of the prepositional phrase 'in a discourse', which modifies 'processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the prepositional phrase 'for describing the processing in a discourse'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "Discourse processing",
                "Method"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'requires'. Entity 2 ('discourse') is the object, appearing in multiple phrases such as 'utterances of the discourse', 'intentions expressed in the discourse', and 'relationships among intentions', and it also appears in the phrase 'tracking the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the various actions and aspects described in the sentence.\"",
        "sdp_path_text": "processing → Discourse",
        "sentence": "Discourse processing involves tracking the discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'involves'. Entity 2 ('discourse') is the object, depending on 'tracking' in the phrase 'tracking the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' and the gerund 'tracking'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "Discourse processing",
                "Method"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'requires'. Entity 2 ('discourse') is the object, appearing multiple times in the sentence, and it depends on different verbs such as 'aggregate', 'expressed', and 'tracking'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 2 is a key element in the clauses that describe what Entity 1 requires.\"",
        "sdp_path_text": "processing → Discourse",
        "sentence": "Discourse processing involves tracking the discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'involves'. Entity 2 ('discourse') is the object, depending on 'tracking' in the phrase 'tracking the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' and the gerund 'tracking'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "Discourse processing",
                "Method"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'requires'. Entity 2 ('discourse') is the object, appearing multiple times within the sentence, each time depending on different verbs or prepositions such as 'in', 'of', and 'through'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the various processes described in the sentence.\"",
        "sdp_path_text": "processing → Discourse",
        "sentence": "Discourse processing involves tracking the discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'involves'. Entity 2 ('discourse') is the object of the preposition 'the', depending on 'tracking' in the phrase 'tracking the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involves' and the action 'tracking'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "Discourse processing",
                "Method"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'requires'. Entity 2 ('attentional state') is the object of the preposition 'with', depending on 'mechanisms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the series of actions and objects described in the sentence, ultimately relating to the broader context of discourse processing requirements.\"",
        "sdp_path_text": "processing → requires → recognizing → recognizing → tracking → through → operation → of → mechanisms → associated → with → state",
        "sentence": "Discourse processing requires recognizing and tracking through the mechanisms associated with attentional state.",
        "sentence_llm_dp_info": "\"Entity 1 ('Discourse processing') is the subject, depending on the verb 'requires'. Entity 2 ('attentional state') is the object, depending on 'associated' with 'mechanisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires' and the prepositional phrase 'through the mechanisms associated with attentional state'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "discourse",
                "OtherScientificTerm"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse') is the object of the verb 'processing', depending on 'requires' with 'Discourse processing'. It also appears as the object of the preposition 'of' in 'operation of the mechanisms associated with'. Entity 2 ('attentional state') is the object of the preposition 'with', depending on 'associated with' in the phrase 'mechanisms associated with attentional state'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'of the mechanisms associated with'.\"",
        "sdp_path_text": "Discourse → processing → requires → recognizing → recognizing → tracking → through → operation → of → mechanisms → associated → with → state",
        "sentence": "Discourse processing requires recognizing and tracking through the operation of mechanisms associated with attentional state.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse') is part of the compound noun 'discourse processing', which is the subject, depending on the verb 'requires'. Entity 2 ('attentional state') is the object of the preposition 'with', depending on 'associated' in the phrase 'associated with attentional state'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of dependencies involving 'processing', 'mechanisms', and 'associated'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "discourse",
                "OtherScientificTerm"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse') is the object of the verbs 'requires', 'aggregate', 'expressed', and 'tracking'. It is central to the actions described in the sentence. Entity 2 ('attentional state') is the object of the preposition 'with', which modifies 'mechanisms'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same complex structure where 'discourse' is processed through mechanisms related to 'attentional state'.\"",
        "sdp_path_text": "Discourse → processing → requires → recognizing → recognizing → tracking → through → operation → of → mechanisms → associated → with → state",
        "sentence": "Discourse processing requires recognizing and tracking through the operation of mechanisms associated with attentional state.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse') is part of the compound noun 'discourse processing', which is the subject, depending on the verb 'requires'. Entity 2 ('attentional state') is the object of the preposition 'with', depending on 'associated' in the phrase 'associated with attentional state'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'requires' and the prepositional phrase 'associated with attentional state'.\""
    },
    {
        "raw_sentence": "Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions , and tracking the discourse through the operation of the mechanisms associated with attentional state .",
        "ner_pair": [
            [
                "discourse",
                "OtherScientificTerm"
            ],
            [
                "attentional state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discourse') is the object of the verbs 'requires', 'aggregate', 'expressed', and 'tracking', showing its role in various processes described in the sentence. Entity 2 ('attentional state') is the object of the preposition 'with', which modifies 'mechanisms'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the broader context of discourse processing, where 'discourse' is central to the operations that involve 'attentional state'.\"",
        "sdp_path_text": "Discourse → processing → requires → recognizing → recognizing → tracking → through → operation → of → mechanisms → associated → with → state",
        "sentence": "Discourse processing requires recognizing and tracking through the mechanisms associated with attentional state.",
        "sentence_llm_dp_info": "\"Entity 1 ('discourse') is part of the compound noun 'discourse processing', which is the subject, depending on the verb 'requires'. Entity 2 ('attentional state') is the object of the preposition 'with', depending on 'mechanisms'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'requires' and the prepositional phrase 'through the mechanisms associated with attentional state'.\""
    },
    {
        "raw_sentence": "This processing description specifies in these recognition tasks the role of information from the discourse and from the participants ' knowledge of the domain .",
        "ner_pair": [
            [
                "processing",
                "Generic"
            ],
            [
                "recognition tasks",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('processing') is part of the compound noun 'processing description', which acts as the subject, depending on the verb 'specifies'. Entity 2 ('recognition tasks') is the object of the preposition 'in', depending on 'in' in the phrase 'in these recognition tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'processing description' specifies aspects within 'recognition tasks'.\"",
        "sdp_path_text": "processing → description → specifies → in → tasks",
        "sentence": "Processing description specifies the role in recognition tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('processing') is part of the compound noun 'processing description', which is the subject, depending on the verb 'specifies'. Entity 2 ('recognition tasks') is the object, depending on the preposition 'in' within the prepositional phrase 'in recognition tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'processing description' specifies the role in 'recognition tasks'.\""
    },
    {
        "raw_sentence": "This processing description specifies in these recognition tasks the role of information from the discourse and from the participants ' knowledge of the domain .",
        "ner_pair": [
            [
                "processing",
                "Generic"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('processing') is part of the compound noun 'processing description', which acts as the subject, depending on the verb 'specifies'. Entity 2 ('discourse') is the object of the preposition 'from', depending on the preposition 'from' in the phrase 'from the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'specifies' and the prepositional phrase that describes the sources of information.\"",
        "sdp_path_text": "processing → description → specifies → role → of → information → from → discourse",
        "sentence": "Processing description specifies the role of information from the discourse.",
        "sentence_llm_dp_info": "\"Entity 1 ('processing') is part of the compound noun 'processing description', which acts as the subject, depending on the verb 'specifies'. Entity 2 ('discourse') is the object of the preposition 'from', depending on 'from' in the phrase 'from the discourse'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'processing description' specifies something about the information derived from the 'discourse'.\""
    },
    {
        "raw_sentence": "This processing description specifies in these recognition tasks the role of information from the discourse and from the participants ' knowledge of the domain .",
        "ner_pair": [
            [
                "recognition tasks",
                "Task"
            ],
            [
                "discourse",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition tasks') is the object of the preposition 'in', depending on 'specifies' with 'This processing description'. Entity 2 ('discourse') is part of the prepositional phrase 'from the discourse', depending on 'from'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the specification of roles in the context of the processing description.\"",
        "sdp_path_text": "tasks → in → specifies → role → of → information → from → discourse",
        "sentence": "The processing description specifies the role of information from the discourse in recognition tasks.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition tasks') is the object, depending on 'in' within the prepositional phrase 'in recognition tasks', which modifies the noun 'role'. Entity 2 ('discourse') is the object of the preposition 'from', depending on 'from' in the phrase 'from the discourse'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrases that modify different parts of the sentence.\""
    },
    {
        "raw_sentence": "We examine the relationship between the two grammatical formalisms : Tree Adjoining Grammars and Head Grammars .",
        "ner_pair": [
            [
                "Tree Adjoining Grammars",
                "Method"
            ],
            [
                "grammatical formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Tree Adjoining Grammars') is one of the objects of the preposition 'between', depending on 'between' in the phrase 'between the two grammatical formalisms'. Entity 2 ('grammatical formalisms') is the object of the preposition 'between', serving as the head noun of the prepositional phrase 'between the two grammatical formalisms'. There is no direct dependency between Entity 1 and Entity 2; both are part of the same prepositional phrase, where 'grammatical formalisms' specifies the category to which 'Tree Adjoining Grammars' belongs.\"",
        "sdp_path_text": "Grammars → formalisms",
        "sentence": "Tree Adjoining Grammars are grammatical formalisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('Tree Adjoining Grammars') is the subject, depending on the verb 'are'. Entity 2 ('grammatical formalisms') is the predicate nominative, depending on 'are' in the sentence. There is a direct dependency between Entity 1 and Entity 2, as 'Tree Adjoining Grammars' is equated to 'grammatical formalisms' through the linking verb 'are'.\""
    },
    {
        "raw_sentence": "We examine the relationship between the two grammatical formalisms : Tree Adjoining Grammars and Head Grammars .",
        "ner_pair": [
            [
                "Head Grammars",
                "Method"
            ],
            [
                "grammatical formalisms",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Head Grammars') is part of a coordination, depending on the conjunction 'and' with 'Tree Adjoining Grammars'. Entity 2 ('grammatical formalisms') is the object of the preposition 'between', depending on 'relationship'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'between the two grammatical formalisms'.\"",
        "sdp_path_text": "Grammars → Grammars → formalisms",
        "sentence": "Head Grammars are grammatical formalisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('Head Grammars') is the subject, depending on the copula 'are'. Entity 2 ('grammatical formalisms') is the predicate nominal, depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, linked by the copula 'are'.\""
    },
    {
        "raw_sentence": "We examine the relationship between the two grammatical formalisms : Tree Adjoining Grammars and Head Grammars .",
        "ner_pair": [
            [
                "Tree Adjoining Grammars",
                "Method"
            ],
            [
                "Head Grammars",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Tree Adjoining Grammars') is part of a coordination, depending on 'between' in the phrase 'between the two grammatical formalisms'. Entity 2 ('Head Grammars') is also part of a coordination, depending on 'and' in the phrase 'Tree Adjoining Grammars and Head Grammars'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same prepositional phrase.\"",
        "sdp_path_text": "Grammars → Grammars",
        "sentence": "We examine the relationship between Tree Adjoining Grammars and Head Grammars.",
        "sentence_llm_dp_info": "\"Entity 1 ('Tree Adjoining Grammars') is the first element in a coordination, depending on 'between' with 'relationship'. Entity 2 ('Head Grammars') is the second element in the coordination, also depending on 'between' with 'relationship'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the coordination introduced by 'between'.\""
    },
    {
        "raw_sentence": "We then turn to a discussion comparing the linguistic expressiveness of the two formalisms .",
        "ner_pair": [
            [
                "linguistic expressiveness",
                "OtherScientificTerm"
            ],
            [
                "formalisms",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic expressiveness') is the object of the preposition 'comparing', depending on 'comparing' in the phrase 'comparing the linguistic expressiveness'. Entity 2 ('formalisms') is the object of the preposition 'of', depending on 'expressiveness' in the phrase 'expressiveness of the two formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional structure 'comparing the linguistic expressiveness of the two formalisms'.\"",
        "sdp_path_text": "expressiveness → of → formalisms",
        "sentence": "We discuss the linguistic expressiveness of the formalisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic expressiveness') is the object of the preposition 'of', depending on 'discuss' with 'We'. Entity 2 ('formalisms') is the object of the preposition 'of', depending on 'of' in the phrase 'of the formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'the linguistic expressiveness of the formalisms'.\""
    },
    {
        "raw_sentence": "We provide a unified account of sentence-level and text-level anaphora within the framework of a dependency-based grammar model .",
        "ner_pair": [
            [
                "dependency-based grammar model",
                "Method"
            ],
            [
                "sentence-level and text-level anaphora",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency-based grammar model') is the object of the preposition 'of', depending on 'framework'. Entity 2 ('sentence-level and text-level anaphora') is the object of the preposition 'of', depending on 'account'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify different parts of the sentence.\"",
        "sdp_path_text": "model → of → framework → within → provide → account → of → anaphora",
        "sentence": "A unified account of sentence-level and text-level anaphora is provided within the framework of a dependency-based grammar model.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency-based grammar model') is the object of the preposition 'of', depending on 'framework'. Entity 2 ('sentence-level and text-level anaphora') is the object of the preposition 'of', depending on 'account'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause through different prepositional phrases.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "Criteria",
                "Generic"
            ],
            [
                "anaphora resolution within sentence boundaries",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'rephrase'. Entity 2 ('anaphora resolution within sentence boundaries') is part of the prepositional phrase 'for anaphora resolution within sentence boundaries', functioning as a modifier, and depends on 'Criteria'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 modifies Entity 1 in the prepositional phrase 'for anaphora resolution within sentence boundaries'.\"",
        "sdp_path_text": "Criteria → for → resolution",
        "sentence": "Criteria for anaphora resolution within sentence boundaries are discussed.",
        "sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'are discussed'. Entity 2 ('anaphora resolution within sentence boundaries') is the complement of the preposition 'for', depending on 'for' in the phrase 'for anaphora resolution within sentence boundaries'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "GB 's binding theory",
                "Method"
            ],
            [
                "Criteria",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase'. Entity 2 ('Criteria') is the subject, depending on 'rephrase' with 'rephrase major concepts'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'rephrase'.\"",
        "sdp_path_text": "theory → from → rephrase → Criteria",
        "sentence": "Criteria rephrase concepts from GB's binding theory.",
        "sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase'. Entity 2 ('Criteria') is the subject, depending on the verb 'rephrase'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'rephrase' where 'Criteria' is the agent performing the action and 'GB's binding theory' is the source of the concepts being rephrased.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "Criteria",
                "Generic"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'rephrase'. Entity 2 ('those') is a demonstrative pronoun, depending on the conjunction 'while' and referring back to 'Criteria'. There is no direct dependency between Entity 1 and Entity 2, but they are semantically related as 'those' refers back to 'Criteria' in the context of different conditions or aspects being discussed.\"",
        "sdp_path_text": "Criteria → rephrase → incorporate → those",
        "sentence": "Criteria rephrase and incorporate those.",
        "sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'rephrase'. Entity 2 ('those') is the object, depending on the verb 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the actions described by the verbs 'rephrase' and 'incorporate'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "Criteria",
                "Generic"
            ],
            [
                "text-level anaphora",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'rephrase'. Entity 2 ('text-level anaphora') is part of a nominal modifier, depending on 'those' in the phrase 'those for text-level anaphora'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the structure describing different criteria for anaphora resolution.\"",
        "sdp_path_text": "Criteria → rephrase → incorporate → those → for → anaphora",
        "sentence": "Criteria for text-level anaphora incorporate an adapted focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'incorporate'. Entity 2 ('text-level anaphora') is the object of the preposition 'for', depending on 'for' in the phrase 'for text-level anaphora'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "Criteria",
                "Generic"
            ],
            [
                "Grosz-Sidner-style focus model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'rephrase'. Entity 2 ('Grosz-Sidner-style focus model') is the object of the preposition 'of', depending on 'version'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause structure where 'Criteria' influences the overall context in which the 'Grosz-Sidner-style focus model' is mentioned.\"",
        "sdp_path_text": "Criteria → rephrase → incorporate → version → of → model",
        "sentence": "Criteria incorporate a Grosz-Sidner-style focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('Criteria') is the subject, depending on the verb 'incorporate'. Entity 2 ('Grosz-Sidner-style focus model') is the object, depending on 'incorporate' with 'Criteria'. There is a direct dependency between Entity 1 and Entity 2, as 'Grosz-Sidner-style focus model' is directly incorporated by 'Criteria'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "anaphora resolution within sentence boundaries",
                "Task"
            ],
            [
                "GB 's binding theory",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the object of the preposition 'for', depending on 'Criteria'. Entity 2 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the criteria rephrase and are related through the verb 'rephrase'.\"",
        "sdp_path_text": "resolution → for → Criteria → rephrase → from → theory",
        "sentence": "Criteria for anaphora resolution within sentence boundaries rephrase concepts from GB's binding theory.",
        "sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the object of the preposition 'for', depending on 'Criteria'. Entity 2 ('GB’s binding theory') is the object of the preposition 'from', depending on 'rephrase'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause where 'Criteria' is the subject and 'rephrase' is the verb.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "anaphora resolution within sentence boundaries",
                "Task"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the subject, depending on the verb 'rephrase'. Entity 2 ('those') is the subject, depending on the verb 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of different clauses in the sentence, indicating parallel structures discussing different aspects of anaphora resolution.\"",
        "sdp_path_text": "resolution → for → Criteria → rephrase → incorporate → those",
        "sentence": "Criteria for anaphora resolution within sentence boundaries rephrase concepts incorporated in those for text-level anaphora.",
        "sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the subject complement, depending on 'for' in the phrase 'Criteria for...'. Entity 2 ('those') is a demonstrative pronoun, depending on 'boundaries' as part of the prepositional phrase 'in those for text-level anaphora'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the prepositional phrases that describe similar criteria for different levels of anaphora.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "anaphora resolution within sentence boundaries",
                "Task"
            ],
            [
                "text-level anaphora",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the subject complement, depending on 'rephrase' with 'criteria'. Entity 2 ('text-level anaphora') is the subject complement, depending on 'incorporate' with 'those'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses describing different criteria.\"",
        "sdp_path_text": "resolution → for → Criteria → rephrase → incorporate → those → for → anaphora",
        "sentence": "Criteria for anaphora resolution within sentence boundaries rephrase concepts, while those for text-level anaphora incorporate a focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the subject, depending on the verb 'rephrase'. Entity 2 ('text-level anaphora') is the subject of the relative clause, depending on 'incorporate' with 'focus model'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different aspects of anaphora resolution described in the sentence.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "anaphora resolution within sentence boundaries",
                "Task"
            ],
            [
                "Grosz-Sidner-style focus model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is part of the subject, depending on the verb 'rephrase' with 'criteria'. Entity 2 ('Grosz-Sidner-style focus model') is the object, depending on 'incorporate' with 'those'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence, each describing a distinct aspect of criteria for anaphora resolution.\"",
        "sdp_path_text": "resolution → for → Criteria → rephrase → incorporate → version → of → model",
        "sentence": "Criteria for anaphora resolution within sentence boundaries incorporate a Grosz-Sidner-style focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('anaphora resolution within sentence boundaries') is the object of the preposition 'for', depending on 'Criteria'. Entity 2 ('Grosz-Sidner-style focus model') is the object, depending on 'incorporate' with 'Criteria'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause involving 'Criteria' and 'incorporate'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "GB 's binding theory",
                "Method"
            ],
            [
                "those",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase'. Entity 2 ('those') is the subject, depending on 'incorporate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence describing different aspects of criteria for anaphora resolution.\"",
        "sdp_path_text": "theory → from → rephrase → incorporate → those",
        "sentence": "Criteria rephrase concepts from GB's binding theory and incorporate those for text-level anaphora.",
        "sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase' with 'concepts'. Entity 2 ('those') is the object, depending on 'incorporate' with 'Criteria'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the action verbs 'rephrase' and 'incorporate' respectively.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "GB 's binding theory",
                "Method"
            ],
            [
                "text-level anaphora",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase'. Entity 2 ('text-level anaphora') is the object of the preposition 'for', depending on 'those'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "theory → from → rephrase → incorporate → those → for → anaphora",
        "sentence": "Criteria for text-level anaphora incorporate concepts rephrased from GB's binding theory.",
        "sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrased'. Entity 2 ('text-level anaphora') is part of the subject, depending on 'Criteria' with the prepositional phrase 'for text-level anaphora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "GB 's binding theory",
                "Method"
            ],
            [
                "Grosz-Sidner-style focus model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase'. Entity 2 ('Grosz-Sidner-style focus model') is the object of the preposition 'of', depending on 'version'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different parts of the sentence describing criteria for anaphora resolution.\"",
        "sdp_path_text": "theory → from → rephrase → incorporate → version → of → model",
        "sentence": "Criteria rephrase concepts from GB's binding theory and incorporate an adapted version of a Grosz-Sidner-style focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('GB's binding theory') is the object of the preposition 'from', depending on 'rephrase' with 'concepts'. Entity 2 ('Grosz-Sidner-style focus model') is the object of the preposition 'of', depending on 'version'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'incorporate' through different prepositional phrases.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "those",
                "Generic"
            ],
            [
                "text-level anaphora",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('those') is the subject, depending on 'incorporate' as its predicate. Entity 2 ('text-level anaphora') is the object of the preposition 'for', depending on 'for' in the phrase 'for text-level anaphora'. There is a direct dependency between Entity 1 and Entity 2, as 'those' refers back to criteria that are being described in relation to 'text-level anaphora'.\"",
        "sdp_path_text": "those → for → anaphora",
        "sentence": "Criteria for text-level anaphora are adapted.",
        "sentence_llm_dp_info": "\"Entity 1 ('those') is not present in the given sentence, so it cannot be analyzed for dependencies within this context. Entity 2 ('text-level anaphora') is the object of the preposition 'for', depending on 'Criteria'. There is no direct dependency between Entity 1 and Entity 2, as Entity 1 is not part of the sentence.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "Grosz-Sidner-style focus model",
                "Method"
            ],
            [
                "those",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Grosz-Sidner-style focus model') is the object, depending on 'incorporate' with 'those'. Entity 2 ('those') is the subject, depending on 'incorporate' with 'an adapted version'. There is a direct dependency between Entity 1 and Entity 2, as 'those' incorporates 'a Grosz-Sidner-style focus model'.\"",
        "sdp_path_text": "model → of → version → incorporate → those",
        "sentence": "Those criteria incorporate an adapted version of the Grosz-Sidner-style focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('Grosz-Sidner-style focus model') is the object of the preposition 'of', depending on 'version'. Entity 2 ('those') is the subject, depending on 'incorporate' with 'criteria'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'incorporate' and the prepositional phrase 'of the Grosz-Sidner-style focus model'.\""
    },
    {
        "raw_sentence": "Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB 's binding theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .",
        "ner_pair": [
            [
                "text-level anaphora",
                "OtherScientificTerm"
            ],
            [
                "Grosz-Sidner-style focus model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text-level anaphora') is the subject complement, depending on 'incorporate' with 'those'. Entity 2 ('Grosz-Sidner-style focus model') is the object, depending on 'incorporate' with 'an adapted version of'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'incorporate'.\"",
        "sdp_path_text": "anaphora → for → those → incorporate → version → of → model",
        "sentence": "Criteria for text-level anaphora incorporate a Grosz-Sidner-style focus model.",
        "sentence_llm_dp_info": "\"Entity 1 ('text-level anaphora') is the object of the preposition 'for', depending on 'Criteria'. Entity 2 ('Grosz-Sidner-style focus model') is the object, depending on 'incorporate' with 'anaphora'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'incorporate'.\""
    },
    {
        "raw_sentence": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages .",
        "ner_pair": [
            [
                "natural language text",
                "Material"
            ],
            [
                "Coedition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language text') is the object of the preposition 'of', depending on 'Coedition'. Entity 2 ('Coedition') is the subject, depending on the verb 'seems'. There is a direct dependency between Entity 1 and Entity 2, as 'natural language text' is part of what 'Coedition' involves in the sentence.\"",
        "sdp_path_text": "text → of → Coedition",
        "sentence": "Coedition of a natural language text is the best and simplest way to share text revision across languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language text') is the object of the preposition 'of', depending on 'Coedition'. Entity 2 ('Coedition') is the subject, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 modifies Entity 2 through the prepositional phrase 'of a natural language text'.\""
    },
    {
        "raw_sentence": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages .",
        "ner_pair": [
            [
                "Coedition",
                "Task"
            ],
            [
                "text revision",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Coedition') is the subject, depending on the verb 'seems'. Entity 2 ('text revision') is part of the noun phrase 'text revision across languages', which is the object of the preposition 'to' in the phrase 'to share text revision across languages'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'share' and the prepositional phrase 'to share text revision across languages'.\"",
        "sdp_path_text": "Coedition → seems → way → share → revision",
        "sentence": "Coedition seems the way to share text revision.",
        "sentence_llm_dp_info": "\"Entity 1 ('Coedition') is the subject, depending on the verb 'seems'. Entity 2 ('text revision') is the object of the preposition 'to', depending on 'share' in the phrase 'to share text revision'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'share' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages .",
        "ner_pair": [
            [
                "Coedition",
                "Task"
            ],
            [
                "languages",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Coedition') is the subject, depending on the verb 'seems'. Entity 2 ('languages') is the object of the preposition 'across', depending on 'across' in the phrase 'across languages'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'across languages'.\"",
        "sdp_path_text": "Coedition → seems → way → share → across → languages",
        "sentence": "Coedition seems a way to share text revision across languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('Coedition') is the subject, depending on the verb 'seems'. Entity 2 ('languages') is the object of the preposition 'across', depending on 'across' in the phrase 'across languages'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'across languages'.\""
    },
    {
        "raw_sentence": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages .",
        "ner_pair": [
            [
                "natural language text",
                "Material"
            ],
            [
                "text revision",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language text') is part of the compound noun phrase, depending on 'coedition' as a direct object. Entity 2 ('text revision') is the object of the preposition 'across', depending on 'share'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the clause describing the action of sharing revisions across languages.\"",
        "sdp_path_text": "text → of → Coedition → seems → way → share → revision",
        "sentence": "Coedition of natural language text seems a way to share text revision.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language text') is the object of the preposition 'of', depending on 'Coedition'. Entity 2 ('text revision') is the object of the preposition 'to', depending on 'share' in the phrase 'to share text revision'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the sentence, with Entity 1 being coedited and Entity 2 being shared.\""
    },
    {
        "raw_sentence": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages .",
        "ner_pair": [
            [
                "natural language text",
                "Material"
            ],
            [
                "languages",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language text') is the object of the preposition 'of', depending on 'Coedition'. Entity 2 ('languages') is the object of the preposition 'across', depending on 'share'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "text → of → Coedition → seems → way → share → across → languages",
        "sentence": "Coedition of natural language text seems a way to share revisions across languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language text') is the object of the preposition 'of', depending on 'Coedition'. Entity 2 ('languages') is the object of the preposition 'across', depending on 'share'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the sharing of revisions.\""
    },
    {
        "raw_sentence": "Coedition of a natural language text and its representation in some interlingual form seems the best and simplest way to share text revision across languages .",
        "ner_pair": [
            [
                "text revision",
                "OtherScientificTerm"
            ],
            [
                "languages",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text revision') is the object of the preposition 'across', depending on 'way' in the phrase 'way to share text revision'. Entity 2 ('languages') is the object of the preposition 'across', depending directly on 'across' in the same phrase 'across languages'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'across text revision across languages'.\"",
        "sdp_path_text": "revision → share → across → languages",
        "sentence": "Text revision can be shared across languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('text revision') is the subject, depending on the verb 'can be shared'. Entity 2 ('languages') is the object of the preposition 'across', depending on 'across' in the phrase 'across languages'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'across'.\""
    },
    {
        "raw_sentence": "The modified graph is then sent to the UNL-L0 deconverter and the result shown .",
        "ner_pair": [
            [
                "graph",
                "OtherScientificTerm"
            ],
            [
                "UNL-L0 deconverter",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graph') is the object, depending on the passive verb 'sent'. Entity 2 ('UNL-L0 deconverter') is the object of the preposition 'to', depending on 'to' in the phrase 'to the UNL-L0 deconverter'. There is a direct dependency between Entity 1 and Entity 2, as 'graph' is sent to the 'UNL-L0 deconverter'.\"",
        "sdp_path_text": "graph → sent → to → deconverter",
        "sentence": "The graph is sent to the UNL-L0 deconverter.",
        "sentence_llm_dp_info": "\"Entity 1 ('graph') is the subject, depending on the verb 'sent'. Entity 2 ('UNL-L0 deconverter') is the object of the preposition 'to', depending on 'to' in the phrase 'to the UNL-L0 deconverter'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'sent' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "If is is satisfactory , the errors were probably due to the graph , not to the deconverter , and the graph is sent to deconverters in other languages .",
        "ner_pair": [
            [
                "graph",
                "OtherScientificTerm"
            ],
            [
                "deconverter",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graph') is the object of the preposition 'to', depending on 'due' in the phrase 'due to the graph'. It also appears as the subject in the clause 'the graph is sent to deconverters'. Entity 2 ('deconverter') is part of a compound noun, depending on 'not to' in the phrase 'not to the deconverter'. There is no direct dependency between Entity 1 and Entity 2; however, they are mentioned in the context of the same clause, which suggests an indirect relationship where the 'graph' can be 'sent to deconverters'.\"",
        "sdp_path_text": "graph → to → to → deconverter",
        "sentence": "The graph is sent to deconverters.",
        "sentence_llm_dp_info": "\"Entity 1 ('graph') is the subject, depending on the verb 'is sent'. Entity 2 ('deconverter') is the object of the preposition 'to', depending on 'to' in the phrase 'to deconverters'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "If is is satisfactory , the errors were probably due to the graph , not to the deconverter , and the graph is sent to deconverters in other languages .",
        "ner_pair": [
            [
                "graph",
                "OtherScientificTerm"
            ],
            [
                "deconverters",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graph') is the object, depending on 'due' in the phrase 'due to the graph'. It also appears later as the subject, depending on 'is' in the clause 'the graph is sent to deconverters'. Entity 2 ('deconverters') is the object of the preposition 'to', depending on 'to' in the phrase 'to deconverters in other languages'. There is a direct dependency between Entity 1 and Entity 2, where 'graph' is sent to 'deconverters'.\"",
        "sdp_path_text": "graph → to → due → were → sent → to → deconverters",
        "sentence": "The graph was sent to deconverters.",
        "sentence_llm_dp_info": "\"Entity 1 ('graph') is the subject, depending on the verb 'sent'. Entity 2 ('deconverters') is the object of the preposition 'to', depending on 'to' in the phrase 'to deconverters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'sent' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "If is is satisfactory , the errors were probably due to the graph , not to the deconverter , and the graph is sent to deconverters in other languages .",
        "ner_pair": [
            [
                "deconverter",
                "Method"
            ],
            [
                "graph",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deconverter') is part of a noun phrase, depending on the preposition 'to' in the phrase 'to the deconverter'. Entity 2 ('graph') is the subject, depending on the verb 'is' in the clause 'the graph is sent'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where the graph is discussed in relation to the deconverter.\"",
        "sdp_path_text": "deconverter → to → to → graph",
        "sentence": "{\n  \"Simplified sentence\": \"The deconverter is related to the graph.\"\n} \n\nHowever, this simplification might lose too much context from the original sentence. A more accurate reflection of the relationship, while still being concise, could be:\n\n{\n  \"Simplified sentence\": \"Errors were likely due to the graph, not the deconverter.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('deconverter') is the object of the preposition 'to', depending on 'related' in the phrase 'is related to'. Entity 2 ('graph') is also the object of the preposition 'to', depending on 'related' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are connected through the preposition 'to' in the relationship described by 'is related to'.\n\nFor the second simplified sentence:\n'Errors were likely due to the graph, not the deconverter.'\n\nEntity 1 ('deconverter') is the complement of negation, depending on 'not' which modifies the prepositional phrase 'due to'. Entity 2 ('graph') is the object of the preposition 'due to', depending on 'due' in the phrase 'due to the graph'. There is no direct dependency between Entity 1 and Entity 2; they are related through the structure of the sentence where one (the graph) is the cause of the errors, and the other (the deconverter) is explicitly excluded as the cause.\""
    },
    {
        "raw_sentence": "If is is satisfactory , the errors were probably due to the graph , not to the deconverter , and the graph is sent to deconverters in other languages .",
        "ner_pair": [
            [
                "graph",
                "OtherScientificTerm"
            ],
            [
                "deconverters",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graph') is the subject, depending on 'sent' with the verb 'is sent'. Entity 2 ('deconverters') is the object of the preposition 'to', depending on 'to' in the phrase 'to deconverters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of the graph being sent to the deconverters.\"",
        "sdp_path_text": "graph → to → due → were → sent → to → deconverters",
        "sentence": "The graph is sent to deconverters.",
        "sentence_llm_dp_info": "\"Entity 1 ('graph') is the subject, depending on the verb 'is sent'. Entity 2 ('deconverters') is the object of the preposition 'to', depending on 'to' in the phrase 'to deconverters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "resources",
                "Generic"
            ],
            [
                "liaisons",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('resources') is the object of the preposition 'using', depending on 'established'. Entity 2 ('liaisons') is the subject, depending on 'are' in the clause 'liaisons are established'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'established' and the preposition 'using'.\"",
        "sdp_path_text": "resources → using → by → established → liaisons",
        "sentence": "Resources are used to establish liaisons.",
        "sentence_llm_dp_info": "\"Entity 1 ('resources') is the subject, depending on the verb 'used'. Entity 2 ('liaisons') is the object, depending on the verb 'establish'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' which indicates that the resources are utilized for the purpose of establishing liaisons.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "liaisons",
                "OtherScientificTerm"
            ],
            [
                "LO-English or better a L0-UNL dictionary",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('liaisons') is the subject, depending on the passive verb 'are established'. Entity 2 ('LO-English or better a L0-UNL dictionary') is the object, depending on the preposition 'such as', which is part of the prepositional phrase modifying 'resources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase that describes the resources used to establish the liaisons.\"",
        "sdp_path_text": "liaisons → established → by → using → resources → as → LO",
        "sentence": "Liaisons are established by using resources such as a LO-English or better a L0-UNL dictionary.",
        "sentence_llm_dp_info": "\"Entity 1 ('liaisons') is the subject, depending on the verb 'established'. Entity 2 ('LO-English or better a L0-UNL dictionary') is the object of the preposition 'such as', depending on 'using' in the phrase 'using resources such as a LO-English or better a L0-UNL dictionary'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'such as'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "liaisons",
                "OtherScientificTerm"
            ],
            [
                "morphosyntactic parser of L0",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('liaisons') is the subject, depending on the verb 'established'. Entity 2 ('morphosyntactic parser of L0') is part of a list of resources, depending on the preposition 'such as' which modifies the noun 'resources'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing the establishment of connections between text elements and the graph using various resources.\"",
        "sdp_path_text": "liaisons → established → by → using → resources → as → LO → English → dictionary → parser",
        "sentence": "Liaisons are established using resources such as a morphosyntactic parser of L0.",
        "sentence_llm_dp_info": "\"Entity 1 ('liaisons') is the subject, depending on the verb 'established'. Entity 2 ('morphosyntactic parser of L0') is the object of the preposition 'such as', depending on 'resources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'established' and the prepositional phrase 'using resources such as'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "liaisons",
                "OtherScientificTerm"
            ],
            [
                "canonical graph2tree transformation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('liaisons') is the subject, depending on the verb 'established'. Entity 2 ('canonical graph2tree transformation') is part of a list of resources, depending on the preposition 'and' which is part of the prepositional phrase 'and a canonical graph2tree transformation'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of resources used to establish connections.\"",
        "sdp_path_text": "liaisons → established → by → using → resources → as → LO → English → dictionary → parser → transformation",
        "sentence": "Liaisons are established using resources such as a dictionary and a canonical graph2tree transformation.",
        "sentence_llm_dp_info": "\"Entity 1 ('liaisons') is the subject, depending on the verb 'established'. Entity 2 ('canonical graph2tree transformation') is the object of the preposition 'and', depending on 'such as' in the phrase 'such as a dictionary and a canonical graph2tree transformation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'established' and the prepositional phrase 'using resources such as'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "LO-English or better a L0-UNL dictionary",
                "Material"
            ],
            [
                "resources",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LO-English or better a L0-UNL dictionary') is part of the list of examples, depending on 'such as' with 'resources'. Entity 2 ('resources') is the object, depending on 'using' with 'established'. There is no direct dependency between Entity 1 and Entity 2, but Entity 1 is an example of Entity 2.\"",
        "sdp_path_text": "LO → as → resources",
        "sentence": "LO-English or better a L0-UNL dictionary is used as a resource.",
        "sentence_llm_dp_info": "\"Entity 1 ('LO-English or better a L0-UNL dictionary') is the subject, depending on the verb 'used'. Entity 2 ('resources') is the object of the preposition 'as', depending on 'as' in the phrase 'as a resource'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'as'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "morphosyntactic parser of L0",
                "Method"
            ],
            [
                "resources",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphosyntactic parser of L0') is the subject, depending on the preposition 'such as' which modifies 'resources'. Entity 2 ('resources') is the object of the preposition 'using', depending on the verb 'using' in the phrase 'using broadly available resources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'such as'.\"",
        "sdp_path_text": "parser → dictionary → English → LO → as → resources",
        "sentence": "A morphosyntactic parser of L0 is used as one of the resources.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphosyntactic parser of L0') is the subject, depending on the verb 'used'. Entity 2 ('resources') is the object of the preposition 'of', depending on 'one' in the phrase 'one of the resources'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the noun 'one'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "canonical graph2tree transformation",
                "OtherScientificTerm"
            ],
            [
                "resources",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('canonical graph2tree transformation') is part of the list of resources, depending on 'and' which connects it to other items in the list. Entity 2 ('resources') is the object of the preposition 'such as', depending on 'using'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger structure where 'resources' is the head noun and 'canonical graph2tree transformation' is one of the listed items under 'resources'.\"",
        "sdp_path_text": "transformation → parser → dictionary → English → LO → as → resources",
        "sentence": "A canonical graph2tree transformation uses resources such as a morphosyntactic parser and a dictionary.",
        "sentence_llm_dp_info": "\"Entity 1 ('canonical graph2tree transformation') is the subject, depending on the verb 'uses'. Entity 2 ('resources') is the object, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, as 'resources' is the direct object of the verb 'uses' which is governed by 'canonical graph2tree transformation'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "LO-English or better a L0-UNL dictionary",
                "Material"
            ],
            [
                "morphosyntactic parser of L0",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LO-English or better a L0-UNL dictionary') is part of a list of resources, depending on 'using' with 'resources'. Entity 2 ('morphosyntactic parser of L0') is also part of the same list of resources, depending on 'using' with 'resources'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated items in the list of resources used for establishing liaisons.\"",
        "sdp_path_text": "LO → English → dictionary → parser",
        "sentence": "A LO-English dictionary or a L0-UNL dictionary is used with a morphosyntactic parser of L0.",
        "sentence_llm_dp_info": "\"Entity 1 ('LO-English or better a L0-UNL dictionary') is the subject, depending on the verb 'is used'. Entity 2 ('morphosyntactic parser of L0') is the object of the preposition 'with', depending on 'with' in the phrase 'with a morphosyntactic parser of L0'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'with' which indicates that the dictionary is used together with the parser.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "LO-English or better a L0-UNL dictionary",
                "Material"
            ],
            [
                "canonical graph2tree transformation",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LO-English or better a L0-UNL dictionary') is part of a list of resources, depending on 'using' with 'resources'. Entity 2 ('canonical graph2tree transformation') is also part of the same list of resources, depending on 'and' which connects it to the previous items in the list. There is no direct dependency between Entity 1 and Entity 2; both are listed as resources used in the process described.\"",
        "sdp_path_text": "LO → English → dictionary → parser → transformation",
        "sentence": "A LO-English or L0-UNL dictionary and a canonical graph2tree transformation are used.",
        "sentence_llm_dp_info": "\"Entity 1 ('LO-English or better a L0-UNL dictionary') is part of a conjunction, depending on 'and' with 'canonical graph2tree transformation'. Entity 2 ('canonical graph2tree transformation') is the second part of the conjunction, also depending on 'and'. Both entities are subjects in the clause, depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "On the internal side , liaisons are established between elements of the text and the graph by using broadly available resources such as a LO-English or better a L0-UNL dictionary , a morphosyntactic parser of L0 , and a canonical graph2tree transformation .",
        "ner_pair": [
            [
                "morphosyntactic parser of L0",
                "Method"
            ],
            [
                "canonical graph2tree transformation",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('morphosyntactic parser of L0') is the object of the preposition 'such as', depending on 'resources'. Entity 2 ('canonical graph2tree transformation') is also the object of the preposition 'such as', depending on 'resources'. There is no direct dependency between Entity 1 and Entity 2; both are listed as examples of the resources used.\"",
        "sdp_path_text": "parser → transformation",
        "sentence": "A morphosyntactic parser of L0 and a canonical graph2tree transformation are used.",
        "sentence_llm_dp_info": "\"Entity 1 ('morphosyntactic parser of L0') is the subject, depending on the verb 'are used'. Entity 2 ('canonical graph2tree transformation') is also a subject, depending on the same verb 'are used'. There is no direct dependency between Entity 1 and Entity 2; both are subjects of the same verb, indicating that they are used together or in parallel.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "UNL-tree + L0",
                "OtherScientificTerm"
            ],
            [
                "MS-L0 structure",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is the object of the preposition 'between', depending on 'correspondence'. Entity 2 ('MS-L0 structure') is also the object of the preposition 'between', depending on 'correspondence'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'between the \"UNL-tree + L0\" and the \"MS-L0 structure\".'.\"",
        "sdp_path_text": "tree → structure",
        "sentence": "Establishing a correspondence between the 'UNL-tree + L0' and the 'MS-L0 structure'.",
        "sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is the first element of the correspondence, depending on 'between' as part of the prepositional phrase 'between the 'UNL-tree + L0' and the 'MS-L0 structure''. Entity 2 ('MS-L0 structure') is the second element of the correspondence, also depending on 'between' as part of the same prepositional phrase. There is no direct dependency between Entity 1 and Entity 2; both are connected through the preposition 'between'.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "UNL-tree + L0",
                "OtherScientificTerm"
            ],
            [
                "lattice",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is part of the object of the preposition 'between', depending on 'between' in the phrase 'between the \"UNL-tree + L0\" and the \"MS-L0 structure\"'. Entity 2 ('lattice') is the complement of the copula 'be', depending on 'be' in the phrase 'a lattice'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of establishing a correspondence.\"",
        "sdp_path_text": "tree → lattice",
        "sentence": "Establishing a correspondence between the 'UNL-tree + L0' and the 'lattice' may be done.",
        "sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is part of a prepositional phrase, depending on 'between' with 'correspondence'. Entity 2 ('lattice') is also part of a prepositional phrase, depending on 'and' which connects it to 'UNL-tree + L0' within the same phrase. There is no direct dependency between Entity 1 and Entity 2; they are both part of the prepositional phrase 'between the 'UNL-tree + L0' and the 'lattice''.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "UNL-tree + L0",
                "OtherScientificTerm"
            ],
            [
                "dictionary",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is part of a prepositional phrase, depending on 'between' with 'correspondence'. Entity 2 ('dictionary') is an object, depending on 'using' with 'done'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described in the sentence, with 'UNL-tree + L0' being one of the elements for which correspondence is established, and 'dictionary' being a tool used in this process.\"",
        "sdp_path_text": "tree → between → correspondence → Establishing → done → using → dictionary",
        "sentence": "Establishing correspondence between the 'UNL-tree + L0' and other structures may be done using the dictionary.",
        "sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is part of the prepositional phrase 'between the UNL-tree + L0 and other structures', depending on the preposition 'between'. Entity 2 ('dictionary') is the object of the preposition 'using', depending on 'using' in the phrase 'using the dictionary'. There is no direct dependency between Entity 1 and Entity 2; both are parts of different prepositional phrases that modify the main clause 'Establishing correspondence may be done'.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "UNL-tree + L0",
                "OtherScientificTerm"
            ],
            [
                "crossing liaisons",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is part of the prepositional phrase 'between the \"UNL-tree + L0\" and the \"MS-L0 structure\"', where it depends on the preposition 'between'. Entity 2 ('crossing liaisons') is the object of the prepositional phrase 'with as few crossing liaisons as possible', where it depends on the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2; they are both part of larger phrases that describe the process of establishing correspondence and aligning structures.\"",
        "sdp_path_text": "tree → between → correspondence → Establishing → done → using → trying → align → with → liaisons",
        "sentence": "Establishing correspondence between the UNL-tree + L0 and the MS-L0 structure may be done by trying to align them with few crossing liaisons.",
        "sentence_llm_dp_info": "\"Entity 1 ('UNL-tree + L0') is the subject of the prepositional phrase 'between the UNL-tree + L0 and the MS-L0 structure', depending on 'correspondence'. Entity 2 ('crossing liaisons') is the object of the prepositional phrase 'with few crossing liaisons', depending on 'align'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'establishing' and 'align'.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "MS-L0 structure",
                "OtherScientificTerm"
            ],
            [
                "lattice",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MS-L0 structure') is part of a prepositional phrase, depending on 'between' with 'correspondence'. Entity 2 ('lattice') is the complement of the copula verb 'be', depending on 'be' with 'may be'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the correspondence that may be established.\"",
        "sdp_path_text": "structure → tree → lattice",
        "sentence": "The 'MS-L0 structure' may be represented as a lattice.",
        "sentence_llm_dp_info": "\"Entity 1 ('MS-L0 structure') is the subject, depending on the verb 'represented'. Entity 2 ('lattice') is the complement, depending on the verb 'represented' through the preposition 'as'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'represented' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "MS-L0 structure",
                "OtherScientificTerm"
            ],
            [
                "dictionary",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MS-L0 structure') is part of a compound noun, depending on the preposition 'between' with 'UNL-tree + L0'. Entity 2 ('dictionary') is the object of the preposition 'using', depending on 'using' in the phrase 'using the dictionary'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the process of establishing a correspondence and the methods used for this purpose.\"",
        "sdp_path_text": "structure → tree → between → correspondence → Establishing → done → using → dictionary",
        "sentence": "Establishing correspondence between the MS-L0 structure and the tree may be done using the dictionary.",
        "sentence_llm_dp_info": "\"Entity 1 ('MS-L0 structure') is part of the prepositional phrase 'between the MS-L0 structure and the tree', where it depends on 'correspondence' through the preposition 'between'. Entity 2 ('dictionary') is the object of the preposition 'using', indicating the tool or means by which the action is performed. There is no direct dependency between Entity 1 and Entity 2; they are connected through the main clause describing the action of establishing correspondence.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "MS-L0 structure",
                "OtherScientificTerm"
            ],
            [
                "crossing liaisons",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MS-L0 structure') is part of the object complement, depending on the preposition 'between' which is part of the phrase 'between the '' UNL-tree + L0 '' and the '' MS-L0 structure ''. Entity 2 ('crossing liaisons') is the object of the preposition 'with', depending on 'with' in the phrase 'with as few crossing liaisons as possible'. There is no direct dependency between Entity 1 and Entity 2, but both are involved in the broader context of establishing a correspondence and minimizing liaisons.\"",
        "sdp_path_text": "structure → tree → between → correspondence → Establishing → done → using → trying → align → with → liaisons",
        "sentence": "Establishing correspondence between the MS-L0 structure and the tree may be done by trying to align them with as few crossing liaisons as possible.",
        "sentence_llm_dp_info": "\"Entity 1 ('MS-L0 structure') is part of the prepositional phrase 'between the MS-L0 structure and the tree', where it serves as the first object of the preposition 'between', depending on 'between'. Entity 2 ('crossing liaisons') is the object of the preposition 'with', depending on 'with' in the phrase 'with as few crossing liaisons as possible'. There is no direct dependency between Entity 1 and Entity 2; both are part of different prepositional phrases that modify the main clause.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "dictionary",
                "Material"
            ],
            [
                "lattice",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionary') is the object, depending on 'using' which modifies the main clause. Entity 2 ('lattice') is the complement of the preposition 'as', depending on the prepositional phrase 'as a lattice'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence.\"",
        "sdp_path_text": "dictionary → using → done → Establishing → correspondence → between → tree → lattice",
        "sentence": "Establishing correspondence between the tree and the lattice may be done using the dictionary.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionary') is the object, depending on the preposition 'using' which modifies the verb 'done'. Entity 2 ('lattice') is part of the compound object of the preposition 'between', depending on 'between' in the phrase 'between the tree and the lattice'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the action of establishing correspondence.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "lattice",
                "OtherScientificTerm"
            ],
            [
                "crossing liaisons",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lattice') is the subject complement, depending on 'be' with 'may be done'. Entity 2 ('crossing liaisons') is part of the object of the preposition 'with', depending on 'with' in the phrase 'with as few crossing liaisons as possible'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "lattice → tree → between → correspondence → Establishing → done → using → trying → align → with → liaisons",
        "sentence": "Establishing correspondence between the lattice and the tree may be done by trying to align them with as few crossing liaisons as possible.",
        "sentence_llm_dp_info": "\"Entity 1 ('lattice') is the object of the preposition 'between', depending on 'correspondence'. Entity 2 ('crossing liaisons') is the object of the preposition 'with', depending on 'align'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the process of establishing correspondence and aligning structures.\""
    },
    {
        "raw_sentence": "Establishing a `` best '' correspondence between the '' UNL-tree + L0 '' and the '' MS-L0 structure '' , a lattice , may be done using the dictionary and trying to align the tree and the selected trajectory with as few crossing liaisons as possible .",
        "ner_pair": [
            [
                "dictionary",
                "Material"
            ],
            [
                "crossing liaisons",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dictionary') is an object, depending on the preposition 'using', which is part of the prepositional phrase 'using the dictionary'. Entity 2 ('crossing liaisons') is the object of the preposition 'as', forming the phrase 'as few crossing liaisons as possible', which modifies the verb 'align'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "dictionary → using → trying → align → with → liaisons",
        "sentence": "Using the dictionary, the alignment is tried with as few crossing liaisons as possible.",
        "sentence_llm_dp_info": "\"Entity 1 ('dictionary') is the object of the preposition 'using', depending on the verb 'tried'. Entity 2 ('crossing liaisons') is part of the noun phrase 'as few crossing liaisons as possible', which is the complement of the preposition 'with', depending on 'with' in the phrase 'with as few crossing liaisons as possible'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "A central goal of this research is to merge approaches from pivot MT , interactive MT , and multilingual text authoring .",
        "ner_pair": [
            [
                "pivot MT",
                "Task"
            ],
            [
                "interactive MT",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pivot MT') is part of a coordinated list, depending on 'from' in the phrase 'from pivot MT'. Entity 2 ('interactive MT') is also part of a coordinated list, depending on 'and' in the phrase 'interactive MT , and multilingual text authoring'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list introduced by the preposition 'from'.\"",
        "sdp_path_text": "MT → MT",
        "sentence": "The research aims to merge approaches from pivot MT and interactive MT.",
        "sentence_llm_dp_info": "\"Entity 1 ('pivot MT') is part of a compound noun, depending on 'from' in the phrase 'from pivot MT'. Entity 2 ('interactive MT') is also part of a compound noun, depending on 'from' in the phrase 'from interactive MT'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'from' in the context of the verb 'merge'.\""
    },
    {
        "raw_sentence": "A central goal of this research is to merge approaches from pivot MT , interactive MT , and multilingual text authoring .",
        "ner_pair": [
            [
                "pivot MT",
                "Task"
            ],
            [
                "multilingual text authoring",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pivot MT') is part of a compound noun, depending on 'approaches' with the preposition 'from'. Entity 2 ('multilingual text authoring') is also part of a compound noun, depending on 'approaches' with the preposition 'from'. There is no direct dependency between Entity 1 and Entity 2; both are related to 'approaches' through the preposition 'from'.\"",
        "sdp_path_text": "MT → MT → authoring",
        "sentence": "The research aims to merge approaches from pivot MT and multilingual text authoring.",
        "sentence_llm_dp_info": "\"Entity 1 ('pivot MT') is part of a compound noun, depending on 'from' in the phrase 'from pivot MT'. Entity 2 ('multilingual text authoring') is also part of a compound noun, depending on 'from' in the phrase 'from multilingual text authoring'. Both entities are objects of the preposition 'from', which itself depends on the verb 'merge'. There is no direct dependency between Entity 1 and Entity 2, but they are both directly connected to the preposition 'from'.\""
    },
    {
        "raw_sentence": "A central goal of this research is to merge approaches from pivot MT , interactive MT , and multilingual text authoring .",
        "ner_pair": [
            [
                "interactive MT",
                "Task"
            ],
            [
                "multilingual text authoring",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('interactive MT') is part of a conjunction, depending on 'merge' through the conjunction 'and'. Entity 2 ('multilingual text authoring') is also part of a conjunction, depending on 'merge' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are connected to the verb 'merge' through the conjunction 'and'.\"",
        "sdp_path_text": "MT → authoring",
        "sentence": "The research aims to merge approaches from interactive MT and multilingual text authoring.",
        "sentence_llm_dp_info": "\"Entity 1 ('interactive MT') is part of a compound noun, depending on 'from' in the prepositional phrase 'from interactive MT'. Entity 2 ('multilingual text authoring') is also part of a compound noun, depending on 'from' in the same prepositional phrase 'from multilingual text authoring'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the preposition 'from' within the same phrase.\""
    },
    {
        "raw_sentence": "We report experiments conducted on a multilingual corpus to estimate the number of analogies among the sentences that it contains .",
        "ner_pair": [
            [
                "multilingual corpus",
                "Material"
            ],
            [
                "analogies",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multilingual corpus') is the object of the preposition 'on', depending on 'conducted'. Entity 2 ('analogies') is the object of the preposition 'of', depending on 'number'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs and prepositions in the sentence.\"",
        "sdp_path_text": "corpus → on → conducted → experiments → report → estimate → number → of → analogies",
        "sentence": "Experiments on a multilingual corpus estimate the number of analogies.",
        "sentence_llm_dp_info": "\"Entity 1 ('multilingual corpus') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('analogies') is the object of the verb 'estimate', depending on 'estimate' in the phrase 'estimate the number of analogies'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Experiments' is the subject.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "loss",
                "OtherScientificTerm"
            ],
            [
                "Mahalanobis distance",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss') is the object, depending on the verb 'minimizing'. Entity 2 ('Mahalanobis distance') is the object of the preposition 'a', depending on 'learn'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'loss' is minimized in the process of learning 'Mahalanobis distance'.\"",
        "sdp_path_text": "loss → minimizing → by → learn → distance",
        "sentence": "A loss is minimized by learning a Mahalanobis distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on the verb 'minimized'. Entity 2 ('Mahalanobis distance') is the object of the preposition 'a', depending on 'learning' in the phrase 'learning a Mahalanobis distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action of 'learning' and the verb 'minimized'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "Mahalanobis distance",
                "Task"
            ],
            [
                "weighted sum",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Mahalanobis distance') is the object of the verb 'learn', depending on 'learn' in the clause 'to learn a Mahalanobis distance'. Entity 2 ('weighted sum') is the object of the preposition 'of', depending on 'sum' in the phrase 'the weighted sum of the precision at different ranks'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger clause structure where the goal is to learn the Mahalanobis distance by minimizing a loss that is defined based on the weighted sum.\"",
        "sdp_path_text": "distance → learn → by → minimizing → loss → defined → on → sum",
        "sentence": "The Mahalanobis distance is learned by minimizing a loss defined on the weighted sum.",
        "sentence_llm_dp_info": "\"Entity 1 ('Mahalanobis distance') is the subject, depending on the verb 'learned'. Entity 2 ('weighted sum') is the object of the preposition 'on', depending on 'defined' in the phrase 'defined on the weighted sum'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'learned' and the prepositional phrase 'on the weighted sum'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "Mahalanobis distance",
                "Task"
            ],
            [
                "precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Mahalanobis distance') is the object of the verb 'learn', depending on 'learn' in the clause 'to learn a Mahalanobis distance'. Entity 2 ('precision') is part of the noun phrase 'the precision at different ranks', which is the object of the preposition 'of' in the phrase 'on the weighted sum of the precision at different ranks', depending on 'sum'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger structure where 'Mahalanobis distance' is the target of learning and 'precision' is a component in the definition of the loss function.\"",
        "sdp_path_text": "distance → learn → by → minimizing → loss → defined → on → sum → of → precision",
        "sentence": "We aim to learn a Mahalanobis distance by minimizing loss defined on the sum of precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('Mahalanobis distance') is the object of the verb 'learn', depending on 'aim'. Entity 2 ('precision') is part of the noun phrase 'sum of precision', which is the object of the preposition 'on', depending on 'defined'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the clause describing the goal of the action.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "Mahalanobis distance",
                "Task"
            ],
            [
                "ranks",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Mahalanobis distance') is the object of the verb 'learn', depending on 'learn' in the phrase 'to learn a Mahalanobis distance'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'precision' in the phrase 'the precision at different ranks'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the goal of learning the Mahalanobis distance by minimizing a loss function that involves the precision at different ranks.\"",
        "sdp_path_text": "distance → learn → by → minimizing → loss → defined → on → sum → at → ranks",
        "sentence": "Mahalanobis distance is learned by minimizing loss defined on the sum at different ranks.",
        "sentence_llm_dp_info": "\"Entity 1 ('Mahalanobis distance') is the subject, depending on the passive verb 'is learned'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'sum'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure involving 'minimizing loss' and 'defined on the sum at different ranks'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "loss",
                "OtherScientificTerm"
            ],
            [
                "weighted sum",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on 'minimizing' with 'is'. Entity 2 ('weighted sum') is the object of the preposition 'of', depending on 'defined' in the phrase 'defined on the weighted sum'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'defined on the weighted sum'.\"",
        "sdp_path_text": "loss → defined → on → sum",
        "sentence": "The loss is defined on the weighted sum.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on the verb 'is defined'. Entity 2 ('weighted sum') is the object, depending on the preposition 'on' in the phrase 'on the weighted sum'. There is a direct dependency between Entity 1 and Entity 2, as 'loss' is defined in relation to 'the weighted sum'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "loss",
                "OtherScientificTerm"
            ],
            [
                "precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss') is the object, depending on the verb 'minimizing'. Entity 2 ('precision') is part of the noun phrase 'the precision at different ranks', which is the object of the preposition 'of', depending on 'sum'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure involving 'defined on the weighted sum of the precision at different ranks'.\"",
        "sdp_path_text": "loss → defined → on → sum → of → precision",
        "sentence": "The loss is defined on the sum of the precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on the verb 'is defined'. Entity 2 ('precision') is part of the object, depending on 'sum' in the phrase 'the sum of the precision'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'loss' is defined in terms that include 'precision'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "loss",
                "OtherScientificTerm"
            ],
            [
                "ranks",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on 'minimizing' as the verb. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'precision'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure 'the precision at different ranks' which defines the 'loss' being minimized.\"",
        "sdp_path_text": "loss → defined → on → sum → at → ranks",
        "sentence": "The loss is defined on the sum at different ranks.",
        "sentence_llm_dp_info": "\"Entity 1 ('loss') is the subject, depending on the verb 'is defined'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'at' in the phrase 'at different ranks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'at different ranks'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "weighted sum",
                "OtherScientificTerm"
            ],
            [
                "precision",
                "Metric"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('weighted sum') is the object of the preposition 'on', depending on 'defined'. Entity 2 ('precision') is part of the compound noun 'precision at different ranks', depending on 'sum' within the phrase 'weighted sum of the precision at different ranks'. There is no direct dependency between Entity 1 and Entity 2, but they are closely related within the same prepositional phrase.\"",
        "sdp_path_text": "sum → of → precision",
        "sentence": "The goal is to minimize a loss defined on the weighted sum of precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('weighted sum') is the object of the preposition 'on', depending on 'defined'. Entity 2 ('precision') is the object of the preposition 'of', depending on 'sum' in the phrase 'sum of precision'. There is a direct dependency between Entity 1 and Entity 2, where 'precision' modifies 'sum'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "weighted sum",
                "OtherScientificTerm"
            ],
            [
                "ranks",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('weighted sum') is the object of the preposition 'on', depending on 'defined'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'precision'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the components involved in defining the loss.\"",
        "sdp_path_text": "sum → at → ranks",
        "sentence": "The weighted sum is defined at different ranks.",
        "sentence_llm_dp_info": "\"Entity 1 ('weighted sum') is the subject, depending on the verb 'defined'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'at' in the phrase 'at different ranks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'at'.\""
    },
    {
        "raw_sentence": "Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks .",
        "ner_pair": [
            [
                "precision",
                "Metric"
            ],
            [
                "ranks",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('precision') is part of a noun phrase, depending on 'sum' as a modifier in the phrase 'sum of the precision'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'at' in the phrase 'at different ranks'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'at different ranks' which modifies 'precision'.\"",
        "sdp_path_text": "precision → of → sum → at → ranks",
        "sentence": "Precision is measured at different ranks in the sum.",
        "sentence_llm_dp_info": "\"Entity 1 ('precision') is the subject, depending on the verb 'is measured'. Entity 2 ('ranks') is the object of the preposition 'at', depending on 'measured' in the phrase 'measured at different ranks'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'measured' and the preposition 'at'.\""
    },
    {
        "raw_sentence": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification .",
        "ner_pair": [
            [
                "weighted rank loss",
                "OtherScientificTerm"
            ],
            [
                "computer vision",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('weighted rank loss') is the object of the verb 'minimizing', which is part of the subject complement 'that minimizing a weighted rank loss is a natural criterion'. Entity 2 ('computer vision') is the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the sentence structure where 'minimizing a weighted rank loss' is described as a criterion relevant to problems in 'computer vision'.\"",
        "sdp_path_text": "loss → minimizing → is → criterion → for → problems → in → vision",
        "sentence": "Minimizing a weighted rank loss is a criterion for problems in computer vision.",
        "sentence_llm_dp_info": "\"Entity 1 ('weighted rank loss') is the subject, depending on the verb 'is'. Entity 2 ('computer vision') is the object of the preposition 'in', depending on 'problems'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'problems' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification .",
        "ner_pair": [
            [
                "weighted rank loss",
                "OtherScientificTerm"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('weighted rank loss') is the object of the verb 'minimizing', which is part of the subject complement of the sentence. It depends on the verb 'is' through the gerund 'minimizing'. Entity 2 ('person re-identification') is the object of the preposition 'such as', which is part of a prepositional phrase modifying 'problems'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where 'minimizing a weighted rank loss' is described as a natural criterion for 'problems' including 'person re-identification'.\"",
        "sdp_path_text": "loss → minimizing → is → criterion → for → problems → as → re",
        "sentence": "Minimizing weighted rank loss is a criterion for person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('weighted rank loss') is the object of the verb 'minimizing', which is the subject of the clause. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'criterion'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'minimizing weighted rank loss' serves as a criterion for 'person re-identification'.\""
    },
    {
        "raw_sentence": "Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification .",
        "ner_pair": [
            [
                "person re-identification",
                "Task"
            ],
            [
                "computer vision",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('person re-identification') is the object of the preposition 'such as', depending on 'such as' in the phrase 'such as person re-identification'. Entity 2 ('computer vision') is the object of the preposition 'in', depending on 'in' in the phrase 'in computer vision'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a larger modifying clause that describes the types of problems for which the criterion is natural.\"",
        "sdp_path_text": "re → as → problems → in → vision",
        "sentence": "Person re-identification is a problem in computer vision.",
        "sentence_llm_dp_info": "\"Entity 1 ('person re-identification') is the subject, depending on the copula 'is'. Entity 2 ('computer vision') is the object of the preposition 'in', depending on 'in' in the phrase 'in computer vision'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB- .",
        "ner_pair": [
            [
                "Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-",
                "Method"
            ],
            [
                "metric learning formulation",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Weighted Approximate Rank Component Analysis -LRB- WARCA -RRB-') is the appositive, depending on the noun 'formulation'. Entity 2 ('metric learning formulation') is the direct object, depending on the verb 'propose'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 renames or specifies Entity 2.\"",
        "sdp_path_text": "Analysis → called → formulation",
        "sentence": "Weighted Approximate Rank Component Analysis (WARCA) is called a metric learning formulation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Weighted Approximate Rank Component Analysis (WARCA)') is the subject, depending on the verb 'is called'. Entity 2 ('metric learning formulation') is the complement, depending on the verb 'is called'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is what Entity 1 is referred to as in the sentence.\""
    },
    {
        "raw_sentence": "We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem .",
        "ner_pair": [
            [
                "stochastic gradient descent algorithm",
                "Method"
            ],
            [
                "learning problem",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('stochastic gradient descent algorithm') is the object, depending on the verb 'derive'. Entity 2 ('learning problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the resulting learning problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "algorithm → for → problem",
        "sentence": "We derive a stochastic gradient descent algorithm for the learning problem.",
        "sentence_llm_dp_info": "\"Entity 1 ('stochastic gradient descent algorithm') is the object, depending on the verb 'derive'. Entity 2 ('learning problem') is the object of the preposition 'for', depending on 'for' in the phrase 'for the learning problem'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'derive' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We also derive an efficient non-linear extension of WARCA by using the kernel trick .",
        "ner_pair": [
            [
                "kernel trick",
                "Method"
            ],
            [
                "non-linear extension of WARCA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('kernel trick') is the object, depending on the preposition 'using', which modifies the verb 'derive'. Entity 2 ('non-linear extension of WARCA') is the direct object, depending on the verb 'derive'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'non-linear extension of WARCA' is derived using the 'kernel trick'.\"",
        "sdp_path_text": "trick → using → by → derive → extension",
        "sentence": "We derive a non-linear extension of WARCA using the kernel trick.",
        "sentence_llm_dp_info": "\"Entity 1 ('kernel trick') is the object, depending on the preposition 'using', which modifies the verb 'derive'. Entity 2 ('non-linear extension of WARCA') is the direct object, depending on the verb 'derive'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'non-linear extension of WARCA' is derived using the 'kernel trick'.\""
    },
    {
        "raw_sentence": "We also derive an efficient non-linear extension of WARCA by using the kernel trick .",
        "ner_pair": [
            [
                "WARCA",
                "Method"
            ],
            [
                "kernel trick",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('WARCA') is part of the noun phrase 'an efficient non-linear extension of WARCA', where it is the object of the preposition 'of', depending on 'extension'. Entity 2 ('kernel trick') is the object of the preposition 'using', depending on 'using' in the phrase 'by using the kernel trick'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the method of derivation.\"",
        "sdp_path_text": "WARCA → of → extension → derive → by → using → trick",
        "sentence": "We derive an efficient non-linear extension of WARCA using the kernel trick.",
        "sentence_llm_dp_info": "\"Entity 1 ('WARCA') is the object of the preposition 'of', depending on 'extension'. Entity 2 ('kernel trick') is the object, depending on 'using' which indicates the method applied. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described in the sentence, with 'kernel trick' being used to derive the 'non-linear extension of WARCA'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "Kernel space embedding",
                "OtherScientificTerm"
            ],
            [
                "training and prediction costs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'decouples'. Entity 2 ('training and prediction costs') is the object, depending on 'decouples' with 'Kernel space embedding'. There is a direct dependency between Entity 1 and Entity 2, as 'Kernel space embedding' decouples 'training and prediction costs' from the data dimension.\"",
        "sdp_path_text": "embedding → decouples → costs",
        "sentence": "Kernel space embedding decouples training and prediction costs.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'decouples'. Entity 2 ('training and prediction costs') is the object, depending on 'decouples' with 'Kernel space embedding'. There is a direct dependency between Entity 1 and Entity 2, as 'Kernel space embedding' directly acts upon 'training and prediction costs' through the verb 'decouples'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "Kernel space embedding",
                "OtherScientificTerm"
            ],
            [
                "data dimension",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'decouples'. Entity 2 ('data dimension') is the object of the preposition 'from', depending on 'from' in the phrase 'from the data dimension'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'decouples'.\"",
        "sdp_path_text": "embedding → decouples → from → dimension",
        "sentence": "Kernel space embedding decouples from the data dimension.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'decouples'. Entity 2 ('data dimension') is the object of the preposition 'from', depending on 'from' in the phrase 'from the data dimension'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "Kernel space embedding",
                "OtherScientificTerm"
            ],
            [
                "inarbitrary distance measures",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'decouples'. Entity 2 ('inarbitrary distance measures') is the object of the preposition 'in', depending on 'enables' through the prepositional phrase 'to plug in arbitrary distance measures'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the enabling action described by the verb 'enables'.\"",
        "sdp_path_text": "embedding → decouples → enables → plug → measures",
        "sentence": "Kernel space embedding enables plugging in arbitrary distance measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'enables'. Entity 2 ('arbitrary distance measures') is the object of the preposition 'in', depending on 'plugging'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables' and the prepositional phrase 'in arbitrary distance measures'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "Kernel space embedding",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on 'decouples' as its verb. Entity 2 ('features') is the object of the preposition 'for', depending on 'natural' in the phrase 'more natural for the features'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the sentence's discussion on how kernel space embedding affects the handling of features.\"",
        "sdp_path_text": "embedding → decouples → enables → plug → measures → are → natural → for → features",
        "sentence": "Kernel space embedding decouples costs and enables using natural measures for features.",
        "sentence_llm_dp_info": "\"Entity 1 ('Kernel space embedding') is the subject, depending on the verb 'decouples'. Entity 2 ('features') is the object of the preposition 'for', depending on 'measures' in the phrase 'natural measures for features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'enables' and the prepositional phrase 'for features'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "training and prediction costs",
                "OtherScientificTerm"
            ],
            [
                "data dimension",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training and prediction costs') is the subject, depending on the verb 'decouples' with 'Kernel space embedding'. Entity 2 ('data dimension') is the object, also depending on the verb 'decouples' with 'Kernel space embedding'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'decouples'.\"",
        "sdp_path_text": "costs → decouples → from → dimension",
        "sentence": "Kernel space embedding decouples training and prediction costs from data dimension.",
        "sentence_llm_dp_info": "\"Entity 1 ('training and prediction costs') is the subject, depending on the verb 'decouples'. Entity 2 ('data dimension') is the object of the preposition 'from', depending on 'from' in the phrase 'from data dimension'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "training and prediction costs",
                "OtherScientificTerm"
            ],
            [
                "inarbitrary distance measures",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training and prediction costs') is the object of the verb 'decouples', depending on 'decouples' with 'Kernel space embedding'. Entity 2 ('inarbitrary distance measures') is the object of the verb 'enables', depending on 'plug in' within the clause 'enables us to plug in arbitrary distance measures'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "costs → decouples → enables → plug → measures",
        "sentence": "Kernel space embedding decouples training and prediction costs and enables plugging in arbitrary distance measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('training and prediction costs') is the object, depending on 'decouples' with 'Kernel space embedding'. Entity 2 ('arbitrary distance measures') is the object, depending on 'enables' with 'Kernel space embedding'. There is no direct dependency between Entity 1 and Entity 2, but both are influenced by 'Kernel space embedding'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "training and prediction costs",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training and prediction costs') is the object of the verb 'decouples', depending on the verb 'decouples' with 'Kernel space embedding'. Entity 2 ('features') is the object of the relative clause, depending on 'natural' with 'which are more natural for the features'. There is no direct dependency between Entity 1 and Entity 2; they are both related to different parts of the sentence, with Entity 1 being part of what is decoupled and Entity 2 being part of the context for the distance measures.\"",
        "sdp_path_text": "costs → decouples → enables → plug → measures → are → natural → for → features",
        "sentence": "Kernel space embedding decouples training and prediction costs and enables using natural measures for features.",
        "sentence_llm_dp_info": "\"Entity 1 ('training and prediction costs') is the object of the verb 'decouples', depending on 'decouples' with 'Kernel space embedding'. Entity 2 ('features') is the object of the preposition 'for', depending on 'measures' in the phrase 'natural measures for features'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "data dimension",
                "OtherScientificTerm"
            ],
            [
                "inarbitrary distance measures",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data dimension') is the object of the preposition 'from', depending on 'decouples' in the phrase 'decouples...from the data dimension'. Entity 2 ('inarbitrary distance measures') is the object of the preposition 'in', depending on 'enables' in the phrase 'enables us to plug in arbitrary distance measures'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "dimension → from → decouples → enables → plug → measures",
        "sentence": "Kernel space embedding decouples from data dimension and enables plugging in arbitrary distance measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('data dimension') is the object of the preposition 'from', depending on 'decouples' with 'Kernel space embedding decouples from'. Entity 2 ('arbitrary distance measures') is the object of the verb 'enables', depending on 'plugging in'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "data dimension",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data dimension') is the object of the preposition 'from', depending on 'decouples'. Entity 2 ('features') is the object of the relative clause 'for the features', depending on 'natural'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "dimension → from → decouples → enables → plug → measures → are → natural → for → features",
        "sentence": "Kernel space embedding decouples from data dimension and enables natural measures for features.",
        "sentence_llm_dp_info": "\"Entity 1 ('data dimension') is the object of the preposition 'from', depending on 'decouples' with 'Kernel space embedding'. Entity 2 ('features') is the object of the preposition 'for', depending on 'measures'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause involving 'Kernel space embedding'.\""
    },
    {
        "raw_sentence": "Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features .",
        "ner_pair": [
            [
                "inarbitrary distance measures",
                "Method"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('inarbitrary distance measures') is the object, depending on 'plug' with 'enables us to plug in'. Entity 2 ('features') is the object of the preposition 'for', depending on 'for' in the phrase 'for the features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'plug' and the preposition 'for'.\"",
        "sdp_path_text": "measures → are → natural → for → features",
        "sentence": "Inarbitrary distance measures are natural for the features.",
        "sentence_llm_dp_info": "\"Entity 1 ('inarbitrary distance measures') is the subject, depending on the verb 'are'. Entity 2 ('features') is the object of the preposition 'for', depending on 'for' in the phrase 'for the features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "matrix rank degeneration",
                "OtherScientificTerm"
            ],
            [
                "non-isolated minima",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is part of a compound noun, depending on the conjunction 'and' with Entity 2. Entity 2 ('non-isolated minima') is also part of a compound noun, depending on the conjunction 'and' with Entity 1. There is a direct dependency between Entity 1 and Entity 2, as they are connected through the conjunction 'and' in the phrase 'matrix rank degeneration & non-isolated minima'.\"",
        "sdp_path_text": "degeneration → minima",
        "sentence": "We address the problem of matrix rank degeneration and non-isolated minima.",
        "sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is part of a coordinated structure, depending on 'problem' through the preposition 'of'. Entity 2 ('non-isolated minima') is also part of a coordinated structure, depending on 'problem' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated elements under the same head, 'problem'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "matrix rank degeneration",
                "OtherScientificTerm"
            ],
            [
                "low-rank matrix optimization",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is part of the compound noun 'problem of matrix rank degeneration & non-isolated minima', depending on 'problem' as a modifier. Entity 2 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'in' in the phrase 'in the low-rank matrix optimization'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the problem addressed in the sentence.\"",
        "sdp_path_text": "degeneration → in → optimization",
        "sentence": "Matrix rank degeneration occurs in low-rank matrix optimization.",
        "sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is the subject, depending on the verb 'occurs'. Entity 2 ('low-rank matrix optimization') is the prepositional object, depending on the preposition 'in' which modifies 'occurs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' indicating the context in which the degeneration occurs.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "matrix rank degeneration",
                "OtherScientificTerm"
            ],
            [
                "regularizer",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is part of the compound object of the preposition 'of', depending on 'problem'. Entity 2 ('regularizer') is the object of the preposition 'using', depending on 'using' in the phrase 'using new type of regularizer'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of addressing a problem and using a method to solve it.\"",
        "sdp_path_text": "degeneration → of → problem → address → by → using → type → of → regularizer",
        "sentence": "Matrix rank degeneration is addressed by using a new type of regularizer.",
        "sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is the subject, depending on the verb 'is addressed'. Entity 2 ('regularizer') is the object of the preposition 'by', depending on 'using' in the phrase 'using a new type of regularizer'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'addressed' and the prepositional phrase 'by using a new type of regularizer'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "matrix rank degeneration",
                "OtherScientificTerm"
            ],
            [
                "or-thonormality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is part of a compound noun, depending on 'problem' with 'of'. Entity 2 ('or-thonormality') is the object of the verb 'enforces', depending on 'enforces' in the clause 'which approximately enforces the or-thonormality'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the problem being addressed and the solution (regularizer) that affects the or-thonormality of the matrix.\"",
        "sdp_path_text": "degeneration → of → problem → address → by → using → type → enforces → or",
        "sentence": "The problem of matrix rank degeneration is addressed by using a regularizer that enforces or-thonormality.",
        "sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is the subject, depending on the verb 'addressed'. Entity 2 ('or-thonormality') is the object of the relative clause, depending on 'enforces' with 'regularizer'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'addressed' and the relative clause describing the method used to address the problem.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "matrix rank degeneration",
                "OtherScientificTerm"
            ],
            [
                "learned matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is part of a compound noun, depending on 'problem' with the preposition 'of'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'or-thonormality'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different parts of the sentence structure, with Entity 1 being part of the problem addressed and Entity 2 being the subject of the or-thonormality enforcement.\"",
        "sdp_path_text": "degeneration → of → problem → address → by → using → type → enforces → thonormality → of → matrix",
        "sentence": "We address the problem of matrix rank degeneration by using a regularizer that enforces the or-thonormality of the learned matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('matrix rank degeneration') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'orthonormality'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the problem being addressed and the method used to address it.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "non-isolated minima",
                "OtherScientificTerm"
            ],
            [
                "low-rank matrix optimization",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is part of a compound noun phrase, depending on 'problem' as a modifier. Entity 2 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'in' in the phrase 'in the low-rank matrix optimization'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the problem being addressed.\"",
        "sdp_path_text": "minima → degeneration → in → optimization",
        "sentence": "Non-isolated minima occur in low-rank matrix optimization.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is the subject, depending on the verb 'occur'. Entity 2 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'in' in the phrase 'in low-rank matrix optimization'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "non-isolated minima",
                "OtherScientificTerm"
            ],
            [
                "regularizer",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is part of the compound noun 'matrix rank degeneration & non-isolated minima', depending on the preposition 'of' with 'problem'. Entity 2 ('regularizer') is the object of the preposition 'using', depending on 'optimization'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of addressing a problem in low-rank matrix optimization.\"",
        "sdp_path_text": "minima → degeneration → of → problem → address → by → using → type → of → regularizer",
        "sentence": "Non-isolated minima in the problem are addressed by using a new type of regularizer.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is the subject, depending on the verb 'are addressed'. Entity 2 ('regularizer') is the object of the preposition 'using', depending on 'using' in the phrase 'using a new type of regularizer'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'are addressed' and the means specified by the preposition 'using'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "non-isolated minima",
                "OtherScientificTerm"
            ],
            [
                "or-thonormality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is part of the compound object in the prepositional phrase 'of matrix rank degeneration & non-isolated minima', depending on the preposition 'of'. Entity 2 ('or-thonormality') is the object of the relative clause 'which approximately enforces the or-thonormality', depending on the verb 'enforces'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of the sentence but do not directly depend on each other.\"",
        "sdp_path_text": "minima → degeneration → of → problem → address → by → using → type → enforces → or",
        "sentence": "We address the problem of non-isolated minima by using a type that enforces or-thonormality.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('or-thonormality') is the object of the verb 'enforces', depending on 'type'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'non-isolated minima' is addressed by a method that involves 'or-thonormality'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "non-isolated minima",
                "OtherScientificTerm"
            ],
            [
                "learned matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is part of a conjunction, depending on 'degeneration' with 'and'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'or-thonormality'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of the sentence but do not directly depend on each other.\"",
        "sdp_path_text": "minima → degeneration → of → problem → address → by → using → type → enforces → thonormality → of → matrix",
        "sentence": "We address the problem of non-isolated minima by enforcing the orthonormality of the learned matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-isolated minima') is the object of the preposition 'of', depending on 'problem'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'orthonormality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "regularizer",
                "Method"
            ],
            [
                "low-rank matrix optimization",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regularizer') is the object of the preposition 'using', depending on 'using' in the phrase 'using new type of regularizer'. Entity 2 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'in' in the phrase 'in the low-rank matrix optimization'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the method used to address the problem.\"",
        "sdp_path_text": "regularizer → of → type → using → by → address → problem → of → degeneration → in → optimization",
        "sentence": "A new type of regularizer addresses the problem of matrix rank degeneration in low-rank matrix optimization.",
        "sentence_llm_dp_info": "\"Entity 1 ('regularizer') is the subject, depending on the verb 'addresses'. Entity 2 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'in' in the phrase 'in low-rank matrix optimization'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "low-rank matrix optimization",
                "Task"
            ],
            [
                "or-thonormality",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'problem'. Entity 2 ('or-thonormality') is the object of the verb 'enforces', depending on 'regularizer'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the sentence, where the 'regularizer' is used in the 'low-rank matrix optimization' to enforce 'or-thonormality'.\"",
        "sdp_path_text": "optimization → in → degeneration → of → problem → address → by → using → type → enforces → or",
        "sentence": "The low-rank matrix optimization addresses the problem of matrix rank degeneration by enforcing or-thonormality.",
        "sentence_llm_dp_info": "\"Entity 1 ('low-rank matrix optimization') is the subject, depending on the verb 'addresses'. Entity 2 ('or-thonormality') is the object, depending on the verb 'enforcing' in the phrase 'enforcing or-thonormality'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enforcing' which is part of the action taken by Entity 1 to address the problem.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "low-rank matrix optimization",
                "Task"
            ],
            [
                "learned matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'problem'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'orthonormality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the problem being addressed and the solution being described.\"",
        "sdp_path_text": "optimization → in → degeneration → of → problem → address → by → using → type → enforces → thonormality → of → matrix",
        "sentence": "The problem of matrix rank degeneration in low-rank matrix optimization is addressed by enforcing the orthonormality of the learned matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('low-rank matrix optimization') is the object of the preposition 'in', depending on 'problem'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'orthonormality'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the problem being addressed and the solution being applied.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "regularizer",
                "Method"
            ],
            [
                "or-thonormality",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regularizer') is the object, depending on 'using' with 'optimization'. Entity 2 ('or-thonormality') is the object, depending on 'enforces' with 'regularizer'. There is a direct dependency between Entity 1 and Entity 2, as 'regularizer' is the agent that enforces 'or-thonormality'.\"",
        "sdp_path_text": "regularizer → of → type → enforces → or",
        "sentence": "A new type of regularizer enforces or-thonormality of the learned matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('regularizer') is the subject, depending on the verb 'enforces'. Entity 2 ('or-thonormality') is the object, depending on 'enforces' with 'regularizer'. There is a direct dependency between Entity 1 and Entity 2, where 'regularizer' enforces 'or-thonormality'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "regularizer",
                "Method"
            ],
            [
                "learned matrix",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('regularizer') is the subject, depending on 'using' with 'new type of'. Entity 2 ('learned matrix') is the object, depending on 'enforces' with 'or-thonormality'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause that describes how the regularizer affects the learned matrix.\"",
        "sdp_path_text": "regularizer → of → type → enforces → thonormality → of → matrix",
        "sentence": "The regularizer enforces the orthonormality of the learned matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('regularizer') is the subject, depending on the verb 'enforces'. Entity 2 ('learned matrix') is the object, depending on the preposition 'of' in the phrase 'orthonormality of the learned matrix'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enforces' and the prepositional phrase 'of the learned matrix'.\""
    },
    {
        "raw_sentence": "We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently .",
        "ner_pair": [
            [
                "or-thonormality",
                "OtherScientificTerm"
            ],
            [
                "learned matrix",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('or-thonormality') is the object of the verb 'enforces', depending on 'enforces' in the clause 'which approximately enforces the or-thonormality'. Entity 2 ('learned matrix') is the object of the preposition 'of', depending on 'or-thonormality' in the phrase 'the or-thonormality of the learned matrix'. There is a direct dependency between Entity 1 and Entity 2, as 'learned matrix' specifies what the 'or-thonormality' is of.\"",
        "sdp_path_text": "or → enforces → thonormality → of → matrix",
        "sentence": "The regularizer enforces the or-thonormality of the learned matrix.",
        "sentence_llm_dp_info": "\"Entity 1 ('or-thonormality') is the object of the preposition 'of', depending on 'enforces' with 'the regularizer'. Entity 2 ('learned matrix') is the object, depending on 'or-thonormality' with the preposition 'of'. There is a direct dependency between Entity 1 and Entity 2, where 'or-thonormality' is the property of the 'learned matrix'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "person re-identification datasets",
                "Material"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('person re-identification datasets') is the object of the preposition 'on', depending on 'validate' with 'We'. Entity 2 ('method') is the object, depending on 'validate' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'validate'.\"",
        "sdp_path_text": "datasets → on → validate → method",
        "sentence": "We validate the method on person re-identification datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('person re-identification datasets') is the object, depending on the preposition 'on', which itself depends on the verb 'validate'. Entity 2 ('method') is the object of the preposition 'the', and it is also the direct object being validated. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'validate'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "scale Market-1501",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the verb 'validate', depending on 'validate' with 'We'. Entity 2 ('scale Market-1501') is part of a compound noun, depending on 'including' as one of the items listed after it. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the datasets being used to validate the method.\"",
        "sdp_path_text": "method → validate → on → datasets → including → datasets → scale",
        "sentence": "We validate the method on large scale Market-1501 datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'validate' with 'We'. Entity 2 ('scale Market-1501') is the modifier of the noun 'datasets', depending on 'datasets' in the noun phrase 'large scale Market-1501 datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'on large scale Market-1501 datasets'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "CUHK03 datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the verb 'validate', depending on 'validate' with 'We'. Entity 2 ('CUHK03 datasets') is part of a compound noun, depending on 'including' which itself depends on 'datasets'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where the method is validated on various datasets, including CUHK03.\"",
        "sdp_path_text": "method → validate → on → datasets → including → datasets",
        "sentence": "We validate the new method on CUHK03 datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'validate' with 'We validate the new method'. Entity 2 ('CUHK03 datasets') is also the object of the preposition 'on', depending directly on 'on' in the phrase 'on CUHK03 datasets'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'on'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'on', depending on 'validate' with 'We'. Entity 2 ('them') is the object of the preposition 'on', depending on 'show' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of different prepositions in the sentence.\"",
        "sdp_path_text": "method → validate → show → improve → upon → methods → on → all → of → them",
        "sentence": "We validate the new method and show that it improves upon the current state-of-the-art methods on all of them.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'the', depending on 'validate' with 'We'. Entity 2 ('them') is the object of the preposition 'of', depending on 'all'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'method' is validated and shown to improve upon 'them'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "scale Market-1501",
                "Material"
            ],
            [
                "person re-identification datasets",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scale Market-1501') is part of a compound noun, depending on 'including' with 'datasets'. Entity 2 ('person re-identification datasets') is the object of the preposition 'on', depending on 'validate' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the datasets being used for validation.\"",
        "sdp_path_text": "scale → datasets → including → datasets",
        "sentence": "We validate the method on large scale Market-1501 and other person re-identification datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('scale Market-1501') is part of the compound noun phrase, depending on 'large' as an adjective modifier and on 'on' as the object of the preposition in the phrase 'on large scale Market-1501'. Entity 2 ('person re-identification datasets') is also part of a noun phrase, depending on 'other' as an adjective modifier and on 'on' as the object of the preposition in the phrase 'on other person re-identification datasets'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same preposition 'on'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "CUHK03 datasets",
                "Material"
            ],
            [
                "person re-identification datasets",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CUHK03 datasets') is part of the list, depending on the conjunction 'and' which connects it to other items in the list 'nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets'. Entity 2 ('person re-identification datasets') is the object of the preposition 'on', depending on 'validate' in the phrase 'validate this new method on nine standard person re-identification datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list and contextually related through the preposition 'on'.\"",
        "sdp_path_text": "datasets → including → datasets",
        "sentence": "CUHK03 datasets are included among person re-identification datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('CUHK03 datasets') is the subject, depending on the verb 'are included'. Entity 2 ('person re-identification datasets') is the object of the preposition 'among', depending on 'among' in the phrase 'among person re-identification datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'among'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "person re-identification datasets",
                "Material"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('person re-identification datasets') is the object of the preposition 'on', depending on 'validate' with 'We'. Entity 2 ('them') is the object of the preposition 'on', depending on 'show' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are semantically related as 'them' refers back to 'person re-identification datasets'.\"",
        "sdp_path_text": "datasets → on → validate → show → improve → upon → methods → on → all → of → them",
        "sentence": "We validate the method on person re-identification datasets and show improvement over existing methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('person re-identification datasets') is the object, depending on the preposition 'on', which modifies the verb 'validate'. Entity 2 ('them') is the object, depending on the preposition 'over', which modifies the noun 'improvement'. There is no direct dependency between Entity 1 and Entity 2; however, 'them' likely refers back to 'person re-identification datasets' in the context of the sentence.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "CUHK03 datasets",
                "Material"
            ],
            [
                "scale Market-1501",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CUHK03 datasets') is the compound, depending on 'including' with 'datasets'. Entity 2 ('scale Market-1501') is the compound, depending on 'including' with 'datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list introduced by 'including'.\"",
        "sdp_path_text": "datasets → scale",
        "sentence": "CUHK03 datasets and scale Market-1501 are used to validate the new method.",
        "sentence_llm_dp_info": "\"Entity 1 ('CUHK03 datasets') is part of a coordinated structure, depending on the conjunction 'and' with 'scale Market-1501'. Entity 2 ('scale Market-1501') is also part of this coordinated structure, depending on the same conjunction 'and'. Both entities together form the subject of the clause, depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "scale Market-1501",
                "Material"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scale Market-1501') is part of a compound noun, depending on 'including' with 'datasets'. Entity 2 ('them') is the object of the preposition 'on', depending on 'on' in the phrase 'on all of them'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the datasets being discussed in the sentence.\"",
        "sdp_path_text": "scale → datasets → including → datasets → on → validate → show → improve → upon → methods → on → all → of → them",
        "sentence": "We validate the method on large scale datasets, including Market-1501, and show improvement over current methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('scale Market-1501') is part of a compound noun, where 'scale' modifies 'datasets', and it depends on 'on' in the prepositional phrase 'on large scale datasets'. Entity 2 ('them') is the object of the verb 'over', depending on 'methods' in the phrase 'current methods'. There is no direct dependency between Entity 1 and Entity 2.\" \n\nHowever, the entities provided might not be the most accurate for the given sentence. If you intended to analyze different parts of the sentence, please specify the correct entities or provide more context. For instance, if you meant 'Market-1501' as a whole and 'methods' instead of 'them', the analysis would differ."
    },
    {
        "raw_sentence": "We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them .",
        "ner_pair": [
            [
                "CUHK03 datasets",
                "Material"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CUHK03 datasets') is part of a compound noun, depending on 'including' with 'datasets'. Entity 2 ('them') is the object, depending on 'upon' with 'improve'. There is no direct dependency between Entity 1 and Entity 2; however, they are indirectly related through the context provided by the sentence, where 'them' refers back to the datasets mentioned, including 'CUHK03 datasets'.\"",
        "sdp_path_text": "datasets → including → datasets → on → validate → show → improve → upon → methods → on → all → of → them",
        "sentence": "We show improvement upon state-of-the-art methods on CUHK03 datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('CUHK03 datasets') is the object of the preposition 'on', depending on 'methods'. Entity 2 ('them') is not explicitly mentioned in the sentence provided; however, if we assume 'them' refers back to 'state-of-the-art methods', then 'them' would be the object of the preposition 'upon', depending on 'improvement'. There is no direct dependency between Entity 1 and Entity 2, as 'them' is not present in the given sentence and 'CUHK03 datasets' is part of a different clause.\" \n\nHowever, since 'them' is not actually present in the sentence, a more accurate response would be:\n\n\"Entity 1 ('CUHK03 datasets') is the object of the preposition 'on', depending on 'methods'. Entity 2 ('them') is not present in the sentence, so no dependencies can be described for it. There is no direct dependency between Entity 1 and Entity 2, as Entity 2 is not part of the sentence.\""
    },
    {
        "raw_sentence": "In this paper , we discuss language model adaptation methods given a word list and a raw corpus .",
        "ner_pair": [
            [
                "word list",
                "OtherScientificTerm"
            ],
            [
                "language model adaptation methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word list') is the object of the preposition 'given', depending on 'given' in the phrase 'given a word list'. Entity 2 ('language model adaptation methods') is the direct object, depending on 'discuss' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context provided for the discussion in the sentence.\"",
        "sdp_path_text": "list → given → methods",
        "sentence": "Language model adaptation methods are discussed given a word list.",
        "sentence_llm_dp_info": "\"Entity 1 ('word list') is the object of the preposition 'given', depending on 'given' in the phrase 'given a word list'. Entity 2 ('language model adaptation methods') is the subject, depending on the verb 'are discussed'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the prepositional phrase 'given a word list' which provides a condition for the discussion of Entity 2.\""
    },
    {
        "raw_sentence": "In this paper , we discuss language model adaptation methods given a word list and a raw corpus .",
        "ner_pair": [
            [
                "raw corpus",
                "Material"
            ],
            [
                "language model adaptation methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the object of the preposition 'given', depending on 'given' in the phrase 'given a word list and a raw corpus'. Entity 2 ('language model adaptation methods') is the direct object, depending on the verb 'discuss'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context provided for the discussion.\"",
        "sdp_path_text": "corpus → list → given → methods",
        "sentence": "We discuss language model adaptation methods given a raw corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the object of the preposition 'given', depending on 'given' in the phrase 'given a raw corpus'. Entity 2 ('language model adaptation methods') is the direct object, depending on 'discuss' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of the discussion.\""
    },
    {
        "raw_sentence": "In this paper , we discuss language model adaptation methods given a word list and a raw corpus .",
        "ner_pair": [
            [
                "word list",
                "OtherScientificTerm"
            ],
            [
                "raw corpus",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word list') is the object of the preposition 'given', depending on 'given' in the phrase 'given a word list'. Entity 2 ('raw corpus') is also the object of the preposition 'given', depending on 'given' in the phrase 'given a raw corpus'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'given'.\"",
        "sdp_path_text": "list → corpus",
        "sentence": "We discuss language model adaptation methods given a word list and a raw corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('word list') is the object of the preposition 'given', depending on 'given' in the phrase 'given a word list'. Entity 2 ('raw corpus') is also the object of the preposition 'given', depending on 'given' in the phrase 'given a raw corpus'. There is no direct dependency between Entity 1 and Entity 2; both are listed as objects of the same preposition 'given'.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "raw corpus",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'is' with 'the general'. Entity 2 ('raw corpus') is the object, depending on 'segment' with 'to segment the raw corpus automatically'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the method involves actions performed on the raw corpus.\"",
        "sdp_path_text": "method → is → segment → corpus",
        "sentence": "The method is to segment the raw corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is'. Entity 2 ('raw corpus') is the object, depending on 'segment' with 'the'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'segment' which describes the action performed on Entity 2 by Entity 1.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "word list",
                "OtherScientificTerm"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word list') is the object, depending on 'using' which modifies the verb 'segment'. Entity 2 ('method') is the subject, depending on 'is' as the main verb of the clause. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action described by the verb 'segment'.\"",
        "sdp_path_text": "list → using → segment → is → method",
        "sentence": "The method uses a word list to segment the raw corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('word list') is the object of the preposition 'a', depending on 'uses' in the phrase 'uses a word list'. Entity 2 ('method') is the subject, depending on the verb 'uses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses'.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is' in the phrase 'the general method is'. Entity 2 ('model') is the object of the verb 'build', depending on 'build' in the phrase 'build a model'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence describing different actions in a process.\"",
        "sdp_path_text": "method → is → segment → correct → build → model",
        "sentence": "The method involves segmenting and correcting a corpus to build a model.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'involves'. Entity 2 ('model') is the object, depending on the verb 'build' in the phrase 'to build a model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the series of actions described in the sentence.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "segmented corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'is' (is used). Entity 2 ('segmented corpus') is the object, depending on 'from' in the phrase 'from the segmented corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the process described in the sentence.\"",
        "sdp_path_text": "method → is → segment → correct → build → from → corpus",
        "sentence": "The method involves segmenting and correcting the corpus to build a model.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'involves'. Entity 2 ('segmented corpus') is the object of the verb 'correcting', which is part of a compound verb 'segmenting and correcting'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'involves' and the actions described (segmenting and correcting) that are applied to the corpus.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "raw corpus",
                "Material"
            ],
            [
                "word list",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the object of the verb 'segment', depending on 'segment' in the phrase 'to segment the raw corpus'. Entity 2 ('word list') is the object of the preposition 'using', depending on 'using' in the phrase 'using a word list'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger process described in the sentence, where the 'word list' is used as a tool to 'segment the raw corpus'.\"",
        "sdp_path_text": "corpus → segment → using → list",
        "sentence": "The raw corpus is segmented using a word list.",
        "sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the subject, depending on the verb 'is segmented'. Entity 2 ('word list') is the object of the preposition 'using', depending on 'using' in the phrase 'using a word list'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is segmented' and the preposition 'using'.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "raw corpus",
                "Material"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the object of the verb 'segment', depending on the verb 'is' in the clause 'the general method is to segment the raw corpus'. Entity 2 ('model') is the object of the verb 'build', depending on the verb 'build' in the clause 'and build a model from the segmented corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\"",
        "sdp_path_text": "corpus → segment → correct → build → model",
        "sentence": "The raw corpus is segmented, corrected, and used to build a model.",
        "sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the subject, depending on the verb 'is' in the clause 'The raw corpus is segmented, corrected, and used'. Entity 2 ('model') is the object, depending on 'build' in the phrase 'to build a model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' which indicates that the 'raw corpus' is utilized in the process of building the 'model'.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "raw corpus",
                "Material"
            ],
            [
                "segmented corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the object of the verb 'segment', depending on 'segment' in the phrase 'segment the raw corpus'. Entity 2 ('segmented corpus') is the object of the preposition 'from', depending on 'from' in the phrase 'from the segmented corpus'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process of segmentation described in the sentence.\"",
        "sdp_path_text": "corpus → segment → correct → build → from → corpus",
        "sentence": "The raw corpus is segmented, corrected, and used to build a model for the segmented corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('raw corpus') is the subject, depending on the verb 'is' in the phrase 'is segmented, corrected, and used'. Entity 2 ('segmented corpus') is the object of the preposition 'for', depending on 'for' in the phrase 'for the segmented corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the process described in the sentence.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "word list",
                "OtherScientificTerm"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word list') is the object, depending on 'using' which modifies the verb 'segment'. Entity 2 ('model') is the object, depending on 'build' which is part of the verb phrase 'and build a model'. There is no direct dependency between Entity 1 and Entity 2; both are part of the process described in the sentence but are not directly linked in terms of dependency relations.\"",
        "sdp_path_text": "list → using → segment → correct → build → model",
        "sentence": "A word list is used to segment and correct sentences, building a model from the segmented corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('word list') is the subject, depending on the verb 'used'. Entity 2 ('model') is the object, depending on 'building' with 'model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described by the verbs 'used' and 'building'.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "word list",
                "OtherScientificTerm"
            ],
            [
                "segmented corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word list') is the object, depending on 'using' which modifies the verb 'segment'. Entity 2 ('segmented corpus') is the object of the preposition 'from', depending on 'build' in the phrase 'build a model from the segmented corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described in the sentence, with 'word list' being used in the segmentation process that results in the 'segmented corpus'.\"",
        "sdp_path_text": "list → using → segment → correct → build → from → corpus",
        "sentence": "A word list is used to segment the corpus, which is then corrected and used to build a model.",
        "sentence_llm_dp_info": "\"Entity 1 ('word list') is the subject, depending on the verb 'used'. Entity 2 ('segmented corpus') is the object, depending on the verb 'segment'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the process described by 'to segment the corpus'.\""
    },
    {
        "raw_sentence": "In this situation , the general method is to segment the raw corpus automatically using a word list , correct the output sentences by hand , and build a model from the segmented corpus .",
        "ner_pair": [
            [
                "segmented corpus",
                "Material"
            ],
            [
                "model",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('segmented corpus') is the object, depending on 'build' with 'model'. Entity 2 ('model') is the subject, depending on 'build' as part of the verb phrase 'build a model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'build' which indicates that the 'model' is built from the 'segmented corpus'.\"",
        "sdp_path_text": "corpus → from → build → model",
        "sentence": "A model is built from the segmented corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('segmented corpus') is the object, depending on the preposition 'from' with 'built'. Entity 2 ('model') is the subject, depending on the verb 'is built'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' indicating that the 'model' is constructed using the 'segmented corpus'.\""
    },
    {
        "raw_sentence": "In the experiments , we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "preparing a segmented corpus",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the object of the preposition 'of', depending on 'variety'. Entity 2 ('preparing a segmented corpus') is the object of the preposition 'for', depending on 'methods'. There is a direct dependency between Entity 1 and Entity 2, as 'preparing a segmented corpus' is part of the methods used.\"",
        "sdp_path_text": "methods → of → variety → used → for → preparing",
        "sentence": "We used various methods for preparing a segmented corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the object, depending on 'used' with 'We'. Entity 2 ('preparing a segmented corpus') is the object of the preposition 'for', depending on 'for' in the phrase 'for preparing a segmented corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In the experiments , we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "language models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the object of the preposition 'of', depending on 'variety'. Entity 2 ('language models') is the object of the preposition 'by', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "methods → of → variety → used → compared → models",
        "sentence": "A variety of methods were used and compared for language models.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on the passive verb 'were used' and also linked to 'compared' through coordination. Entity 2 ('language models') is the object of the preposition 'for', depending on 'for' in the phrase 'for language models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose or application context of the methods.\""
    },
    {
        "raw_sentence": "In the experiments , we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies .",
        "ner_pair": [
            [
                "methods",
                "Generic"
            ],
            [
                "speech recognition accuracies",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('methods') is the object of the preposition 'of', depending on 'variety'. Entity 2 ('speech recognition accuracies') is the object of the preposition 'by', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the actions taken in the experiments.\"",
        "sdp_path_text": "methods → of → variety → used → compared → by → accuracies",
        "sentence": "A variety of methods were used and compared by speech recognition accuracies.",
        "sentence_llm_dp_info": "\"Entity 1 ('methods') is the subject, depending on the passive verb 'were used' and also part of the compound verb 'were used and compared'. Entity 2 ('speech recognition accuracies') is the object of the preposition 'by', depending on 'by' in the phrase 'by speech recognition accuracies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'used' and 'compared' which describe actions performed relative to both entities.\""
    },
    {
        "raw_sentence": "In the experiments , we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies .",
        "ner_pair": [
            [
                "preparing a segmented corpus",
                "Task"
            ],
            [
                "language models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('preparing a segmented corpus') is the object of the preposition 'for', depending on 'methods'. Entity 2 ('language models') is the subject of the verb 'compared'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the experiments conducted.\"",
        "sdp_path_text": "preparing → for → used → compared → models",
        "sentence": "We prepared a segmented corpus and compared language models.",
        "sentence_llm_dp_info": "\"Entity 1 ('preparing a segmented corpus') is part of the compound verb 'prepared a segmented corpus', where 'prepared' is the main verb and 'a segmented corpus' is its direct object. Entity 2 ('language models') is the object of the verb 'compared'. There is no direct dependency between Entity 1 and Entity 2; both are actions described in the sentence but are not directly linked in terms of dependency structure.\""
    },
    {
        "raw_sentence": "In the experiments , we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies .",
        "ner_pair": [
            [
                "preparing a segmented corpus",
                "Task"
            ],
            [
                "speech recognition accuracies",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('preparing a segmented corpus') is part of the object complement, depending on 'methods' through the preposition 'for'. Entity 2 ('speech recognition accuracies') is the object of the preposition 'by', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence, with Entity 1 being part of the methods used and Entity 2 being the metric by which the language models were compared.\"",
        "sdp_path_text": "preparing → for → used → compared → by → accuracies",
        "sentence": "Preparing a segmented corpus was used and compared by speech recognition accuracies.",
        "sentence_llm_dp_info": "\"Entity 1 ('preparing a segmented corpus') is the subject, depending on the passive verb 'was used'. Entity 2 ('speech recognition accuracies') is the object, depending on the preposition 'by' in the phrase 'by speech recognition accuracies'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction and the preposition 'by'.\""
    },
    {
        "raw_sentence": "In the experiments , we used a variety of methods for preparing a segmented corpus and compared the language models by their speech recognition accuracies .",
        "ner_pair": [
            [
                "speech recognition accuracies",
                "Metric"
            ],
            [
                "language models",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech recognition accuracies') is the object of the preposition 'by', depending on 'compared'. Entity 2 ('language models') is the object of the preposition 'of', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparison described in the sentence.\"",
        "sdp_path_text": "accuracies → by → compared → models",
        "sentence": "Speech recognition accuracies were compared by language models.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech recognition accuracies') is the subject, depending on the verb 'were compared'. Entity 2 ('language models') is the object of the preposition 'by', depending on 'by' in the phrase 'by language models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'were compared' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions .",
        "ner_pair": [
            [
                "discrete data",
                "Material"
            ],
            [
                "modeling problems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discrete data') is the subject complement, depending on 'involve' with 'problems'. Entity 2 ('modeling problems') is the subject, depending on 'are' with 'Many practical'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'involve'.\"",
        "sdp_path_text": "data → involve → problems",
        "sentence": "Discrete data are involved in many modeling problems.",
        "sentence_llm_dp_info": "\"Entity 1 ('discrete data') is the subject, depending on the verb 'are involved'. Entity 2 ('modeling problems') is the object of the preposition 'in', depending on 'involved' in the phrase 'involved in'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' and the verb 'are involved'.\""
    },
    {
        "raw_sentence": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions .",
        "ner_pair": [
            [
                "multinomial or categorical distributions",
                "Method"
            ],
            [
                "modeling problems",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial or categorical distributions') is the complement of the preposition 'as', depending on 'represented'. Entity 2 ('modeling problems') is the subject, depending on the verb 'involve'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'involve' and the prepositional phrase 'as draws from multinomial or categorical distributions'.\"",
        "sdp_path_text": "distributions → from → draws → as → represented → data → involve → problems",
        "sentence": "Modeling problems involve data represented as draws from multinomial or categorical distributions.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial or categorical distributions') is the object of the preposition 'from', depending on 'draws'. Entity 2 ('modeling problems') is the subject, depending on the verb 'involve'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'involve' and the noun phrase 'data represented as draws from'.\""
    },
    {
        "raw_sentence": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions .",
        "ner_pair": [
            [
                "discrete data",
                "Material"
            ],
            [
                "multinomial or categorical distributions",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discrete data') is the subject complement, depending on the verb 'involve'. Entity 2 ('multinomial or categorical distributions') is the object of the preposition 'as', depending on 'as' in the phrase 'as draws from multinomial or categorical distributions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'as'.\"",
        "sdp_path_text": "data → represented → as → draws → from → distributions",
        "sentence": "Discrete data are represented as draws from multinomial or categorical distributions.",
        "sentence_llm_dp_info": "\"Entity 1 ('discrete data') is the subject, depending on the verb 'are represented'. Entity 2 ('multinomial or categorical distributions') is the object of the preposition 'from', depending on 'draws'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are represented' and the prepositional phrase 'as draws from multinomial or categorical distributions'.\""
    },
    {
        "raw_sentence": "For example , nucleotides in a DNA sequence , children 's names in a given state and year , and text documents are all commonly modeled with multinomial distributions .",
        "ner_pair": [
            [
                "nucleotides in a DNA sequence",
                "Material"
            ],
            [
                "text documents",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nucleotides in a DNA sequence') is part of a list, coordinated with 'children’s names in a given state and year' and 'text documents', and together they are the subject of the clause, depending on the verb 'are'. Entity 2 ('text documents') is also part of the same list, coordinated with 'nucleotides in a DNA sequence' and 'children’s names in a given state and year', and together they form the subject of the clause, depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both elements of a coordinated subject.\"",
        "sdp_path_text": "nucleotides → modeled → names → documents",
        "sentence": "Nucleotides in a DNA sequence and text documents are commonly modeled.",
        "sentence_llm_dp_info": "\"Entity 1 ('nucleotides in a DNA sequence') is the subject, depending on the verb 'modeled'. Entity 2 ('text documents') is also a subject, depending on the same verb 'modeled'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated subjects of the verb 'modeled'.\""
    },
    {
        "raw_sentence": "For example , nucleotides in a DNA sequence , children 's names in a given state and year , and text documents are all commonly modeled with multinomial distributions .",
        "ner_pair": [
            [
                "multinomial distributions",
                "Method"
            ],
            [
                "nucleotides in a DNA sequence",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial distributions') is the object, depending on the verb 'modeled' with 'are all commonly modeled'. Entity 2 ('nucleotides in a DNA sequence') is the first item in a list of examples, depending on the conjunction 'and' which connects it with other examples. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'modeled' which indicates that Entity 2 (along with other items) can be modeled using Entity 1.\"",
        "sdp_path_text": "distributions → with → modeled → nucleotides",
        "sentence": "Nucleotides in a DNA sequence are modeled with multinomial distributions.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial distributions') is the object, depending on the verb 'modeled'. Entity 2 ('nucleotides in a DNA sequence') is the subject, also depending on the verb 'modeled'. There is a direct dependency between Entity 1 and Entity 2, as 'nucleotides in a DNA sequence' are being modeled with 'multinomial distributions'.\""
    },
    {
        "raw_sentence": "For example , nucleotides in a DNA sequence , children 's names in a given state and year , and text documents are all commonly modeled with multinomial distributions .",
        "ner_pair": [
            [
                "multinomial distributions",
                "Method"
            ],
            [
                "text documents",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial distributions') is the object, depending on the verb 'modeled' with 'are'. Entity 2 ('text documents') is the subject, depending on the conjunction 'and' with other subjects like 'nucleotides' and 'children’s names'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items that can be modeled with multinomial distributions.\"",
        "sdp_path_text": "distributions → with → modeled → names → documents",
        "sentence": "Text documents are modeled with multinomial distributions.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial distributions') is the object, depending on 'modeled' with 'are'. Entity 2 ('text documents') is the subject, depending on the verb 'are modeled'. There is a direct dependency between Entity 1 and Entity 2, as 'text documents' are the subject being modeled with 'multinomial distributions'.\""
    },
    {
        "raw_sentence": "In all of these cases , we expect some form of dependency between the draws : the nucleotide at one position in the DNA strand may depend on the preceding nucleotides , children 's names are highly correlated from year to year , and topics in text may be correlated and dynamic .",
        "ner_pair": [
            [
                "nucleotide",
                "OtherScientificTerm"
            ],
            [
                "DNA strand",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nucleotide') is the subject of the clause 'the nucleotide at one position in the DNA strand may depend on the preceding nucleotides', depending on the preposition 'at' with 'one position'. Entity 2 ('DNA strand') is the object of the preposition 'in', depending on 'position'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional phrase 'at one position in the DNA strand'.\"",
        "sdp_path_text": "nucleotide → at → position → in → strand",
        "sentence": "The nucleotide at a position in the DNA strand may depend on preceding nucleotides.",
        "sentence_llm_dp_info": "\"Entity 1 ('nucleotide') is the subject of the clause, depending on the verb 'depend'. Entity 2 ('DNA strand') is the object of the preposition 'in', depending on 'in' in the phrase 'in the DNA strand'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that specifies the location of the nucleotide.\""
    },
    {
        "raw_sentence": "In all of these cases , we expect some form of dependency between the draws : the nucleotide at one position in the DNA strand may depend on the preceding nucleotides , children 's names are highly correlated from year to year , and topics in text may be correlated and dynamic .",
        "ner_pair": [
            [
                "DNA strand",
                "OtherScientificTerm"
            ],
            [
                "preceding nucleotides",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('DNA strand') is part of a prepositional phrase, depending on 'at' with 'position'. Entity 2 ('preceding nucleotides') is the object of the preposition 'on', depending on 'depend'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'depend' which indicates a relationship where the nucleotide at one position in the DNA strand may depend on the preceding nucleotides.\"",
        "sdp_path_text": "strand → in → position → at → nucleotide → depend → on → nucleotides",
        "sentence": "The nucleotide at a position in the DNA strand may depend on the preceding nucleotides.",
        "sentence_llm_dp_info": "\"Entity 1 ('DNA strand') is the object of the preposition 'in', depending on 'position'. Entity 2 ('preceding nucleotides') is the object of the preposition 'on', depending on 'depend'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the dependency relationship in the context of the sentence.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of a conjunction, depending on the verb 'leverage' with 'we'. Entity 2 ('Pólya-gamma augmentation') is also part of a conjunction, depending on the same verb 'leverage' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'leverage' within the same clause.\"",
        "sdp_path_text": "representation → innovations → in → augmentation",
        "sentence": "We leverage a logistic stick-breaking representation and innovations in Pólya-gamma augmentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of the compound object, depending on 'leverage' with 'We'. Entity 2 ('Pólya-gamma augmentation') is also part of the compound object, depending on 'and' which connects it to 'logistic stick-breaking representation'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the verb 'leverage' and are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "multinomial distribution",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of the object of the preposition 'a', depending on 'leverage'. Entity 2 ('multinomial distribution') is the object of the preposition 'the', depending on 'reformulate'. There is no direct dependency between Entity 1 and Entity 2; both are involved in the clause describing the action of reformulating the multinomial distribution using the logistic stick-breaking representation and other innovations.\"",
        "sdp_path_text": "representation → leverage → late → distribution",
        "sentence": "We leverage a logistic stick-breaking representation to reformulate the multinomial distribution.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object of the preposition 'a', depending on 'leverage'. Entity 2 ('multinomial distribution') is the object, depending on 'reformulate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reformulate' which indicates that Entity 1 is used to reformulate Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of the object of the preposition 'a', depending on 'leverage' with 'we'. Entity 2 ('latent variables') is the object of the preposition 'of', depending on 'reformulate' with 'distribution'. There is no direct dependency between Entity 1 and Entity 2; both are involved in the broader context of methods and representations used to reformulate the multinomial distribution.\"",
        "sdp_path_text": "representation → leverage → late → distribution → in → terms → of → variables",
        "sentence": "We leverage a logistic stick-breaking representation to reformulate the distribution in terms of latent variables.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object, depending on the verb 'leverage'. Entity 2 ('latent variables') is the object of the preposition 'of', depending on 'terms' in the phrase 'in terms of latent variables'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'reformulate' which indicates that Entity 1 is used to reformulate the distribution in terms of Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object of the preposition 'a', depending on 'leverage' with 'we'. Entity 2 ('jointly Gaussian likelihoods') is the complement of the preposition 'with', depending on 'variables'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context of the sentence describing methods used to reformulate the multinomial distribution.\"",
        "sdp_path_text": "representation → leverage → late → with → likelihoods",
        "sentence": "We leverage a logistic stick-breaking representation with jointly Gaussian likelihoods.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object, depending on 'leverage' with 'We'. Entity 2 ('jointly Gaussian likelihoods') is the object complement, depending on 'with' in the phrase 'with jointly Gaussian likelihoods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being leveraged.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "Bayesian inference techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of the object of the verb 'leverage', depending on 'and' which connects it to 'recent innovations in Pólya-gamma augmentation'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'take advantage of'. There is no direct dependency between Entity 1 and Entity 2; both contribute to the overall process described in the sentence, but they are not directly linked in the dependency structure.\"",
        "sdp_path_text": "representation → leverage → enabling → take → of → host → of → techniques",
        "sentence": "Leveraging a logistic stick-breaking representation enables taking advantage of Bayesian inference techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object of the gerund 'Leveraging', depending on 'Leveraging'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'techniques' in the phrase 'of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'Leveraging' leads to 'taking advantage of' Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of the object of the verb 'leverage', depending on 'leverage' with 'we'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'for' in the phrase 'for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of the sentence, where Entity 1 is used along with other innovations to reformulate the multinomial distribution, which then enables the use of techniques related to Entity 2.\"",
        "sdp_path_text": "representation → leverage → enabling → take → of → host → of → techniques → for → models",
        "sentence": "Leveraging a logistic stick-breaking representation enables taking advantage of techniques for Gaussian models.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object of the verb 'Leveraging', depending on the verb 'enables'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the enabling action and the techniques used.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "logistic stick-breaking representation",
                "Method"
            ],
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is part of the compound object of the verb 'leverage', depending on 'and' which connects it to 'recent innovations in Pólya-gamma augmentation'. Entity 2 ('minimal overhead') is the complement of the preposition 'with', depending on 'with' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing what enables the taking advantage of Bayesian inference techniques.\"",
        "sdp_path_text": "representation → leverage → enabling → take → of → host → of → techniques → for → models → with → overhead",
        "sentence": "Leveraging a logistic stick-breaking representation enables taking advantage of Bayesian inference techniques for Gaussian models with minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('logistic stick-breaking representation') is the object of the gerund-participle 'Leveraging', depending on 'enables'. Entity 2 ('minimal overhead') is the object complement, depending on 'with' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the enabling effect of leveraging the logistic stick-breaking representation.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            [
                "multinomial distribution",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is part of the compound noun phrase, depending on 'innovations' with the preposition 'in'. Entity 2 ('multinomial distribution') is the object of the verb 'reformulate', depending on 'reformulate' with the preposition 'the'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the clause describing the method used to reformulate the multinomial distribution.\"",
        "sdp_path_text": "augmentation → in → innovations → representation → leverage → late → distribution",
        "sentence": "We leverage Pólya-gamma augmentation to reformulate the multinomial distribution.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the object of the preposition 'to', depending on 'leverage'. Entity 2 ('multinomial distribution') is the object of the verb 'reformulate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the action of leveraging and reformulating.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the object of the preposition 'in', depending on the prepositional phrase 'in Pólya-gamma augmentation'. Entity 2 ('latent variables') is the object of the preposition 'of', depending on the phrase 'terms of latent variables'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the clause describing the reformulation of the multinomial distribution.\"",
        "sdp_path_text": "augmentation → in → innovations → representation → leverage → late → distribution → in → terms → of → variables",
        "sentence": "We leverage Pólya-gamma augmentation to represent the multinomial distribution in terms of latent variables.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the object of the verb 'leverage', depending on 'we'. Entity 2 ('latent variables') is the object of the preposition 'of', depending on 'variables' in the phrase 'in terms of latent variables'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and are connected through the verb 'represent'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the object of the preposition 'in', depending on 'innovations'. Entity 2 ('jointly Gaussian likelihoods') is the object of the preposition 'with', depending on 'variables'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause describing the reformulation of the multinomial distribution.\"",
        "sdp_path_text": "augmentation → in → innovations → representation → leverage → late → with → likelihoods",
        "sentence": "Recent innovations in Pólya-gamma augmentation enable the use of jointly Gaussian likelihoods.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the object of the preposition 'in', depending on 'innovations'. Entity 2 ('jointly Gaussian likelihoods') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the enabling of certain methods by recent innovations.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            [
                "Bayesian inference techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is part of a compound noun, depending on 'and' which connects it to 'logistic stick-breaking representation'. It is also the object of the preposition 'in', forming the phrase 'in Pólya-gamma augmentation'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'techniques' in the phrase 'techniques for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that contribute to the overall meaning of the sentence.\"",
        "sdp_path_text": "augmentation → in → innovations → representation → leverage → enabling → take → of → host → of → techniques",
        "sentence": "Pólya-gamma augmentation enables taking advantage of Bayesian inference techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the subject, depending on the verb 'enables'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'advantage' in the phrase 'advantage of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables' and the prepositional phrase 'taking advantage of'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is part of a compound noun, depending on 'and' which connects it to 'logistic stick-breaking representation'. It is also an instrumental modifier, depending on 'reformulate' with the phrase 'to reformulate the multinomial distribution'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques' in the phrase 'Bayesian inference techniques for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the sentence that discusses methods used to reformulate and enable certain techniques.\"",
        "sdp_path_text": "augmentation → in → innovations → representation → leverage → enabling → take → of → host → of → techniques → for → models",
        "sentence": "Pólya-gamma augmentation enables techniques for Gaussian models.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the subject, depending on the verb 'enables'. Entity 2 ('Gaussian models') is the object, depending on 'enables' with 'Pólya-gamma augmentation'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 enables Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Pólya-gamma augmentation",
                "Task"
            ],
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is part of the compound noun phrase, depending on 'innovations' with the preposition 'in'. Entity 2 ('minimal overhead') is the object complement, depending on 'overhead' with the adjective 'minimal'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the broader context of enabling Bayesian inference techniques with low additional cost.\"",
        "sdp_path_text": "augmentation → in → innovations → representation → leverage → enabling → take → of → host → of → techniques → for → models → with → overhead",
        "sentence": "Pólya-gamma augmentation enables taking advantage of Bayesian inference techniques for Gaussian models with minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('Pólya-gamma augmentation') is the subject, depending on the verb 'enables'. Entity 2 ('minimal overhead') is the object, depending on the preposition 'with' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'enables' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            [
                "multinomial distribution",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the object of the preposition 'in', depending on 'reformulate' in the phrase 'reformulate the multinomial distribution in terms of latent variables'. Entity 2 ('multinomial distribution') is the direct object, depending on 'reformulate' with 'to reformulate the multinomial distribution'. There is a direct dependency between Entity 1 and Entity 2, as the sentence describes the reformulation of Entity 2 in terms of Entity 1.\"",
        "sdp_path_text": "variables → of → terms → in → distribution",
        "sentence": "Latent variables are used to reformulate the multinomial distribution.",
        "sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the subject, depending on the verb 'used'. Entity 2 ('multinomial distribution') is the object of the verb 'reformulate', depending on 'reformulate' in the phrase 'to reformulate the multinomial distribution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'used' and the purpose clause 'to reformulate the multinomial distribution'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "multinomial distribution",
                "Method"
            ],
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the object of the verb 'reformulate', depending on 'reformulate' with 'to reformulate the multinomial distribution'. Entity 2 ('jointly Gaussian likelihoods') is the complement of the preposition 'with', depending on 'with' in the phrase 'with jointly Gaussian likelihoods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the multinomial distribution is reformulated in terms of latent variables that have jointly Gaussian likelihoods.\"",
        "sdp_path_text": "distribution → late → with → likelihoods",
        "sentence": "The multinomial distribution is reformulated with jointly Gaussian likelihoods.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the subject, depending on the passive verb 'is reformulated'. Entity 2 ('jointly Gaussian likelihoods') is the object of the preposition 'with', depending on 'reformulated' in the phrase 'with jointly Gaussian likelihoods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is reformulated' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "multinomial distribution",
                "Method"
            ],
            [
                "Bayesian inference techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the object of the verb 'reformulate', depending on 'reformulate' which is part of the clause 'to reformulate the multinomial distribution'. Entity 2 ('Bayesian inference techniques') is the object of the verb 'take advantage of', depending on 'take advantage of' in the clause 'enabling us to take advantage of a host of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the purpose of reformulating the multinomial distribution to enable the use of Bayesian inference techniques.\"",
        "sdp_path_text": "distribution → late → leverage → enabling → take → of → host → of → techniques",
        "sentence": "The multinomial distribution is reformulated to enable the use of Bayesian inference techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the subject, depending on the passive verb 'is reformulated'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'use' in the phrase 'the use of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose of the reformulation which enables the use of Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "multinomial distribution",
                "Method"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the object of the verb 'reformulate', depending on the verb 'reformulate' which is part of the clause 'to reformulate the multinomial distribution'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques' in the phrase 'Bayesian inference techniques for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose of the reformulation and the techniques that can be applied as a result.\"",
        "sdp_path_text": "distribution → late → leverage → enabling → take → of → host → of → techniques → for → models",
        "sentence": "The multinomial distribution is reformulated to enable the use of techniques for Gaussian models.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the subject, depending on the passive verb 'is reformulated'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'to enable the use of techniques for Gaussian models'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "multinomial distribution",
                "Method"
            ],
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the object of the verb 'reformulate', depending on 'reformulate' which is part of the clause 'to reformulate the multinomial distribution'. Entity 2 ('minimal overhead') is the object complement, depending on 'overhead' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the broader context of the sentence where the reformulation of the multinomial distribution enables taking advantage of Bayesian inference techniques with minimal overhead.\"",
        "sdp_path_text": "distribution → late → leverage → enabling → take → of → host → of → techniques → for → models → with → overhead",
        "sentence": "Leveraging innovations enables reformulating the multinomial distribution with minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('multinomial distribution') is the object of the preposition 'the', depending on 'reformulating' with the prepositional phrase 'the multinomial distribution'. Entity 2 ('minimal overhead') is the object complement, depending on 'with' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the outcome of leveraging innovations.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the object, depending on the verb 'with' in the phrase 'with jointly Gaussian likelihoods'. Entity 2 ('latent variables') is the object of the preposition 'of', depending on 'reformulate' in the phrase 'reformulate the multinomial distribution in terms of latent variables'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the reformulation process.\"",
        "sdp_path_text": "likelihoods → with → late → distribution → in → terms → of → variables",
        "sentence": "The likelihoods are with the latent variables in the distribution.",
        "sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the subject, depending on the verb 'are'. Entity 2 ('latent variables') is the object of the preposition 'with', depending on 'with' in the phrase 'with the latent variables'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'with' which indicates an association or connection between them.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            [
                "Bayesian inference techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the object of the preposition 'in', depending on 'reformulate' with the phrase 'to reformulate the multinomial distribution in terms of latent variables'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'take advantage' with the phrase 'to take advantage of a host of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of reformulating the multinomial distribution and applying Bayesian inference techniques.\"",
        "sdp_path_text": "variables → of → terms → in → distribution → late → leverage → enabling → take → of → host → of → techniques",
        "sentence": "Latent variables enable the use of Bayesian inference techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the subject, depending on the verb 'enable'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'use' in the phrase 'use of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enable' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the object of the preposition 'in', depending on the verb 'reformu-late'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on the verb 'take advantage of'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause and related through the context of the sentence, where 'latent variables' are used in the reformulation that enables the use of 'Gaussian models'.\"",
        "sdp_path_text": "variables → of → terms → in → distribution → late → leverage → enabling → take → of → host → of → techniques → for → models",
        "sentence": "Latent variables enable the use of techniques for Gaussian models.",
        "sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the subject, depending on the verb 'enable'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'enable' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "latent variables",
                "OtherScientificTerm"
            ],
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the object of the preposition 'in', depending on 'reformulate'. Entity 2 ('minimal overhead') is the object of the preposition 'with', depending on 'take advantage'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the reformulation and its benefits.\"",
        "sdp_path_text": "variables → of → terms → in → distribution → late → leverage → enabling → take → of → host → of → techniques → for → models → with → overhead",
        "sentence": "Leveraging latent variables enables taking advantage of techniques for models with minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('latent variables') is the object of the verb 'Leveraging', depending on 'Leveraging'. Entity 2 ('minimal overhead') is the object of the preposition 'with', depending on 'with' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            [
                "Bayesian inference techniques",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the object of the preposition 'with', depending on 'reformu-late'. Entity 2 ('Bayesian inference techniques') is the object of the preposition 'for', depending on 'take advantage of'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of the sentence which discusses reformulating the multinomial distribution and the benefits that follow from this reformulation.\"",
        "sdp_path_text": "likelihoods → with → late → leverage → enabling → take → of → host → of → techniques",
        "sentence": "Jointly Gaussian likelihoods enable the use of a host of Bayesian inference techniques.",
        "sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the subject, depending on the verb 'enable'. Entity 2 ('Bayesian inference techniques') is the object, depending on the preposition 'of' in the phrase 'a host of Bayesian inference techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enable' which indicates that Entity 1 facilitates the use of Entity 2.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the object, depending on 'with' in the phrase 'with jointly Gaussian likelihoods'. Entity 2 ('Gaussian models') is the object, depending on 'for' in the phrase 'for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the reformulation of the multinomial distribution and the application of Bayesian inference techniques.\"",
        "sdp_path_text": "likelihoods → with → late → leverage → enabling → take → of → host → of → techniques → for → models",
        "sentence": "Jointly Gaussian likelihoods enable taking advantage of a host of techniques for Gaussian models.",
        "sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the subject, depending on the verb 'enable'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'enable' and the prepositional phrase 'for Gaussian models'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "jointly Gaussian likelihoods",
                "OtherScientificTerm"
            ],
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the object, depending on the preposition 'with' which modifies 'latent variables'. Entity 2 ('minimal overhead') is the object, depending on the preposition 'with' which modifies 'minimal overhead' in the phrase 'with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause that describes the characteristics of the latent variables and the efficiency of the approach.\"",
        "sdp_path_text": "likelihoods → with → late → leverage → enabling → take → of → host → of → techniques → for → models → with → overhead",
        "sentence": "Jointly Gaussian likelihoods enable taking advantage of Bayesian inference techniques for models with minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('jointly Gaussian likelihoods') is the subject, depending on the verb 'enable'. Entity 2 ('minimal overhead') is the object of the preposition 'for', depending on 'for' in the phrase 'for models with minimal overhead'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'enable' and the prepositional phrase 'for models with minimal overhead'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Bayesian inference techniques",
                "Method"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference techniques') is the object, depending on 'take advantage of' with 'enabling us'. Entity 2 ('Gaussian models') is the object, depending on 'for' with 'techniques'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates that the techniques are applicable to or designed for Gaussian models.\"",
        "sdp_path_text": "techniques → for → models",
        "sentence": "Bayesian inference techniques are used for Gaussian models.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference techniques') is the subject, depending on the verb 'are used'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'for' in the phrase 'for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "Bayesian inference techniques",
                "Method"
            ],
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference techniques') is the object of the preposition 'of', depending on 'take advantage'. Entity 2 ('minimal overhead') is the complement of the adjective 'minimal', depending on 'with'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the benefits of the described method.\"",
        "sdp_path_text": "techniques → for → models → with → overhead",
        "sentence": "Bayesian inference techniques for Gaussian models have minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('Bayesian inference techniques') is the subject, depending on the verb 'have'. Entity 2 ('minimal overhead') is the object, depending on the verb 'have'. There is a direct dependency between Entity 1 and Entity 2, as 'minimal overhead' is the direct object of the verb 'have' which is associated with 'Bayesian inference techniques'.\""
    },
    {
        "raw_sentence": "Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .",
        "ner_pair": [
            [
                "minimal overhead",
                "OtherScientificTerm"
            ],
            [
                "Gaussian models",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('minimal overhead') is the object, depending on the verb 'take' in the phrase 'take advantage of'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'for' in the phrase 'for Gaussian models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the benefits of the described method.\"",
        "sdp_path_text": "overhead → with → models",
        "sentence": "We can take advantage of Bayesian inference techniques for Gaussian models with minimal overhead.",
        "sentence_llm_dp_info": "\"Entity 1 ('minimal overhead') is the object, depending on 'with' which modifies the verb phrase 'take advantage of'. Entity 2 ('Gaussian models') is the object of the preposition 'for', depending on 'techniques'. There is no direct dependency between Entity 1 and Entity 2; both are related to different parts of the sentence structure.\""
    },
    {
        "raw_sentence": "MINPRAN , a new robust operator , nds good ts in data sets where more than 50 % of the points are outliers .",
        "ner_pair": [
            [
                "MINPRAN",
                "Method"
            ],
            [
                "robust operator",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'nds'. Entity 2 ('robust operator') is an appositive, providing additional information about 'MINPRAN'. There is a direct dependency between Entity 1 and Entity 2, as 'robust operator' modifies and specifies 'MINPRAN'.\"",
        "sdp_path_text": "MINPRAN → operator",
        "sentence": "MINPRAN is a new robust operator.",
        "sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the copula 'is'. Entity 2 ('robust operator') is the predicate nominative, also depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'MINPRAN' is described as being a 'robust operator'.\""
    },
    {
        "raw_sentence": "Unlike other techniques that handle large outlier percentages , MINPRAN does not rely on a known error bound for the good data .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "large outlier percentages",
                "Metric"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('techniques') is the subject of the relative clause, depending on 'handle' with 'that'. Entity 2 ('large outlier percentages') is the object, depending on 'handle' with 'techniques'. There is a direct dependency between Entity 1 and Entity 2, as 'techniques' handles 'large outlier percentages'.\"",
        "sdp_path_text": "techniques → handle → percentages",
        "sentence": "Techniques handle large outlier percentages.",
        "sentence_llm_dp_info": "\"Entity 1 ('techniques') is the subject, depending on the verb 'handle'. Entity 2 ('large outlier percentages') is the object, depending on 'handle' with 'techniques'. There is a direct dependency between Entity 1 and Entity 2, where 'techniques' handles 'large outlier percentages'.\""
    },
    {
        "raw_sentence": "Unlike other techniques that handle large outlier percentages , MINPRAN does not rely on a known error bound for the good data .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "MINPRAN",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('techniques') is the subject of the clause 'that handle large outlier percentages', depending on the relative pronoun 'that'. Entity 2 ('MINPRAN') is the subject of the main clause, depending on the negated verb 'does not rely'. There is no direct dependency between Entity 1 and Entity 2; they are contrasted through the use of the conjunction 'Unlike'.\"",
        "sdp_path_text": "techniques → Unlike → rely → MINPRAN",
        "sentence": "Unlike techniques, MINPRAN does not rely on a known error bound.",
        "sentence_llm_dp_info": "\"Entity 1 ('techniques') is the subject of the comparative clause, depending on the verb 'rely' through the negative comparison 'Unlike'. Entity 2 ('MINPRAN') is the subject of the main clause, also depending on the verb 'rely'. There is no direct dependency between Entity 1 and Entity 2; they are contrasted through the use of 'Unlike'.\""
    },
    {
        "raw_sentence": "Unlike other techniques that handle large outlier percentages , MINPRAN does not rely on a known error bound for the good data .",
        "ner_pair": [
            [
                "techniques",
                "Generic"
            ],
            [
                "error bound",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('techniques') is the subject of the relative clause, depending on 'handle' with 'that'. Entity 2 ('error bound') is the object of the preposition 'on', depending on 'rely' in the phrase 'rely on a known error bound'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "techniques → Unlike → rely → on → error",
        "sentence": "Unlike other techniques, MINPRAN does not rely on an error bound.",
        "sentence_llm_dp_info": "\"Entity 1 ('techniques') is the object of the preposition 'Unlike', depending on the preposition 'Unlike' in the phrase 'Unlike other techniques'. Entity 2 ('error bound') is the object of the preposition 'on', depending on 'rely' in the phrase 'rely on an error bound'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Unlike other techniques that handle large outlier percentages , MINPRAN does not rely on a known error bound for the good data .",
        "ner_pair": [
            [
                "large outlier percentages",
                "Metric"
            ],
            [
                "MINPRAN",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large outlier percentages') is the object of the relative clause, depending on 'handle' with 'that'. Entity 2 ('MINPRAN') is the subject, depending on 'does not rely' as the main verb of the sentence. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence context where MINPRAN's characteristic is contrasted with the handling of large outlier percentages by other techniques.\"",
        "sdp_path_text": "percentages → handle → techniques → Unlike → rely → MINPRAN",
        "sentence": "MINPRAN does not rely on handling large outlier percentages.",
        "sentence_llm_dp_info": "\"Entity 1 ('large outlier percentages') is the object, depending on the verb 'handling'. Entity 2 ('MINPRAN') is the subject, depending on the negated verb 'does not rely'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the preposition 'on' in the phrase 'on handling large outlier percentages'.\""
    },
    {
        "raw_sentence": "Unlike other techniques that handle large outlier percentages , MINPRAN does not rely on a known error bound for the good data .",
        "ner_pair": [
            [
                "large outlier percentages",
                "Metric"
            ],
            [
                "error bound",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large outlier percentages') is the object of the relative clause, depending on 'handle' with 'techniques'. Entity 2 ('error bound') is the object of the preposition 'on', depending on 'rely' in the phrase 'rely on a known error bound'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the handling or reliance mechanisms described in the sentence.\"",
        "sdp_path_text": "percentages → handle → techniques → Unlike → rely → on → error",
        "sentence": "Unlike techniques that handle large outlier percentages, MINPRAN does not rely on an error bound.",
        "sentence_llm_dp_info": "\"Entity 1 ('large outlier percentages') is the object of the relative clause, depending on 'handle' with 'techniques'. Entity 2 ('error bound') is the object of the preposition 'on', depending on 'rely' in the phrase 'does not rely on'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the handling or reliance of techniques and MINPRAN, respectively.\""
    },
    {
        "raw_sentence": "Unlike other techniques that handle large outlier percentages , MINPRAN does not rely on a known error bound for the good data .",
        "ner_pair": [
            [
                "MINPRAN",
                "Method"
            ],
            [
                "error bound",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'does' in the phrase 'does not rely'. Entity 2 ('error bound') is the object of the preposition 'on', depending on 'rely' in the phrase 'rely on a known error bound'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'rely' and the preposition 'on'.\"",
        "sdp_path_text": "MINPRAN → rely → on → error",
        "sentence": "MINPRAN does not rely on an error bound.",
        "sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the negated verb 'does not rely'. Entity 2 ('error bound') is the object of the preposition 'on', depending on 'on' in the phrase 'on an error bound'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Instead it assumes that the bad data are randomly -LRB- uniformly -RRB- distributed within the dynamic range of the sensor .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "dynamic range of the sensor",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'assumes'. Entity 2 ('dynamic range of the sensor') is the object of the preposition 'within', depending on 'distributed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate structure where 'it' assumes something about the distribution within the 'dynamic range of the sensor'.\"",
        "sdp_path_text": "it → assumes → distributed → within → range",
        "sentence": "It assumes that data are distributed within the dynamic range of the sensor.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'assumes'. Entity 2 ('dynamic range of the sensor') is the object of the preposition 'within', depending on 'within' in the phrase 'within the dynamic range of the sensor'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'within the dynamic range of the sensor'.\""
    },
    {
        "raw_sentence": "Based on this , MINPRAN uses random sampling to search for the t and the number of inliers to the t that are least likely to have occurred randomly .",
        "ner_pair": [
            [
                "random sampling",
                "Method"
            ],
            [
                "MINPRAN",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('random sampling') is the object of the preposition 'uses', depending on 'MINPRAN'. Entity 2 ('MINPRAN') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, where 'MINPRAN' uses 'random sampling'.\"",
        "sdp_path_text": "sampling → uses → MINPRAN",
        "sentence": "MINPRAN uses random sampling.",
        "sentence_llm_dp_info": "\"Entity 1 ('random sampling') is the object, depending on the verb 'uses' with 'MINPRAN'. Entity 2 ('MINPRAN') is the subject, depending on the verb 'uses'. There is a direct dependency between Entity 1 and Entity 2, where 'MINPRAN' is the agent that performs the action of 'using' 'random sampling'.\""
    },
    {
        "raw_sentence": "We demonstrate analytically that MINPRAN distinguishes good ts from ts to random data , and that MINPRAN nds accurate ts and nearly the correct number of inliers , regardless of the percentage of true inliers .",
        "ner_pair": [
            [
                "MINPRAN",
                "Method"
            ],
            [
                "percentage of true inliers",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'distinguishes' and 'nds' (finds). Entity 2 ('percentage of true inliers') is the object of the preposition 'of', depending on 'regardless' in the phrase 'regardless of the percentage of true inliers'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'regardless of the percentage of true inliers'.\"",
        "sdp_path_text": "MINPRAN → distinguishes → nds → regardless → of → percentage",
        "sentence": "MINPRAN distinguishes good fits from random data and finds accurate fits regardless of the percentage of true inliers.",
        "sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'distinguishes'. Entity 2 ('percentage of true inliers') is the object of the preposition 'of', depending on 'regardless' in the phrase 'regardless of the percentage of true inliers'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'MINPRAN' performs actions that are unaffected by the 'percentage of true inliers'.\""
    },
    {
        "raw_sentence": "We demonstrate analytically that MINPRAN distinguishes good ts from ts to random data , and that MINPRAN nds accurate ts and nearly the correct number of inliers , regardless of the percentage of true inliers .",
        "ner_pair": [
            [
                "MINPRAN",
                "Method"
            ],
            [
                "percentage of true inliers",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on 'distinguishes' and 'nds' (finds) in the sentence. Entity 2 ('percentage of true inliers') is the object of the preposition 'of', depending on 'regardless' in the phrase 'regardless of the percentage of true inliers'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same clause.\"",
        "sdp_path_text": "MINPRAN → distinguishes → nds → regardless → of → percentage",
        "sentence": "MINPRAN distinguishes good fits from random data and finds accurate fits regardless of the percentage of true inliers.",
        "sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'distinguishes'. Entity 2 ('percentage of true inliers') is the object of the preposition 'of', depending on 'regardless' in the phrase 'regardless of the percentage of true inliers'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'regardless of'.\""
    },
    {
        "raw_sentence": "MINPRAN 's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares .",
        "ner_pair": [
            [
                "synthetic data",
                "Material"
            ],
            [
                "MINPRAN",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic data') is the object of the preposition 'on', depending on 'confirmed'. Entity 2 ('MINPRAN') is the subject, depending on the possessive form 'MINPRAN's' with 'properties'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'confirmed'.\"",
        "sdp_path_text": "data → on → connrmed → properties → MINPRAN",
        "sentence": "MINPRAN's properties are confirmed on synthetic data.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic data') is the object, depending on the preposition 'on', which itself depends on the verb 'confirmed'. Entity 2 ('MINPRAN') is the subject, depending on the possessive form 'MINPRAN's' which modifies 'properties'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure where 'MINPRAN's properties' are being confirmed 'on synthetic data'.\""
    },
    {
        "raw_sentence": "MINPRAN 's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares .",
        "ner_pair": [
            [
                "least median of squares",
                "Method"
            ],
            [
                "MINPRAN",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('least median of squares') is the complement, depending on 'compare' with 'favorably'. Entity 2 ('MINPRAN') is the subject, depending on 'properties' with 'are confirmed'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure where 'MINPRAN' is being compared to 'least median of squares'.\"",
        "sdp_path_text": "median → to → compare → connrmed → properties → MINPRAN",
        "sentence": "MINPRAN's properties compare favorably to least median of squares.",
        "sentence_llm_dp_info": "\"Entity 1 ('least median of squares') is the complement of the preposition 'to', depending on 'compare'. Entity 2 ('MINPRAN') is the subject, depending on the verb 'compare'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'compare'.\""
    },
    {
        "raw_sentence": "MINPRAN 's properties are connrmed experimentally on synthetic data and compare favorably to least median of squares .",
        "ner_pair": [
            [
                "synthetic data",
                "Material"
            ],
            [
                "least median of squares",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic data') is the object of the preposition 'on', depending on 'confirmed'. Entity 2 ('least median of squares') is the complement of the comparison, depending on 'compare'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the experimental confirmation and favorable comparison of MINPRAN's properties.\"",
        "sdp_path_text": "data → on → connrmed → compare → to → median",
        "sentence": "Properties confirmed on synthetic data compare favorably to least median of squares.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic data') is the object of the verb 'confirmed', depending on 'confirmed' in the phrase 'confirmed on synthetic data'. Entity 2 ('least median of squares') is the object of the preposition 'to', depending on 'to' in the phrase 'to least median of squares'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in the context of the sentence.\""
    },
    {
        "raw_sentence": "Related work applies MINPRAN to complex range and intensity data 23 -RSB- .",
        "ner_pair": [
            [
                "MINPRAN",
                "Method"
            ],
            [
                "complex range",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the object of the preposition 'applies', depending on 'applies' in the phrase 'applies MINPRAN'. Entity 2 ('complex range') is part of a compound noun, depending on 'and' with 'intensity data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence.\"",
        "sdp_path_text": "MINPRAN → applies → to → data → complex",
        "sentence": "MINPRAN applies to complex range data.",
        "sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'applies'. Entity 2 ('complex range') is part of the object complement, depending on 'data' in the noun phrase 'complex range data'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applies' and the noun 'data'.\""
    },
    {
        "raw_sentence": "Related work applies MINPRAN to complex range and intensity data 23 -RSB- .",
        "ner_pair": [
            [
                "MINPRAN",
                "Method"
            ],
            [
                "intensity data",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the object of the preposition 'to', depending on 'applies' with 'Related work'. Entity 2 ('intensity data') is part of a compound noun, depending on 'and' in the phrase 'complex range and intensity data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'applies'.\"",
        "sdp_path_text": "MINPRAN → applies → to → data",
        "sentence": "MINPRAN is applied to intensity data.",
        "sentence_llm_dp_info": "\"Entity 1 ('MINPRAN') is the subject, depending on the verb 'applied'. Entity 2 ('intensity data') is the object, depending on the preposition 'to', which connects it to 'MINPRAN'. There is a direct dependency between Entity 1 and Entity 2, as 'MINPRAN' is applied directly to 'intensity data'.\""
    },
    {
        "raw_sentence": "Related work applies MINPRAN to complex range and intensity data 23 -RSB- .",
        "ner_pair": [
            [
                "complex range",
                "OtherScientificTerm"
            ],
            [
                "intensity data",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('complex range') is part of a compound noun, depending on the conjunction 'and' with 'intensity data'. Entity 2 ('intensity data') is also part of the compound noun, depending on the conjunction 'and' with 'complex range'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same noun phrase.\"",
        "sdp_path_text": "complex → data",
        "sentence": "{\n  \"Simplified sentence\": \"Related work applies MINPRAN to complex range and intensity data.\"\n} \n\nNote: In this case, the provided SDP (\"complex → data\") is too short to capture the full relationship between \"complex range\" and \"intensity data\" without losing essential context. Therefore, the original sentence is retained to preserve the integrity of the information.",
        "sentence_llm_dp_info": "\"Entity 1 ('complex range') is part of the compound noun, depending on the preposition 'to' with 'applies'. Entity 2 ('intensity data') is also part of the compound noun, depending on the conjunction 'and' with 'complex range'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same prepositional phrase.\""
    },
    {
        "raw_sentence": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages .",
        "ner_pair": [
            [
                "context-free phrase structure rules",
                "OtherScientificTerm"
            ],
            [
                "Metagrammatical formalisms",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('context-free phrase structure rules') is the object of the preposition 'combine', depending on 'formalisms'. Entity 2 ('Metagrammatical formalisms') is the subject, depending on the verb 'allow'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'that combine context-free phrase structure rules and metarules'.\"",
        "sdp_path_text": "rules → combine → formalisms",
        "sentence": "Metagrammatical formalisms combine context-free phrase structure rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('context-free phrase structure rules') is the object, depending on the verb 'combine'. Entity 2 ('Metagrammatical formalisms') is the subject, depending on the verb 'combine'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 combines Entity 1.\""
    },
    {
        "raw_sentence": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages .",
        "ner_pair": [
            [
                "metarules -LRB- MPS grammars -RRB-",
                "OtherScientificTerm"
            ],
            [
                "Metagrammatical formalisms",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('metarules -LRB- MPS grammars -RRB-') is part of the object complement, depending on 'combine' with 'context-free phrase structure rules'. Entity 2 ('Metagrammatical formalisms') is the subject, depending on the verb 'allow'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combine' which is part of the subject's predicate.\"",
        "sdp_path_text": "grammars → rules → combine → formalisms",
        "sentence": "Metagrammatical formalisms combine metarules (MPS grammars).",
        "sentence_llm_dp_info": "\"Entity 1 ('metarules (MPS grammars)') is the object, depending on the verb 'combine'. Entity 2 ('Metagrammatical formalisms') is the subject, depending on the verb 'combine'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 combines Entity 1.\""
    },
    {
        "raw_sentence": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages .",
        "ner_pair": [
            [
                "Metagrammatical formalisms",
                "Method"
            ],
            [
                "syntax of natural languages",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Metagrammatical formalisms') is the subject, depending on the verb 'allow'. Entity 2 ('syntax of natural languages') is the object of the preposition 'about', depending on 'generalizations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'allow' and the prepositional phrase 'about the syntax of natural languages'.\"",
        "sdp_path_text": "formalisms → allow → statement → of → generalizations → about → syntax",
        "sentence": "Metagrammatical formalisms allow statement of generalizations about the syntax of natural languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('Metagrammatical formalisms') is the subject, depending on the verb 'allow'. Entity 2 ('syntax of natural languages') is the object of the preposition 'about', depending on 'about' in the phrase 'about the syntax of natural languages'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allow' and the preposition 'about'.\""
    },
    {
        "raw_sentence": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages .",
        "ner_pair": [
            [
                "context-free phrase structure rules",
                "OtherScientificTerm"
            ],
            [
                "metarules -LRB- MPS grammars -RRB-",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('context-free phrase structure rules') is the object of the relative clause, depending on the verb 'combine' within the clause 'that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB-'. Entity 2 ('metarules -LRB- MPS grammars -RRB-') is also an object of the relative clause, depending on the conjunction 'and' which connects it to 'context-free phrase structure rules'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated objects of the verb 'combine'.\"",
        "sdp_path_text": "rules → grammars",
        "sentence": "Context-free phrase structure rules and metarules (MPS grammars) allow concise statement of generalizations about syntax.",
        "sentence_llm_dp_info": "\"Entity 1 ('context-free phrase structure rules') is a conjunct, depending on the conjunction 'and' with 'metarules (MPS grammars)'. Entity 2 ('metarules (MPS grammars)') is also a conjunct, depending on the conjunction 'and' with 'context-free phrase structure rules'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages .",
        "ner_pair": [
            [
                "context-free phrase structure rules",
                "OtherScientificTerm"
            ],
            [
                "syntax of natural languages",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('context-free phrase structure rules') is part of the compound object, depending on 'combine' with 'that'. Entity 2 ('syntax of natural languages') is the object, depending on 'generalizations' with 'about'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the formalisms allow.\"",
        "sdp_path_text": "rules → combine → formalisms → allow → statement → of → generalizations → about → syntax",
        "sentence": "Formalisms combining context-free phrase structure rules allow concise statements about the syntax of natural languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('context-free phrase structure rules') is the object of the verb 'combining', which modifies 'Formalisms'. Entity 2 ('syntax of natural languages') is the object of the preposition 'about', depending on 'statements'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes what the formalisms allow.\""
    },
    {
        "raw_sentence": "Metagrammatical formalisms that combine context-free phrase structure rules and metarules -LRB- MPS grammars -RRB- allow concise statement of generalizations about the syntax of natural languages .",
        "ner_pair": [
            [
                "metarules -LRB- MPS grammars -RRB-",
                "OtherScientificTerm"
            ],
            [
                "syntax of natural languages",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('metarules -LRB- MPS grammars -RRB-') is part of the compound object of the preposition 'combine', depending on 'combine' with 'context-free phrase structure rules'. Entity 2 ('syntax of natural languages') is the object of the preposition 'about', depending on 'generalizations'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing what the formalisms allow.\"",
        "sdp_path_text": "grammars → rules → combine → formalisms → allow → statement → of → generalizations → about → syntax",
        "sentence": "MPS grammars allow concise statement of generalizations about the syntax of natural languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('metarules (MPS grammars)') is the subject, depending on the verb 'allow'. Entity 2 ('syntax of natural languages') is the object of the preposition 'about', depending on 'about' in the phrase 'about the syntax of natural languages'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'allow' and the preposition 'about'.\""
    },
    {
        "raw_sentence": "We evaluate several proposals for constraining them , basing our assessment on computational tractability and explanatory adequacy .",
        "ner_pair": [
            [
                "computational tractability and explanatory adequacy",
                "Metric"
            ],
            [
                "them",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computational tractability and explanatory adequacy') is the object of the preposition 'on', depending on 'basing'. Entity 2 ('them') is the object of the preposition 'for', depending on 'constraining'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "tractability → on → basing → evaluate → proposals → for → constraining → them",
        "sentence": "We evaluate proposals for constraining them based on computational tractability and explanatory adequacy.",
        "sentence_llm_dp_info": "\"Entity 1 ('computational tractability and explanatory adequacy') is the object of the preposition 'on', depending on 'based'. Entity 2 ('them') is the object of the preposition 'for', depending on 'constraining'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'them' refers to the proposals that are being evaluated based on the criteria mentioned in Entity 1.\""
    },
    {
        "raw_sentence": "We show that none of them satisfies both criteria , and suggest new directions for research on alternative metagrammatical formalisms .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "criteria",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'satisfies', depending on 'satisfies' in the clause 'none of them satisfies both criteria'. Entity 2 ('criteria') is the object complement, depending on 'both' in the same clause. There is a direct dependency between Entity 1 and Entity 2, as 'criteria' is part of the clause that 'them' is satisfying.\"",
        "sdp_path_text": "them → of → none → satisfies → criteria",
        "sentence": "None of them satisfies the criteria.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on the verb 'satisfies'. Entity 2 ('criteria') is the object of the preposition 'the', depending on 'satisfies' as well. There is no direct dependency between Entity 1 and Entity 2; both are independently related to the verb 'satisfies'.\""
    },
    {
        "raw_sentence": "We show that none of them satisfies both criteria , and suggest new directions for research on alternative metagrammatical formalisms .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "metagrammatical formalisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'satisfies', depending on 'satisfies' in the clause 'none of them satisfies both criteria'. Entity 2 ('metagrammatical formalisms') is the object of the preposition 'on', depending on 'on' in the phrase 'research on alternative metagrammatical formalisms'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "them → of → none → satisfies → show → suggest → directions → for → research → on → formalisms",
        "sentence": "We show that none of them satisfies criteria and suggest new directions for research on metagrammatical formalisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'satisfies', depending on 'satisfies' in the clause 'none of them satisfies criteria'. Entity 2 ('metagrammatical formalisms') is the object of the preposition 'on', depending on 'on' in the phrase 'on metagrammatical formalisms'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence context, where 'them' refers to subjects being discussed in relation to 'metagrammatical formalisms'.\""
    },
    {
        "raw_sentence": "We show that none of them satisfies both criteria , and suggest new directions for research on alternative metagrammatical formalisms .",
        "ner_pair": [
            [
                "criteria",
                "Generic"
            ],
            [
                "metagrammatical formalisms",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('criteria') is the object of the verb 'satisfies', depending on the pronoun 'them'. Entity 2 ('metagrammatical formalisms') is the object of the preposition 'on', depending on 'research'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence, connected through the logical flow of the argument presented.\"",
        "sdp_path_text": "criteria → satisfies → show → suggest → directions → for → research → on → formalisms",
        "sentence": "We show that none satisfies the criteria and suggest new research directions for metagrammatical formalisms.",
        "sentence_llm_dp_info": "\"Entity 1 ('criteria') is the object of the verb 'satisfies', depending on 'none'. Entity 2 ('metagrammatical formalisms') is the object of the preposition 'for', depending on 'directions'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "tree-adjoining grammars -LRB- TAG -RRB-",
                "Method"
            ],
            [
                "TAGs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars -LRB- TAG -RRB-') is the subject, depending on the verb 'present'. Entity 2 ('TAGs') is the object of the preposition 'of', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where Entity 2 refers to an application of the concept described by Entity 1.\"",
        "sdp_path_text": "grammars → of → properties → present → challenge → for → application → of → TAGs",
        "sentence": "The properties of tree-adjoining grammars present a challenge for the application of TAGs.",
        "sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars') is the subject of the clause, depending on the verb 'present'. Entity 2 ('TAGs') is the object of the preposition 'of', depending on 'application' in the phrase 'the application of TAGs'. There is no direct dependency between Entity 1 and Entity 2, but they are semantically related as 'TAGs' is an acronym for 'tree-adjoining grammars'.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "tree-adjoining grammars -LRB- TAG -RRB-",
                "Method"
            ],
            [
                "syntax",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars -LRB- TAG -RRB-') is the subject, depending on the verb 'present'. Entity 2 ('syntax') is part of the noun phrase 'the limited confines of syntax', which is the object of the preposition 'beyond', depending on 'beyond'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'beyond the limited confines of syntax'.\"",
        "sdp_path_text": "grammars → of → properties → present → challenge → for → application → beyond → confines → of → syntax",
        "sentence": "The properties of tree-adjoining grammars present a challenge for their application beyond syntax.",
        "sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars') is the object of the preposition 'of', depending on 'properties'. Entity 2 ('syntax') is the object of the preposition 'beyond', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the challenges presented by the properties of tree-adjoining grammars for their application.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "tree-adjoining grammars -LRB- TAG -RRB-",
                "Method"
            ],
            [
                "semantic interpretation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars -LRB- TAG -RRB-') is the subject complement, depending on 'present' with 'properties'. Entity 2 ('semantic interpretation') is part of the prepositional phrase, depending on 'to' in the phrase 'to the task of semantic interpretation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'present'.\"",
        "sdp_path_text": "grammars → of → properties → present → challenge → for → application → to → task → of → interpretation",
        "sentence": "The properties of tree-adjoining grammars present a challenge for their application to semantic interpretation.",
        "sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars') is the object of the preposition 'of', depending on 'properties'. Entity 2 ('semantic interpretation') is the object of the preposition 'to', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'present' and the noun 'challenge' which indicates that the properties of Entity 1 pose difficulties for Entity 2.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "tree-adjoining grammars -LRB- TAG -RRB-",
                "Method"
            ],
            [
                "automatic translation of natural language",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars -LRB- TAG -RRB-') is the subject, depending on the verb 'present'. Entity 2 ('automatic translation of natural language') is part of the prepositional phrase 'to the task of semantic interpretation or automatic translation of natural language', depending on 'to'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the preposition 'to' which indicates that the challenge presented by Entity 1 affects tasks including Entity 2.\"",
        "sdp_path_text": "grammars → of → properties → present → challenge → for → application → to → task → of → interpretation → translation",
        "sentence": "The properties of tree-adjoining grammars present a challenge for their application to automatic translation of natural language.",
        "sentence_llm_dp_info": "\"Entity 1 ('tree-adjoining grammars') is the subject complement, depending on the verb 'present'. Entity 2 ('automatic translation of natural language') is the object of the preposition 'to', depending on 'application'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'present' and the prepositional phrase 'to automatic translation of natural language'.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "TAGs",
                "Method"
            ],
            [
                "syntax",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the object of the preposition 'of', depending on 'application'. Entity 2 ('syntax') is the object of the preposition 'of', depending on 'confines'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the challenge presented by the unique properties of tree-adjoining grammars.\"",
        "sdp_path_text": "TAGs → of → application → beyond → confines → of → syntax",
        "sentence": "The unique properties of TAGs present a challenge for their application beyond syntax.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the subject of the clause, depending on 'present' as the verb. Entity 2 ('syntax') is part of the prepositional phrase 'beyond syntax', which modifies 'application'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase that specifies the context in which the challenge is presented.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "TAGs",
                "Method"
            ],
            [
                "semantic interpretation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the object of the preposition 'of', depending on 'application'. Entity 2 ('semantic interpretation') is part of a coordination, depending on 'task' which is the object of the preposition 'to'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, where the application of TAGs is discussed in the context of tasks such as semantic interpretation.\"",
        "sdp_path_text": "TAGs → of → application → to → task → of → interpretation",
        "sentence": "TAGs present a challenge for the application to semantic interpretation.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the subject, depending on the verb 'present'. Entity 2 ('semantic interpretation') is the object of the preposition 'to', depending on 'application' in the phrase 'to semantic interpretation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'challenge' and the prepositional phrase 'to semantic interpretation'.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "TAGs",
                "Method"
            ],
            [
                "automatic translation of natural language",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the object of the preposition 'of', depending on 'application' in the phrase 'the application of TAGs'. Entity 2 ('automatic translation of natural language') is the object of the preposition 'to', depending on 'to' in the phrase 'to the task of semantic interpretation or automatic translation of natural language'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same larger clause describing challenges for the application of TAGs.\"",
        "sdp_path_text": "TAGs → of → application → to → task → of → interpretation → translation",
        "sentence": "TAGs present a challenge for the application to the task of automatic translation of natural language.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the subject, depending on the verb 'present'. Entity 2 ('automatic translation of natural language') is the object of the preposition 'to', depending on 'task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'to the task of automatic translation of natural language'.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "syntax",
                "OtherScientificTerm"
            ],
            [
                "semantic interpretation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntax') is the object of the preposition 'of', depending on 'confines'. Entity 2 ('semantic interpretation') is the object of the preposition 'to', depending on 'to' in the phrase 'to the task of semantic interpretation'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the challenges presented by the application of TAGs.\"",
        "sdp_path_text": "syntax → of → confines → beyond → application → to → task → of → interpretation",
        "sentence": "The unique properties of tree-adjoining grammars present a challenge for applying them beyond syntax to tasks like semantic interpretation.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntax') is the object of the preposition 'beyond', depending on 'beyond' in the phrase 'beyond syntax'. Entity 2 ('semantic interpretation') is the object of the preposition 'to', depending on 'to' in the phrase 'to tasks like semantic interpretation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify the noun 'tasks'.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "syntax",
                "OtherScientificTerm"
            ],
            [
                "automatic translation of natural language",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('syntax') is the object of the preposition 'of', depending on 'confines'. Entity 2 ('automatic translation of natural language') is the object of the preposition 'to', depending on 'task'. There is no direct dependency between Entity 1 and Entity 2; both are part of the broader context describing the challenges and applications of TAGs.\"",
        "sdp_path_text": "syntax → of → confines → beyond → application → to → task → of → interpretation → translation",
        "sentence": "The unique properties of tree-adjoining grammars present a challenge for applying them beyond syntax to tasks like automatic translation of natural language.",
        "sentence_llm_dp_info": "\"Entity 1 ('syntax') is the object of the preposition 'beyond', depending on 'applying'. Entity 2 ('automatic translation of natural language') is the object of the preposition 'like', depending on 'tasks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of tasks that the challenge pertains to.\""
    },
    {
        "raw_sentence": "The unique properties of tree-adjoining grammars -LRB- TAG -RRB- present a challenge for the application of TAGs beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural language .",
        "ner_pair": [
            [
                "semantic interpretation",
                "Task"
            ],
            [
                "automatic translation of natural language",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantic interpretation') is the object of the preposition 'to', depending on 'to' in the phrase 'to the task of semantic interpretation'. Entity 2 ('automatic translation of natural language') is also the object of the preposition 'to', depending on 'to' in the phrase 'to the task of automatic translation of natural language'. There is no direct dependency between Entity 1 and Entity 2; both are objects of the same preposition 'to' in the context of tasks beyond the limited confines of syntax.\"",
        "sdp_path_text": "interpretation → translation",
        "sentence": "The unique properties of tree-adjoining grammars present a challenge for semantic interpretation and automatic translation of natural language.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantic interpretation') is part of the compound object, depending on 'challenge' with 'present'. Entity 2 ('automatic translation of natural language') is also part of the compound object, depending on 'challenge' with 'present'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the compound object introduced by 'for'.\""
    },
    {
        "raw_sentence": "We present a variant of TAGs , called synchronous TAGs , which characterize correspondences between languages .",
        "ner_pair": [
            [
                "variant of TAGs",
                "Method"
            ],
            [
                "synchronous TAGs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('variant of TAGs') is the subject complement, depending on the verb 'present'. Entity 2 ('synchronous TAGs') is the appositive, depending on 'called' which clarifies what the 'variant of TAGs' is. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 specifies what Entity 1 is.\"",
        "sdp_path_text": "variant → of → TAGs → called → TAGs",
        "sentence": "A variant of TAGs is called synchronous TAGs.",
        "sentence_llm_dp_info": "\"Entity 1 ('variant of TAGs') is the subject, depending on the verb 'is called'. Entity 2 ('synchronous TAGs') is the complement, depending on the verb 'called'. There is a direct dependency between Entity 1 and Entity 2, as 'synchronous TAGs' is what the 'variant of TAGs' is called.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "expressions of natural languages",
                "OtherScientificTerm"
            ],
            [
                "semantics",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the object of the verb 'relate', depending on 'relate' with 'intended usage'. Entity 2 ('semantics') is the object of the preposition 'to', depending on 'to' in the phrase 'to their associated semantics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'relate' which indicates that the expressions are related to the semantics.\"",
        "sdp_path_text": "expressions → relate → to → semantics",
        "sentence": "Expressions of natural languages are related to their semantics.",
        "sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the subject, depending on the verb 'are related'. Entity 2 ('semantics') is the object, depending on the verb 'are related'. There is a direct dependency between Entity 1 and Entity 2, as they are directly connected through the verb 'are related'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "expressions of natural languages",
                "OtherScientificTerm"
            ],
            [
                "logical form language",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the object of the verb 'relate', depending on 'relate' in the clause 'to relate expressions of natural languages to their associated semantics'. Entity 2 ('logical form language') is the object of the preposition 'in', depending on 'represented' in the phrase 'represented in a logical form language'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'relate' and the preposition 'in'.\"",
        "sdp_path_text": "expressions → relate → to → semantics → represented → in → language",
        "sentence": "Expressions of natural languages are related to their semantics represented in a logical form language.",
        "sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the subject, depending on the verb 'are related'. Entity 2 ('logical form language') is the object of the preposition 'in', depending on 'represented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are related' and the prepositional phrase 'in a logical form language'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "expressions of natural languages",
                "OtherScientificTerm"
            ],
            [
                "TAGs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the object of the preposition 'of', depending on 'relate' in the phrase 'to relate expressions of natural languages to their associated semantics'. Entity 2 ('TAGs') is the object of the preposition 'to', depending on 'allow' in the phrase 'to allow TAGs to be used'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader purpose described in the sentence.\"",
        "sdp_path_text": "expressions → relate → is → intend → allow → used → TAGs",
        "sentence": "Expressions of natural languages are intended to be related to allow TAGs to be used.",
        "sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the subject, depending on the verb 'intended'. Entity 2 ('TAGs') is the object of the infinitive 'to be used', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to be related to allow TAGs to be used'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "expressions of natural languages",
                "OtherScientificTerm"
            ],
            [
                "syntax proper",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the object of the verb 'relate', depending on the verb 'relate' in the clause 'to relate expressions of natural languages to their associated semantics'. Entity 2 ('syntax proper') is the object of the preposition 'beyond', depending on the preposition 'beyond' in the phrase 'beyond their role in syntax proper'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context described in the sentence.\"",
        "sdp_path_text": "expressions → relate → is → intend → allow → used → beyond → role → in → syntax",
        "sentence": "Expressions of natural languages are intended to be used beyond their role in syntax proper.",
        "sentence_llm_dp_info": "\"Entity 1 ('expressions of natural languages') is the subject, depending on the verb 'are intended'. Entity 2 ('syntax proper') is the object of the preposition 'in', depending on 'in' in the phrase 'in syntax proper'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in' and the verb 'are intended'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "logical form language",
                "OtherScientificTerm"
            ],
            [
                "semantics",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the object of the preposition 'in', depending on 'represented' in the phrase 'represented in a logical form language'. Entity 2 ('semantics') is the object of the preposition 'to', depending on 'relate' in the phrase 'relate expressions of natural languages to their associated semantics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'represented' and the preposition 'to'.\"",
        "sdp_path_text": "language → in → represented → semantics",
        "sentence": "The logical form language represents the semantics.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the subject, depending on the verb 'represents'. Entity 2 ('semantics') is the object, depending on the verb 'represents'. There is a direct dependency between Entity 1 and Entity 2, as 'logical form language' directly represents 'semantics'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "semantics",
                "OtherScientificTerm"
            ],
            [
                "natural language",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantics') is the object of the preposition 'to', depending on 'relate' with 'expressions of natural languages'. Entity 2 ('natural language') is the object of the preposition 'in', depending on 'translates' in the phrase 'their translates in another natural language'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'relate' and the noun 'expressions' within the context of the sentence.\"",
        "sdp_path_text": "semantics → to → relate → expressions → of → languages",
        "sentence": "Semantics are related to expressions of natural language.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantics') is the subject, depending on the verb 'are related'. Entity 2 ('natural language') is the object of the preposition 'of', depending on 'expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'are related' and the prepositional phrase 'of natural language'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "semantics",
                "OtherScientificTerm"
            ],
            [
                "TAGs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantics') is the object of the preposition 'to', depending on 'relate' in the phrase 'to relate expressions... to their associated semantics'. Entity 2 ('TAGs') is the object of the verb 'allow', depending on 'intend' in the clause 'we intend it to allow TAGs to be used'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "semantics → to → relate → is → intend → allow → used → TAGs",
        "sentence": "Semantics are intended to allow TAGs to be used for relating expressions to their associated meanings.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantics') is the subject, depending on the verb 'intended'. Entity 2 ('TAGs') is the object of the preposition 'to', depending on 'used' in the phrase 'to be used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'intended' and the purpose clause 'to be used for relating expressions to their associated meanings'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "semantics",
                "OtherScientificTerm"
            ],
            [
                "syntax proper",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('semantics') is the object, depending on 'relate' with 'expressions'. Entity 2 ('syntax proper') is the object complement, depending on 'beyond' with 'role'. There is no direct dependency between Entity 1 and Entity 2; both are related through different parts of the sentence structure, specifically through the verbs 'relate' and 'intend'.\"",
        "sdp_path_text": "semantics → to → relate → is → intend → allow → used → beyond → role → in → syntax",
        "sentence": "Semantics are intended to allow usage beyond the role in syntax proper.",
        "sentence_llm_dp_info": "\"Entity 1 ('semantics') is the subject, depending on the verb 'intended'. Entity 2 ('syntax proper') is part of a prepositional phrase, depending on 'beyond' in the phrase 'beyond the role in syntax proper'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating the scope or extent of the usage of semantics.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "logical form language",
                "OtherScientificTerm"
            ],
            [
                "natural language",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the object of the preposition 'in', depending on 'represented' in the phrase 'represented in a logical form language'. Entity 2 ('natural language') is the object of the preposition 'in', depending on 'translates' in the phrase 'their translates in another natural language'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of prepositions that describe different aspects of the formalism's intended usage.\"",
        "sdp_path_text": "language → in → represented → semantics → to → relate → expressions → of → languages",
        "sentence": "The formalism relates expressions of natural languages to their associated semantics represented in a logical form language.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the object of the preposition 'in', depending on 'represented'. Entity 2 ('natural language') is the object of the preposition 'of', depending on 'expressions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'relates' and the structure of the sentence.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "logical form language",
                "OtherScientificTerm"
            ],
            [
                "TAGs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the object of the preposition 'in', depending on 'represented' in the phrase 'represented in a logical form language'. Entity 2 ('TAGs') is the subject complement, depending on 'intend' in the phrase 'we intend it to allow TAGs'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the same sentence.\"",
        "sdp_path_text": "language → in → represented → semantics → to → relate → is → intend → allow → used → TAGs",
        "sentence": "The logical form language is intended to allow TAGs to relate expressions to their semantics.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the subject, depending on the verb 'is intended'. Entity 2 ('TAGs') is the subject of the infinitive clause 'to relate', depending on 'relate'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose clause 'to allow TAGs to relate expressions to their semantics'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "logical form language",
                "OtherScientificTerm"
            ],
            [
                "syntax proper",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the object of the preposition 'in', depending on 'represented'. Entity 2 ('syntax proper') is the object of the preposition 'in', depending on 'beyond'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the broader context of the sentence through the use of prepositions.\"",
        "sdp_path_text": "language → in → represented → semantics → to → relate → is → intend → allow → used → beyond → role → in → syntax",
        "sentence": "The formalism is intended to allow logical form language to be used beyond syntax proper.",
        "sentence_llm_dp_info": "\"Entity 1 ('logical form language') is the subject complement, depending on 'allow' with 'to be used'. Entity 2 ('syntax proper') is the object complement, depending on 'beyond' with 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the scope of usage allowed by the formalism.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "natural language",
                "OtherScientificTerm"
            ],
            [
                "TAGs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language') is the object of the preposition 'of', depending on 'expressions'. It also appears as the object of the preposition 'in' in the phrase 'in another natural language', depending on 'another'. Entity 2 ('TAGs') is the object of the verb 'allow', depending on 'it' (referring to the formalism). There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence, connected through the overarching context provided by the formalism's intended usage.\"",
        "sdp_path_text": "languages → of → expressions → relate → is → intend → allow → used → TAGs",
        "sentence": "The formalism is intended to allow TAGs to relate expressions of natural languages.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language') is the object, depending on 'expressions' with the preposition 'of'. Entity 2 ('TAGs') is the subject, depending on the verb 'relate' in the clause 'TAGs to relate'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'TAGs' are used to relate expressions of 'natural languages'.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "natural language",
                "OtherScientificTerm"
            ],
            [
                "syntax proper",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural language') is the object of the preposition 'of', depending on 'expressions'. It also appears as the object of the preposition 'in', depending on 'another'. Entity 2 ('syntax proper') is the object of the preposition 'in', depending on 'beyond'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger clauses that describe different aspects of the formalism's intended usage.\"",
        "sdp_path_text": "languages → of → expressions → relate → is → intend → allow → used → beyond → role → in → syntax",
        "sentence": "The formalism is intended to allow natural languages to be used beyond syntax proper.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural language') is the object of the infinitive 'to be used', depending on 'allow'. Entity 2 ('syntax proper') is the complement of 'beyond', depending on 'beyond'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that specifies the scope of usage allowed by the formalism.\""
    },
    {
        "raw_sentence": "The formalism 's intended usage is to relate expressions of natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper .",
        "ner_pair": [
            [
                "TAGs",
                "Method"
            ],
            [
                "syntax proper",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the object of the verb 'allow', depending on 'intend' which is part of the clause 'we intend it to allow'. Entity 2 ('syntax proper') is the object complement, depending on 'beyond' in the phrase 'beyond their role in syntax proper'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context provided by the sentence, where 'TAGs' are intended to have a role that extends beyond 'syntax proper'.\"",
        "sdp_path_text": "TAGs → used → beyond → role → in → syntax",
        "sentence": "TAGs are intended to be used beyond their role in syntax proper.",
        "sentence_llm_dp_info": "\"Entity 1 ('TAGs') is the subject, depending on the verb 'intended'. Entity 2 ('syntax proper') is the object of the preposition 'in', depending on 'role'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'beyond their role in syntax proper'.\""
    },
    {
        "raw_sentence": "A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated .",
        "ner_pair": [
            [
                "model-based approach",
                "Method"
            ],
            [
                "on-line cursive handwriting analysis and recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model-based approach') is the subject, depending on the verb 'presented'. Entity 2 ('on-line cursive handwriting analysis and recognition') is the object of the preposition 'to', depending on 'to' in the phrase 'to on-line cursive handwriting analysis and recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to'.\"",
        "sdp_path_text": "approach → to → analysis",
        "sentence": "A model-based approach is used for on-line cursive handwriting analysis and recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('model-based approach') is the subject, depending on the verb 'is used'. Entity 2 ('on-line cursive handwriting analysis and recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for on-line cursive handwriting analysis and recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this model , on-line handwriting is considered as a modulation of a simple cycloidal pen motion , described by two coupled oscillations with a constant linear drift along the line of the writing .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "on-line handwriting",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'In', depending on the prepositional phrase 'In this model'. Entity 2 ('on-line handwriting') is the subject, depending on the verb 'is' in the clause 'on-line handwriting is considered'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related within the same sentence, where 'on-line handwriting' is described within the scope of the 'model'.\"",
        "sdp_path_text": "model → In → considered → handwriting",
        "sentence": "In this model, on-line handwriting is considered.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'In', depending on 'In' in the phrase 'In this model'. Entity 2 ('on-line handwriting') is the subject, depending on the verb 'is considered'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'model' sets the context for what is being considered.\""
    },
    {
        "raw_sentence": "In this model , on-line handwriting is considered as a modulation of a simple cycloidal pen motion , described by two coupled oscillations with a constant linear drift along the line of the writing .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "cycloidal pen motion",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the preposition 'in' with 'In this model'. Entity 2 ('cycloidal pen motion') is the object of the preposition 'of', depending on 'modulation' in the phrase 'a modulation of a simple cycloidal pen motion'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'considered' and the prepositional phrase 'as a modulation of a simple cycloidal pen motion'.\"",
        "sdp_path_text": "model → In → considered → as → modulation → of → motion",
        "sentence": "In this model, on-line handwriting is considered as a modulation of cycloidal pen motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the preposition 'In' with 'this'. Entity 2 ('cycloidal pen motion') is the object of the preposition 'of', depending on 'modulation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the phrase 'is considered as a modulation of cycloidal pen motion'.\""
    },
    {
        "raw_sentence": "In this model , on-line handwriting is considered as a modulation of a simple cycloidal pen motion , described by two coupled oscillations with a constant linear drift along the line of the writing .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "constant linear drift",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the preposition 'In' with 'In this'. Entity 2 ('constant linear drift') is part of the object, depending on 'drift' which is modified by 'constant' and 'linear', and it is part of a prepositional phrase 'along the line of the writing', which modifies 'oscillations'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'model' introduces the context in which 'constant linear drift' is described as part of the modulation of pen motion.\"",
        "sdp_path_text": "model → In → considered → as → modulation → described → by → oscillations → with → drift",
        "sentence": "In this model, on-line handwriting is considered as a modulation described by oscillations with a constant linear drift.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the preposition 'In' which introduces it. Entity 2 ('constant linear drift') is the object of the preposition 'with', depending on 'with' in the phrase 'with a constant linear drift'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considered' and the prepositional phrase that follows.\""
    },
    {
        "raw_sentence": "In this model , on-line handwriting is considered as a modulation of a simple cycloidal pen motion , described by two coupled oscillations with a constant linear drift along the line of the writing .",
        "ner_pair": [
            [
                "on-line handwriting",
                "Task"
            ],
            [
                "cycloidal pen motion",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('on-line handwriting') is the subject, depending on the verb 'considered'. Entity 2 ('cycloidal pen motion') is the object of the preposition 'of', depending on 'modulation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the phrase 'considered as a modulation of a simple cycloidal pen motion'.\"",
        "sdp_path_text": "handwriting → considered → as → modulation → of → motion",
        "sentence": "On-line handwriting is considered as a modulation of cycloidal pen motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('on-line handwriting') is the subject, depending on the verb 'considered'. Entity 2 ('cycloidal pen motion') is the object of the preposition 'of', depending on 'modulation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'considered' and the preposition 'of' in the phrase 'as a modulation of cycloidal pen motion'.\""
    },
    {
        "raw_sentence": "In this model , on-line handwriting is considered as a modulation of a simple cycloidal pen motion , described by two coupled oscillations with a constant linear drift along the line of the writing .",
        "ner_pair": [
            [
                "on-line handwriting",
                "Task"
            ],
            [
                "constant linear drift",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('on-line handwriting') is the subject, depending on the verb 'considered'. Entity 2 ('constant linear drift') is part of the prepositional phrase 'with a constant linear drift', which modifies 'oscillations'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause where 'on-line handwriting' is described through a series of modifications and attributes.\"",
        "sdp_path_text": "handwriting → considered → as → modulation → described → by → oscillations → with → drift",
        "sentence": "On-line handwriting is considered as a modulation described by oscillations with a constant linear drift.",
        "sentence_llm_dp_info": "\"Entity 1 ('on-line handwriting') is the subject, depending on the verb 'is considered'. Entity 2 ('constant linear drift') is part of a noun phrase, depending on 'with' in the phrase 'with a constant linear drift'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with a constant linear drift' that modifies the noun 'oscillations'.\""
    },
    {
        "raw_sentence": "In this model , on-line handwriting is considered as a modulation of a simple cycloidal pen motion , described by two coupled oscillations with a constant linear drift along the line of the writing .",
        "ner_pair": [
            [
                "cycloidal pen motion",
                "Task"
            ],
            [
                "constant linear drift",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cycloidal pen motion') is the object of the preposition 'of', depending on 'modulation'. Entity 2 ('constant linear drift') is part of a prepositional phrase, depending on 'along' in the phrase 'along the line of the writing'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of 'modulation' and 'writing' within the sentence.\"",
        "sdp_path_text": "motion → of → modulation → described → by → oscillations → with → drift",
        "sentence": "Cycloidal pen motion is described by oscillations with constant linear drift.",
        "sentence_llm_dp_info": "\"Entity 1 ('cycloidal pen motion') is the subject, depending on the verb 'is described'. Entity 2 ('constant linear drift') is the object, depending on 'with' in the phrase 'with constant linear drift'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'described' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented .",
        "ner_pair": [
            [
                "cycloidal motion parameters",
                "OtherScientificTerm"
            ],
            [
                "arbitrary handwriting",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cycloidal motion parameters') is the object of the preposition 'of', depending on 'estimation'. Entity 2 ('arbitrary handwriting') is the object of the preposition 'for', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger noun phrase that serves as the object of the sentence, which is governed by the verb 'presented'.\"",
        "sdp_path_text": "parameters → of → estimation → for → handwriting",
        "sentence": "A procedure for estimating cycloidal motion parameters for arbitrary handwriting is presented.",
        "sentence_llm_dp_info": "\"Entity 1 ('cycloidal motion parameters') is the object of the preposition 'for', depending on 'estimating'. Entity 2 ('arbitrary handwriting') is also the object of the preposition 'for', depending on 'parameters'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrases that modify different parts of the sentence, with 'cycloidal motion parameters' being closer to the verb 'presented' through the chain of dependencies.\""
    },
    {
        "raw_sentence": "The result is a discrete motor control representation of the continuous pen motion , via the quantized levels of the model parameters .",
        "ner_pair": [
            [
                "discrete motor control representation",
                "Method"
            ],
            [
                "continuous pen motion",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discrete motor control representation') is the complement of the copula 'is', depending on 'is' with 'result'. Entity 2 ('continuous pen motion') is the object of the preposition 'of', depending on 'of' in the phrase 'of the continuous pen motion'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'of the continuous pen motion'.\"",
        "sdp_path_text": "representation → of → motion",
        "sentence": "The discrete motor control representation models the continuous pen motion.",
        "sentence_llm_dp_info": "\"Entity 1 ('discrete motor control representation') is the subject, depending on the verb 'models'. Entity 2 ('continuous pen motion') is the object, depending on the verb 'models'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is modeling Entity 2.\""
    },
    {
        "raw_sentence": "This motor control representation enables successful word spotting and matching of cursive scripts .",
        "ner_pair": [
            [
                "motor control representation",
                "Method"
            ],
            [
                "word spotting",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('motor control representation') is the subject, depending on the verb 'enables'. Entity 2 ('word spotting') is part of the compound object, depending on 'matching' with 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'enables' which facilitates the action described by the compound object 'word spotting and matching'.\"",
        "sdp_path_text": "representation → enables → spotting",
        "sentence": "Motor control representation enables word spotting.",
        "sentence_llm_dp_info": "\"Entity 1 ('motor control representation') is the subject, depending on the verb 'enables'. Entity 2 ('word spotting') is the object, depending on the verb 'enables'. There is a direct dependency between Entity 1 and Entity 2, as 'motor control representation' directly enables 'word spotting'.\""
    },
    {
        "raw_sentence": "This motor control representation enables successful word spotting and matching of cursive scripts .",
        "ner_pair": [
            [
                "motor control representation",
                "Method"
            ],
            [
                "matching of cursive scripts",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('motor control representation') is the subject, depending on the verb 'enables'. Entity 2 ('matching of cursive scripts') is the object of the conjunction 'and', which is part of the compound object of the verb 'enables'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where Entity 1 enables the action described by Entity 2.\"",
        "sdp_path_text": "representation → enables → spotting → matching",
        "sentence": "Motor control representation enables matching of cursive scripts.",
        "sentence_llm_dp_info": "\"Entity 1 ('motor control representation') is the subject, depending on the verb 'enables'. Entity 2 ('matching of cursive scripts') is the object, depending on the verb 'enables'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 enables Entity 2.\""
    },
    {
        "raw_sentence": "This motor control representation enables successful word spotting and matching of cursive scripts .",
        "ner_pair": [
            [
                "word spotting",
                "Task"
            ],
            [
                "matching of cursive scripts",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word spotting') is part of the compound object of the verb 'enables', depending on the conjunction 'and' with 'matching of cursive scripts'. Entity 2 ('matching of cursive scripts') is also part of the compound object, depending on the conjunction 'and' with 'word spotting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' as parts of a compound object.\"",
        "sdp_path_text": "spotting → matching",
        "sentence": "Word spotting enables matching of cursive scripts.",
        "sentence_llm_dp_info": "\"Entity 1 ('word spotting') is the subject, depending on the verb 'enables'. Entity 2 ('matching of cursive scripts') is the object, depending on 'enables' with 'word spotting'. There is a direct dependency between Entity 1 and Entity 2, where 'word spotting' enables 'matching of cursive scripts'.\""
    },
    {
        "raw_sentence": "Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition .",
        "ner_pair": [
            [
                "dynamic representation",
                "Method"
            ],
            [
                "cursive handwriting recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dynamic representation') is the object of the preposition 'of', depending on 'indicate' through the prepositional phrase 'the potential of this dynamic representation'. Entity 2 ('cursive handwriting recognition') is the object of the preposition 'for', depending on 'representation' through the prepositional phrase 'for complete cursive handwriting recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose or application of Entity 1 towards Entity 2.\"",
        "sdp_path_text": "representation → of → potential → for → recognition",
        "sentence": "The dynamic representation has potential for cursive handwriting recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('dynamic representation') is the subject, depending on the verb 'has'. Entity 2 ('cursive handwriting recognition') is the object of the preposition 'for', depending on 'for' in the phrase 'for cursive handwriting recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "Object Recognition task",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the object of the preposition 'between', depending on 'di-chotomy'. Entity 2 ('Object Recognition task') is the subject, depending on the verb 'exists'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related within the same clause describing aspects of the 'Object Recognition task'.\"",
        "sdp_path_text": "categorization → between → chotomy → exists → In → task",
        "sentence": "In the Object Recognition task, there exists a dichotomy between the categorization of objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the object of the preposition 'between', depending on 'between' in the phrase 'between the categorization of objects'. Entity 2 ('Object Recognition task') is the object of the preposition 'in', depending on 'in' in the phrase 'In the Object Recognition task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases that describe their roles in the sentence.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "estimating object pose",
                "Task"
            ],
            [
                "Object Recognition task",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is part of the coordination, depending on the conjunction 'and' with 'categorization of objects'. It is also the object of the preposition 'between', which depends on the noun 'di-chotomy'. Entity 2 ('Object Recognition task') is the subject complement, depending on the verb 'exists'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as parts of the description within the same sentence.\"",
        "sdp_path_text": "estimating → categorization → between → chotomy → exists → In → task",
        "sentence": "In the Object Recognition task, estimating object pose differs from object categorization.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject of the clause, depending on 'differs' as the main verb. Entity 2 ('Object Recognition task') is the object of the preposition 'in', depending on the preposition 'in' at the beginning of the sentence. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the sentence where Entity 1 is described as differing from another concept within the scope of Entity 2.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "Object Recognition task",
                "Task"
            ],
            [
                "former",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the existential verb 'exists'. Entity 2 ('former') is the subject, depending on the verb 'necessitates' in the clause 'the former necessitates a view-invariant representation'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the same sentence.\"",
        "sdp_path_text": "task → In → exists → chotomy → necessitates → former",
        "sentence": "The Object Recognition task necessitates a view-invariant representation for the former.",
        "sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the verb 'necessitates'. Entity 2 ('former') is the object of the preposition 'for', depending on 'for' in the phrase 'for the former'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'necessitates' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "Object Recognition task",
                "Task"
            ],
            [
                "view-invariant representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on 'exists' with 'there'. Entity 2 ('view-invariant representation') is the object, depending on 'necessitates' with 'former'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the logical structure of the sentence, where the 'Object Recognition task' is part of the context in which the need for a 'view-invariant representation' is discussed.\"",
        "sdp_path_text": "task → In → exists → chotomy → necessitates → representation",
        "sentence": "The Object Recognition task necessitates a view-invariant representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the verb 'necessitates'. Entity 2 ('view-invariant representation') is the object, depending on 'necessitates' with 'Object Recognition task'. There is a direct dependency between Entity 1 and Entity 2, as 'view-invariant representation' is directly required by the 'Object Recognition task'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "Object Recognition task",
                "Task"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the verb 'exists'. Entity 2 ('latter') is the subject of the clause 'the latter requires a representation capable of capturing pose information over different categories of objects', depending on 'requires'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related within the same sentence, where 'latter' refers back to one of the aspects mentioned in the dichotomy described in the sentence.\"",
        "sdp_path_text": "task → In → exists → chotomy → necessitates → requires → latter",
        "sentence": "In the Object Recognition task, the latter requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the noun modifier, depending on the preposition 'in' with 'In'. Entity 2 ('latter') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'latter' refers to an element mentioned earlier that is related to the 'Object Recognition task'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "Object Recognition task",
                "Task"
            ],
            [
                "representation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the existential verb 'exists'. Entity 2 ('representation') appears twice in the sentence: first as the object of the noun 'view-invariant', and second as the object of the noun 'representation' that is part of the clause requiring 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2; however, they are contextually related through the discussion of requirements for different aspects of the Object Recognition task.\"",
        "sdp_path_text": "task → In → exists → chotomy → necessitates → representation",
        "sentence": "The Object Recognition task necessitates a representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the verb 'necessitates'. Entity 2 ('representation') is the object, depending on the verb 'necessitates'. There is a direct dependency between Entity 1 and Entity 2, as 'representation' is directly required or necessitated by the 'Object Recognition task'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "Object Recognition task",
                "Task"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on 'exists' with 'there'. Entity 2 ('pose information') is the object, depending on 'capturing' with 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the discussion of different aspects (categorization vs. estimating) within the 'Object Recognition task'.\"",
        "sdp_path_text": "task → In → exists → chotomy → necessitates → requires → representation → capable → of → capturing → information",
        "sentence": "The Object Recognition task requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('Object Recognition task') is the subject, depending on the verb 'requires'. Entity 2 ('pose information') is the object, depending on the verb 'capturing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the requirement that the representation must capture Entity 2 for Entity 1 to be fulfilled.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "estimating object pose",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the object of the preposition 'between', depending on 'di-chotomy'. Entity 2 ('estimating object pose') is also the object of the preposition 'between', depending on 'di-chotomy'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase describing the di-chotomy.\"",
        "sdp_path_text": "categorization → estimating",
        "sentence": "Categorization of objects differs from estimating object pose.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the subject, depending on the verb 'differs'. Entity 2 ('estimating object pose') is the complement, depending on 'from' in the phrase 'from estimating object pose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' which indicates a comparison or distinction between them.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "former",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the object of the preposition 'between', depending on 'di-chotomy'. Entity 2 ('former') is an expletive, referring back to 'the categorization of objects' and depending on 'necessitates'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the reference of 'former' to 'categorization of objects'.\"",
        "sdp_path_text": "categorization → between → chotomy → necessitates → former",
        "sentence": "The categorization of objects necessitates a view-invariant representation, which is the former.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the subject, depending on the verb 'necessitates'. Entity 2 ('former') is an appositive, depending on 'representation' to provide additional information about it. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause that describes the necessity of a 'view-invariant representation'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "view-invariant representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the object of the preposition 'between', depending on 'di-chotomy'. Entity 2 ('view-invariant representation') is the object of the preposition 'of', depending on 'necessitates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the complex sentence structure describing the requirements for different aspects of the Object Recognition task.\"",
        "sdp_path_text": "categorization → between → chotomy → necessitates → representation",
        "sentence": "Categorization of objects necessitates a view-invariant representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the subject, depending on the verb 'necessitates'. Entity 2 ('view-invariant representation') is the object, depending on 'necessitates' with 'categorization of objects'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is the direct object of the verb that Entity 1 depends on.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is part of the coordination, depending on 'between' in the phrase 'between the categorization of objects and estimating object pose'. Entity 2 ('latter') is the subject, depending on 'requires' in the clause 'the latter requires a representation capable of capturing pose information over different categories of objects'. There is no direct dependency between Entity 1 and Entity 2; they are part of a coordinated structure introduced by 'between'.\"",
        "sdp_path_text": "categorization → between → chotomy → necessitates → requires → latter",
        "sentence": "The categorization of objects necessitates a view-invariant representation, while the latter requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the subject, depending on the verb 'necessitates'. Entity 2 ('latter') is the subject of the clause 'the latter requires', depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2; however, they are both subjects of related clauses that describe requirements for processes or representations.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "representation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the object of the preposition 'between', depending on 'di-chotomy'. Entity 2 ('representation') is the subject, depending on 'necessitates' in the clause 'the former necessitates a view-invariant representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the logical structure of the sentence, where the necessity for a 'view-invariant representation' (Entity 2) is associated with the 'categorization of objects' (Entity 1) as part of the dichotomy described.\"",
        "sdp_path_text": "categorization → between → chotomy → necessitates → representation",
        "sentence": "Categorization of objects necessitates a view-invariant representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the subject, depending on the verb 'necessitates'. Entity 2 ('representation') is the object, depending on 'necessitates' with 'categorization of objects'. There is a direct dependency between Entity 1 and Entity 2, as 'representation' is the direct object of the verb 'necessitates' which is governed by 'categorization of objects'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "categorization of objects",
                "Task"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is part of a nominal clause, depending on 'di-chotomy' with the preposition 'between'. Entity 2 ('pose information') is the object of the preposition 'of', depending on 'capturing' in the phrase 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the 'di-chotomy' described in the sentence.\"",
        "sdp_path_text": "categorization → between → chotomy → necessitates → requires → representation → capable → of → capturing → information",
        "sentence": "Categorization of objects necessitates a view-invariant representation, while capturing pose information requires a different representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('categorization of objects') is the subject, depending on the verb 'necessitates'. Entity 2 ('pose information') is the object, depending on 'capturing' which is part of the clause 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2, but both are related to different aspects of representation in the sentence.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "estimating object pose",
                "Task"
            ],
            [
                "former",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is part of a coordination, depending on 'between' in the phrase 'between the categorization of objects and estimating object pose'. Entity 2 ('former') is the subject, depending on 'necessitates' in the clause 'the former necessitates a view-invariant representation'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the coordinating conjunction 'and' and the preposition 'between'.\"",
        "sdp_path_text": "estimating → categorization → between → chotomy → necessitates → former",
        "sentence": "Estimating object pose requires a representation capable of capturing pose information, while the former necessitates a view-invariant representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject, depending on the verb 'requires'. Entity 2 ('former') is the subject of the clause 'the former necessitates a view-invariant representation', depending on 'necessitates'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where 'the former' refers back to 'estimating object pose'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "estimating object pose",
                "Task"
            ],
            [
                "view-invariant representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is part of the coordination, depending on the conjunction 'and' with 'categorization of objects'. Entity 2 ('view-invariant representation') is the object of the preposition 'of', depending on 'necessitates'. There is no direct dependency between Entity 1 and Entity 2; however, they are both related to different aspects of the dichotomy described in the sentence.\"",
        "sdp_path_text": "estimating → categorization → between → chotomy → necessitates → representation",
        "sentence": "Estimating object pose requires a representation capable of capturing pose information, while categorization necessitates a view-invariant representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject, depending on the verb 'requires'. Entity 2 ('view-invariant representation') is the object, depending on 'necessitates' with 'categorization'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of representation in the context of their respective processes (requiring and necessitating).\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "estimating object pose",
                "Task"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is part of a coordination, depending on 'between' in the phrase 'between the categorization of objects and estimating object pose'. Entity 2 ('latter') is the subject complement, depending on 'requires' in the clause 'the latter requires a representation capable of capturing pose information over different categories of objects'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 refers back to Entity 1 in the context of the sentence.\"",
        "sdp_path_text": "estimating → categorization → between → chotomy → necessitates → requires → latter",
        "sentence": "Estimating object pose requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject, depending on the verb 'requires'. Entity 2 ('latter') is not present in the sentence provided, so it cannot be analyzed for dependencies within this context. There is no direct dependency between Entity 1 and Entity 2 because Entity 2 does not appear in the sentence.\"\n\nNote: The term \"latter\" typically refers back to something mentioned earlier in the text, which is not provided in the given sentence. If you meant to use a different word or if there's additional context, please provide it for a more accurate analysis."
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "estimating object pose",
                "Task"
            ],
            [
                "representation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is part of the coordination, depending on 'between' with 'di-chotomy'. Entity 2 ('representation') is the object, depending on 'requires' with 'latter'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence, where Entity 2 is required for the process described by Entity 1.\"",
        "sdp_path_text": "estimating → categorization → between → chotomy → necessitates → representation",
        "sentence": "Estimating object pose requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject, depending on the verb 'requires'. Entity 2 ('representation') is the object, depending on 'requires' with 'estimating object pose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "estimating object pose",
                "Task"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject of the clause, depending on the verb 'exists'. It is also part of a larger comparison introduced by 'between'. Entity 2 ('pose information') is the object of the preposition 'of', depending on 'capturing' in the phrase 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence, specifically the comparison introduced by 'between' and the context provided by the clauses describing what each part necessitates or requires.\"",
        "sdp_path_text": "estimating → categorization → between → chotomy → necessitates → requires → representation → capable → of → capturing → information",
        "sentence": "Estimating object pose requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('estimating object pose') is the subject, depending on the verb 'requires'. Entity 2 ('pose information') is the object, depending on 'capturing' with 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the requirement that a representation capable of capturing Entity 2 is needed for Entity 1.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "view-invariant representation",
                "Method"
            ],
            [
                "former",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('view-invariant representation') is the object, depending on 'necessitates' with 'former'. Entity 2 ('former') is the subject, depending on 'necessitates' with 'representation'. There is a direct dependency between Entity 1 and Entity 2, as 'former' refers back to 'categorization of objects', which necessitates a 'view-invariant representation'.\"",
        "sdp_path_text": "representation → necessitates → former",
        "sentence": "The former necessitates a view-invariant representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('view-invariant representation') is the object, depending on 'necessitates' with 'former'. Entity 2 ('former') is the subject, depending on 'necessitates'. There is a direct dependency between Entity 1 and Entity 2, where 'former' necessitates 'view-invariant representation'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('former') is the subject, depending on 'necessitates' with the verb 'necessitates'. Entity 2 ('latter') is the subject, depending on 'requires' with the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a coordinated structure introduced by 'where', indicating a contrast between two aspects of the Object Recognition task.\"",
        "sdp_path_text": "former → necessitates → requires → latter",
        "sentence": "The former necessitates a view-invariant representation, while the latter requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('former') is the subject, depending on the verb 'necessitates'. Entity 2 ('latter') is also the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects of different clauses in the sentence, connected by the conjunction 'while'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "representation",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('former') is the subject, depending on 'necessitates' with 'a view-invariant representation'. Entity 2 ('representation') is the object, depending on 'necessitates' with 'former'. There is a direct dependency between Entity 1 and Entity 2, as 'former' necessitates 'representation'.\"\n\nHowever, for a more accurate dependency analysis, let's break down the sentence further:\n\n- \"Entity 1 ('former')\" is the subject of the clause \"the former necessitates a view-invariant representation,\" where it depends on the verb 'necessitates'.\n- \"Entity 2 ('representation')\" is the object of the verb 'necessitates' in the same clause, directly dependent on 'former'.\n\nThus, the final answer is:\n\"Entity 1 ('former') is the subject, depending on the verb 'necessitates'. Entity 2 ('representation') is the object, depending on 'necessitates' with 'former'. There is a direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "former → necessitates → representation",
        "sentence": "The former necessitates a representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('former') is the subject, depending on the verb 'necessitates'. Entity 2 ('representation') is the object, depending on 'necessitates' with 'former'. There is a direct dependency between Entity 1 and Entity 2, where 'representation' is the direct object of 'necessitates'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "former",
                "Generic"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('former') is the subject, depending on 'necessitates' with 'view-invariant representation'. Entity 2 ('pose information') is the object, depending on 'capturing' with 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure, where 'former' refers to 'categorization of objects' and 'pose information' is related to 'estimating object pose'.\"",
        "sdp_path_text": "former → necessitates → requires → representation → capable → of → capturing → information",
        "sentence": "The former necessitates a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('former') is the subject, depending on the verb 'necessitates'. Entity 2 ('pose information') is the object, depending on the verb 'capturing' within the prepositional phrase 'of capturing pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'necessitates' and the prepositional phrase 'of capturing'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "view-invariant representation",
                "Method"
            ],
            [
                "latter",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('view-invariant representation') is the object, depending on 'necessitates' with 'the former'. Entity 2 ('latter') is the subject, depending on 'requires' with 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the discussion of requirements for different aspects of the object recognition task.\"",
        "sdp_path_text": "representation → necessitates → requires → latter",
        "sentence": "A view-invariant representation necessitates the latter, which requires capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('view-invariant representation') is the subject, depending on the verb 'necessitates'. Entity 2 ('latter') is the object, depending on 'requires' in the clause 'which requires capturing pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause 'which requires capturing pose information' where 'which' refers back to 'view-invariant representation'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "view-invariant representation",
                "Method"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('view-invariant representation') is the object, depending on 'necessitates' with 'the former'. Entity 2 ('pose information') is the object of the preposition 'of', depending on 'capturing' in the phrase 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2; both are related to the concepts of 'categorization of objects' and 'estimating object pose' respectively, which are described as being in a dichotomy.\"",
        "sdp_path_text": "representation → necessitates → requires → representation → capable → of → capturing → information",
        "sentence": "A view-invariant representation necessitates capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('view-invariant representation') is the subject, depending on the verb 'necessitates'. Entity 2 ('pose information') is the object, depending on the verb 'capturing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'necessitates' which indicates that Entity 1 requires the action of capturing Entity 2.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "representation",
                "Generic"
            ],
            [
                "latter",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('representation') is the object, depending on 'necessitates' in the clause 'the former necessitates a view-invariant representation'. Entity 2 ('latter') is the subject, depending on 'requires' in the clause 'the latter requires a representation capable of capturing pose information over different categories of objects'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'representation' in different contexts within the sentence.\"",
        "sdp_path_text": "representation → necessitates → requires → latter",
        "sentence": "The latter requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject, depending on the verb 'requires' with 'The latter'. Entity 2 ('latter') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where 'representation' is what 'the latter' requires.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "latter",
                "Generic"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('latter') is the subject, depending on the verb 'requires'. Entity 2 ('pose information') is the object, depending on the verb 'capturing' in the phrase 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires' and the prepositional phrase 'of capturing pose information over different categories of objects'.\"",
        "sdp_path_text": "latter → requires → representation → capable → of → capturing → information",
        "sentence": "The latter requires a representation capable of capturing pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('latter') is the subject, depending on the verb 'requires'. Entity 2 ('pose information') is the object, depending on 'capturing' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires' and the prepositional phrase 'of capturing pose information'.\""
    },
    {
        "raw_sentence": "In the Object Recognition task , there exists a di-chotomy between the categorization of objects and estimating object pose , where the former necessitates a view-invariant representation , while the latter requires a representation capable of capturing pose information over different categories of objects .",
        "ner_pair": [
            [
                "representation",
                "Generic"
            ],
            [
                "pose information",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('representation') is the object of the preposition 'of', depending on 'necessitates' in the clause 'the former necessitates a view-invariant representation'. Entity 2 ('pose information') is the object of the preposition 'of', depending on 'capturing' in the clause 'a representation capable of capturing pose information over different categories of objects'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of 'representation' in their respective clauses.\"",
        "sdp_path_text": "representation → necessitates → requires → representation → capable → of → capturing → information",
        "sentence": "A representation capable of capturing pose information is required.",
        "sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject, depending on the verb 'required'. Entity 2 ('pose information') is the object of the preposition 'of', depending on 'capturing' in the phrase 'capturing pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'capturing' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "With the rise of deep archi-tectures , the prime focus has been on object category recognition .",
        "ner_pair": [
            [
                "deep archi-tectures",
                "Method"
            ],
            [
                "object category recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep archi-tectures') is the object of the preposition 'of', depending on 'rise'. Entity 2 ('object category recognition') is the object of the preposition 'on', depending on 'focus'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context described by the sentence, where the rise of deep architectures influences the focus on object category recognition.\"",
        "sdp_path_text": "archi → of → rise → With → been → on → recognition",
        "sentence": "The rise of deep architectures has focused on object category recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep architectures') is the subject, depending on the verb 'has focused'. Entity 2 ('object category recognition') is the object of the preposition 'on', depending on 'on' in the phrase 'on object category recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has focused' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Deep learning methods have achieved wide success in this task .",
        "ner_pair": [
            [
                "Deep learning methods",
                "Method"
            ],
            [
                "task",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Deep learning methods') is the subject, depending on the verb 'have achieved'. Entity 2 ('task') is the object of the preposition 'in', depending on 'in' in the phrase 'in this task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in this task'.\"",
        "sdp_path_text": "methods → achieved → in → task",
        "sentence": "Deep learning methods have achieved success in the task.",
        "sentence_llm_dp_info": "\"Entity 1 ('Deep learning methods') is the subject, depending on the verb 'have achieved'. Entity 2 ('task') is the object of the preposition 'in', depending on 'in' in the phrase 'in the task'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'have achieved' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "In contrast , object pose estimation using these approaches has received relatively less attention .",
        "ner_pair": [
            [
                "approaches",
                "Generic"
            ],
            [
                "object pose estimation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approaches') is the object of the preposition 'using', depending on 'using' in the phrase 'using these approaches'. Entity 2 ('object pose estimation') is the subject, depending on the verb 'has received'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with Entity 1 being part of the prepositional phrase that modifies the subject (Entity 2).\"",
        "sdp_path_text": "approaches → using → estimation",
        "sentence": "Approaches have been used for object pose estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('approaches') is the subject, depending on the verb 'have been used'. Entity 2 ('object pose estimation') is the object of the preposition 'for', depending on 'for' in the phrase 'for object pose estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this work , we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation .",
        "ner_pair": [
            [
                "Convolutional Neural Networks -LRB- CNN -RRB- architectures",
                "Method"
            ],
            [
                "object recognition",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Convolutional Neural Networks -LRB- CNN -RRB- architectures') is the subject complement, depending on 'can be adapted' with 'architectures'. Entity 2 ('object recognition') is part of the compound object, depending on 'task' with 'and pose estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'adapted' and the prepositional phrase 'to the task of simultaneous object recognition and pose estimation'.\"",
        "sdp_path_text": "architectures → adapted → to → task → of → recognition",
        "sentence": "Convolutional Neural Network architectures can be adapted for object recognition.",
        "sentence_llm_dp_info": "\"Entity 1 ('Convolutional Neural Networks (CNN) architectures') is the subject, depending on the modal verb 'can' and the main verb 'be adapted'. Entity 2 ('object recognition') is the object, depending on the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb phrase 'can be adapted for'.\""
    },
    {
        "raw_sentence": "In this work , we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation .",
        "ner_pair": [
            [
                "Convolutional Neural Networks -LRB- CNN -RRB- architectures",
                "Method"
            ],
            [
                "pose estimation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Convolutional Neural Networks -LRB- CNN -RRB- architectures') is the subject complement, depending on 'adapted' with 'can be'. Entity 2 ('pose estimation') is part of a compound object, depending on 'task' in the phrase 'task of simultaneous object recognition and pose estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the adaptation task.\"",
        "sdp_path_text": "architectures → adapted → to → task → of → recognition → estimation",
        "sentence": "Convolutional Neural Network (CNN) architectures can be adapted for pose estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Convolutional Neural Networks (CNN) architectures') is the subject, depending on the modal verb 'can' which is part of the predicate 'can be adapted'. Entity 2 ('pose estimation') is the object, depending on the verb 'adapted' through the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'adapted' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this work , we study how Convolutional Neural Networks -LRB- CNN -RRB- architectures can be adapted to the task of simultaneous object recognition and pose estimation .",
        "ner_pair": [
            [
                "object recognition",
                "Task"
            ],
            [
                "pose estimation",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object recognition') is part of the compound object, depending on the verb 'adapted'. Entity 2 ('pose estimation') is also part of the compound object, depending on the conjunction 'and' which connects it to 'object recognition'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of a larger compound object that depends on the verb 'adapted'.\"",
        "sdp_path_text": "recognition → estimation",
        "sentence": "We study adapting CNN architectures for object recognition and pose estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('object recognition') is part of the compound object, depending on 'for' in the phrase 'for object recognition'. Entity 2 ('pose estimation') is also part of the compound object, depending on 'and' which links it to 'object recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the compound object linked by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers",
                "OtherScientificTerm"
            ],
            [
                "CNN models",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'investigate and analyze'. Entity 2 ('CNN models') is the object of the preposition 'of', depending on 'various'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'the layers of various CNN models'.\"",
        "sdp_path_text": "layers → of → models",
        "sentence": "We investigate the layers of CNN models.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'investigate'. Entity 2 ('CNN models') is the second part of the compound object, also depending on 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both parts of the compound object in the prepositional phrase 'of CNN models'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers",
                "OtherScientificTerm"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'models'. Entity 2 ('them') is a pronoun, depending on 'compare' as its object. There is no direct dependency between Entity 1 and Entity 2; however, 'them' likely refers back to 'layers' in the context of the sentence.\"",
        "sdp_path_text": "layers → analyze → investigate → compare → between → them",
        "sentence": "We analyze and compare the layers of various CNN models.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'compare'. Entity 2 ('them') is a pronoun, serving as the object of the verb 'analyze' and 'compare', referring back to 'CNN models'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause and related through the verbs 'analyze' and 'compare'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers",
                "OtherScientificTerm"
            ],
            [
                "CNNs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'investigate and analyze'. Entity 2 ('CNNs') is the object of the preposition 'of', depending on 'layers' in the phrase 'the layers of various CNN models'. There is a direct dependency between Entity 1 and Entity 2, as 'layers' directly modifies 'CNNs' to specify which layers are being discussed.\"",
        "sdp_path_text": "layers → analyze → investigate → compare → with → goal → of → discovering → represent → layers → of → representations → within → CNNs",
        "sentence": "We investigate and analyze the layers of CNNs to discover how they represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'CNNs'. Entity 2 ('CNNs') is the subject, depending on the verb 'investigate' and 'analyze'. There is a direct dependency between Entity 1 and Entity 2, as 'layers' is part of 'CNNs' in the context of the sentence.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers",
                "OtherScientificTerm"
            ],
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'investigate and analyze'. Entity 2 ('object pose information') is the object of the preposition 'of', depending on 'discovering'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader structure where 'layers' are analyzed for their representation of 'object pose information'.\"",
        "sdp_path_text": "layers → analyze → investigate → compare → with → goal → of → discovering → represent → information",
        "sentence": "We investigate how layers represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the verb 'investigate', depending on 'We'. Entity 2 ('object pose information') is the object of the verb 'represent', depending on 'layers'. There is a direct dependency between Entity 1 and Entity 2, as 'layers' is the subject of the verb 'represent' which has 'object pose information' as its object.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers",
                "OtherScientificTerm"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'CNN models'. Entity 2 ('this') is part of the noun phrase 'this contradicts', depending on 'contradicts' as its subject. There is no direct dependency between Entity 1 and Entity 2; they are connected through the broader context of the sentence, where both are discussed in the context of CNN models and their representations.\"",
        "sdp_path_text": "layers → analyze → investigate → compare → with → goal → of → discovering → represent → contradicts → this",
        "sentence": "We analyze and compare layers to discover how they represent and contradict this.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the verbs 'analyze' and 'compare', depending on the conjunction 'and' which connects the two verbs. Entity 2 ('this') is the object of the preposition 'of', depending on 'contradict' in the phrase 'contradict this'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'layers' are being analyzed and compared to understand their representation and contradiction of 'this'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers",
                "OtherScientificTerm"
            ],
            [
                "object category representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers') is the object of the preposition 'of', depending on 'CNN models'. Entity 2 ('object category representations') is the object of the preposition 'with', depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the investigation and comparison of CNN models and their representation of different types of information.\"",
        "sdp_path_text": "layers → analyze → investigate → compare → with → goal → of → discovering → represent → contradicts → with → representations",
        "sentence": "We investigate how layers represent object pose information and contradict object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers') is the subject, depending on the verb 'investigate'. Entity 2 ('object category representations') is the object of the verb 'contradict', depending on 'contradict' in the clause 'and contradict object category representations'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the verbs 'represent' and 'contradict'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNN models",
                "Method"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('them') is the object of the preposition 'between', depending on 'compare'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers back to 'CNN models' in the context of the comparison.\"",
        "sdp_path_text": "models → of → layers → analyze → investigate → compare → between → them",
        "sentence": "We investigate and analyze the layers of CNN models and compare them.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('them') is a pronoun, referring back to 'layers of CNN models', and is the object of the verb 'compare'. There is no direct dependency between Entity 1 and Entity 2, but 'them' refers back to 'layers of CNN models', creating an indirect reference.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNN models",
                "Method"
            ],
            [
                "layers of distributed representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('layers of distributed representations') is the subject complement, depending on 'represent' in the clause 'how the layers of distributed representations within CNNs represent object pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the investigation and comparison described in the sentence.\"",
        "sdp_path_text": "models → of → layers → analyze → investigate → compare → with → goal → of → discovering → represent → layers",
        "sentence": "We investigate and analyze the layers of CNN models to discover how they represent distributed representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('layers of distributed representations') is the direct object, depending on 'discover'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'discover' and the prepositional structure involving 'of'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNN models",
                "Method"
            ],
            [
                "CNNs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('CNNs') is the object of the preposition 'within', depending on 'representations'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of neural network architectures being analyzed and compared.\"",
        "sdp_path_text": "models → of → layers → analyze → investigate → compare → with → goal → of → discovering → represent → layers → of → representations → within → CNNs",
        "sentence": "We investigate and analyze the layers of CNN models and compare them to discover how layers within CNNs represent information.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('CNNs') is the object of the preposition 'within', depending on 'layers'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the concept of 'layers' in the context of the sentence.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNN models",
                "Method"
            ],
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('object pose information') is the object of the preposition 'of', depending on 'represent'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the layers of CNN models are compared in terms of how they represent different types of information, including object pose information.\"",
        "sdp_path_text": "models → of → layers → analyze → investigate → compare → with → goal → of → discovering → represent → information",
        "sentence": "We investigate and analyze the layers of CNN models to discover how they represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('object pose information') is the object, depending on 'represent' which is part of the clause 'how they represent object pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'represent' and the clause 'how they represent'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNN models",
                "Method"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('this') is the subject complement, depending on 'contradicts' with 'how'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same complex sentence structure, where 'this' refers back to a previously mentioned concept related to the layers of CNN models.\"",
        "sdp_path_text": "models → of → layers → analyze → investigate → compare → with → goal → of → discovering → represent → contradicts → this",
        "sentence": "We investigate and analyze the layers of CNN models to discover how they represent object pose information and how this contradicts with object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('this') is the subject, depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'this' refers back to the information about 'CNN models'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNN models",
                "Method"
            ],
            [
                "object category representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('object category representations') is the object of the preposition 'with', depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the goal of the investigation and analysis.\"",
        "sdp_path_text": "models → of → layers → analyze → investigate → compare → with → goal → of → discovering → represent → contradicts → with → representations",
        "sentence": "We investigate and analyze the layers of CNN models to discover how they represent object pose information and contradict object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN models') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('object category representations') is the object, depending on 'contradict' with 'how they represent object pose information'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'CNN models' are analyzed to understand their representation of different aspects, including 'object category representations'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "layers of distributed representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'between', depending on 'compare'. Entity 2 ('layers of distributed representations') is the subject complement, depending on 'of' with 'how'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader structure describing what is being compared and analyzed in the sentence.\"",
        "sdp_path_text": "them → between → compare → with → goal → of → discovering → represent → layers",
        "sentence": "We compare them to discover how the layers of distributed representations represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'compare' with 'We'. Entity 2 ('layers of distributed representations') is the subject complement, depending on 'discover' through the prepositional phrase 'how the layers of distributed representations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the purpose of comparison and discovery.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "CNNs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'between', depending on 'compare'. Entity 2 ('CNNs') is the object of the preposition 'of', depending on 'layers'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the comparison described in the sentence.\"",
        "sdp_path_text": "them → between → compare → with → goal → of → discovering → represent → layers → of → representations → within → CNNs",
        "sentence": "We compare them with the goal of discovering how the layers of representations within CNNs represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'compare', depending on 'We' as the subject. Entity 2 ('CNNs') is the head noun of the prepositional phrase 'of CNNs', which modifies 'layers'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'them' refers to the objects being compared and 'CNNs' specifies the type of neural network whose layers are being analyzed.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'between', depending on 'compare'. Entity 2 ('object pose information') is the object of the preposition 'of', depending on 'discovering'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger clauses that describe the actions being taken in the investigation and comparison of CNN models.\"",
        "sdp_path_text": "them → between → compare → with → goal → of → discovering → represent → information",
        "sentence": "We compare them to discover how they represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'compare', depending on 'compare' in the clause 'We compare them'. Entity 2 ('object pose information') is the object of the verb 'represent', depending on 'represent' in the clause 'how they represent object pose information'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'between', depending on 'compare' in the phrase 'compare between them'. Entity 2 ('this') is the subject complement, depending on 'contradicts' in the phrase 'contradicts with this'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger comparative structure in the sentence.\"",
        "sdp_path_text": "them → between → compare → with → goal → of → discovering → represent → contradicts → this",
        "sentence": "We compare them with the goal of discovering how this represents contradictions.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'compare' with 'We'. Entity 2 ('this') is the subject, depending on 'represents' in the clause 'how this represents contradictions'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "object category representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the preposition 'between', depending on 'compare'. Entity 2 ('object category representations') is the object of the preposition 'with', depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the comparative analysis described in the sentence.\"",
        "sdp_path_text": "them → between → compare → with → goal → of → discovering → represent → contradicts → with → representations",
        "sentence": "We compare them with the goal of discovering how the layers represent object pose information and contradict object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object of the verb 'compare', depending on 'compare' with 'We'. Entity 2 ('object category representations') is the object of the verb 'contradict', depending on 'contradict' within the clause 'and contradict object category representations'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers of distributed representations",
                "Method"
            ],
            [
                "CNNs",
                "Method"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the object of the preposition 'of', depending on 'represent' in the clause 'how the layers of distributed representations within CNNs represent object pose information'. Entity 2 ('CNNs') is the object of the preposition 'within', depending on 'representations'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and connected through the prepositional phrase 'within CNNs'.\"",
        "sdp_path_text": "layers → of → representations → within → CNNs",
        "sentence": "Layers of distributed representations are found within CNNs.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the subject, depending on the verb 'found'. Entity 2 ('CNNs') is the object of the preposition 'within', depending on 'within' in the phrase 'within CNNs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'within'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers of distributed representations",
                "Method"
            ],
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the object of the preposition 'of', depending on 'represent' in the clause 'how the layers of distributed representations within CNNs represent object pose information'. Entity 2 ('object pose information') is the object, depending on 'represent' with 'layers of distributed representations'. There is a direct dependency between Entity 1 and Entity 2, as 'object pose information' is directly represented by 'layers of distributed representations'.\"",
        "sdp_path_text": "layers → represent → information",
        "sentence": "Layers of distributed representations represent object pose information.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the subject, depending on the verb 'represent'. Entity 2 ('object pose information') is the object, depending on 'represent' with 'layers of distributed representations'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 represents Entity 2.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers of distributed representations",
                "Method"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the object of the preposition 'of', depending on 'how' which introduces the clause 'how the layers of distributed representations within CNNs represent object pose information'. Entity 2 ('this') is the subject, depending on 'contradicts' in the phrase 'how this contradicts with object category representations'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same complex sentence structure, where Entity 1 is discussed in the context that contrasts with what Entity 2 refers to.\"",
        "sdp_path_text": "layers → represent → contradicts → this",
        "sentence": "Layers of distributed representations represent and contradict this.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the subject, depending on the verb 'represent'. Entity 2 ('this') is the object of the preposition 'of', but in this context, it is more accurately described as the object that is being represented and contradicted. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verbs 'represent' and 'contradict', which describe the actions performed by Entity 1 towards Entity 2.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "layers of distributed representations",
                "Method"
            ],
            [
                "object category representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the object of the preposition 'of', depending on 'how' in the clause 'how the layers of distributed representations within CNNs represent object pose information'. Entity 2 ('object category representations') is also an object of the preposition 'with', depending on 'contradicts' in the clause 'how this contradicts with object category representations'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the complex structure describing what is being discovered and how it contrasts with another concept.\"",
        "sdp_path_text": "layers → represent → contradicts → with → representations",
        "sentence": "Layers of distributed representations represent information that contradicts object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('layers of distributed representations') is the subject, depending on the verb 'represent'. Entity 2 ('object category representations') is the object of the relative clause, depending on 'contradicts' in the phrase 'that contradicts object category representations'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'contradicts' in the relative clause.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNNs",
                "Method"
            ],
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNNs') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('object pose information') is the object of the preposition 'of', depending on 'represent'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'represent' which describes how the layers of CNNs represent object pose information.\"",
        "sdp_path_text": "CNNs → within → representations → of → layers → represent → information",
        "sentence": "CNNs represent object pose information within their layers.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNNs') is the subject, depending on the verb 'represent'. Entity 2 ('object pose information') is the direct object, depending on 'represent' with 'CNNs'. There is a direct dependency between Entity 1 and Entity 2, as 'CNNs' represents 'object pose information'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNNs",
                "Method"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNNs') is the object of the preposition 'of', depending on 'layers'. Entity 2 ('this') is the subject, depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of the sentence where 'this' refers back to the concept discussed about 'CNNs'.\"",
        "sdp_path_text": "CNNs → within → representations → of → layers → represent → contradicts → this",
        "sentence": "The layers within CNNs represent object pose information, which contradicts this with object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNNs') is part of a prepositional phrase, depending on 'within' with 'layers'. Entity 2 ('this') is the object of the preposition 'with', depending on 'contradicts' in the clause 'which contradicts this with object category representations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'contradicts' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "CNNs",
                "Method"
            ],
            [
                "object category representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNNs') is the object of the preposition 'of', depending on 'layers'. It is part of the phrase 'the layers of CNNs'. Entity 2 ('object category representations') is the object of the preposition 'with', depending on 'contradicts'. It is part of the phrase 'how this contradicts with object category representations'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the larger context of the investigation described in the sentence.\"",
        "sdp_path_text": "CNNs → within → representations → of → layers → represent → contradicts → with → representations",
        "sentence": "CNNs represent object pose information in a way that contradicts with object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNNs') is the subject, depending on the verb 'represent'. Entity 2 ('object category representations') is the object of the preposition 'with', depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'contradicts' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            [
                "this",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object pose information') is the object of the preposition 'of', depending on 'represent'. Entity 2 ('this') is the subject, depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'represent' and the structure of the sentence that links the representation of object pose information to how it contradicts with object category representations.\"",
        "sdp_path_text": "information → represent → contradicts → this",
        "sentence": "The representation of object pose information contradicts this.",
        "sentence_llm_dp_info": "\"Entity 1 ('object pose information') is the subject, depending on 'contradicts' as the main verb. Entity 2 ('this') is the object, depending on 'contradicts' with 'object pose information'. There is a direct dependency between Entity 1 and Entity 2, where 'object pose information' is the subject that performs the action of contradicting 'this'.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "object pose information",
                "OtherScientificTerm"
            ],
            [
                "object category representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('object pose information') is the object of the preposition 'of', depending on 'represent'. Entity 2 ('object category representations') is the complement of the preposition 'with', depending on 'contradicts'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'represent' and the structure describing the investigation and comparison in the sentence.\"",
        "sdp_path_text": "information → represent → contradicts → with → representations",
        "sentence": "The layers of CNNs represent object pose information, which contradicts object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('object pose information') is the object of the verb 'represent', depending on 'layers'. Entity 2 ('object category representations') is the subject of the relative clause, depending on 'which' in the phrase 'which contradicts object category representations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'contradicts' in the relative clause.\""
    },
    {
        "raw_sentence": "We investigate and analyze the layers of various CNN models and extensively compare between them with the goal of discovering how the layers of distributed representations within CNNs represent object pose information and how this contradicts with object category representations .",
        "ner_pair": [
            [
                "this",
                "Generic"
            ],
            [
                "object category representations",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('this') is the object of the preposition 'with', depending on 'goal'. Entity 2 ('object category representations') is the object, depending on 'contradicts' with 'how this contradicts with object category representations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the goal of the investigation.\"",
        "sdp_path_text": "this → contradicts → with → representations",
        "sentence": "This contradicts with object category representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('this') is the subject, depending on the verb 'contradicts'. Entity 2 ('object category representations') is the object of the preposition 'with', depending on 'with' in the phrase 'with object category representations'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy .",
        "ner_pair": [
            [
                "English-Chinese bitexts",
                "Material"
            ],
            [
                "them",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Chinese bitexts') is the object of the preposition 'on', depending on 'work'. Entity 2 ('them') is the object, depending on 'aligning' with 'them'. There is a direct dependency between Entity 1 and Entity 2, as 'them' refers back to 'English-Chinese bitexts'.\"",
        "sdp_path_text": "bitexts → harvesting → aligning → them",
        "sentence": "We harvested and aligned English-Chinese bitexts.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Chinese bitexts') is the object, depending on the verb 'harvested' and also part of the compound verb 'aligned'. Entity 2 ('them') is the object pronoun, referring back to 'English-Chinese bitexts' and depending on the verb 'harvested'. There is a direct dependency between Entity 1 and Entity 2, as 'them' is a pronoun that refers back to 'English-Chinese bitexts'.\""
    },
    {
        "raw_sentence": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy .",
        "ner_pair": [
            [
                "English-Chinese bitexts",
                "Material"
            ],
            [
                "numbering system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Chinese bitexts') is the object of the preposition 'on', depending on 'work'. Entity 2 ('numbering system') is the object of the preposition 'via', depending on 'utilizing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the work presented in the paper.\"",
        "sdp_path_text": "bitexts → harvesting → aligning → via → utilizing → system",
        "sentence": "English-Chinese bitexts are harvested and aligned using the numbering system.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Chinese bitexts') is the subject, depending on the verb 'harvested'. Entity 2 ('numbering system') is the object of the preposition 'using', depending on 'using' in the phrase 'using the numbering system'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'using'.\""
    },
    {
        "raw_sentence": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy .",
        "ner_pair": [
            [
                "English-Chinese bitexts",
                "Material"
            ],
            [
                "legal text hierarchy",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Chinese bitexts') is the object of the preposition 'on', depending on 'work' in the phrase 'our recent work on harvesting English-Chinese bitexts'. Entity 2 ('legal text hierarchy') is the object of the preposition 'in', depending on 'system' in the phrase 'the numbering system in the legal text hierarchy'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "bitexts → harvesting → aligning → via → utilizing → system → in → hierarchy",
        "sentence": "English-Chinese bitexts are harvested and aligned via utilizing the legal text hierarchy.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Chinese bitexts') is the subject, depending on the verb 'harvested'. Entity 2 ('legal text hierarchy') is the object of the preposition 'via', depending on 'via' in the phrase 'via utilizing the legal text hierarchy'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the process described by the verb 'harvested' and the preposition 'via'.\""
    },
    {
        "raw_sentence": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "numbering system",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'aligning' with 'them'. Entity 2 ('numbering system') is the object, depending on 'utilizing' with 'system'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing actions taken on the bitexts and the method used for alignment.\"",
        "sdp_path_text": "them → aligning → via → utilizing → system",
        "sentence": "They align them via utilizing the numbering system.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'align' with 'They'. Entity 2 ('numbering system') is the object of the preposition 'the', depending on 'utilizing' in the phrase 'utilizing the numbering system'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the action described by the verb 'align'.\""
    },
    {
        "raw_sentence": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy .",
        "ner_pair": [
            [
                "them",
                "Generic"
            ],
            [
                "legal text hierarchy",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('them') is the object, depending on 'aligning' with 'them'. Entity 2 ('legal text hierarchy') is the object of the preposition 'in', depending on 'in' in the phrase 'in the legal text hierarchy'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the process of aligning the bitexts.\"",
        "sdp_path_text": "them → aligning → via → utilizing → system → in → hierarchy",
        "sentence": "They are aligned via utilizing the system in the legal text hierarchy.",
        "sentence_llm_dp_info": "\"Entity 1 ('them') is the subject, depending on the verb 'are aligned'. Entity 2 ('legal text hierarchy') is the object of the preposition 'in', depending on 'in' in the phrase 'in the legal text hierarchy'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the legal text hierarchy' which modifies the manner or context of the alignment.\""
    },
    {
        "raw_sentence": "In this paper we present our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the subparagraph level via utilizing the numbering system in the legal text hierarchy .",
        "ner_pair": [
            [
                "numbering system",
                "Method"
            ],
            [
                "legal text hierarchy",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('numbering system') is the object, depending on 'utilizing' with 'via'. Entity 2 ('legal text hierarchy') is the object of the preposition 'in', depending on 'in' in the phrase 'in the legal text hierarchy'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the method used for aligning the bitexts.\"",
        "sdp_path_text": "system → in → hierarchy",
        "sentence": "The numbering system is utilized in the legal text hierarchy.",
        "sentence_llm_dp_info": "\"Entity 1 ('numbering system') is the subject, depending on the verb 'is utilized'. Entity 2 ('legal text hierarchy') is the object of the preposition 'in', depending on 'in' in the phrase 'in the legal text hierarchy'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "It is particularly valuable to empirical MT research .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "empirical MT research",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'is'. Entity 2 ('empirical MT research') is the object of the preposition 'to', depending on 'to' in the phrase 'to empirical MT research'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is particularly valuable to'.\"",
        "sdp_path_text": "It → is → valuable → to → research",
        "sentence": "It is valuable to empirical MT research.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'is'. Entity 2 ('empirical MT research') is the object of the preposition 'to', depending on 'to' in the phrase 'to empirical MT research'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is valuable to'.\""
    },
    {
        "raw_sentence": "Light fields are image-based representations that use densely sampled rays as a scene description .",
        "ner_pair": [
            [
                "Light fields",
                "OtherScientificTerm"
            ],
            [
                "image-based representations",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Light fields') is the subject, depending on the verb 'are'. Entity 2 ('image-based representations') is the predicate nominative, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, as 'Light fields' are equated to 'image-based representations' through the copular verb 'are'.\"",
        "sdp_path_text": "fields → are → representations",
        "sentence": "Light fields are image-based representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('Light fields') is the subject, depending on the copula 'are'. Entity 2 ('image-based representations') is the predicate nominative, also depending on the copula 'are'. There is a direct dependency between Entity 1 and Entity 2, as they are linked through the copula 'are' to form the complete meaning of the sentence.\""
    },
    {
        "raw_sentence": "Light fields are image-based representations that use densely sampled rays as a scene description .",
        "ner_pair": [
            [
                "Light fields",
                "OtherScientificTerm"
            ],
            [
                "densely sampled rays",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Light fields') is the subject, depending on the verb 'are'. Entity 2 ('densely sampled rays') is the object of the relative clause, depending on 'use' with 'Light fields'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use'.\"",
        "sdp_path_text": "fields → are → representations → use → rays",
        "sentence": "Light fields use densely sampled rays as representations.",
        "sentence_llm_dp_info": "\"Entity 1 ('Light fields') is the subject, depending on the verb 'use'. Entity 2 ('densely sampled rays') is the object, depending on 'use' with 'Light fields'. There is a direct dependency between Entity 1 and Entity 2, as 'Light fields' uses 'densely sampled rays' as representations.\""
    },
    {
        "raw_sentence": "Light fields are image-based representations that use densely sampled rays as a scene description .",
        "ner_pair": [
            [
                "Light fields",
                "OtherScientificTerm"
            ],
            [
                "scene description",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Light fields') is the subject, depending on the verb 'are'. Entity 2 ('scene description') is the complement, depending on 'description' which is part of the noun phrase 'as a scene description'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'as a scene description'.\"",
        "sdp_path_text": "fields → are → representations → use → as → description",
        "sentence": "Light fields use densely sampled rays as a scene description.",
        "sentence_llm_dp_info": "\"Entity 1 ('Light fields') is the subject, depending on the verb 'use'. Entity 2 ('scene description') is the object, depending on 'as' in the phrase 'as a scene description'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Light fields are image-based representations that use densely sampled rays as a scene description .",
        "ner_pair": [
            [
                "image-based representations",
                "Method"
            ],
            [
                "densely sampled rays",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image-based representations') is the subject complement, depending on the copular verb 'are' with 'Light fields'. Entity 2 ('densely sampled rays') is the subject of the relative clause, depending on 'use' with 'image-based representations'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is used by Entity 1 in the context of the sentence.\"",
        "sdp_path_text": "representations → use → rays",
        "sentence": "Image-based representations use densely sampled rays.",
        "sentence_llm_dp_info": "\"Entity 1 ('image-based representations') is the subject, depending on the verb 'use'. Entity 2 ('densely sampled rays') is the object, depending on the verb 'use'. There is a direct dependency between Entity 1 and Entity 2, as 'image-based representations' uses 'densely sampled rays'.\""
    },
    {
        "raw_sentence": "Light fields are image-based representations that use densely sampled rays as a scene description .",
        "ner_pair": [
            [
                "image-based representations",
                "Method"
            ],
            [
                "scene description",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image-based representations') is the subject complement, depending on 'are' with 'Light fields'. Entity 2 ('scene description') is the object, depending on 'as' in the phrase 'as a scene description'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'use' where 'image-based representations' are described as using 'scene description'.\"",
        "sdp_path_text": "representations → use → as → description",
        "sentence": "{\n  \"Simplified sentence\": \"Image-based representations use densely sampled rays as a scene description.\"\n} \n\nHowever, to strictly adhere to the instructions and remove any unnecessary information while focusing on the relationship between \"image-based representations\" and \"scene description,\" we can further refine the sentence:\n\n{\n  \"Simplified sentence\": \"Image-based representations use rays as a scene description.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('image-based representations') is the subject, depending on the verb 'use'. Entity 2 ('scene description') is the complement of the preposition 'as', depending on 'as' in the phrase 'as a scene description'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Light fields are image-based representations that use densely sampled rays as a scene description .",
        "ner_pair": [
            [
                "densely sampled rays",
                "OtherScientificTerm"
            ],
            [
                "scene description",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('densely sampled rays') is the object of the relative clause, depending on 'use' as its verb. Entity 2 ('scene description') is the object complement, depending on 'as' which introduces it in the phrase 'as a scene description'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'as'.\"",
        "sdp_path_text": "rays → use → as → description",
        "sentence": "Densely sampled rays are used as a scene description.",
        "sentence_llm_dp_info": "\"Entity 1 ('densely sampled rays') is the subject, depending on the verb 'are used'. Entity 2 ('scene description') is the object of the preposition 'as', depending on 'as' in the phrase 'as a scene description'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'as'.\""
    },
    {
        "raw_sentence": "In this paper , we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching .",
        "ner_pair": [
            [
                "ray space",
                "OtherScientificTerm"
            ],
            [
                "geometric structures of 3D lines",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on 'explore'. Entity 2 ('geometric structures of 3D lines') is the direct object, depending on 'explore'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'geometric structures of 3D lines' is explored within the context of 'ray space'.\"",
        "sdp_path_text": "space → in → lines → of → structures",
        "sentence": "Geometric structures of 3D lines in ray space are explored.",
        "sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on 'explored'. Entity 2 ('geometric structures of 3D lines') is the subject, depending on the verb 'are explored'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in ray space' which modifies the subject.\""
    },
    {
        "raw_sentence": "In this paper , we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching .",
        "ner_pair": [
            [
                "geometric structures of 3D lines",
                "Task"
            ],
            [
                "light field triangulation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric structures of 3D lines') is the object of the verb 'explore', depending on 'explore' with 'we'. Entity 2 ('light field triangulation') is part of the compound object of the preposition 'for', depending on 'for' in the phrase 'for improving light field triangulation and stereo matching'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the purpose of the exploration described in the sentence.\"",
        "sdp_path_text": "structures → explore → for → improving → triangulation",
        "sentence": "We explore geometric structures of 3D lines for improving light field triangulation.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric structures of 3D lines') is the object of the preposition 'of', depending on 'explore'. Entity 2 ('light field triangulation') is the object of the preposition 'for', depending on 'improving'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure where 'geometric structures of 3D lines' is what is being explored to improve 'light field triangulation'.\""
    },
    {
        "raw_sentence": "In this paper , we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching .",
        "ner_pair": [
            [
                "geometric structures of 3D lines",
                "Task"
            ],
            [
                "stereo matching",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('geometric structures of 3D lines') is the object of the preposition 'of', depending on 'explore' with 'we'. Entity 2 ('stereo matching') is the second item in a compound object, depending on 'for improving' which modifies 'triangulation and stereo matching'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the research described in the sentence.\"",
        "sdp_path_text": "structures → explore → for → improving → triangulation → matching",
        "sentence": "We explore geometric structures of 3D lines for improving stereo matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('geometric structures of 3D lines') is the object of the preposition 'of', depending on 'explore' with 'We'. Entity 2 ('stereo matching') is the object of the preposition 'for', depending on 'improving' in the phrase 'for improving stereo matching'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the purpose expressed by 'for improving'.\""
    },
    {
        "raw_sentence": "In this paper , we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching .",
        "ner_pair": [
            [
                "ray space",
                "OtherScientificTerm"
            ],
            [
                "light field triangulation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on the preposition 'in' in the phrase 'in ray space'. Entity 2 ('light field triangulation') is part of the object of the preposition 'for', depending on the verb 'improving'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause that describes the purpose of exploring geometric structures.\"",
        "sdp_path_text": "space → in → lines → of → structures → explore → for → improving → triangulation",
        "sentence": "We explore geometric structures of 3D lines in ray space for improving light field triangulation.",
        "sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on 'explore'. Entity 2 ('light field triangulation') is the object of the preposition 'for', depending on 'improving'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the purpose and context of the exploration.\""
    },
    {
        "raw_sentence": "In this paper , we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching .",
        "ner_pair": [
            [
                "ray space",
                "OtherScientificTerm"
            ],
            [
                "stereo matching",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on 'explore' with the phrase 'geometric structures of 3D lines in ray space'. Entity 2 ('stereo matching') is the second object in a compound object, depending on 'for improving' with 'light field triangulation and stereo matching'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "space → in → lines → of → structures → explore → for → improving → triangulation → matching",
        "sentence": "We explore geometric structures of 3D lines in ray space for improving stereo matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on 'explore'. Entity 2 ('stereo matching') is the object of the gerund 'improving', depending on 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the purpose clause introduced by 'for improving'.\""
    },
    {
        "raw_sentence": "In this paper , we explore geometric structures of 3D lines in ray space for improving light field triangulation and stereo matching .",
        "ner_pair": [
            [
                "light field triangulation",
                "Task"
            ],
            [
                "stereo matching",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('light field triangulation') is part of the compound object, depending on the preposition 'for' which modifies the verb 'improving'. Entity 2 ('stereo matching') is also part of the compound object, coordinated with 'light field triangulation' through the conjunction 'and', and depends on the same preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and share the same prepositional relationship with 'improving'.\"",
        "sdp_path_text": "triangulation → matching",
        "sentence": "We explore geometric structures for improving light field triangulation and stereo matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('light field triangulation') is the object of the preposition 'for', depending on 'improving'. Entity 2 ('stereo matching') is also the object of the preposition 'for', depending on 'improving'. There is no direct dependency between Entity 1 and Entity 2; both are connected to the verb 'improving' through the preposition 'for'.\""
    },
    {
        "raw_sentence": "The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points -LRB- rays -RRB- .",
        "ner_pair": [
            [
                "triangulation problem",
                "Task"
            ],
            [
                "ray space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulation problem') is the subject, depending on the verb 'aims'. Entity 2 ('ray space') is the object of the preposition 'in', depending on 'fill' in the phrase 'to fill in the ray space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aims' and the preposition 'in'.\"",
        "sdp_path_text": "problem → aims → fill → space",
        "sentence": "The triangulation problem aims to fill the ray space.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulation problem') is the subject, depending on the verb 'aims'. Entity 2 ('ray space') is the object of the verb 'fill', depending on 'fill' in the phrase 'to fill the ray space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aims' and the purpose clause 'to fill the ray space'.\""
    },
    {
        "raw_sentence": "The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points -LRB- rays -RRB- .",
        "ner_pair": [
            [
                "triangulation problem",
                "Task"
            ],
            [
                "continuous and non-overlapping simplices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulation problem') is the subject, depending on the verb 'aims'. Entity 2 ('continuous and non-overlapping simplices') is the object, depending on the verb 'fill' in the phrase 'to fill in the ray space with continuous and non-overlapping simplices'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'aims to fill in the ray space with...'.\"",
        "sdp_path_text": "problem → aims → fill → with → simplices",
        "sentence": "The triangulation problem aims to fill the ray space with continuous and non-overlapping simplices.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulation problem') is the subject, depending on 'aims' as the main verb. Entity 2 ('continuous and non-overlapping simplices') is the object, depending on 'fill' in the phrase 'to fill the ray space with continuous and non-overlapping simplices'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'aims' and the infinitive phrase 'to fill the ray space with'.\""
    },
    {
        "raw_sentence": "The triangulation problem aims to fill in the ray space with continuous and non-overlapping simplices anchored at sampled points -LRB- rays -RRB- .",
        "ner_pair": [
            [
                "ray space",
                "OtherScientificTerm"
            ],
            [
                "continuous and non-overlapping simplices",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ray space') is the object of the preposition 'in', depending on 'fill'. Entity 2 ('continuous and non-overlapping simplices') is the direct object, depending on 'fill'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is what is being filled into Entity 1.\"",
        "sdp_path_text": "space → fill → with → simplices",
        "sentence": "The ray space is filled with continuous and non-overlapping simplices.",
        "sentence_llm_dp_info": "\"Entity 1 ('ray space') is the subject, depending on the verb 'is filled'. Entity 2 ('continuous and non-overlapping simplices') is the object, depending on 'is filled' with 'ray space'. There is a direct dependency between Entity 1 and Entity 2, as 'continuous and non-overlapping simplices' fills the 'ray space'.\""
    },
    {
        "raw_sentence": "Such a triangulation provides a piecewise-linear interpolant useful for light field super-resolution .",
        "ner_pair": [
            [
                "triangulation",
                "OtherScientificTerm"
            ],
            [
                "piecewise-linear interpolant",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulation') is the subject, depending on 'provides' with 'Such a'. Entity 2 ('piecewise-linear interpolant') is the object, depending on 'provides' with 'a'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides'.\"",
        "sdp_path_text": "triangulation → provides → interpolant",
        "sentence": "Triangulation provides a piecewise-linear interpolant.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulation') is the subject, depending on the verb 'provides'. Entity 2 ('piecewise-linear interpolant') is the object, depending on 'provides' with 'triangulation'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 provides Entity 2.\""
    },
    {
        "raw_sentence": "Such a triangulation provides a piecewise-linear interpolant useful for light field super-resolution .",
        "ner_pair": [
            [
                "triangulation",
                "OtherScientificTerm"
            ],
            [
                "light field super-resolution",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulation') is the subject, depending on 'provides' as the verb. Entity 2 ('light field super-resolution') is the object, depending on 'useful' as the adjective that modifies it. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun phrase 'a piecewise-linear interpolant' which is the direct object of 'provides' and the prepositional phrase 'for light field super-resolution' which specifies the purpose or beneficiary of the interpolant.\"",
        "sdp_path_text": "triangulation → provides → interpolant → useful → for → super",
        "sentence": "Triangulation provides an interpolant useful for light field super-resolution.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulation') is the subject, depending on the verb 'provides'. Entity 2 ('light field super-resolution') is the object of the preposition 'for', depending on 'useful' in the phrase 'useful for light field super-resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'provides' and the prepositional phrase 'useful for'.\""
    },
    {
        "raw_sentence": "Such a triangulation provides a piecewise-linear interpolant useful for light field super-resolution .",
        "ner_pair": [
            [
                "piecewise-linear interpolant",
                "OtherScientificTerm"
            ],
            [
                "light field super-resolution",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('piecewise-linear interpolant') is the object, depending on 'provides' with 'triangulation'. Entity 2 ('light field super-resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for light field super-resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'provides' and the preposition 'for'.\"",
        "sdp_path_text": "interpolant → useful → for → super",
        "sentence": "A piecewise-linear interpolant is useful for light field super-resolution.",
        "sentence_llm_dp_info": "\"Entity 1 ('piecewise-linear interpolant') is the subject, depending on the adjective 'useful'. Entity 2 ('light field super-resolution') is the object of the preposition 'for', depending on 'for' in the phrase 'for light field super-resolution'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose or application of Entity 1.\""
    },
    {
        "raw_sentence": "We show that the light field space is largely bi-linear due to 3D line segments in the scene , and direct tri-angulation of these bilinear subspaces leads to large errors .",
        "ner_pair": [
            [
                "light field space",
                "OtherScientificTerm"
            ],
            [
                "3D line segments",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('light field space') is the subject complement, depending on the verb 'is' in the clause 'the light field space is largely bi-linear'. Entity 2 ('3D line segments') is the object of the preposition 'to', depending on 'due' in the phrase 'due to 3D line segments'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the causal relationship expressed by 'due to'.\"",
        "sdp_path_text": "space → is → due → segments",
        "sentence": "The light field space is largely bi-linear due to 3D line segments.",
        "sentence_llm_dp_info": "\"Entity 1 ('light field space') is the subject, depending on the verb 'is'. Entity 2 ('3D line segments') is the object of the preposition 'due to', depending on 'due to' in the phrase 'due to 3D line segments'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'due to'.\""
    },
    {
        "raw_sentence": "We show that the light field space is largely bi-linear due to 3D line segments in the scene , and direct tri-angulation of these bilinear subspaces leads to large errors .",
        "ner_pair": [
            [
                "light field space",
                "OtherScientificTerm"
            ],
            [
                "bilinear subspaces",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('light field space') is the subject complement, depending on 'is' with 'largely bi-linear'. Entity 2 ('bilinear subspaces') is the object of the preposition 'of', depending on 'tri-angulation' in the phrase 'tri-angulation of these bilinear subspaces'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence, where both are described as being bi-linear.\"",
        "sdp_path_text": "space → is → leads → angulation → of → subspaces",
        "sentence": "The light field space leads to bilinear subspaces.",
        "sentence_llm_dp_info": "\"Entity 1 ('light field space') is the subject, depending on the verb 'leads'. Entity 2 ('bilinear subspaces') is the object, depending on 'leads' with 'light field space'. There is a direct dependency between Entity 1 and Entity 2, as 'light field space' directly leads to 'bilinear subspaces'.\""
    },
    {
        "raw_sentence": "We show that the light field space is largely bi-linear due to 3D line segments in the scene , and direct tri-angulation of these bilinear subspaces leads to large errors .",
        "ner_pair": [
            [
                "3D line segments",
                "OtherScientificTerm"
            ],
            [
                "bilinear subspaces",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('3D line segments') is the object of the preposition 'to', depending on 'due' in the phrase 'due to 3D line segments'. Entity 2 ('bilinear subspaces') is the object of the preposition 'of', depending on 'tri-angulation' in the phrase 'tri-angulation of these bilinear subspaces'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the explanation of why the light field space is largely bi-linear and how tri-angulation leads to large errors.\"",
        "sdp_path_text": "segments → due → is → leads → angulation → of → subspaces",
        "sentence": "3D line segments lead to bilinear subspaces.",
        "sentence_llm_dp_info": "\"Entity 1 ('3D line segments') is the subject, depending on the verb 'lead'. Entity 2 ('bilinear subspaces') is the object, depending on 'lead' in the phrase 'lead to bilinear subspaces'. There is a direct dependency between Entity 1 and Entity 2, as '3D line segments' leads to 'bilinear subspaces'.\""
    },
    {
        "raw_sentence": "We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation -LRB- CDT -RRB- .",
        "ner_pair": [
            [
                "bilinear subspaces",
                "OtherScientificTerm"
            ],
            [
                "line constraints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bilinear subspaces') is the object of the verb 'map', depending on 'map' in the phrase 'map bilinear subspaces'. Entity 2 ('line constraints') is the complement of the preposition 'to', depending on 'to' in the phrase 'to line constraints'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'map' and the preposition 'to'.\"",
        "sdp_path_text": "subspaces → map → to → constraints",
        "sentence": "Bilinear subspaces are mapped to line constraints.",
        "sentence_llm_dp_info": "\"Entity 1 ('bilinear subspaces') is the subject, depending on the verb 'mapped'. Entity 2 ('line constraints') is the object, depending on 'to' in the phrase 'to line constraints'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'mapped' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation -LRB- CDT -RRB- .",
        "ner_pair": [
            [
                "bilinear subspaces",
                "OtherScientificTerm"
            ],
            [
                "Constrained Delaunay Triangulation -LRB- CDT -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('bilinear subspaces') is the object of the verb 'map', depending on 'map' in the phrase 'map bilinear subspaces to line constraints'. Entity 2 ('Constrained Delaunay Triangulation -LRB- CDT -RRB-') is the object of the verb 'apply', depending on 'apply' in the phrase 'apply Constrained Delaunay Triangulation -LRB- CDT -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a sequence of actions described in the sentence.\"",
        "sdp_path_text": "subspaces → map → apply → -RRB-",
        "sentence": "Bilinear subspaces are mapped to constraints and then Constrained Delaunay Triangulation (CDT) is applied.",
        "sentence_llm_dp_info": "\"Entity 1 ('bilinear subspaces') is the subject, depending on the verb 'mapped'. Entity 2 ('Constrained Delaunay Triangulation (CDT)') is the subject of the clause 'is applied', depending on the verb 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\""
    },
    {
        "raw_sentence": "We instead present a simple but effective algorithm to first map bilinear subspaces to line constraints and then apply Constrained Delaunay Triangulation -LRB- CDT -RRB- .",
        "ner_pair": [
            [
                "line constraints",
                "OtherScientificTerm"
            ],
            [
                "Constrained Delaunay Triangulation -LRB- CDT -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('line constraints') is the object of the verb 'map', depending on 'map' in the phrase 'map bilinear subspaces to line constraints'. Entity 2 ('Constrained Delaunay Triangulation -LRB- CDT -RRB-') is the object of the verb 'apply', depending on 'apply' in the phrase 'apply Constrained Delaunay Triangulation -LRB- CDT -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same process described in the sentence.\"",
        "sdp_path_text": "constraints → to → map → apply → -RRB-",
        "sentence": "We map line constraints to apply Constrained Delaunay Triangulation (CDT).",
        "sentence_llm_dp_info": "\"Entity 1 ('line constraints') is the object of the verb 'map', depending on 'map'. Entity 2 ('Constrained Delaunay Triangulation (CDT)') is the object of the verb 'apply', depending on 'apply'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verbs 'map' and 'apply' which describe actions performed on or with these entities.\""
    },
    {
        "raw_sentence": "Based on our analysis , we further develop a novel line-assisted graph-cut -LRB- LAGC -RRB- algorithm that effectively encodes 3D line constraints into light field stereo matching .",
        "ner_pair": [
            [
                "line-assisted graph-cut -LRB- LAGC -RRB- algorithm",
                "Method"
            ],
            [
                "3D line constraints",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('line-assisted graph-cut -LRB- LAGC -RRB- algorithm') is the subject complement, depending on the verb 'develop' with 'we'. Entity 2 ('3D line constraints') is the object, depending on 'encodes' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'encodes'.\"",
        "sdp_path_text": "algorithm → encodes → constraints",
        "sentence": "The line-assisted graph-cut (LAGC) algorithm encodes 3D line constraints.",
        "sentence_llm_dp_info": "\"Entity 1 ('line-assisted graph-cut (LAGC) algorithm') is the subject, depending on the verb 'encodes'. Entity 2 ('3D line constraints') is the object, depending on the verb 'encodes'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 performs the action of encoding Entity 2.\""
    },
    {
        "raw_sentence": "Based on our analysis , we further develop a novel line-assisted graph-cut -LRB- LAGC -RRB- algorithm that effectively encodes 3D line constraints into light field stereo matching .",
        "ner_pair": [
            [
                "line-assisted graph-cut -LRB- LAGC -RRB- algorithm",
                "Method"
            ],
            [
                "light field stereo matching",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('line-assisted graph-cut -LRB- LAGC -RRB- algorithm') is the subject complement, depending on 'develop' with 'we'. Entity 2 ('light field stereo matching') is the object of the preposition 'into', depending on 'encodes' in the phrase 'encodes 3D line constraints into light field stereo matching'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'encodes' and the preposition 'into'.\"",
        "sdp_path_text": "algorithm → encodes → into → matching",
        "sentence": "The line-assisted graph-cut (LAGC) algorithm encodes 3D line constraints into light field stereo matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('line-assisted graph-cut (LAGC) algorithm') is the subject, depending on the verb 'encodes'. Entity 2 ('light field stereo matching') is the object, depending on 'encodes' with 'algorithm'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 performs the action (encodes) on Entity 2.\""
    },
    {
        "raw_sentence": "Based on our analysis , we further develop a novel line-assisted graph-cut -LRB- LAGC -RRB- algorithm that effectively encodes 3D line constraints into light field stereo matching .",
        "ner_pair": [
            [
                "3D line constraints",
                "OtherScientificTerm"
            ],
            [
                "light field stereo matching",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('3D line constraints') is the object, depending on 'encodes' with 'algorithm'. Entity 2 ('light field stereo matching') is the object, depending on 'into' with 'encodes'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the action of encoding performed by the algorithm.\"",
        "sdp_path_text": "constraints → encodes → into → matching",
        "sentence": "3D line constraints are encoded into light field stereo matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('3D line constraints') is the subject, depending on the passive verb 'are encoded'. Entity 2 ('light field stereo matching') is the object of the preposition 'into', depending on 'into' in the phrase 'into light field stereo matching'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the passive construction 'are encoded into'.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "synthetic and real data",
                "Material"
            ],
            [
                "triangulation and LAGC algorithms",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('triangulation and LAGC algorithms') is the subject, depending on the verb 'outperform'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure describing the context and the subjects of the comparison.\"",
        "sdp_path_text": "data → on → Experiments → show → outperform → algorithms",
        "sentence": "Experiments on synthetic and real data show that triangulation and LAGC algorithms outperform state-of-the-art solutions.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('triangulation and LAGC algorithms') is the subject, depending on the verb 'outperform'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'Experiments' are conducted 'on' Entity 1 and the results show that Entity 2 'outperform' other solutions.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "synthetic and real data",
                "Material"
            ],
            [
                "state-of-the-art solutions",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('state-of-the-art solutions') is the object of the preposition 'in', depending on 'outperform'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the outcomes of the experiments.\"",
        "sdp_path_text": "data → on → Experiments → show → outperform → solutions",
        "sentence": "Experiments on synthetic and real data show that our algorithms outperform state-of-the-art solutions.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('state-of-the-art solutions') is the object, depending on 'outperform' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "synthetic and real data",
                "Material"
            ],
            [
                "accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('accuracy') is part of a compound object, depending on 'outperform' with 'solutions'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "data → on → Experiments → show → outperform → in → accuracy",
        "sentence": "Experiments on synthetic and real data show outperformance in accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('accuracy') is the object, depending on 'show' with 'outperformance'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "synthetic and real data",
                "Material"
            ],
            [
                "visual quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('visual quality') is part of a compound object, depending on 'in' within the phrase 'in accuracy and visual quality'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "data → on → Experiments → show → outperform → in → accuracy → quality",
        "sentence": "Experiments on synthetic and real data show improved visual quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('synthetic and real data') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('visual quality') is the object, depending on 'show' with 'Experiments'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the verb 'show' within the context of the experiments.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "triangulation and LAGC algorithms",
                "Method"
            ],
            [
                "state-of-the-art solutions",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('triangulation and LAGC algorithms') is the subject, depending on the verb 'outperform'. Entity 2 ('state-of-the-art solutions') is the object, depending on 'outperform' with 'triangulation and LAGC algorithms'. There is a direct dependency between Entity 1 and Entity 2, as 'state-of-the-art solutions' is the direct object being outperformed by 'triangulation and LAGC algorithms'.\"",
        "sdp_path_text": "algorithms → outperform → solutions",
        "sentence": "Triangulation and LAGC algorithms outperform state-of-the-art solutions.",
        "sentence_llm_dp_info": "\"Entity 1 ('triangulation and LAGC algorithms') is the subject, depending on the verb 'outperform'. Entity 2 ('state-of-the-art solutions') is the object, depending on 'outperform' with 'triangulation and LAGC algorithms'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 is performing the action (outperforming) on Entity 2.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "triangulation and LAGC algorithms",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is part of the object complement, depending on the preposition 'in' within the phrase 'in accuracy and visual quality'. Entity 2 ('triangulation and LAGC algorithms') is the subject of the clause, depending on the verb 'outperform'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where Entity 2 is described as outperforming other solutions in terms of Entity 1.\"",
        "sdp_path_text": "accuracy → in → outperform → algorithms",
        "sentence": "Triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object of the preposition 'in', depending on 'outperform'. Entity 2 ('triangulation and LAGC algorithms') is the subject, depending on the verb 'outperform'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'outperform' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "visual quality",
                "Metric"
            ],
            [
                "triangulation and LAGC algorithms",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual quality') is part of a compound object, depending on 'outperform' with 'algorithms'. Entity 2 ('triangulation and LAGC algorithms') is the subject, depending on 'outperform' with 'solutions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the verb 'outperform'.\"",
        "sdp_path_text": "quality → accuracy → in → outperform → algorithms",
        "sentence": "Triangulation and LAGC algorithms outperform state-of-the-art solutions in visual quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual quality') is the object of the preposition 'in', depending on 'outperform'. Entity 2 ('triangulation and LAGC algorithms') is the subject, depending on the verb 'outperform'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'outperform' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "state-of-the-art solutions",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is part of the compound object, depending on 'outperform' with 'both our triangulation and LAGC algorithms'. Entity 2 ('state-of-the-art solutions') is the direct object, also depending on 'outperform' with 'both our triangulation and LAGC algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same predicate structure under the verb 'outperform'.\"",
        "sdp_path_text": "accuracy → in → outperform → solutions",
        "sentence": "Our algorithms outperform state-of-the-art solutions in accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object of the preposition 'in', depending on 'outperform'. Entity 2 ('state-of-the-art solutions') is the object, depending on 'outperform' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the same clause where 'algorithms' outperform 'state-of-the-art solutions' in terms of 'accuracy'.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "visual quality",
                "Metric"
            ],
            [
                "state-of-the-art solutions",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual quality') is part of a compound object, depending on 'outperform' with 'algorithms'. Entity 2 ('state-of-the-art solutions') is the direct object, depending on 'outperform' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what the algorithms outperform.\"",
        "sdp_path_text": "quality → accuracy → in → outperform → solutions",
        "sentence": "Our algorithms outperform state-of-the-art solutions in visual quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual quality') is the object of the preposition 'in', depending on 'outperform'. Entity 2 ('state-of-the-art solutions') is the object, depending on 'outperform' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what the algorithms outperform and in what aspect.\""
    },
    {
        "raw_sentence": "Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "visual quality",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is part of a compound object, depending on 'outperform' with 'algorithms'. Entity 2 ('visual quality') is also part of a compound object, depending on 'outperform' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'outperform'.\"",
        "sdp_path_text": "accuracy → quality",
        "sentence": "Experiments show that our algorithms outperform in accuracy and visual quality.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'outperform' with 'algorithms'. Entity 2 ('visual quality') is also an object, depending on 'outperform' with 'algorithms'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same verb 'outperform'.\""
    },
    {
        "raw_sentence": "This paper presents a phrase-based statistical machine translation method , based on non-contiguous phrases , i.e. phrases with gaps .",
        "ner_pair": [
            [
                "non-contiguous phrases",
                "Material"
            ],
            [
                "phrase-based statistical machine translation method",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('non-contiguous phrases') is the object of the preposition 'on', depending on the prepositional phrase 'based on non-contiguous phrases'. Entity 2 ('phrase-based statistical machine translation method') is the direct object, depending on the verb 'presents'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on non-contiguous phrases' which modifies Entity 2.\"",
        "sdp_path_text": "phrases → on → based → method",
        "sentence": "The method is based on non-contiguous phrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('non-contiguous phrases') is the object, depending on the preposition 'on', which modifies 'based'. Entity 2 ('phrase-based statistical machine translation method') is not present in the given sentence. Therefore, there is no dependency between Entity 1 and Entity 2 within the context of this sentence.\"\n\nHowever, it seems there might be a discrepancy since Entity 2 ('phrase-based statistical machine translation method') does not appear in the provided sentence. If you intended for both entities to be part of the same sentence, please provide an updated sentence that includes both entities. Otherwise, the analysis above reflects the dependency structure of the given sentence with respect to Entity 1."
    },
    {
        "raw_sentence": "A method for producing such phrases from a word-aligned corpora is proposed .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "phrases",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'proposed'. Entity 2 ('phrases') is the object of the preposition 'for', depending on 'producing' in the phrase 'for producing such phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for' and the verb 'producing'.\"",
        "sdp_path_text": "method → for → producing → phrases",
        "sentence": "A method for producing phrases is proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'proposed'. Entity 2 ('phrases') is the object of the preposition 'for', depending on 'for' in the phrase 'for producing phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A method for producing such phrases from a word-aligned corpora is proposed .",
        "ner_pair": [
            [
                "word-aligned corpora",
                "Material"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word-aligned corpora') is the object of the preposition 'from', depending on 'from' in the phrase 'from a word-aligned corpora'. Entity 2 ('method') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from a word-aligned corpora'.\"",
        "sdp_path_text": "corpora → from → producing → for → method",
        "sentence": "A method for producing phrases from word-aligned corpora is proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('word-aligned corpora') is the object of the preposition 'from', depending on 'from' in the phrase 'from word-aligned corpora'. Entity 2 ('method') is the subject, depending on the verb 'proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'from word-aligned corpora'.\""
    },
    {
        "raw_sentence": "A method for producing such phrases from a word-aligned corpora is proposed .",
        "ner_pair": [
            [
                "phrases",
                "Generic"
            ],
            [
                "word-aligned corpora",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the preposition 'for', depending on 'producing'. Entity 2 ('word-aligned corpora') is the object of the preposition 'from', depending on 'producing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that modify the verb 'producing'.\"",
        "sdp_path_text": "phrases → producing → from → corpora",
        "sentence": "A method for producing phrases from word-aligned corpora is proposed.",
        "sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the preposition 'for', depending on 'for' in the phrase 'for producing phrases'. Entity 2 ('word-aligned corpora') is also an object of the preposition 'from', depending on 'from' in the phrase 'from word-aligned corpora'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the prepositional phrases that modify the noun 'method'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "statistical translation model",
                "Method"
            ],
            [
                "phrases",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical translation model') is the subject, depending on the verb 'presented'. Entity 2 ('phrases') is the object of the relative clause 'that deals such phrases', depending on the verb 'deals'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the relative clause where 'statistical translation model' is the subject of 'presented' and 'phrases' is part of what the model 'deals' with.\"",
        "sdp_path_text": "model → deals → phrases",
        "sentence": "A statistical translation model deals with phrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical translation model') is the subject, depending on the verb 'deals'. Entity 2 ('phrases') is the object, depending on 'with' in the phrase 'with phrases'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "statistical translation model",
                "Method"
            ],
            [
                "training method",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical translation model') is the subject, depending on 'presented' with the auxiliary verb 'is'. Entity 2 ('training method') is the subject of a relative clause, depending on 'based' with 'on the maximization of translation accuracy'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger sentence structure where they are described as being presented.\"",
        "sdp_path_text": "model → method",
        "sentence": "A statistical translation model includes a training method.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical translation model') is the subject, depending on the verb 'includes'. Entity 2 ('training method') is the object, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, as 'training method' is directly included in 'statistical translation model'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "statistical translation model",
                "Method"
            ],
            [
                "maximization of translation accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical translation model') is the subject, depending on the verb 'presented'. Entity 2 ('maximization of translation accuracy') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the maximization of translation accuracy'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence describing different aspects of the presented model and methods.\"",
        "sdp_path_text": "model → method → based → on → maximization",
        "sentence": "A statistical translation model is based on the maximization of translation accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical translation model') is the subject, depending on the verb 'is'. Entity 2 ('maximization of translation accuracy') is the complement, depending on the preposition 'on' in the phrase 'based on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' which indicates that the model is based on the maximization process.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "NIST evaluation metric",
                "Metric"
            ],
            [
                "statistical translation model",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NIST evaluation metric') is the object of the preposition 'with', depending on 'measured'. Entity 2 ('statistical translation model') is the subject, depending on the verb 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure, where Entity 1 is used to measure the accuracy of the translation, which is a characteristic of Entity 2.\"",
        "sdp_path_text": "metric → with → measured → maximization → on → based → method → model",
        "sentence": "The statistical translation model is based on a method for maximizing translation accuracy measured with the NIST evaluation metric.",
        "sentence_llm_dp_info": "\"Entity 1 ('NIST evaluation metric') is the object, depending on the preposition 'with', which modifies 'measured'. Entity 2 ('statistical translation model') is the subject, depending on the verb 'is' and modified by the prepositional phrase 'based on a method for maximizing translation accuracy'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of dependencies involving 'measured' and 'with'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "phrases",
                "Generic"
            ],
            [
                "training method",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the verb 'deals', depending on 'deals' in the clause 'that deals such phrases'. Entity 2 ('training method') is the subject, depending on 'presented' with 'is'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "phrases → deals → model → method",
        "sentence": "A training method deals with phrases.",
        "sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object, depending on the verb 'deals'. Entity 2 ('training method') is the subject, depending on the verb 'deals' with 'with'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'deals'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "phrases",
                "Generic"
            ],
            [
                "maximization of translation accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the relative clause modifier 'that deals such phrases', depending on 'deals'. Entity 2 ('maximization of translation accuracy') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "phrases → deals → model → method → based → on → maximization",
        "sentence": "A model deals with phrases and uses a method based on the maximization of translation accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the preposition 'with', depending on 'deals'. Entity 2 ('maximization of translation accuracy') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "phrases",
                "Generic"
            ],
            [
                "NIST evaluation metric",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the preposition 'such', depending on 'deals' with 'that deals such phrases'. Entity 2 ('NIST evaluation metric') is the object of the preposition 'with', depending on 'measured' with 'as measured with the NIST evaluation metric'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "phrases → deals → model → method → based → on → maximization → measured → with → metric",
        "sentence": "A model deals with phrases and uses the NIST evaluation metric for measurement.",
        "sentence_llm_dp_info": "\"Entity 1 ('phrases') is the object of the preposition 'with', depending on 'deals' in the phrase 'deals with phrases'. Entity 2 ('NIST evaluation metric') is the object of the preposition 'for', depending on 'uses' in the phrase 'uses the NIST evaluation metric for measurement'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "maximization of translation accuracy",
                "Metric"
            ],
            [
                "training method",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('maximization of translation accuracy') is the object, depending on the preposition 'on', which is part of the phrase 'based on the maximization of translation accuracy'. Entity 2 ('training method') is the subject, depending on the verb 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on the maximization of translation accuracy'.\"",
        "sdp_path_text": "maximization → on → based → method",
        "sentence": "A training method based on the maximization of translation accuracy is presented.",
        "sentence_llm_dp_info": "\"Entity 1 ('maximization of translation accuracy') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the maximization of translation accuracy'. Entity 2 ('training method') is the subject, depending on the verb 'presented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "training method",
                "Method"
            ],
            [
                "NIST evaluation metric",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('training method') is the subject, depending on the verb 'presented'. Entity 2 ('NIST evaluation metric') is the object of the preposition 'with', depending on 'measured'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing how the accuracy is measured.\"",
        "sdp_path_text": "method → based → on → maximization → measured → with → metric",
        "sentence": "A training method is based on the maximization of translation accuracy measured with the NIST evaluation metric.",
        "sentence_llm_dp_info": "\"Entity 1 ('training method') is the subject, depending on 'is' which links it to the predicate 'based on'. Entity 2 ('NIST evaluation metric') is the object of the preposition 'with', depending on 'with' in the phrase 'with the NIST evaluation metric'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'based on the maximization of translation accuracy' and 'measured with the NIST evaluation metric'.\""
    },
    {
        "raw_sentence": "A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric .",
        "ner_pair": [
            [
                "maximization of translation accuracy",
                "Metric"
            ],
            [
                "NIST evaluation metric",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('maximization of translation accuracy') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the maximization of translation accuracy'. Entity 2 ('NIST evaluation metric') is the object of the preposition 'with', depending on 'measured' in the phrase 'as measured with the NIST evaluation metric'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the training method.\"",
        "sdp_path_text": "maximization → measured → with → metric",
        "sentence": "The maximization of translation accuracy is measured with the NIST evaluation metric.",
        "sentence_llm_dp_info": "\"Entity 1 ('maximization of translation accuracy') is the subject, depending on the verb 'is measured'. Entity 2 ('NIST evaluation metric') is the object of the preposition 'with', depending on 'with' in the phrase 'with the NIST evaluation metric'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Translations are produced by means of a beam-search decoder .",
        "ner_pair": [
            [
                "beam-search decoder",
                "Method"
            ],
            [
                "Translations",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('beam-search decoder') is the object of the preposition 'of', depending on 'by means of'. Entity 2 ('Translations') is the subject, depending on the verb 'produced'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'produced' and the prepositional phrase 'by means of'.\"",
        "sdp_path_text": "decoder → of → means → by → produced → Translations",
        "sentence": "Translations are produced by a beam-search decoder.",
        "sentence_llm_dp_info": "\"Entity 1 ('beam-search decoder') is the agent, depending on the verb 'produced'. Entity 2 ('Translations') is the subject, depending on the verb 'are produced'. There is a direct dependency between Entity 1 and Entity 2, where 'beam-search decoder' is the producer of 'Translations'.\""
    },
    {
        "raw_sentence": "GLOSSER is designed to support reading and learning to read in a foreign language .",
        "ner_pair": [
            [
                "GLOSSER",
                "Method"
            ],
            [
                "reading and learning",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the subject, depending on the verb 'designed'. Entity 2 ('reading and learning') is the object of the preposition 'for', depending on 'support' in the phrase 'to support reading and learning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'support' and the preposition 'for'.\"",
        "sdp_path_text": "GLOSSER → designed → support → reading",
        "sentence": "GLOSSER is designed to support reading and learning.",
        "sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the subject, depending on the verb 'designed'. Entity 2 ('reading and learning') is the object of the preposition 'to', depending on 'to' in the phrase 'to support reading and learning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'designed' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "language pairs",
                "Generic"
            ],
            [
                "GLOSSER",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('language pairs') is the subject complement, depending on the verb 'supported'. Entity 2 ('GLOSSER') is the subject, depending on the preposition 'by' in the phrase 'by GLOSSER'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'supported' and the preposition 'by'.\"",
        "sdp_path_text": "pairs → supported → by → GLOSSER",
        "sentence": "Language pairs are supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('language pairs') is the subject, depending on the verb 'supported'. Entity 2 ('GLOSSER') is the agent, depending on 'supported' with the preposition 'by'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'supported'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Bulgarian",
                "Material"
            ],
            [
                "language pairs",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is an element of a list, depending on the conjunction 'and' and the preposition 'supported by'. Entity 2 ('language pairs') is the subject complement, depending on the verb 'are' and modified by the adjective 'four'. There is no direct dependency between Entity 1 and Entity 2; however, Entity 1 is part of the list that specifies the instances of Entity 2.\"",
        "sdp_path_text": "English → pairs",
        "sentence": "English-Bulgarian is one of the language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is the subject, depending on 'is' as part of the copular construction. Entity 2 ('language pairs') is the object of the preposition 'of', depending on 'one'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'one of the language pairs'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Estonian",
                "Material"
            ],
            [
                "language pairs",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Estonian') is part of a list, depending on the verb 'supported' with 'GLOSSER'. Entity 2 ('language pairs') is the subject, depending on the verb 'are' with 'There'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'supported'.\"",
        "sdp_path_text": "Estonian → pairs",
        "sentence": "English-Estonian is one of the supported language pairs.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Estonian') is the subject complement, depending on the copula 'is'. Entity 2 ('language pairs') is the object of the preposition 'of', depending on 'supported'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of' and the adjective 'supported'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Hungarian",
                "Material"
            ],
            [
                "language pairs",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Hungarian') is the object of the preposition 'and', which is part of a list of items that are the objects of the preposition 'by'. Entity 2 ('language pairs') is the subject complement, depending on the verb 'are' and modified by 'four'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'language pairs' is described by the list that includes 'English-Hungarian'.\"",
        "sdp_path_text": "Hungarian → pairs",
        "sentence": "English-Hungarian is one of the language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Hungarian') is the subject complement, depending on 'is' with 'one'. Entity 2 ('language pairs') is the object of the preposition 'of', depending on 'of' in the phrase 'of the language pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional structure 'one of the language pairs'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "French-Dutch",
                "Material"
            ],
            [
                "language pairs",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('French-Dutch') is a conjunct, depending on 'and' which connects it to the list of language pairs. Entity 2 ('language pairs') is the direct object, depending on 'supported' with 'GLOSSER'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the list structure where 'French-Dutch' is one of the items listed as part of the 'language pairs'.\"",
        "sdp_path_text": "Dutch → pairs",
        "sentence": "French-Dutch is one of the language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('French-Dutch') is the subject complement, depending on 'is' in the phrase 'is one of the language pairs'. Entity 2 ('language pairs') is the object of the preposition 'of', depending on 'one' in the phrase 'one of the language pairs'. There is a direct dependency between Entity 1 and Entity 2, as 'French-Dutch' is specified as being one of the 'language pairs'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "GLOSSER",
                "Method"
            ],
            [
                "English-Bulgarian",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the object of the preposition 'by', depending on 'supported'. Entity 2 ('English-Bulgarian') is one of the items in a list, depending on the verb 'are' through the preposition 'supported by'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where 'GLOSSER' supports multiple language pairs including 'English-Bulgarian'.\"",
        "sdp_path_text": "GLOSSER → by → supported → pairs → English",
        "sentence": "GLOSSER supports English-Bulgarian.",
        "sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the subject, depending on the verb 'supports'. Entity 2 ('English-Bulgarian') is the object, depending on 'supports' with 'GLOSSER'. There is a direct dependency between Entity 1 and Entity 2, where 'GLOSSER' supports 'English-Bulgarian'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "GLOSSER",
                "Method"
            ],
            [
                "English-Estonian",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the object of the preposition 'by', depending on 'supported'. Entity 2 ('English-Estonian') is part of a list of objects, depending on 'pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the language pairs supported by GLOSSER.\"",
        "sdp_path_text": "GLOSSER → by → supported → pairs → Estonian",
        "sentence": "GLOSSER supports the English-Estonian language pair.",
        "sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the subject, depending on the verb 'supports'. Entity 2 ('English-Estonian') is the object of the preposition 'the', forming part of the noun phrase 'the English-Estonian language pair'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'supports' and the prepositional phrase 'the English-Estonian language pair'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "GLOSSER",
                "Method"
            ],
            [
                "English-Hungarian",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the object of the preposition 'by', depending on 'supported'. Entity 2 ('English-Hungarian') is one of the items in a list, depending on 'pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'GLOSSER' supports the 'language pairs' which include 'English-Hungarian'.\"",
        "sdp_path_text": "GLOSSER → by → supported → pairs → Hungarian",
        "sentence": "GLOSSER supports the English-Hungarian language pair.",
        "sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the subject, depending on the verb 'supports'. Entity 2 ('English-Hungarian') is the object of the preposition 'the', depending on 'language pair'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'supports' and the prepositional phrase 'the English-Hungarian language pair'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "GLOSSER",
                "Method"
            ],
            [
                "French-Dutch",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the object of the preposition 'by', depending on 'supported'. Entity 2 ('French-Dutch') is part of a list of objects, depending on 'pairs'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "GLOSSER → by → supported → pairs → Dutch",
        "sentence": "GLOSSER supports French-Dutch as one of the language pairs.",
        "sentence_llm_dp_info": "\"Entity 1 ('GLOSSER') is the subject, depending on the verb 'supports'. Entity 2 ('French-Dutch') is the object of the preposition 'as', depending on 'as' in the phrase 'as one of the language pairs'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'as'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Bulgarian",
                "Material"
            ],
            [
                "English-Estonian",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is an item in a list, depending on the conjunction 'and' and the preposition 'supported by'. Entity 2 ('English-Estonian') is also an item in the same list, depending on the conjunction 'and' and the preposition 'supported by'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordinated list of items.\"",
        "sdp_path_text": "English → pairs → Estonian",
        "sentence": "English-Bulgarian and English-Estonian are among the language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is a conjunct, depending on 'and' with 'English-Estonian'. Entity 2 ('English-Estonian') is also a conjunct, depending on 'and' with 'English-Bulgarian'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Bulgarian",
                "Material"
            ],
            [
                "English-Hungarian",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is part of a list, depending on the verb 'supported' through the preposition 'of' in the phrase 'four language pairs...supported by GLOSSER'. Entity 2 ('English-Hungarian') is also part of the same list, depending on the same verb 'supported' through the same prepositional structure. There is no direct dependency between Entity 1 and Entity 2; they are both elements of the list of language pairs supported by GLOSSER.\"",
        "sdp_path_text": "English → pairs → Hungarian",
        "sentence": "English-Bulgarian and English-Hungarian are supported language pairs.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is the subject, depending on the verb 'are' in the phrase 'are supported'. Entity 2 ('English-Hungarian') is also a subject, depending on the same verb 'are' in the phrase 'are supported'. There is no direct dependency between Entity 1 and Entity 2; both are coordinated subjects in the sentence.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Bulgarian",
                "Material"
            ],
            [
                "French-Dutch",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is one of the objects listed, depending on the preposition 'supported by'. Entity 2 ('French-Dutch') is another object listed, also depending on the preposition 'supported by'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of objects that are supported by GLOSSER.\"",
        "sdp_path_text": "English → pairs → Dutch",
        "sentence": "English-Bulgarian and French-Dutch are language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Bulgarian') is the subject, depending on the conjunction 'and' with Entity 2 ('French-Dutch'). Entity 2 ('French-Dutch') is also a subject, depending on the conjunction 'and' with Entity 1 ('English-Bulgarian'). Both entities are part of the noun phrase 'language pairs' which is the subject of the verb 'supported'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and together form the subject of the verb 'supported'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Estonian",
                "Material"
            ],
            [
                "English-Hungarian",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Estonian') is part of a list, depending on the verb 'supported' through the conjunction 'and'. Entity 2 ('English-Hungarian') is also part of the same list, depending on the verb 'supported' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a coordinated list of language pairs.\"",
        "sdp_path_text": "Estonian → pairs → Hungarian",
        "sentence": "English-Estonian and English-Hungarian are supported language pairs.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Estonian') is the subject, depending on the verb 'are' in the clause 'English-Estonian and English-Hungarian are'. Entity 2 ('English-Hungarian') is also a subject, conjoined with 'English-Estonian' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; they are both subjects of the same clause and are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Estonian",
                "Material"
            ],
            [
                "French-Dutch",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Estonian') is part of a list, depending on the conjunction 'and' which connects it with 'English-Hungarian'. It also depends on the verb 'supported' through the preposition 'by' in the phrase 'supported by GLOSSER'. Entity 2 ('French-Dutch') is the last item in the list, directly depending on the conjunction 'and' that connects it to the previous items. There is no direct dependency between Entity 1 and Entity 2; they are both part of a coordinated list under the verb 'supported'.\"",
        "sdp_path_text": "Estonian → pairs → Dutch",
        "sentence": "English-Estonian and French-Dutch are among the language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Estonian') is part of a conjunction, depending on 'are' as a subject. Entity 2 ('French-Dutch') is also part of the same conjunction, depending on 'are' as a subject. There is no direct dependency between Entity 1 and Entity 2; they are both subjects in a coordinated structure.\""
    },
    {
        "raw_sentence": "There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , English-Hungarian and French-Dutch .",
        "ner_pair": [
            [
                "English-Hungarian",
                "Material"
            ],
            [
                "French-Dutch",
                "Material"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('English-Hungarian') is the object of the preposition 'and', which is part of a list of objects of the verb 'supported'. Entity 2 ('French-Dutch') is the last item in the list, also an object of the preposition 'and', directly following 'English-Hungarian'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a coordinated list of objects.\"",
        "sdp_path_text": "Hungarian → pairs → Dutch",
        "sentence": "English-Hungarian and French-Dutch are among the language pairs supported by GLOSSER.",
        "sentence_llm_dp_info": "\"Entity 1 ('English-Hungarian') is part of a coordination, depending on 'are' as a subject. Entity 2 ('French-Dutch') is also part of the same coordination, depending on 'are' as a coordinated subject. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' within the same subject position.\""
    },
    {
        "raw_sentence": "The program is operational on UNIX and Windows '95 platforms , and has undergone a pilot user-study .",
        "ner_pair": [
            [
                "program",
                "Generic"
            ],
            [
                "UNIX and Windows '95 platforms",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('program') is the subject, depending on the verb 'is' in the phrase 'is operational'. Entity 2 ('UNIX and Windows '95 platforms') is the object of the preposition 'on', depending on 'on' in the phrase 'on UNIX and Windows '95 platforms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\"",
        "sdp_path_text": "program → is → on → platforms",
        "sentence": "The program is operational on UNIX and Windows '95 platforms.",
        "sentence_llm_dp_info": "\"Entity 1 ('program') is the subject, depending on the verb 'is'. Entity 2 ('UNIX and Windows '95 platforms') is the object of the preposition 'on', depending on 'on' in the phrase 'on UNIX and Windows '95 platforms'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating where the program operates.\""
    },
    {
        "raw_sentence": "The program is operational on UNIX and Windows '95 platforms , and has undergone a pilot user-study .",
        "ner_pair": [
            [
                "program",
                "Generic"
            ],
            [
                "user-study",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('program') is the subject, depending on the verb 'is' and also related to 'has undergone'. Entity 2 ('user-study') is the object, depending on the verb 'undergone'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'has undergone'.\"",
        "sdp_path_text": "program → is → undergone → -",
        "sentence": "The program has undergone a user-study.",
        "sentence_llm_dp_info": "\"Entity 1 ('program') is the subject, depending on the verb 'has undergone'. Entity 2 ('user-study') is the object, depending on the verb 'has undergone'. There is a direct dependency between Entity 1 and Entity 2, as 'user-study' is the object of the action performed by 'program'.\""
    },
    {
        "raw_sentence": "The program is operational on UNIX and Windows '95 platforms , and has undergone a pilot user-study .",
        "ner_pair": [
            [
                "UNIX and Windows '95 platforms",
                "OtherScientificTerm"
            ],
            [
                "user-study",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UNIX and Windows '95 platforms') is the object of the preposition 'on', depending on 'operational'. Entity 2 ('user-study') is the object of the noun 'pilot', depending on 'undergone'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "platforms → on → is → undergone → -",
        "sentence": "The program on UNIX and Windows '95 platforms has undergone a user-study.",
        "sentence_llm_dp_info": "\"Entity 1 ('UNIX and Windows '95 platforms') is the object of the preposition 'on', depending on 'program'. Entity 2 ('user-study') is the object, depending on the verb 'undergone'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing aspects of the 'program'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "Applied Natural Language Processing",
                "Task"
            ],
            [
                "components",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the object of the preposition 'for', depending on 'demonstration'. Entity 2 ('components') is the subject of the verb 'emphasizes', depending on 'emphasizes' with 'demonstration'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the structure of the sentence where the demonstration for Entity 1 emphasizes Entity 2.\"",
        "sdp_path_text": "Processing → for → demonstration → emphasizes → components",
        "sentence": "Applied Natural Language Processing emphasizes components.",
        "sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the subject, depending on the verb 'emphasizes'. Entity 2 ('components') is the object, depending on 'emphasizes' with 'Applied Natural Language Processing'. There is a direct dependency between Entity 1 and Entity 2, as 'components' is directly affected by the action of 'emphasizes' performed by 'Applied Natural Language Processing'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "Applied Natural Language Processing",
                "Task"
            ],
            [
                "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the object of the preposition 'for', depending on 'demonstration'. Entity 2 ('intelligent computer-assisted morphological analysis (ICALL)') is part of the noun phrase that is the object of the preposition 'in', depending on 'components'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of different clauses within the sentence.\"",
        "sdp_path_text": "Processing → for → demonstration → emphasizes → components → -RRB-",
        "sentence": "Applied Natural Language Processing emphasizes components in intelligent computer-assisted morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the subject, depending on the verb 'emphasizes'. Entity 2 ('intelligent computer-assisted morphological analysis') is the object of the preposition 'in', depending on 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'emphasizes' and the prepositional phrase 'in intelligent computer-assisted morphological analysis'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "Applied Natural Language Processing",
                "Task"
            ],
            [
                "disambiguated morphological analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the object of the preposition 'for', depending on 'demonstration'. Entity 2 ('disambiguated morphological analysis') is part of a list of components, depending on 'includes'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger structure describing the demonstration and its components.\"",
        "sdp_path_text": "Processing → for → demonstration → emphasizes → components → including → analysis",
        "sentence": "Applied Natural Language Processing emphasizes components including disambiguated morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the subject, depending on the verb 'emphasizes'. Entity 2 ('disambiguated morphological analysis') is the object of the preposition 'including', depending on 'including' in the phrase 'including disambiguated morphological analysis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'including'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "Applied Natural Language Processing",
                "Task"
            ],
            [
                "lemmatized indexing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the object of the preposition 'for', depending on 'demonstration'. Entity 2 ('lemmatized indexing') is part of a list of components, depending on 'includes' within the clause 'including disambiguated morphological analysis and lemmatized indexing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the demonstration's content.\"",
        "sdp_path_text": "Processing → for → demonstration → emphasizes → components → including → analysis → indexing",
        "sentence": "Applied Natural Language Processing emphasizes lemmatized indexing.",
        "sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the subject, depending on the verb 'emphasizes'. Entity 2 ('lemmatized indexing') is the object, depending on 'emphasizes' with 'Applied Natural Language Processing'. There is a direct dependency between Entity 1 and Entity 2, as 'lemmatized indexing' is directly emphasized by 'Applied Natural Language Processing'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "Applied Natural Language Processing",
                "Task"
            ],
            [
                "aligned bilingual corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the object of the preposition 'for', depending on 'demonstration'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'indexing'. There is no direct dependency between Entity 1 and Entity 2; both are part of larger phrases that describe different aspects of the demonstration.\"",
        "sdp_path_text": "Processing → for → demonstration → emphasizes → components → including → analysis → for → corpus",
        "sentence": "Applied Natural Language Processing emphasizes components including analysis for an aligned bilingual corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('Applied Natural Language Processing') is the subject, depending on the verb 'emphasizes'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'for' in the phrase 'for an aligned bilingual corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for an aligned bilingual corpus'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "components",
                "Generic"
            ],
            [
                "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('components') is the object of the verb 'emphasizes', depending on 'emphasizes' with 'demonstration'. Entity 2 ('intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-') is the object of the preposition 'in', depending on 'put' within the phrase 'put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'components' are emphasized as being used in 'intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-.'\"",
        "sdp_path_text": "components → -RRB-",
        "sentence": "Components are used in intelligent computer-assisted morphological analysis (ICALL).",
        "sentence_llm_dp_info": "\"Entity 1 ('components') is the subject, depending on the verb 'used'. Entity 2 ('intelligent computer-assisted morphological analysis (ICALL)') is the object of the preposition 'in', depending on 'in' in the phrase 'in intelligent computer-assisted morphological analysis (ICALL)'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "disambiguated morphological analysis",
                "Method"
            ],
            [
                "components",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('disambiguated morphological analysis') is part of a list, depending on the conjunction 'and' with 'lemmatized indexing'. It is also an object within the prepositional phrase 'for an aligned bilingual corpus of word examples'. Entity 2 ('components') is the subject, depending on the verb 'emphasizes' with 'demonstration'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure describing what the demonstration emphasizes.\"",
        "sdp_path_text": "analysis → including → components",
        "sentence": "Disambiguated morphological analysis includes components.",
        "sentence_llm_dp_info": "\"Entity 1 ('disambiguated morphological analysis') is the subject, depending on the verb 'includes'. Entity 2 ('components') is the direct object, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 includes Entity 2.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "lemmatized indexing",
                "Method"
            ],
            [
                "components",
                "Generic"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lemmatized indexing') is part of the list of objects, depending on the verb 'emphasizes'. Entity 2 ('components') is the direct object, depending on 'emphasizes'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger structure that 'emphasizes' puts into focus.\"",
        "sdp_path_text": "indexing → analysis → including → components",
        "sentence": "Lemmatized indexing is included among the components for morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('lemmatized indexing') is the subject, depending on the verb 'is included'. Entity 2 ('components') is the object of the preposition 'among', depending on 'among' in the phrase 'among the components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'among'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "components",
                "Generic"
            ],
            [
                "aligned bilingual corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('components') is the subject, depending on 'emphasizes' with 'demonstration'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'corpus'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'emphasizes' and the prepositional phrase 'for an aligned bilingual corpus'.\"",
        "sdp_path_text": "components → including → analysis → for → corpus",
        "sentence": "Components include analysis for an aligned bilingual corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('components') is the subject, depending on the verb 'include'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'for' in the phrase 'for an aligned bilingual corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-",
                "Task"
            ],
            [
                "disambiguated morphological analysis",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-') is the object of the preposition 'in', depending on 'components'. Entity 2 ('disambiguated morphological analysis') is part of a list of items, depending on the conjunction 'and' within the prepositional phrase 'including disambiguated morphological analysis and lemmatized indexing'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through different prepositional and conjunctive structures.\"",
        "sdp_path_text": "-RRB- → components → including → analysis",
        "sentence": "Intelligent computer-assisted morphological analysis (ICALL) includes disambiguated morphological analysis.",
        "sentence_llm_dp_info": "\"Entity 1 ('intelligent computer-assisted morphological analysis (ICALL)') is the subject, depending on the verb 'includes'. Entity 2 ('disambiguated morphological analysis') is the object, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is directly included by Entity 1.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-",
                "Task"
            ],
            [
                "lemmatized indexing",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-') is the object of the preposition 'in', depending on 'components'. Entity 2 ('lemmatized indexing') is part of a list of items, depending on 'including'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause through the verb 'emphasizes' and the preposition 'including'.\"",
        "sdp_path_text": "-RRB- → components → including → analysis → indexing",
        "sentence": "Intelligent computer-assisted morphological analysis includes lemmatized indexing.",
        "sentence_llm_dp_info": "\"Entity 1 ('intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-') is the subject, depending on the verb 'includes'. Entity 2 ('lemmatized indexing') is the object, depending on the verb 'includes'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 includes Entity 2.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-",
                "Task"
            ],
            [
                "aligned bilingual corpus",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intelligent computer-assisted morphological analysis -LRB- ICALL -RRB-') is the object of the preposition 'in', depending on 'uses'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'indexing'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context provided by the sentence, where Entity 1 is described as being used in the process that includes Entity 2.\"",
        "sdp_path_text": "-RRB- → components → including → analysis → for → corpus",
        "sentence": "Intelligent computer-assisted morphological analysis (ICALL) includes components for an aligned bilingual corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('intelligent computer-assisted morphological analysis (ICALL)') is the subject, depending on the verb 'includes'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'components'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'includes' and the prepositional phrase 'for an aligned bilingual corpus'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "disambiguated morphological analysis",
                "Method"
            ],
            [
                "lemmatized indexing",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('disambiguated morphological analysis') is part of the list of components, depending on the verb 'includes' with 'demonstration'. Entity 2 ('lemmatized indexing') is also part of the list of components, depending on the same verb 'includes' with 'demonstration'. There is no direct dependency between Entity 1 and Entity 2; both are listed as components included in the demonstration.\"",
        "sdp_path_text": "analysis → indexing",
        "sentence": "Disambiguated morphological analysis and lemmatized indexing are used in the demonstration.",
        "sentence_llm_dp_info": "\"Entity 1 ('disambiguated morphological analysis') is part of a coordination, depending on 'and' with 'lemmatized indexing'. Entity 2 ('lemmatized indexing') is also part of the coordination, depending on 'and' with 'disambiguated morphological analysis'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated elements in the subject of the sentence.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "disambiguated morphological analysis",
                "Method"
            ],
            [
                "aligned bilingual corpus",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('disambiguated morphological analysis') is part of the list of components, depending on 'includes' with 'demonstration'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'corpus' within the phrase 'for an aligned bilingual corpus'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through the verb 'includes'.\"",
        "sdp_path_text": "analysis → for → corpus",
        "sentence": "Disambiguated morphological analysis is used for an aligned bilingual corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('disambiguated morphological analysis') is the subject, depending on the verb 'is used'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'for' in the phrase 'for an aligned bilingual corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "A demonstration -LRB- in UNIX -RRB- for Applied Natural Language Processing emphasizes components put to novel technical uses in intelligent computer-assisted morphological analysis -LRB- ICALL -RRB- , including disambiguated morphological analysis and lemmatized indexing for an aligned bilingual corpus of word examples .",
        "ner_pair": [
            [
                "lemmatized indexing",
                "Method"
            ],
            [
                "aligned bilingual corpus",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lemmatized indexing') is part of the list of components, depending on 'includes' with the subject 'demonstration'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'examples'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the components and their application in the demonstration.\"",
        "sdp_path_text": "indexing → analysis → for → corpus",
        "sentence": "Lemmatized indexing is used for an aligned bilingual corpus.",
        "sentence_llm_dp_info": "\"Entity 1 ('lemmatized indexing') is the subject, depending on the verb 'is used'. Entity 2 ('aligned bilingual corpus') is the object of the preposition 'for', depending on 'for' in the phrase 'for an aligned bilingual corpus'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "tag contexts",
                "OtherScientificTerm"
            ],
            [
                "part-of-speech tagger",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the object of the preposition 'of', depending on 'use'. Entity 2 ('part-of-speech tagger') is the object of the relative clause, depending on 'demonstrates'. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the structure of the sentence where the 'part-of-speech tagger' demonstrates the idea of using 'tag contexts' among others.\"",
        "sdp_path_text": "contexts → of → use → ideas → demonstrates → tagger",
        "sentence": "The part-of-speech tagger demonstrates the use of tag contexts.",
        "sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the object, depending on 'use' with 'demonstrates'. Entity 2 ('part-of-speech tagger') is the subject, depending on the verb 'demonstrates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrates' which shows the action performed by Entity 2 involving Entity 1.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "part-of-speech tagger",
                "Method"
            ],
            [
                "dependency network representation",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('part-of-speech tagger') is the subject complement, depending on the verb 'present' with 'We'. Entity 2 ('dependency network representation') is the object of the preposition 'via', depending on 'use' in the phrase 'explicit use of both preceding and following tag contexts via a dependency network representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'via a dependency network representation'.\"",
        "sdp_path_text": "tagger → demonstrates → ideas → use → via → representation",
        "sentence": "The part-of-speech tagger uses a dependency network representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('part-of-speech tagger') is the subject, depending on the verb 'uses'. Entity 2 ('dependency network representation') is the object, depending on 'uses' with 'part-of-speech tagger'. There is a direct dependency between Entity 1 and Entity 2, as 'part-of-speech tagger' uses 'dependency network representation'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "lexical features",
                "OtherScientificTerm"
            ],
            [
                "part-of-speech tagger",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the object, depending on 'use' with 'broad use'. Entity 2 ('part-of-speech tagger') is the subject complement, depending on 'presenter' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where the part-of-speech tagger demonstrates ideas that include the broad use of lexical features.\"",
        "sdp_path_text": "features → of → use → use → ideas → demonstrates → tagger",
        "sentence": "The part-of-speech tagger demonstrates the use of lexical features.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the object, depending on 'use' with 'demonstrates'. Entity 2 ('part-of-speech tagger') is the subject, depending on the verb 'demonstrates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrates' which shows the relationship where the 'part-of-speech tagger' demonstrates the 'use of lexical features'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "part-of-speech tagger",
                "Method"
            ],
            [
                "multiple consecutive words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('part-of-speech tagger') is the object of the verb 'present', depending on 'presents' with 'We'. Entity 2 ('multiple consecutive words') is the object of the preposition 'on', depending on 'conditioning' within the clause describing one of the ideas presented. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the ideas being described about the part-of-speech tagger.\"",
        "sdp_path_text": "tagger → demonstrates → ideas → use → use → including → conditioning → on → words",
        "sentence": "The part-of-speech tagger demonstrates the use of conditioning on multiple consecutive words.",
        "sentence_llm_dp_info": "\"Entity 1 ('part-of-speech tagger') is the subject, depending on the verb 'demonstrates'. Entity 2 ('multiple consecutive words') is the object, depending on 'on' in the prepositional phrase 'on multiple consecutive words'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "priors in conditional loglinear models",
                "OtherScientificTerm"
            ],
            [
                "part-of-speech tagger",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priors in conditional loglinear models') is the object of the preposition 'of', depending on 'use' in the clause '-LRB- iii -RRB- effective use of priors in conditional loglinear models'. Entity 2 ('part-of-speech tagger') is the object of the relative clause 'that demonstrates the following ideas', depending on 'demonstrates' in the main clause 'We present a new part-of-speech tagger that demonstrates the following ideas'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "in → use → use → use → ideas → demonstrates → tagger",
        "sentence": "The part-of-speech tagger demonstrates the use of priors in conditional loglinear models.",
        "sentence_llm_dp_info": "\"Entity 1 ('priors in conditional loglinear models') is the object of the preposition 'of', depending on 'use'. Entity 2 ('part-of-speech tagger') is the subject, depending on the verb 'demonstrates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrates' and the prepositional phrase 'the use of priors in conditional loglinear models'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "fine-grained modeling of unknown word features",
                "Method"
            ],
            [
                "part-of-speech tagger",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('fine-grained modeling of unknown word features') is the object of the preposition 'of', depending on 'ideas'. Entity 2 ('part-of-speech tagger') is the subject complement, depending on the verb 'present'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'part-of-speech tagger' is the main subject and 'fine-grained modeling of unknown word features' is one of the ideas it demonstrates.\"",
        "sdp_path_text": "modeling → use → use → ideas → demonstrates → tagger",
        "sentence": "The part-of-speech tagger demonstrates fine-grained modeling of unknown word features.",
        "sentence_llm_dp_info": "\"Entity 1 ('fine-grained modeling of unknown word features') is the object, depending on the verb 'demonstrates'. Entity 2 ('part-of-speech tagger') is the subject, depending on the verb 'demonstrates'. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is demonstrating Entity 1.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "dependency network representation",
                "Method"
            ],
            [
                "tag contexts",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object of the preposition 'via', depending on 'via' in the phrase 'via a dependency network representation'. Entity 2 ('tag contexts') is the object of the preposition 'of', depending on 'use' in the phrase 'use of both preceding and following tag contexts'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of ideas presented in the sentence.\"",
        "sdp_path_text": "representation → via → use → of → contexts",
        "sentence": "The part-of-speech tagger uses tag contexts via a dependency network representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object, depending on the verb 'uses' with 'part-of-speech tagger'. Entity 2 ('tag contexts') is the object of the preposition 'via', depending on 'via' in the phrase 'via tag contexts'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing how the part-of-speech tagger operates.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "tag contexts",
                "OtherScientificTerm"
            ],
            [
                "lexical features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the object of the preposition 'of', depending on 'use' within the clause 'explicit use of both preceding and following tag contexts'. Entity 2 ('lexical features') is the object of the preposition 'of', depending on 'use' within the clause 'broad use of lexical features'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of different uses mentioned in the list of ideas presented.\"",
        "sdp_path_text": "contexts → of → use → use → of → features",
        "sentence": "Tag contexts and lexical features are used effectively.",
        "sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is part of a coordination, depending on 'and' with 'lexical features'. Entity 2 ('lexical features') is also part of the coordination, depending on 'and' with 'tag contexts'. Both entities together form the subject of the sentence, depending on the verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the coordinating conjunction 'and'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "tag contexts",
                "OtherScientificTerm"
            ],
            [
                "multiple consecutive words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the object of the preposition 'of', depending on 'use' within the phrase 'explicit use of both preceding and following tag contexts'. Entity 2 ('multiple consecutive words') is the object of the preposition 'on', depending on 'conditioning' within the phrase 'jointly conditioning on multiple consecutive words'. There is no direct dependency between Entity 1 and Entity 2; they are parts of separate clauses within the list of ideas presented.\"",
        "sdp_path_text": "contexts → of → use → use → including → conditioning → on → words",
        "sentence": "Tag contexts are used including conditioning on multiple consecutive words.",
        "sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the subject, depending on the verb 'used'. Entity 2 ('multiple consecutive words') is the object of the preposition 'on', depending on 'conditioning'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the prepositional phrase 'including conditioning on'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "tag contexts",
                "OtherScientificTerm"
            ],
            [
                "priors in conditional loglinear models",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the object of the preposition 'of', depending on 'use' in the phrase 'explicit use of both preceding and following tag contexts'. Entity 2 ('priors in conditional loglinear models') is the object of the preposition 'of', depending on 'use' in the phrase 'effective use of priors in conditional loglinear models'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of different uses listed as separate ideas in the sentence.\"",
        "sdp_path_text": "contexts → of → use → use → use → in",
        "sentence": "Tag contexts are used in priors in conditional loglinear models.",
        "sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the subject, depending on the verb 'are used'. Entity 2 ('priors in conditional loglinear models') is the object of the preposition 'in', depending on 'used' in the phrase 'used in priors in conditional loglinear models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' and the verb 'used'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "tag contexts",
                "OtherScientificTerm"
            ],
            [
                "fine-grained modeling of unknown word features",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the object of the preposition 'of', depending on 'use' within the phrase 'explicit use of both preceding and following tag contexts'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'of', depending on 'use' within the phrase 'fine-grained modeling of unknown word features'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of ideas being described in the sentence.\"",
        "sdp_path_text": "contexts → of → use → use → modeling",
        "sentence": "Tag contexts are used for fine-grained modeling of unknown word features.",
        "sentence_llm_dp_info": "\"Entity 1 ('tag contexts') is the subject, depending on the verb 'are used'. Entity 2 ('fine-grained modeling of unknown word features') is the complement of the preposition 'for', depending on 'for' in the phrase 'for fine-grained modeling of unknown word features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose of using 'tag contexts'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "dependency network representation",
                "Method"
            ],
            [
                "lexical features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object of the preposition 'via', depending on 'demonstrates' with the verb 'demonstrates'. Entity 2 ('lexical features') is the object of the preposition 'of', depending on 'use' with the verb 'use'. There is no direct dependency between Entity 1 and Entity 2; both are parts of the list of ideas being demonstrated by the part-of-speech tagger.\"",
        "sdp_path_text": "representation → via → use → use → of → features",
        "sentence": "The dependency network representation uses lexical features.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the subject, depending on the verb 'uses'. Entity 2 ('lexical features') is the object, depending on 'uses' in the phrase 'uses lexical features'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the direct object of the verb that Entity 1 depends on.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "dependency network representation",
                "Method"
            ],
            [
                "multiple consecutive words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object of the preposition 'via', depending on 'demonstrates' in the clause describing the ideas presented by the part-of-speech tagger. Entity 2 ('multiple consecutive words') is the object of the preposition 'on', depending on 'conditioning' in the context of using lexical features. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the list of ideas.\"",
        "sdp_path_text": "representation → via → use → use → including → conditioning → on → words",
        "sentence": "The dependency network representation uses conditioning on multiple consecutive words.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the subject, depending on 'uses' as the verb. Entity 2 ('multiple consecutive words') is the object, depending on 'conditioning' through the preposition 'on'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the prepositional phrase 'on multiple consecutive words'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "dependency network representation",
                "Method"
            ],
            [
                "priors in conditional loglinear models",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object of the preposition 'via', depending on 'tag contexts'. Entity 2 ('priors in conditional loglinear models') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a list of ideas presented in the sentence, connected through the conjunction 'and'.\"",
        "sdp_path_text": "representation → via → use → use → use → in",
        "sentence": "The part-of-speech tagger uses a dependency network representation and effectively uses priors in conditional loglinear models.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object of the verb 'uses', depending on 'uses' with 'tagger'. Entity 2 ('priors in conditional loglinear models') is the object of the verb 'uses', depending on 'uses' with 'effectively'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the verb 'uses'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "dependency network representation",
                "Method"
            ],
            [
                "fine-grained modeling of unknown word features",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the object of the preposition 'via', depending on the noun 'ideas'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'of', depending on the noun 'unknown word features'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a list of ideas presented in the sentence, connected through the conjunction 'and'.\"",
        "sdp_path_text": "representation → via → use → use → modeling",
        "sentence": "A dependency network representation uses fine-grained modeling of unknown word features.",
        "sentence_llm_dp_info": "\"Entity 1 ('dependency network representation') is the subject, depending on the verb 'uses'. Entity 2 ('fine-grained modeling of unknown word features') is the object, depending on 'uses' with 'dependency network representation'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the direct object of the action performed by Entity 1.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "lexical features",
                "OtherScientificTerm"
            ],
            [
                "multiple consecutive words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the object, depending on 'use' with the adjective 'broad'. Entity 2 ('multiple consecutive words') is the object of the preposition 'on', depending on 'conditioning'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context of the sentence where both are part of the broader concept of using various features in the part-of-speech tagger.\"",
        "sdp_path_text": "features → of → use → including → conditioning → on → words",
        "sentence": "The tagger uses lexical features, including conditioning on multiple consecutive words.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the object, depending on the verb 'uses' with 'tagger'. Entity 2 ('multiple consecutive words') is the object of the preposition 'on', depending on 'conditioning'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what the tagger uses.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "lexical features",
                "OtherScientificTerm"
            ],
            [
                "priors in conditional loglinear models",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the object, depending on 'use' with 'broad use of lexical features'. Entity 2 ('priors in conditional loglinear models') is the object, depending on 'use' with 'effective use of priors in conditional loglinear models'. There is no direct dependency between Entity 1 and Entity 2; both are objects of different uses listed in the sentence.\"",
        "sdp_path_text": "features → of → use → use → in",
        "sentence": "Lexical features and priors in conditional loglinear models are effectively used.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical features') is part of a conjunction, depending on 'and' with 'priors in conditional loglinear models'. Entity 2 ('priors in conditional loglinear models') is also part of the conjunction, depending on 'and' with 'lexical features'. Both Entity 1 and Entity 2 are the subjects of the passive verb 'are used'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and' and share a common dependency on the verb 'are used'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "lexical features",
                "OtherScientificTerm"
            ],
            [
                "fine-grained modeling of unknown word features",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the object of the preposition 'of', depending on 'use' in the phrase 'broad use of lexical features'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'of', depending on 'use' in the phrase 'effective use of priors in conditional loglinear models and fine-grained modeling of unknown word features'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of ideas presented in the sentence, connected through the conjunction 'and' and the shared verb 'demonstrates'.\"",
        "sdp_path_text": "features → of → use → modeling",
        "sentence": "Lexical features are used in fine-grained modeling of unknown word features.",
        "sentence_llm_dp_info": "\"Entity 1 ('lexical features') is the subject, depending on the verb 'are used'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'in', depending on 'in' in the phrase 'in fine-grained modeling of unknown word features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "multiple consecutive words",
                "OtherScientificTerm"
            ],
            [
                "priors in conditional loglinear models",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple consecutive words') is the object, depending on 'conditioning' within the clause 'including jointly conditioning on multiple consecutive words'. Entity 2 ('priors in conditional loglinear models') is the object, depending on 'use' within the clause 'effective use of priors in conditional loglinear models'. There is no direct dependency between Entity 1 and Entity 2, as they are part of different clauses listed as separate ideas in the sentence.\"",
        "sdp_path_text": "words → on → conditioning → including → use → use → in",
        "sentence": "Multiple consecutive words are used in conditioning, which includes the use of priors in conditional loglinear models.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple consecutive words') is the subject, depending on the verb 'are used'. Entity 2 ('priors in conditional loglinear models') is the object of the preposition 'of', depending on 'use' in the clause 'the use of priors in conditional loglinear models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of what is being used in conditioning.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "multiple consecutive words",
                "OtherScientificTerm"
            ],
            [
                "fine-grained modeling of unknown word features",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('multiple consecutive words') is the object, depending on 'conditioning' with 'jointly'. Entity 2 ('fine-grained modeling of unknown word features') is the object, depending on 'modeling' with 'fine-grained'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of ideas presented in the sentence.\"",
        "sdp_path_text": "words → on → conditioning → including → use → modeling",
        "sentence": "The tagger uses multiple consecutive words for fine-grained modeling of unknown word features.",
        "sentence_llm_dp_info": "\"Entity 1 ('multiple consecutive words') is the object, depending on the verb 'uses' with 'The tagger'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'for', depending on 'for' in the phrase 'for fine-grained modeling of unknown word features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'uses' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We present a new part-of-speech tagger that demonstrates the following ideas : -LRB- i -RRB- explicit use of both preceding and following tag contexts via a dependency network representation , -LRB- ii -RRB- broad use of lexical features , including jointly conditioning on multiple consecutive words , -LRB- iii -RRB- effective use of priors in conditional loglinear models , and -LRB- iv -RRB- fine-grained modeling of unknown word features .",
        "ner_pair": [
            [
                "priors in conditional loglinear models",
                "OtherScientificTerm"
            ],
            [
                "fine-grained modeling of unknown word features",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('priors in conditional loglinear models') is the object of the preposition 'of', depending on 'use' in the phrase 'effective use of priors in conditional loglinear models'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'of', depending on 'modeling' in the phrase 'fine-grained modeling of unknown word features'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of ideas presented in the sentence, each being an object of the verb 'demonstrates' through the conjunction 'and'.\"",
        "sdp_path_text": "in → use → use → modeling",
        "sentence": "The tagger uses priors in conditional loglinear models for fine-grained modeling of unknown word features.",
        "sentence_llm_dp_info": "\"Entity 1 ('priors in conditional loglinear models') is the object of the preposition 'in', depending on 'uses' with 'The tagger'. Entity 2 ('fine-grained modeling of unknown word features') is the object of the preposition 'for', depending on 'models' with 'The tagger'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main action performed by 'The tagger'.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "tagger",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on the preposition 'on', which modifies 'gives'. Entity 2 ('tagger') is the subject, depending on 'gives' as the main verb of the clause. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives' and the preposition 'on'.\"",
        "sdp_path_text": "accuracy → gives → tagger",
        "sentence": "The tagger gives 97.24% accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on the verb 'gives' with 'tagger'. Entity 2 ('tagger') is the subject, depending on the verb 'gives'. There is a direct dependency between Entity 1 and Entity 2, as 'tagger' provides or yields 'accuracy'.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "Penn Treebank WSJ",
                "Material"
            ],
            [
                "tagger",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'accuracy'. Entity 2 ('tagger') is the subject, depending on 'gives' with 'the resulting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'gives' and the preposition 'on'.\"",
        "sdp_path_text": "WSJ → on → accuracy → gives → tagger",
        "sentence": "The tagger gives 97.24% accuracy on the Penn Treebank WSJ.",
        "sentence_llm_dp_info": "\"Entity 1 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'gives'. Entity 2 ('tagger') is the subject, depending on the verb 'gives'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives' where 'tagger' is the performer of the action and 'Penn Treebank WSJ' is part of the context in which the action's result (accuracy) is measured.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "error",
                "Metric"
            ],
            [
                "tagger",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error') is part of a nominal compound, depending on 'reduction' with 'of 4.4 %'. Entity 2 ('tagger') is the subject, depending on 'gives' with 'the resulting'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of performance metrics related to the tagger's results.\"",
        "sdp_path_text": "error → reduction → accuracy → gives → tagger",
        "sentence": "The tagger gives an error reduction in accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('error') is the object, depending on the verb 'gives' with 'tagger'. Entity 2 ('tagger') is the subject, depending on the verb 'gives'. There is a direct dependency between Entity 1 and Entity 2, where 'error' is the object of the action performed by 'tagger'.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "tagger",
                "Method"
            ],
            [
                "tagging",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('tagger') is the subject, depending on 'gives' with 'the resulting'. Entity 2 ('tagging') is part of a compound noun, depending on 'result' with 'tagging result'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of performance metrics (accuracy and error reduction) mentioned in the sentence.\"",
        "sdp_path_text": "tagger → gives → accuracy → reduction → on → result → tagging",
        "sentence": "The tagger gives an accuracy improvement on tagging results.",
        "sentence_llm_dp_info": "\"Entity 1 ('tagger') is the subject, depending on the verb 'gives'. Entity 2 ('tagging') is part of the noun phrase 'tagging results', which is the object of the preposition 'on', depending on 'on' in the phrase 'on tagging results'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "Penn Treebank WSJ",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'gives' with 'tagger'. Entity 2 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'on' in the phrase 'on the Penn Treebank WSJ'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'gives' and the preposition 'on'.\"",
        "sdp_path_text": "accuracy → on → WSJ",
        "sentence": "The tagger gives 97.24% accuracy on the Penn Treebank WSJ.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'gives' with 'The tagger'. Entity 2 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'on' in the phrase 'on the Penn Treebank WSJ'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "error",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on the preposition 'on' within the phrase 'on the Penn Treebank WSJ'. Entity 2 ('error') is the subject, depending on the noun 'reduction' within the phrase 'an error reduction'. There is no direct dependency between Entity 1 and Entity 2; both are part of separate clauses describing different aspects of the performance improvement.\"",
        "sdp_path_text": "accuracy → reduction → error",
        "sentence": "The resulting tagger gives 97.24% accuracy, achieving a 4.4% error reduction.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on the verb 'gives' with 'tagger'. Entity 2 ('error') is part of the compound noun 'error reduction', depending on 'reduction'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the performance metrics of the tagger.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "accuracy",
                "Metric"
            ],
            [
                "tagging",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the object, depending on 'gives' with 'tagger'. Entity 2 ('tagging') is part of the compound noun 'tagging result', depending on 'result'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of evaluating the performance of a tagging system.\"",
        "sdp_path_text": "accuracy → reduction → on → result → tagging",
        "sentence": "The accuracy improvement results in better tagging.",
        "sentence_llm_dp_info": "\"Entity 1 ('accuracy') is the subject, depending on the verb 'improvement'. Entity 2 ('tagging') is the object, depending on the adjective 'better' which modifies 'tagging'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'results in' which shows the effect of the accuracy improvement on tagging.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "Penn Treebank WSJ",
                "Material"
            ],
            [
                "error",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'accuracy'. Entity 2 ('error') is the subject of the noun phrase 'error reduction', depending on 'reduction'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the larger context describing the performance metrics of the tagger.\"",
        "sdp_path_text": "WSJ → on → accuracy → reduction → error",
        "sentence": "The tagger gives an error reduction on the Penn Treebank WSJ.",
        "sentence_llm_dp_info": "\"Entity 1 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'on' in the phrase 'on the Penn Treebank WSJ'. Entity 2 ('error') is part of the noun compound 'error reduction', acting as the head noun, and depends on 'reduction' which is modified by 'gives'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the structure describing where and what the action (giving reduction) affects.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "Penn Treebank WSJ",
                "Material"
            ],
            [
                "tagging",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'accuracy'. Entity 2 ('tagging') is part of the compound noun 'tagging result', depending on 'result'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of accuracy and tagging performance described in the sentence.\"",
        "sdp_path_text": "WSJ → on → accuracy → reduction → on → result → tagging",
        "sentence": "The tagger achieves accuracy on the Penn Treebank WSJ, reducing errors in tagging.",
        "sentence_llm_dp_info": "\"Entity 1 ('Penn Treebank WSJ') is the object of the preposition 'on', depending on 'accuracy'. Entity 2 ('tagging') is the object of the preposition 'in', depending on 'errors'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the performance of the tagger described in the sentence.\""
    },
    {
        "raw_sentence": "Using these ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ , an error reduction of 4.4 % on the best previous single automatically learned tagging result .",
        "ner_pair": [
            [
                "error",
                "Metric"
            ],
            [
                "tagging",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('error') is the subject of the noun phrase 'an error reduction of 4.4%', depending on the preposition 'of' in the phrase 'reduction of'. Entity 2 ('tagging') is part of the compound noun 'tagging result', depending on 'result' in the phrase 'tagging result'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a larger clause describing the performance improvement of a tagging system.\"",
        "sdp_path_text": "error → reduction → on → result → tagging",
        "sentence": "There is an error reduction on the tagging result.",
        "sentence_llm_dp_info": "\"Entity 1 ('error') is the subject, depending on the verb 'reduction'. Entity 2 ('tagging') is the modifier, depending on 'result' in the noun phrase 'tagging result'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'error reduction' affects 'tagging result'.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "Person re-identification",
                "Task"
            ],
            [
                "pose",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('pose') is part of a noun phrase functioning as the object of the preposition 'of', depending on 'variations'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'due to the large variations of...'.\"",
        "sdp_path_text": "re → is → due → variations → of → pose",
        "sentence": "Person re-identification is challenging due to variations in pose.",
        "sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the copula 'is'. Entity 2 ('pose') is the object of the preposition 'in', depending on 'variations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'due to variations in pose'.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "Person re-identification",
                "Task"
            ],
            [
                "illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('illumination') is part of a list of nouns, depending on the preposition 'of' in the phrase 'variations of pose, illumination, occlusion and camera view'. There is no direct dependency between Entity 1 and Entity 2; both are connected through the noun 'variations' and the preposition 'of'.\"",
        "sdp_path_text": "re → is → due → variations → of → pose → illumination",
        "sentence": "Person re-identification is challenging due to variations in pose and illumination.",
        "sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('illumination') is part of a noun phrase, depending on 'variations' with the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'due to variations in pose and illumination'.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "Person re-identification",
                "Task"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('occlusion') is part of a list of nouns, depending on 'variations' through the preposition 'of' in the phrase 'variations of pose, illumination, occlusion and camera view'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "re → is → due → variations → of → pose → illumination → occlusion",
        "sentence": "Person re-identification is challenging due to variations of pose, illumination, and occlusion.",
        "sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('occlusion') is part of a list of objects, depending on 'variations' through the preposition 'of' in the phrase 'variations of pose, illumination, and occlusion'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the explanatory clause that describes the challenges related to Entity 1.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "Person re-identification",
                "Task"
            ],
            [
                "camera view",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('camera view') is one of the objects listed after the preposition 'of', depending on 'variations'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure describing the challenges of Entity 1.\"",
        "sdp_path_text": "re → is → due → variations → of → pose → illumination → occlusion → view",
        "sentence": "Person re-identification is challenging due to variations in pose, illumination, occlusion, and camera view.",
        "sentence_llm_dp_info": "\"Entity 1 ('Person re-identification') is the subject, depending on the verb 'is'. Entity 2 ('camera view') is part of a list of objects, depending on 'variations' through the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are related through the clause 'due to variations in...'.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "illumination",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a list of nouns, depending on 'variations' with the preposition 'of'. Entity 2 ('illumination') is also part of the same list of nouns, depending on 'variations' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both elements in the list of variations that make 'Person re-identification' challenging.\"",
        "sdp_path_text": "pose → illumination",
        "sentence": "Pose and illumination variations contribute to the challenges in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a compound noun, depending on 'variations' with 'and'. Entity 2 ('illumination') is also part of the same compound noun, depending on 'variations' with 'and'. There is no direct dependency between Entity 1 and Entity 2; both are components of the noun phrase 'pose and illumination variations' which acts as the subject of the sentence.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a list, depending on the noun 'variations' through the preposition 'of'. Entity 2 ('occlusion') is also part of the same list, depending on the noun 'variations' through the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; both are listed elements of 'variations'.\"",
        "sdp_path_text": "pose → illumination → occlusion",
        "sentence": "Pose and occlusion variations contribute to the challenge of person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a compound noun, depending on the conjunction 'and' with 'occlusion'. Entity 2 ('occlusion') is also part of a compound noun, depending on the conjunction 'and' with 'pose'. Both 'pose' and 'occlusion' together form the subject of the clause, depending on the verb 'contribute'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "pose",
                "OtherScientificTerm"
            ],
            [
                "camera view",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pose') is part of a list, depending on 'variations' with the conjunction 'and'. Entity 2 ('camera view') is also part of the same list, depending on 'variations' with the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both listed as elements of 'variations'.\"",
        "sdp_path_text": "pose → illumination → occlusion → view",
        "sentence": "Pose, illumination, occlusion, and camera view vary significantly in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('pose') is a conjunct, depending on the conjunction 'and' with 'camera view'. Entity 2 ('camera view') is also a conjunct, depending on the conjunction 'and' with 'pose'. Both are part of a list that serves as the subject of the sentence, depending on the verb 'vary'. There is no direct dependency between Entity 1 and Entity 2; they are both part of a coordinated structure.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "illumination",
                "OtherScientificTerm"
            ],
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a list, depending on the preposition 'of' in the phrase 'variations of pose, illumination, occlusion and camera view'. Entity 2 ('occlusion') is also part of the same list, depending on the preposition 'of' in the same phrase. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list of variations mentioned in the sentence.\"",
        "sdp_path_text": "illumination → occlusion",
        "sentence": "Illumination and occlusion contribute to the challenges in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is a conjunct, depending on 'contribute' with 'and'. Entity 2 ('occlusion') is also a conjunct, depending on 'contribute' with 'and'. There is no direct dependency between Entity 1 and Entity 2; both are part of a coordination structure contributing to the same predicate 'contribute'.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "illumination",
                "OtherScientificTerm"
            ],
            [
                "camera view",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a list of nouns, depending on 'variations' with the preposition 'of'. Entity 2 ('camera view') is also part of the same list of nouns, depending on 'variations' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2; both are elements in the list of factors contributing to the 'large variations'.\"",
        "sdp_path_text": "illumination → occlusion → view",
        "sentence": "Illumination and camera view variations contribute to the challenge of person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('illumination') is part of a coordination, depending on 'and' with 'camera view'. Entity 2 ('camera view') is also part of a coordination, depending on 'and' with 'illumination'. Both entities together form the subject of the clause, depending on the verb 'contribute'. There is no direct dependency between Entity 1 and Entity 2; they are coordinated subjects.\""
    },
    {
        "raw_sentence": "Person re-identification is challenging due to the large variations of pose , illumination , occlusion and camera view .",
        "ner_pair": [
            [
                "occlusion",
                "OtherScientificTerm"
            ],
            [
                "camera view",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('occlusion') is part of a list, depending on the conjunction 'and' with 'pose', 'illumination', and 'camera view'. Entity 2 ('camera view') is also part of the same list, depending on the conjunction 'and' with 'pose', 'illumination', and 'occlusion'. There is no direct dependency between Entity 1 and Entity 2; they are both listed as reasons contributing to the challenge described in the sentence.\"",
        "sdp_path_text": "occlusion → view",
        "sentence": "Occlusion and camera view contribute to the challenges in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('occlusion') is the subject, depending on the verb 'contribute'. Entity 2 ('camera view') is also a subject, depending on the same verb 'contribute'. There is no direct dependency between Entity 1 and Entity 2, but they both serve as subjects contributing to the same action described by the verb 'contribute'.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "highly-curved manifolds",
                "Method"
            ],
            [
                "pedestrian data",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('highly-curved manifolds') is the object, depending on 'distributed' with 'is'. Entity 2 ('pedestrian data') is the subject, depending on 'is' with 'distributed'. There is a direct dependency between Entity 1 and Entity 2, as 'pedestrian data' is the subject that is described as being 'distributed as highly-curved manifolds'.\"",
        "sdp_path_text": "manifolds → as → distributed → data",
        "sentence": "The pedestrian data is distributed as highly-curved manifolds.",
        "sentence_llm_dp_info": "\"Entity 1 ('highly-curved manifolds') is the complement, depending on the verb 'distributed'. Entity 2 ('pedestrian data') is the subject, depending on the verb 'is' (copula). There is a direct dependency between Entity 1 and Entity 2, as 'highly-curved manifolds' describes how 'pedestrian data' is distributed.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "pedestrian data",
                "Material"
            ],
            [
                "feature space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pedestrian data') is the subject, depending on the verb 'is' with the predicate 'distributed'. Entity 2 ('feature space') is the location, depending on the preposition 'in' within the phrase 'in the feature space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates that the 'pedestrian data' is distributed within the 'feature space'.\"",
        "sdp_path_text": "data → distributed → as → manifolds → in → space",
        "sentence": "Pedestrian data is distributed as manifolds in the feature space.",
        "sentence_llm_dp_info": "\"Entity 1 ('pedestrian data') is the subject, depending on the verb 'is distributed'. Entity 2 ('feature space') is the object of the preposition 'in', depending on 'in' in the phrase 'in the feature space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the feature space'.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "pedestrian data",
                "Material"
            ],
            [
                "convolutional neural networks -LRB- CNN -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pedestrian data') is the subject, depending on the verb 'is distributed'. Entity 2 ('convolutional neural networks -LRB- CNN -RRB-') is part of a possessive noun phrase, depending on 'capability' with the possessive marker '’s'. There is no direct dependency between Entity 1 and Entity 2, but they are both mentioned in the context of the same sentence, where the distribution of Entity 1 is discussed in relation to the capabilities of Entity 2.\"",
        "sdp_path_text": "data → distributed → despite → capability → networks",
        "sentence": "Pedestrian data is distributed despite CNN's capability.",
        "sentence_llm_dp_info": "\"Entity 1 ('pedestrian data') is the subject, depending on the verb 'is distributed'. Entity 2 ('convolutional neural networks (CNN)') is the possessive noun, depending on 'capability' with the genitive marker 's'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where the distribution of pedestrian data is mentioned in the context of CNN's capability.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "pedestrian data",
                "Material"
            ],
            [
                "feature extraction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pedestrian data') is the subject, depending on the verb 'is distributed'. Entity 2 ('feature extraction') is the object of the preposition 'of', depending on 'capability' in the phrase 'capability of feature extraction'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where the distribution of pedestrian data affects the feature extraction capabilities of CNNs.\"",
        "sdp_path_text": "data → distributed → despite → capability → of → extraction",
        "sentence": "Pedestrian data is distributed despite the capability of feature extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('pedestrian data') is the subject, depending on the verb 'is' in the clause 'is distributed'. Entity 2 ('feature extraction') is the object of the preposition 'of', depending on 'capability'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context of the sentence, where 'pedestrian data' is described as being distributed, and 'feature extraction' is mentioned as having a certain capability.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "feature space",
                "OtherScientificTerm"
            ],
            [
                "highly-curved manifolds",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature space') is the object of the preposition 'in', depending on 'distributed'. Entity 2 ('highly-curved manifolds') is the subject complement, depending on 'is distributed' with 'the pedestrian data'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'distributed' where 'highly-curved manifolds' is what is distributed 'in' the 'feature space'.\"",
        "sdp_path_text": "space → in → manifolds",
        "sentence": "The pedestrian data is distributed as highly-curved manifolds in the feature space.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature space') is the location where the action occurs, depending on the preposition 'in'. Entity 2 ('highly-curved manifolds') is the subject complement, depending on the verb 'is distributed'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the prepositional phrase 'in the feature space' which describes the location of the distribution of Entity 2.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "highly-curved manifolds",
                "Method"
            ],
            [
                "convolutional neural networks -LRB- CNN -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('highly-curved manifolds') is the object of the verb 'distributed', depending on 'is distributed'. Entity 2 ('convolutional neural networks -LRB- CNN -RRB-') is the subject of the possessive noun phrase, depending on 'capability' with the genitive marker '’s'. There is no direct dependency between Entity 1 and Entity 2; they are part of separate clauses within the sentence.\"",
        "sdp_path_text": "manifolds → as → distributed → despite → capability → networks",
        "sentence": "Highly-curved manifolds are distributed despite the capability of convolutional neural networks.",
        "sentence_llm_dp_info": "\"Entity 1 ('highly-curved manifolds') is the subject, depending on the verb 'are distributed'. Entity 2 ('convolutional neural networks') is the object of the preposition 'of', depending on 'capability'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'convolutional neural networks' being part of a modifying phrase that provides context for the distribution of 'highly-curved manifolds'.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "highly-curved manifolds",
                "Method"
            ],
            [
                "feature extraction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('highly-curved manifolds') is the object, depending on 'distributed' with 'is'. Entity 2 ('feature extraction') is the object, depending on 'capability' with 'CNN's'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "manifolds → as → distributed → despite → capability → of → extraction",
        "sentence": "Highly-curved manifolds are distributed despite the capability of feature extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('highly-curved manifolds') is the subject, depending on the verb 'are distributed'. Entity 2 ('feature extraction') is the object of the preposition 'of', depending on 'capability'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'highly-curved manifolds' are described as being distributed regardless of the capability related to 'feature extraction'.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "feature space",
                "OtherScientificTerm"
            ],
            [
                "convolutional neural networks -LRB- CNN -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature space') is the object of the preposition 'in', depending on 'distributed' with 'manifolds'. Entity 2 ('convolutional neural networks -LRB- CNN -RRB-') is the subject of the possessive modifier, depending on 'capability' with 'of'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "space → in → manifolds → as → distributed → despite → capability → networks",
        "sentence": "Despite their capability, convolutional neural networks process data distributed as manifolds in the feature space.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature space') is the object of the preposition 'in', depending on 'process' with 'convolutional neural networks'. Entity 2 ('convolutional neural networks') is the subject, depending on the verb 'process'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in the feature space'.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "feature space",
                "OtherScientificTerm"
            ],
            [
                "feature extraction",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature space') is the object of the preposition 'in', depending on 'distributed' with 'manifolds'. Entity 2 ('feature extraction') is the object of the preposition 'of', depending on 'capability' with 'CNN's'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "space → in → manifolds → as → distributed → despite → capability → of → extraction",
        "sentence": "The pedestrian data is distributed in the feature space, despite the capability of feature extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature space') is the object of the preposition 'in', depending on 'distributed'. Entity 2 ('feature extraction') is the object of the preposition 'of', depending on 'capability'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the distribution of pedestrian data and the capability of feature extraction.\""
    },
    {
        "raw_sentence": "Owing to these variations , the pedestrian data is distributed as highly-curved manifolds in the feature space , despite the current convolutional neural networks -LRB- CNN -RRB- 's capability of feature extraction .",
        "ner_pair": [
            [
                "convolutional neural networks -LRB- CNN -RRB-",
                "Method"
            ],
            [
                "feature extraction",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('convolutional neural networks -LRB- CNN -RRB-') is the possessor, depending on the possessive marker 's' with 'capability'. Entity 2 ('feature extraction') is the object, depending on the preposition 'of' with 'capability'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the possessive structure indicating that the capability belongs to the convolutional neural networks.\"",
        "sdp_path_text": "networks → capability → of → extraction",
        "sentence": "Convolutional neural networks have the capability of feature extraction.",
        "sentence_llm_dp_info": "\"Entity 1 ('convolutional neural networks -LRB- CNN -RRB-') is the subject, depending on the verb 'have'. Entity 2 ('feature extraction') is the object of the preposition 'of', depending on 'capability'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'capability' which is possessed by Entity 1.\""
    },
    {
        "raw_sentence": "In practice , the current deep embedding methods use the Euclidean distance for the training and test .",
        "ner_pair": [
            [
                "Euclidean distance",
                "OtherScientificTerm"
            ],
            [
                "deep embedding methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the object, depending on 'use' with 'methods'. Entity 2 ('deep embedding methods') is the subject, depending on 'use' with 'distance'. There is a direct dependency between Entity 1 and Entity 2, as 'Euclidean distance' is used by the 'deep embedding methods'.\"",
        "sdp_path_text": "distance → use → methods",
        "sentence": "Deep embedding methods use Euclidean distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the object, depending on the verb 'use'. Entity 2 ('deep embedding methods') is the subject, depending on the verb 'use'. There is a direct dependency between Entity 1 and Entity 2, as 'deep embedding methods' uses 'Euclidean distance'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "Euclidean distance",
                "OtherScientificTerm"
            ],
            [
                "manifold learning methods",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the object of the verb 'use', depending on 'suggest' with 'manifold learning methods'. Entity 2 ('manifold learning methods') is the subject, depending on the verb 'suggest'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the suggestion made by Entity 2 regarding the use of Entity 1.\"",
        "sdp_path_text": "distance → use → suggest → methods",
        "sentence": "Manifold learning methods suggest using Euclidean distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the object, depending on the verb 'suggest'. Entity 2 ('manifold learning methods') is the subject, depending on the verb 'suggest'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'suggest'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "manifold learning methods",
                "Method"
            ],
            [
                "local range",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manifold learning methods') is the subject, depending on the verb 'suggest'. Entity 2 ('local range') is the object of the preposition 'in', depending on 'use' in the phrase 'use the Euclidean distance in the local range'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the suggestion made by Entity 1 about how to use the Euclidean distance.\"",
        "sdp_path_text": "methods → suggest → use → in → range",
        "sentence": "Manifold learning methods suggest using the Euclidean distance in the local range.",
        "sentence_llm_dp_info": "\"Entity 1 ('manifold learning methods') is the subject, depending on the verb 'suggest'. Entity 2 ('local range') is the object of the preposition 'in', depending on 'in' in the phrase 'in the local range'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "manifold learning methods",
                "Method"
            ],
            [
                "graphical relationship",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manifold learning methods') is the subject, depending on the verb 'suggest'. Entity 2 ('graphical relationship') is the object of the preposition 'between', depending on 'samples' in the phrase 'between samples'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where Entity 1 suggests a method that involves Entity 2.\"",
        "sdp_path_text": "methods → suggest → use → combining → with → relationship",
        "sentence": "Manifold learning methods suggest using the graphical relationship between samples.",
        "sentence_llm_dp_info": "\"Entity 1 ('manifold learning methods') is the subject, depending on the verb 'suggest'. Entity 2 ('graphical relationship') is the object of the preposition 'the', depending on 'using' in the phrase 'using the graphical relationship'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'suggest' and the prepositional phrase 'using the graphical relationship'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "manifold learning methods",
                "Method"
            ],
            [
                "geodesic distance",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('manifold learning methods') is the subject, depending on 'suggest' as the main verb. Entity 2 ('geodesic distance') is the object of the gerund 'approximating', depending on 'for' in the phrase 'for approximating the geodesic distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the suggestion made by the methods for approximating the geodesic distance.\"",
        "sdp_path_text": "methods → suggest → use → for → approximating → distance",
        "sentence": "Manifold learning methods suggest using the Euclidean distance for approximating the geodesic distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('manifold learning methods') is the subject, depending on the verb 'suggest'. Entity 2 ('geodesic distance') is the object of the preposition 'for', depending on 'approximating' in the phrase 'for approximating the geodesic distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the suggestion of using the Euclidean distance for approximation.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "local range",
                "OtherScientificTerm"
            ],
            [
                "Euclidean distance",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'in', depending on 'use'. Entity 2 ('Euclidean distance') is the object, depending on 'use' with 'the manifold learning methods suggest'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'use' and the preposition 'in'.\"",
        "sdp_path_text": "range → in → use → distance",
        "sentence": "The manifold learning methods suggest using Euclidean distance in the local range.",
        "sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'in', depending on 'in' in the phrase 'in the local range'. Entity 2 ('Euclidean distance') is the object of the verb 'using', depending on 'using' in the phrase 'using Euclidean distance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'Euclidean distance' being used in relation to 'local range'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "Euclidean distance",
                "OtherScientificTerm"
            ],
            [
                "graphical relationship",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the object of the verb 'use', depending on 'suggest' with 'manifold learning methods'. Entity 2 ('graphical relationship') is the object of the preposition 'between', depending on 'combining' with 'for approximating the geodesic distance'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the method suggested by the manifold learning methods for approximating the geodesic distance.\"",
        "sdp_path_text": "distance → use → combining → with → relationship",
        "sentence": "The Euclidean distance is used in combination with the graphical relationship between samples.",
        "sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the subject, depending on 'is used' with 'used'. Entity 2 ('graphical relationship') is the object of the preposition 'with', depending on 'with' in the phrase 'with the graphical relationship'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing what the Euclidean distance is used in combination with.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "Euclidean distance",
                "OtherScientificTerm"
            ],
            [
                "geodesic distance",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the object of the preposition 'use', depending on the verb 'suggest' with 'the manifold learning methods'. Entity 2 ('geodesic distance') is the object of the gerund 'approximating', depending on the verb 'approximating' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the context provided by the sentence, where the use of Entity 1 is part of the method to approximate Entity 2.\"",
        "sdp_path_text": "distance → use → for → approximating → distance",
        "sentence": "Euclidean distance is used for approximating geodesic distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('Euclidean distance') is the subject, depending on the verb 'is used'. Entity 2 ('geodesic distance') is the object of the preposition 'for', depending on 'for' in the phrase 'for approximating geodesic distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' and the verb 'approximating'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "local range",
                "OtherScientificTerm"
            ],
            [
                "graphical relationship",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'in', depending on 'use' with 'the Euclidean distance'. Entity 2 ('graphical relationship') is the object of the preposition 'with', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "range → in → use → combining → with → relationship",
        "sentence": "The methods suggest using the graphical relationship in the local range.",
        "sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'in', depending on 'in' in the phrase 'in the local range'. Entity 2 ('graphical relationship') is the object of the preposition 'using', depending on 'using' in the phrase 'using the graphical relationship'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'suggest' and the prepositions 'using' and 'in'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "local range",
                "OtherScientificTerm"
            ],
            [
                "geodesic distance",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'in', depending on 'use' in the phrase 'use the Euclidean distance in the local range'. Entity 2 ('geodesic distance') is the object of the verb 'approximating', depending on 'for' in the phrase 'for approximating the geodesic distance'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the method (using Euclidean distance in the local range) is described as a means to achieve the goal (approximating the geodesic distance).\"",
        "sdp_path_text": "range → in → use → for → approximating → distance",
        "sentence": "The local range is used for approximating the geodesic distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('local range') is the subject, depending on the verb 'is used'. Entity 2 ('geodesic distance') is the object of the preposition 'for', depending on 'for' in the phrase 'for approximating the geodesic distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'for'.\""
    },
    {
        "raw_sentence": "On the other hand , the manifold learning methods suggest to use the Euclidean distance in the local range , combining with the graphical relationship between samples , for approximating the geodesic distance .",
        "ner_pair": [
            [
                "graphical relationship",
                "OtherScientificTerm"
            ],
            [
                "geodesic distance",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('graphical relationship') is the object of the preposition 'between', depending on 'samples'. Entity 2 ('geodesic distance') is the object of the verb 'approximating', depending on 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the method used for approximating the geodesic distance.\"",
        "sdp_path_text": "relationship → with → combining → use → for → approximating → distance",
        "sentence": "The graphical relationship between samples is used for approximating the geodesic distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('graphical relationship') is the subject complement, depending on 'is' with 'The'. Entity 2 ('geodesic distance') is the object, depending on 'approximating' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the preposition 'for' which indicates that the graphical relationship is utilized in the process of approximating the geodesic distance.\""
    },
    {
        "raw_sentence": "From this point of view , selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding , especially when the data has large intra-class variations .",
        "ner_pair": [
            [
                "local range",
                "OtherScientificTerm"
            ],
            [
                "CNN embedding",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'within', depending on the verb 'selecting'. Entity 2 ('CNN embedding') is the object of the preposition 'for', depending on the adjective 'critical'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the context and purpose of the selection process.\"",
        "sdp_path_text": "range → within → selecting → is → for → training → embedding",
        "sentence": "Selecting suitable positive training samples within a local range is critical for training the CNN embedding.",
        "sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'within', depending on 'samples'. Entity 2 ('CNN embedding') is the object of the preposition 'for', depending on 'critical'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the critical aspect of selecting training samples.\""
    },
    {
        "raw_sentence": "From this point of view , selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding , especially when the data has large intra-class variations .",
        "ner_pair": [
            [
                "local range",
                "OtherScientificTerm"
            ],
            [
                "data",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'within', depending on 'selecting'. Entity 2 ('data') is the subject, depending on the verb 'has'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing conditions that are critical for training the CNN embedding.\"",
        "sdp_path_text": "range → within → selecting → is → has → data",
        "sentence": "Selecting samples within a local range is critical when the data has large variations.",
        "sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'within', depending on 'selecting'. Entity 2 ('data') is the subject of the clause, depending on 'has' with 'large variations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same sentence context where the selection of samples within a 'local range' is discussed in relation to 'data' that has large variations.\""
    },
    {
        "raw_sentence": "From this point of view , selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding , especially when the data has large intra-class variations .",
        "ner_pair": [
            [
                "local range",
                "OtherScientificTerm"
            ],
            [
                "intra-class variations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'within', depending on 'selecting'. Entity 2 ('intra-class variations') is the object of the relative clause 'has large intra-class variations', depending on 'has'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of selecting training samples and the characteristics of the data.\"",
        "sdp_path_text": "range → within → selecting → is → has → variations",
        "sentence": "Selecting samples within a local range is critical when data has large intra-class variations.",
        "sentence_llm_dp_info": "\"Entity 1 ('local range') is the object of the preposition 'within', depending on 'within' in the phrase 'within a local range'. Entity 2 ('intra-class variations') is the subject complement, depending on 'has' with 'data'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing conditions for selecting samples.\""
    },
    {
        "raw_sentence": "From this point of view , selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding , especially when the data has large intra-class variations .",
        "ner_pair": [
            [
                "CNN embedding",
                "OtherScientificTerm"
            ],
            [
                "data",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN embedding') is the object of the preposition 'for', depending on 'critical' in the phrase 'critical for training the CNN embedding'. Entity 2 ('data') is the subject, depending on 'has' with 'variations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the conditions and importance of training the CNN embedding.\"",
        "sdp_path_text": "embedding → training → for → is → has → data",
        "sentence": "Training the CNN embedding is critical when the data has large variations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN embedding') is the object of the verb 'training', depending on 'is' which indicates that training it is critical. Entity 2 ('data') is the subject of the clause 'the data has large variations', depending on 'has' with 'variations'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the context where training the CNN embedding is critical due to the nature of the data.\""
    },
    {
        "raw_sentence": "From this point of view , selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding , especially when the data has large intra-class variations .",
        "ner_pair": [
            [
                "CNN embedding",
                "OtherScientificTerm"
            ],
            [
                "intra-class variations",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('CNN embedding') is the object of the preposition 'for', depending on 'critical' in the phrase 'critical for training the CNN embedding'. Entity 2 ('intra-class variations') is the object of the preposition 'of', depending on 'has' in the clause 'the data has large intra-class variations'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the conditions and importance for training the CNN embedding.\"",
        "sdp_path_text": "embedding → training → for → is → has → variations",
        "sentence": "Training the CNN embedding is critical when the data has large intra-class variations.",
        "sentence_llm_dp_info": "\"Entity 1 ('CNN embedding') is the object, depending on 'Training' as the subject. Entity 2 ('intra-class variations') is the subject complement, depending on 'has' which is part of the clause 'the data has large intra-class variations'. There is no direct dependency between Entity 1 and Entity 2; they are related through the context provided by the sentence.\""
    },
    {
        "raw_sentence": "From this point of view , selecting suitable positive -LRB- i.e. intra-class -RRB- training samples within a local range is critical for training the CNN embedding , especially when the data has large intra-class variations .",
        "ner_pair": [
            [
                "intra-class variations",
                "OtherScientificTerm"
            ],
            [
                "data",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('intra-class variations') is the complement, depending on 'has' with 'data'. Entity 2 ('data') is the subject, depending on 'has' with 'intra-class variations'. There is a direct dependency between Entity 1 and Entity 2, where 'data' is the subject of the verb 'has', and 'intra-class variations' is the complement.\"",
        "sdp_path_text": "variations → has → data",
        "sentence": "Data has large intra-class variations.",
        "sentence_llm_dp_info": "\"Entity 1 ('intra-class variations') is the complement, depending on the adjective 'large'. Entity 2 ('data') is the subject, depending on the verb 'has'. There is a direct dependency between Entity 1 and Entity 2, as 'intra-class variations' is the object of what 'data' has.\""
    },
    {
        "raw_sentence": "In this paper , we propose a novel moderate positive sample mining method to train robust CNN for person re-identification , dealing with the problem of large variation .",
        "ner_pair": [
            [
                "moderate positive sample mining method",
                "Method"
            ],
            [
                "robust CNN",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('moderate positive sample mining method') is the object, depending on the verb 'propose'. Entity 2 ('robust CNN') is the object of the preposition 'for', depending on 'for' in the phrase 'for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the purpose clause introduced by 'to train'.\"",
        "sdp_path_text": "method → train → CNN",
        "sentence": "A moderate positive sample mining method trains a robust CNN.",
        "sentence_llm_dp_info": "\"Entity 1 ('moderate positive sample mining method') is the subject, depending on the verb 'trains'. Entity 2 ('robust CNN') is the object, depending on the verb 'trains'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 is performing the action (training) on Entity 2.\""
    },
    {
        "raw_sentence": "In this paper , we propose a novel moderate positive sample mining method to train robust CNN for person re-identification , dealing with the problem of large variation .",
        "ner_pair": [
            [
                "moderate positive sample mining method",
                "Method"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('moderate positive sample mining method') is the object of the verb 'propose', depending on 'we'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'train'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'to train robust CNN for person re-identification'.\"",
        "sdp_path_text": "method → train → for → re",
        "sentence": "A moderate positive sample mining method trains a robust CNN for person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('moderate positive sample mining method') is the subject, depending on the verb 'trains'. Entity 2 ('person re-identification') is the object, depending on 'for' in the phrase 'for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , we propose a novel moderate positive sample mining method to train robust CNN for person re-identification , dealing with the problem of large variation .",
        "ner_pair": [
            [
                "robust CNN",
                "Method"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust CNN') is the object of the preposition 'for', depending on 'train' in the phrase 'to train robust CNN'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'robust CNN' in the context of its purpose. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for' indicating that the 'robust CNN' is trained for the purpose of 'person re-identification'.\"",
        "sdp_path_text": "CNN → train → for → re",
        "sentence": "A method is proposed to train a robust CNN for person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust CNN') is the object of the preposition 'to', depending on 'train' in the phrase 'to train a robust CNN'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'CNN' in the phrase 'for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositions 'to' and 'for'.\""
    },
    {
        "raw_sentence": "In addition , we improve the learning by a metric weight constraint , so that the learned metric has a better generalization ability .",
        "ner_pair": [
            [
                "metric weight constraint",
                "OtherScientificTerm"
            ],
            [
                "learning",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('metric weight constraint') is the object of the preposition 'by', depending on 'improve'. Entity 2 ('learning') is the object, depending on 'improve' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve'.\"",
        "sdp_path_text": "constraint → by → improve → learning",
        "sentence": "A metric weight constraint improves learning.",
        "sentence_llm_dp_info": "\"Entity 1 ('metric weight constraint') is the subject, depending on the verb 'improves'. Entity 2 ('learning') is the object, depending on 'improves' with 'metric weight constraint'. There is a direct dependency between Entity 1 and Entity 2, where 'metric weight constraint' directly influences 'learning' through the verb 'improves'.\""
    },
    {
        "raw_sentence": "In addition , we improve the learning by a metric weight constraint , so that the learned metric has a better generalization ability .",
        "ner_pair": [
            [
                "learning",
                "Generic"
            ],
            [
                "learned metric",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learning') is the object of the preposition 'the', depending on 'improve' with 'we'. Entity 2 ('learned metric') is the subject complement, depending on 'has' with 'a better generalization ability'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the improvement and the outcome of applying the metric weight constraint.\"",
        "sdp_path_text": "learning → improve → has → metric",
        "sentence": "We improve learning by enhancing the learned metric.",
        "sentence_llm_dp_info": "\"Entity 1 ('learning') is the object of the verb 'improve', depending on 'improve' with 'We'. Entity 2 ('learned metric') is the object of the verb 'enhancing', depending on 'enhancing' in the phrase 'enhancing the learned metric'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the process described by the sentence where 'learning' is improved through the enhancement of the 'learned metric'.\""
    },
    {
        "raw_sentence": "In addition , we improve the learning by a metric weight constraint , so that the learned metric has a better generalization ability .",
        "ner_pair": [
            [
                "learning",
                "Generic"
            ],
            [
                "generalization ability",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('learning') is the object of the preposition 'by', depending on 'improve' with 'we'. Entity 2 ('generalization ability') is the object of the clause, depending on 'has' with 'metric'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause 'the learned metric has a better generalization ability' which describes an outcome of improving the learning process.\"",
        "sdp_path_text": "learning → improve → has → ability",
        "sentence": "We improve learning to enhance generalization ability.",
        "sentence_llm_dp_info": "\"Entity 1 ('learning') is the object, depending on the verb 'improve'. Entity 2 ('generalization ability') is the object, depending on the verb 'enhance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, with 'learning' being the target of improvement and 'generalization ability' being the outcome of that enhancement.\""
    },
    {
        "raw_sentence": "In addition , we improve the learning by a metric weight constraint , so that the learned metric has a better generalization ability .",
        "ner_pair": [
            [
                "metric weight constraint",
                "OtherScientificTerm"
            ],
            [
                "learned metric",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('metric weight constraint') is the object of the preposition 'by', depending on 'improve'. Entity 2 ('learned metric') is the subject, depending on 'has' with 'a better generalization ability'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the effect of the 'metric weight constraint' on improving the 'learning' which benefits the 'learned metric'.\"",
        "sdp_path_text": "constraint → by → improve → has → metric",
        "sentence": "A metric weight constraint improves the learned metric's generalization ability.",
        "sentence_llm_dp_info": "\"Entity 1 ('metric weight constraint') is the subject, depending on the verb 'improves'. Entity 2 ('learned metric') is part of the possessive construction, depending on 'generalization' with the genitive marker 'metric’s'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves' and the possessive construction indicating that the 'metric weight constraint' affects the 'learned metric's generalization ability'.\""
    },
    {
        "raw_sentence": "In addition , we improve the learning by a metric weight constraint , so that the learned metric has a better generalization ability .",
        "ner_pair": [
            [
                "metric weight constraint",
                "OtherScientificTerm"
            ],
            [
                "generalization ability",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('metric weight constraint') is the object of the preposition 'by', depending on 'improve'. Entity 2 ('generalization ability') is the object of the preposition 'has', depending on 'metric'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'improve' and the structure of the sentence which indicates that the 'metric weight constraint' contributes to improving the 'generalization ability'.\"",
        "sdp_path_text": "constraint → by → improve → has → ability",
        "sentence": "The metric weight constraint improves the generalization ability.",
        "sentence_llm_dp_info": "\"Entity 1 ('metric weight constraint') is the subject, depending on the verb 'improves'. Entity 2 ('generalization ability') is the object, depending on the verb 'improves'. There is a direct dependency between Entity 1 and Entity 2, as 'metric weight constraint' directly acts upon 'generalization ability' through the verb 'improves'.\""
    },
    {
        "raw_sentence": "In addition , we improve the learning by a metric weight constraint , so that the learned metric has a better generalization ability .",
        "ner_pair": [
            [
                "generalization ability",
                "OtherScientificTerm"
            ],
            [
                "learned metric",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('generalization ability') is the object, depending on the verb 'has' which is part of the clause 'has a better generalization ability'. Entity 2 ('learned metric') is the subject, depending on the verb 'has' in the same clause. There is a direct dependency between Entity 1 and Entity 2, as 'learned metric' is the subject that possesses the 'generalization ability'.\"",
        "sdp_path_text": "ability → has → metric",
        "sentence": "The learned metric has a better generalization ability.",
        "sentence_llm_dp_info": "\"Entity 1 ('generalization ability') is the object, depending on the adjective 'better' which modifies it. Entity 2 ('learned metric') is the subject, depending on the verb 'has'. There is a direct dependency between Entity 1 and Entity 2, where 'generalization ability' is the object of the verb 'has' that is governed by the subject 'learned metric'.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "robust deep metrics",
                "OtherScientificTerm"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the object of the preposition 'for', depending on 'learning'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'metrics'. There is no direct dependency between Entity 1 and Entity 2; both are part of the prepositional phrase 'for person re-identification' where 'robust deep metrics' is the metric being learned for the purpose of 'person re-identification'.\"",
        "sdp_path_text": "metrics → for → re",
        "sentence": "Robust deep metrics are effective for person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the subject, depending on the verb 'are'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'effective' in the phrase 'effective for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'are effective for'.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "robust deep metrics",
                "OtherScientificTerm"
            ],
            [
                "deep model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the object of the preposition 'for', depending on 'learning'. Entity 2 ('deep model') is the subject, depending on 'outperforms' with 'significantly'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the context of 'person re-identification'.\"",
        "sdp_path_text": "metrics → learning → in → effective → are → show → outperforms → model",
        "sentence": "Experiments show that learning robust deep metrics leads to a deep model that outperforms state-of-the-art methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the object of the verb 'learning', which is part of the clause 'learning robust deep metrics leads to a deep model'. Entity 2 ('deep model') is the subject complement, depending on 'leads to' with 'learning robust deep metrics'. There is a direct dependency between Entity 1 and Entity 2, as the learning of Entity 1 leads to the creation or improvement of Entity 2.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "robust deep metrics",
                "OtherScientificTerm"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the object of the preposition 'for', depending on 'learning'. Entity 2 ('state-of-the-art methods') is the object of the preposition 'on', depending on 'outperforms'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "metrics → learning → in → effective → are → show → outperforms → methods",
        "sentence": "Robust deep metrics learning outperforms state-of-the-art methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is part of the subject, depending on the verb 'outperforms'. Entity 2 ('state-of-the-art methods') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, as 'robust deep metrics learning' is the subject that performs the action (outperforms) on 'state-of-the-art methods'.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "robust deep metrics",
                "OtherScientificTerm"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the object of the preposition 'for', depending on 'learning'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'metrics'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for person re-identification' where Entity 1 serves as the head noun modified by the prepositional phrase that includes Entity 2.\"",
        "sdp_path_text": "metrics → for → re",
        "sentence": "Robust deep metrics are effective for person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('robust deep metrics') is the subject, depending on the verb 'are'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'effective' in the phrase 'effective for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the predicate 'are effective for'.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "deep model",
                "Method"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep model') is the subject, depending on 'outperforms' with 'significantly'. Entity 2 ('person re-identification') is the object of the preposition 'of', depending on 'benchmarks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence, where the performance of the 'deep model' is described in the context of 'person re-identification' benchmarks.\"",
        "sdp_path_text": "model → outperforms → show → are → effective → in → learning → metrics → for → re",
        "sentence": "The deep model outperforms methods in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep model') is the subject, depending on the verb 'outperforms'. Entity 2 ('person re-identification') is the object of the preposition 'in', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'outperforms' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "state-of-the-art methods",
                "Generic"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('state-of-the-art methods') is the object, depending on 'outperforms' with 'model'. Entity 2 ('person re-identification') is the object of the preposition 'on', depending on 'benchmarks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the performance of the deep model on benchmarks related to person re-identification.\"",
        "sdp_path_text": "methods → outperforms → show → are → effective → in → learning → metrics → for → re",
        "sentence": "Our deep model outperforms state-of-the-art methods in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('state-of-the-art methods') is the object of the preposition 'in', depending on 'outperforms'. Entity 2 ('person re-identification') is the object of the preposition 'in', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase 'in person re-identification' where 'methods' is compared in the context of this task.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "deep model",
                "Method"
            ],
            [
                "state-of-the-art methods",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep model') is the subject, depending on 'outperforms' with 'significantly'. Entity 2 ('state-of-the-art methods') is the object, depending on 'outperforms' with 'deep model'. There is a direct dependency between Entity 1 and Entity 2, as 'deep model' outperforms 'state-of-the-art methods'.\"",
        "sdp_path_text": "model → outperforms → methods",
        "sentence": "The deep model outperforms state-of-the-art methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep model') is the subject, depending on the verb 'outperforms'. Entity 2 ('state-of-the-art methods') is the object, depending on the verb 'outperforms'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 performs the action (outperforms) on Entity 2.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "deep model",
                "Method"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep model') is the subject, depending on 'outperforms' as the verb. Entity 2 ('person re-identification') is the object of the preposition 'of', depending on 'benchmarks'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'outperforms' and the prepositional phrase 'on several benchmarks of person re-identification'.\"",
        "sdp_path_text": "model → outperforms → show → are → effective → in → learning → metrics → for → re",
        "sentence": "The deep model outperforms state-of-the-art methods in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep model') is the subject, depending on the verb 'outperforms'. Entity 2 ('person re-identification') is the object of the preposition 'in', depending on 'in' in the phrase 'in person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification , and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification .",
        "ner_pair": [
            [
                "state-of-the-art methods",
                "Generic"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('state-of-the-art methods') is the object of the comparative clause, depending on 'outperforms' with 'our deep model'. Entity 2 ('person re-identification') is the object of the preposition 'on', depending on 'benchmarks'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same comparative context where the performance of 'our deep model' is being evaluated against 'state-of-the-art methods' on 'benchmarks of person re-identification'.\"",
        "sdp_path_text": "methods → outperforms → show → are → effective → in → learning → metrics → for → re",
        "sentence": "Our deep model outperforms state-of-the-art methods in person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('state-of-the-art methods') is the object of the preposition 'in', depending on 'outperforms'. Entity 2 ('person re-identification') is the object of the preposition 'in', depending on 'in' in the phrase 'in person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the same preposition 'in'.\""
    },
    {
        "raw_sentence": "Therefore , the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification .",
        "ner_pair": [
            [
                "deep models",
                "Method"
            ],
            [
                "person re-identification",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('deep models') is the object of the preposition 'of', depending on 'designs'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'for' in the phrase 'for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, where 'deep models' are mentioned as being designed for the purpose of 'person re-identification'.\"",
        "sdp_path_text": "models → for → re",
        "sentence": "Deep models are designed for person re-identification.",
        "sentence_llm_dp_info": "\"Entity 1 ('deep models') is the subject, depending on the verb 'are designed'. Entity 2 ('person re-identification') is the object of the preposition 'for', depending on 'for' in the phrase 'for person re-identification'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Utterance Verification -LRB- UV -RRB-",
                "Method"
            ],
            [
                "Automatic Speech Recognition -LRB- ASR -RRB- System",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification -LRB- UV -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('Automatic Speech Recognition -LRB- ASR -RRB- System') is the noun modifier, depending on 'function' with the preposition 'of' in the phrase 'function of an Automatic Speech Recognition -LRB- ASR -RRB- System'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is' and the prepositional phrase 'a critical function of'.\"",
        "sdp_path_text": "-RRB- → is → function → of → System",
        "sentence": "Utterance Verification is a function of an Automatic Speech Recognition System.",
        "sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification -LRB- UV -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('Automatic Speech Recognition -LRB- ASR -RRB- System') is the complement, depending on the preposition 'of' which modifies 'function'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'function' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Utterance Verification -LRB- UV -RRB-",
                "Method"
            ],
            [
                "spontaneous speech",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification -LRB- UV -RRB-') is the subject, depending on the verb 'is'. It is also modified by the adjective 'critical' and the noun 'function'. Entity 2 ('spontaneous speech') is part of a list of items, depending on 'present' with 'are'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger context describing the conditions under which an Automatic Speech Recognition (ASR) System operates.\"",
        "sdp_path_text": "-RRB- → is → function → of → System → working → on → applications → are → speech",
        "sentence": "Utterance Verification is a function of an Automatic Speech Recognition System working with spontaneous speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification') is the subject, depending on the verb 'is'. Entity 2 ('spontaneous speech') is the object of the preposition 'with', depending on 'working'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with spontaneous speech' that modifies the noun 'System'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Utterance Verification -LRB- UV -RRB-",
                "Method"
            ],
            [
                "out-of-vocabulary -LRB- OOV -RRB- words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification -LRB- UV -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('out-of-vocabulary -LRB- OOV -RRB- words') is part of a list, depending on 'present' which is part of the clause describing the conditions in real applications. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context describing the challenges faced by an Automatic Speech Recognition System.\"",
        "sdp_path_text": "-RRB- → is → function → of → System → working → on → applications → are → speech → words",
        "sentence": "Utterance Verification is a function of an ASR System working on applications with out-of-vocabulary words.",
        "sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification') is the subject, depending on 'is' as the main verb. Entity 2 ('out-of-vocabulary words') is the object, depending on the preposition 'with' in the phrase 'with out-of-vocabulary words'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase that describes the context in which the function operates.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Utterance Verification -LRB- UV -RRB-",
                "Method"
            ],
            [
                "acoustic noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification -LRB- UV -RRB-') is the subject, depending on the verb 'is'. Entity 2 ('acoustic noises') is part of a list of objects, depending on the verb 'are' in the clause describing what is present in real applications. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "-RRB- → is → function → of → System → working → on → applications → are → speech → words → noises",
        "sentence": "Utterance Verification is a function of an ASR System working on applications with acoustic noises.",
        "sentence_llm_dp_info": "\"Entity 1 ('Utterance Verification') is the subject, depending on 'is' as the main verb. Entity 2 ('acoustic noises') is the object of the preposition 'with', depending on 'applications'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'with acoustic noises' which modifies 'applications'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Automatic Speech Recognition -LRB- ASR -RRB- System",
                "Method"
            ],
            [
                "spontaneous speech",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Automatic Speech Recognition -LRB- ASR -RRB- System') is the object of the preposition 'of', depending on 'function'. Entity 2 ('spontaneous speech') is part of a list of items, depending on 'present' which is the main verb of the clause describing the conditions in real applications. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of real applications where the ASR system operates.\"",
        "sdp_path_text": "System → working → on → applications → are → speech",
        "sentence": "An Automatic Speech Recognition (ASR) System works on applications involving spontaneous speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('Automatic Speech Recognition (ASR) System') is the subject, depending on the verb 'works'. Entity 2 ('spontaneous speech') is the object of the preposition 'involving', depending on 'involving' in the phrase 'involving spontaneous speech'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'involving' which indicates that the system operates in applications that include spontaneous speech.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Automatic Speech Recognition -LRB- ASR -RRB- System",
                "Method"
            ],
            [
                "out-of-vocabulary -LRB- OOV -RRB- words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Automatic Speech Recognition -LRB- ASR -RRB- System') is the object of the preposition 'of', depending on 'function'. Entity 2 ('out-of-vocabulary -LRB- OOV -RRB- words') is part of a list of items, depending on 'are' within the clause describing the conditions present in the applications. There is no direct dependency between Entity 1 and Entity 2; both are part of the broader context described in the sentence.\"",
        "sdp_path_text": "System → working → on → applications → are → speech → words",
        "sentence": "An Automatic Speech Recognition (ASR) System works on applications involving out-of-vocabulary (OOV) words.",
        "sentence_llm_dp_info": "\"Entity 1 ('Automatic Speech Recognition (ASR) System') is the subject, depending on the verb 'works'. Entity 2 ('out-of-vocabulary (OOV) words') is the object of the preposition 'involving', depending on 'involving' in the phrase 'involving out-of-vocabulary (OOV) words'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'involving'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "Automatic Speech Recognition -LRB- ASR -RRB- System",
                "Method"
            ],
            [
                "acoustic noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Automatic Speech Recognition -LRB- ASR -RRB- System') is the subject complement, depending on 'is' with 'Utterance Verification -LRB- UV -RRB-'. Entity 2 ('acoustic noises') is part of a list of items, depending on 'are' within the clause describing the conditions present in real applications. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the environment in which the ASR system operates.\"",
        "sdp_path_text": "System → working → on → applications → are → speech → words → noises",
        "sentence": "An Automatic Speech Recognition (ASR) System works on applications where acoustic noises are present.",
        "sentence_llm_dp_info": "\"Entity 1 ('Automatic Speech Recognition (ASR) System') is the subject, depending on the verb 'works'. Entity 2 ('acoustic noises') is the object of the relative clause, depending on 'are' in the phrase 'where acoustic noises are present'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the preposition 'on' and the relative clause 'where acoustic noises are present'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "spontaneous speech",
                "OtherScientificTerm"
            ],
            [
                "out-of-vocabulary -LRB- OOV -RRB- words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spontaneous speech') is part of a list, depending on the conjunction 'and' with 'out-of-vocabulary (OOV) words' and 'acoustic noises', all of which are objects of the preposition 'where'. Entity 2 ('out-of-vocabulary (OOV) words') is also part of this list, similarly depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same list of items described in the context of the conditions present in real applications.\"",
        "sdp_path_text": "speech → words",
        "sentence": "Spontaneous speech and out-of-vocabulary (OOV) words are present.",
        "sentence_llm_dp_info": "\"Entity 1 ('spontaneous speech') is part of a conjunction, depending on the conjunction 'and' with 'out-of-vocabulary (OOV) words'. Entity 2 ('out-of-vocabulary (OOV) words') is also part of the conjunction, depending on the conjunction 'and' with 'spontaneous speech'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "spontaneous speech",
                "OtherScientificTerm"
            ],
            [
                "acoustic noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spontaneous speech') is part of a list, depending on 'are' with the subject 'where'. Entity 2 ('acoustic noises') is also part of the same list, depending on 'and' which connects it with other items in the list. There is no direct dependency between Entity 1 and Entity 2, but they are both elements in a list of conditions present in real applications.\"",
        "sdp_path_text": "speech → words → noises",
        "sentence": "Spontaneous speech and acoustic noises are present in real applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('spontaneous speech') is the subject, depending on the verb 'are' with 'present'. Entity 2 ('acoustic noises') is coordinated with 'spontaneous speech' through the conjunction 'and', both being subjects of the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are part of a coordinate structure.\""
    },
    {
        "raw_sentence": "Utterance Verification -LRB- UV -RRB- is a critical function of an Automatic Speech Recognition -LRB- ASR -RRB- System working on real applications where spontaneous speech , out-of-vocabulary -LRB- OOV -RRB- words and acoustic noises are present .",
        "ner_pair": [
            [
                "out-of-vocabulary -LRB- OOV -RRB- words",
                "OtherScientificTerm"
            ],
            [
                "acoustic noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('out-of-vocabulary -LRB- OOV -RRB- words') is part of a list, depending on the conjunction 'and', which connects it to 'acoustic noises'. Entity 2 ('acoustic noises') is also part of the same list, depending on the conjunction 'and'. There is no direct dependency between Entity 1 and Entity 2; both are elements of a list that serves as the object of the preposition 'where'.\"",
        "sdp_path_text": "words → noises",
        "sentence": "Out-of-vocabulary words and acoustic noises are present in real applications.",
        "sentence_llm_dp_info": "\"Entity 1 ('out-of-vocabulary (OOV) words') is part of a conjunction, depending on 'and' with 'acoustic noises'. Entity 2 ('acoustic noises') is also part of the conjunction, depending on 'and' with 'out-of-vocabulary (OOV) words'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "Confidence tests",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the object of the verb 'present', depending on 'we'. Entity 2 ('Confidence tests') is the subject of the clause 'are applied', depending on the verb 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where the 'UV procedure' has 'Confidence tests' as one of its features.\"",
        "sdp_path_text": "procedure → applied → tests",
        "sentence": "The UV procedure applies confidence tests.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'applies'. Entity 2 ('confidence tests') is the object, depending on the verb 'applies'. There is a direct dependency between Entity 1 and Entity 2, where 'UV procedure' applies 'confidence tests'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "decoded string hypotheses",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the object of the preposition 'a', depending on 'present' with 'we'. Entity 2 ('decoded string hypotheses') is the object of the preposition 'to', depending on 'applied' with 'Confidence tests'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the features of the UV procedure.\"",
        "sdp_path_text": "procedure → applied → to → hypotheses",
        "sentence": "The UV procedure is applied to decoded string hypotheses.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is applied'. Entity 2 ('decoded string hypotheses') is the object, depending on the preposition 'to' with 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is applied' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "OOV words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'present'. Entity 2 ('OOV words') is part of a prepositional phrase, depending on 'represent' with 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the models that represent OOV words in the context of the UV procedure.\"",
        "sdp_path_text": "procedure → applied → to → hypotheses → obtained → from → using → models → represent → words",
        "sentence": "The UV procedure applies confidence tests to hypotheses obtained from using models that represent OOV words.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'applies'. Entity 2 ('OOV words') is the object of the preposition 'from', depending on 'obtained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the series of actions described in the sentence.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on 'present' with 'we'. Entity 2 ('noises') is the object, depending on 'represent' with 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the features of the UV procedure.\"",
        "sdp_path_text": "procedure → applied → to → hypotheses → obtained → from → using → models → represent → words → noises",
        "sentence": "The UV procedure applies confidence tests to hypotheses obtained from models representing noises.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'applies'. Entity 2 ('noises') is the object of the preposition 'representing', which is part of the noun phrase 'models representing noises'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applies' and the prepositional phrase 'representing noises'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "Confidence tests",
                "Method"
            ],
            [
                "decoded string hypotheses",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Confidence tests') is the subject, depending on the verb 'applied'. Entity 2 ('decoded string hypotheses') is the object, depending on the preposition 'to', which is part of the phrase 'applied to decoded string hypotheses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to' indicating the application of the tests to the hypotheses.\"",
        "sdp_path_text": "tests → applied → to → hypotheses",
        "sentence": "Confidence tests are applied to decoded string hypotheses.",
        "sentence_llm_dp_info": "\"Entity 1 ('Confidence tests') is the subject, depending on the verb 'applied'. Entity 2 ('decoded string hypotheses') is the object, depending on the preposition 'to', which is part of the phrase 'to decoded string hypotheses'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' and the preposition 'to'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "Confidence tests",
                "Method"
            ],
            [
                "OOV words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Confidence tests') is the subject, depending on the verb 'applied'. Entity 2 ('OOV words') is the object, depending on the verb 'represent' with 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the models that apply confidence tests to hypotheses involving OOV words.\"",
        "sdp_path_text": "tests → applied → to → hypotheses → obtained → from → using → models → represent → words",
        "sentence": "Confidence tests are applied to hypotheses obtained from models representing OOV words.",
        "sentence_llm_dp_info": "\"Entity 1 ('Confidence tests') is the subject, depending on the verb 'applied'. Entity 2 ('OOV words') is the object, depending on 'representing' with 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of dependencies involving 'applied', 'hypotheses', and 'representing'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "Confidence tests",
                "Method"
            ],
            [
                "noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Confidence tests') is the subject, depending on the verb 'applied'. Entity 2 ('noises') is part of a compound noun, depending on 'and' which connects it with 'OOV words'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the clause describing what the confidence tests are applied to.\"",
        "sdp_path_text": "tests → applied → to → hypotheses → obtained → from → using → models → represent → words → noises",
        "sentence": "Confidence tests are applied to hypotheses obtained from models representing noises.",
        "sentence_llm_dp_info": "\"Entity 1 ('Confidence tests') is the subject, depending on the verb 'applied'. Entity 2 ('noises') is the object of the participle 'representing', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the chain of relations involving 'hypotheses' and 'models'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "decoded string hypotheses",
                "OtherScientificTerm"
            ],
            [
                "OOV words",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('decoded string hypotheses') is the object, depending on the passive verb 'obtained'. Entity 2 ('OOV words') is the object of the relative clause, depending on 'represent' with 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context provided by the models and the process described.\"",
        "sdp_path_text": "hypotheses → obtained → from → using → models → represent → words",
        "sentence": "Decoded string hypotheses are obtained from using models that represent OOV words.",
        "sentence_llm_dp_info": "\"Entity 1 ('decoded string hypotheses') is the subject, depending on the verb 'obtained'. Entity 2 ('OOV words') is the object of the preposition 'represent', depending on 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'obtained' and the prepositional phrase 'from using models that represent OOV words'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "decoded string hypotheses",
                "OtherScientificTerm"
            ],
            [
                "noises",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('decoded string hypotheses') is the object, depending on 'obtained' which is part of the clause 'hypotheses obtained from using word and garbage models'. Entity 2 ('noises') is the object, depending on 'represent' with 'models'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing what the models represent.\"",
        "sdp_path_text": "hypotheses → obtained → from → using → models → represent → words → noises",
        "sentence": "Decoded string hypotheses are obtained from using models that represent noises.",
        "sentence_llm_dp_info": "\"Entity 1 ('decoded string hypotheses') is the subject, depending on the verb 'obtained'. Entity 2 ('noises') is the object of the verb 'represent', which is part of the relative clause modifying 'models'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'obtained' and the prepositional phrase 'from using models that represent noises'.\""
    },
    {
        "raw_sentence": "In this paper we present a new UV procedure with two major features : a -RRB- Confidence tests are applied to decoded string hypotheses obtained from using word and garbage models that represent OOV words and noises .",
        "ner_pair": [
            [
                "noises",
                "OtherScientificTerm"
            ],
            [
                "OOV words",
                "OtherScientificTerm"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('noises') is the object, depending on the conjunction 'and' with 'OOV words'. Entity 2 ('OOV words') is also an object, depending on the relative clause 'that represent' which modifies both 'OOV words' and 'noises'. There is no direct dependency between Entity 1 and Entity 2; they are part of a coordinated structure under the verb 'represent'.\"",
        "sdp_path_text": "noises → words",
        "sentence": "Noises and OOV words are represented using word and garbage models.",
        "sentence_llm_dp_info": "\"Entity 1 ('noises') is the subject, depending on the verb 'are represented'. Entity 2 ('OOV words') is coordinated with 'noises' as a conjunct, also depending on the verb 'are represented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through coordination (i.e., the conjunction 'and').\""
    },
    {
        "raw_sentence": "Thus the ASR system is designed to deal with what we refer to as Word Spotting and Noise Spotting capabilities .",
        "ner_pair": [
            [
                "ASR system",
                "Method"
            ],
            [
                "Word Spotting",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASR system') is the subject, depending on the verb 'designed'. Entity 2 ('Word Spotting') is part of the object of the preposition 'as', which is part of the larger phrase 'what we refer to as Word Spotting and Noise Spotting capabilities'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the purpose or function described by the prepositional phrase.\"",
        "sdp_path_text": "system → designed → deal → with → refer → as → capabilities → Spotting",
        "sentence": "The ASR system is designed to deal with Word Spotting.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASR system') is the subject, depending on the verb 'designed'. Entity 2 ('Word Spotting') is the object of the preposition 'with', depending on 'deal' in the phrase 'to deal with Word Spotting'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'deal' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Thus the ASR system is designed to deal with what we refer to as Word Spotting and Noise Spotting capabilities .",
        "ner_pair": [
            [
                "ASR system",
                "Method"
            ],
            [
                "Noise Spotting capabilities",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASR system') is the subject, depending on the verb 'is designed'. Entity 2 ('Noise Spotting capabilities') is part of the object complement, depending on the conjunction 'and' which connects it to 'Word Spotting' in the phrase 'Word Spotting and Noise Spotting capabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the design purpose of the ASR system.\"",
        "sdp_path_text": "system → designed → deal → with → refer → as → capabilities",
        "sentence": "The ASR system is designed to deal with Noise Spotting capabilities.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASR system') is the subject, depending on the verb 'is designed'. Entity 2 ('Noise Spotting capabilities') is the object of the preposition 'with', depending on 'deal' in the phrase 'to deal with'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'designed' and the prepositional phrase 'to deal with'.\""
    },
    {
        "raw_sentence": "Thus the ASR system is designed to deal with what we refer to as Word Spotting and Noise Spotting capabilities .",
        "ner_pair": [
            [
                "Word Spotting",
                "Task"
            ],
            [
                "Noise Spotting capabilities",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Word Spotting') is part of a coordinated structure, depending on the conjunction 'and' which connects it to Entity 2. Entity 2 ('Noise Spotting capabilities') is also part of this coordinated structure, depending on 'as' which introduces the clause 'what we refer to as...'. There is no direct dependency between Entity 1 and Entity 2; they are both objects of the preposition 'to' within the clause introduced by 'as'.\"",
        "sdp_path_text": "Spotting → capabilities",
        "sentence": "The ASR system is designed to handle Word Spotting and Noise Spotting capabilities.",
        "sentence_llm_dp_info": "\"Entity 1 ('Word Spotting') is part of a conjunction, depending on 'and' which connects it with 'Noise Spotting capabilities'. Entity 2 ('Noise Spotting capabilities') is the object of the preposition 'to', depending on 'handle' in the phrase 'to handle Word Spotting and Noise Spotting capabilities'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "confidence tests",
                "Method"
            ],
            [
                "UV procedure",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the object of the preposition 'on', depending on 'based' in the phrase 'based on three different confidence tests'. Entity 2 ('UV procedure') is the subject, depending on 'is' in the main clause 'The UV procedure is based...'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on' which links 'confidence tests' to the predicate 'is based'.\"",
        "sdp_path_text": "tests → on → based → procedure",
        "sentence": "The UV procedure is based on confidence tests.",
        "sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the object, depending on the preposition 'on', which is part of the phrase 'based on'. Entity 2 ('UV procedure') is the subject, depending on the verb 'is' in the phrase 'is based'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "two",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is' which indicates that it is based on certain elements. Entity 2 ('two') is a numeral, depending on the adjective 'based' in the phrase 'two based on acoustic measures'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of the same clause describing the components of the UV procedure.\"",
        "sdp_path_text": "procedure → based → two",
        "sentence": "The UV procedure is based on two tests.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is'. Entity 2 ('two') is a numeral modifier, depending on 'tests'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where 'two tests' describes what the 'UV procedure' is based on.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "acoustic measures",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is' with 'based'. Entity 2 ('acoustic measures') is the object, depending on the preposition 'on' within the phrase 'based on acoustic measures'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'on' and the verb 'based'.\"",
        "sdp_path_text": "procedure → based → two → based → on → measures",
        "sentence": "The UV procedure is based on acoustic measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is'. Entity 2 ('acoustic measures') is the object, depending on the preposition 'on' in the phrase 'based on acoustic measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' in the phrase 'based on'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "one",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on 'is' (the copula). Entity 2 ('one') is the subject complement, depending on 'and' in the list of items described after 'tests'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the list of confidence tests described in the sentence.\"",
        "sdp_path_text": "procedure → based → two → one",
        "sentence": "{\n  \"Simplified sentence\": \"The UV procedure is based on one.\"\n} \n\nHowever, this simplification might be too concise and lose some context. A slightly more detailed but still concise version could be:\n\n{\n  \"Simplified sentence\": \"The UV procedure is based on one test.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is'. Entity 2 ('one') is the object of the preposition 'on', depending on 'based' in the phrase 'based on one'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is' in the phrase 'is based'. Entity 2 ('linguistic information') is the object, depending on 'founded' in the phrase 'one founded on linguistic information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where 'linguistic information' is part of the details describing what the 'UV procedure' is based on.\"",
        "sdp_path_text": "procedure → based → two → one → founded → on → information",
        "sentence": "The UV procedure is based on linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is'. Entity 2 ('linguistic information') is the object of the preposition 'on', depending on 'based' in the phrase 'based on linguistic information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "UV procedure",
                "Method"
            ],
            [
                "hierarchical structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'is' which links it to its attributes. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied' in the phrase 'applied in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where the 'UV procedure' is described as being applied in a 'hierarchical structure'.\"",
        "sdp_path_text": "procedure → based → two → one → applied → in → structure",
        "sentence": "The UV procedure is applied in a hierarchical structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('UV procedure') is the subject, depending on the verb 'applied'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'in' in the phrase 'in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates where the UV procedure is applied.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "two",
                "Generic"
            ],
            [
                "confidence tests",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('two') is the quantifier, depending on 'based' with 'tests'. Entity 2 ('confidence tests') is the object of the preposition 'on', depending on 'based' in the phrase 'based on confidence tests'. There is a direct dependency between Entity 1 and Entity 2, as 'two' modifies 'confidence tests' to specify the number of tests mentioned.\"",
        "sdp_path_text": "two → based → on → tests",
        "sentence": "Two confidence tests are based on acoustic measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('two') is the numeral modifier, depending on 'confidence tests'. Entity 2 ('confidence tests') is the subject, depending on the verb 'are'. There is a direct dependency between Entity 1 and Entity 2, where 'two' modifies 'confidence tests'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "confidence tests",
                "Method"
            ],
            [
                "acoustic measures",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the object of the preposition 'on', depending on 'based' in the phrase 'based on three different confidence tests'. Entity 2 ('acoustic measures') is the object of the preposition 'on', depending on 'based' in the phrase 'two based on acoustic measures'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same larger structure described by the sentence.\"",
        "sdp_path_text": "tests → on → based → two → based → on → measures",
        "sentence": "Two confidence tests are based on acoustic measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the subject, depending on the verb 'are'. Entity 2 ('acoustic measures') is the object of the preposition 'on', depending on 'based' in the phrase 'based on acoustic measures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "one",
                "Generic"
            ],
            [
                "confidence tests",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('one') is the subject, depending on 'founded' with 'on linguistic information'. Entity 2 ('confidence tests') is the object of the preposition 'on', depending on 'based' in the phrase 'based on three different confidence tests'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same list of items described in the sentence.\"",
        "sdp_path_text": "one → two → based → on → tests",
        "sentence": "One confidence test is based on linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('one') is a numeral modifier, depending on 'confidence test' with a determiner relation. Entity 2 ('confidence tests') is the subject, depending on the verb 'is' as the main noun of the sentence. There is a direct dependency between Entity 1 and Entity 2, where 'one' modifies 'confidence tests'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "confidence tests",
                "Method"
            ],
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the object, depending on 'based' with 'procedure'. Entity 2 ('linguistic information') is the object, depending on 'founded' with 'one'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the confidence tests.\"",
        "sdp_path_text": "tests → on → based → two → one → founded → on → information",
        "sentence": "Confidence tests include one based on linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the subject, depending on the verb 'include'. Entity 2 ('linguistic information') is the object of the preposition 'on', depending on 'based' in the phrase 'based on linguistic information'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on linguistic information'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "confidence tests",
                "Method"
            ],
            [
                "hierarchical structure",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the object of the preposition 'on', depending on 'based' in the phrase 'based on three different confidence tests'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied' in the phrase 'applied in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing aspects of the UV procedure.\"",
        "sdp_path_text": "tests → on → based → two → one → applied → in → structure",
        "sentence": "Confidence tests, including two and one based on different measures, are applied in a hierarchical structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('confidence tests') is the subject, depending on the verb 'are applied'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied' in the phrase 'applied in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'applied' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "acoustic measures",
                "Metric"
            ],
            [
                "two",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the object, depending on 'based' with 'two'. Entity 2 ('two') is the subject, depending on the preposition 'of' in the phrase 'two based on acoustic measures'. There is a direct dependency between Entity 1 and Entity 2, where 'two' modifies 'acoustic measures' to specify the number of tests based on these measures.\"",
        "sdp_path_text": "measures → on → based → two",
        "sentence": "Two confidence tests are based on acoustic measures.",
        "sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the object, depending on 'based' with 'tests'. Entity 2 ('two') is a numeral modifier, depending on 'tests'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the noun 'tests'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "two",
                "Generic"
            ],
            [
                "one",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('two') is the subject, depending on the preposition 'based' in the phrase 'based on acoustic measures'. Entity 2 ('one') is the subject, depending on the past participle 'founded' in the phrase 'founded on linguistic information'. There is no direct dependency between Entity 1 and Entity 2; both are part of a list of items described in the sentence.\"",
        "sdp_path_text": "two → one",
        "sentence": "Two tests are based on acoustic measures and one test is founded on linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('two') is a numeral modifier, depending on 'tests' as its quantifier. Entity 2 ('one') is also a numeral modifier, depending on 'test' as its quantifier. There is no direct dependency between Entity 1 and Entity 2; both independently modify different instances of the noun 'test'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "two",
                "Generic"
            ],
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('two') is the numeral modifier, depending on 'based' with 'tests'. Entity 2 ('linguistic information') is the object, depending on 'founded' with 'one'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list describing the types of confidence tests used in the procedure.\"",
        "sdp_path_text": "two → one → founded → on → information",
        "sentence": "Two tests are based on acoustic measures, and one is founded on linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('two') is a numeral modifier, depending on 'tests' as a quantifier. Entity 2 ('linguistic information') is the object, depending on 'founded' with 'one'. There is no direct dependency between Entity 1 and Entity 2, as they are part of different clauses within the sentence.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "two",
                "Generic"
            ],
            [
                "hierarchical structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('two') is the numeral modifier, depending on 'based' with 'tests'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied' in the phrase 'applied in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "two → one → applied → in → structure",
        "sentence": "Two tests are applied in a hierarchical structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('two') is a numeral modifier, depending on 'tests'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "acoustic measures",
                "Metric"
            ],
            [
                "one",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the object of the preposition 'on', depending on 'based' in the phrase 'based on acoustic measures'. Entity 2 ('one') is the subject of the clause 'one founded on linguistic information', depending on 'founded'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a list described by 'three different confidence tests'.\"",
        "sdp_path_text": "measures → on → based → two → one",
        "sentence": "Two acoustic measures and one are used in the UV procedure.",
        "sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the subject complement, depending on the verb 'used'. Entity 2 ('one') is the subject complement, also depending on the verb 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same predicate, indicating that they are used together in the UV procedure.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "acoustic measures",
                "Metric"
            ],
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the object of the preposition 'on', depending on 'based' in the phrase 'based on acoustic measures'. Entity 2 ('linguistic information') is the object of the preposition 'on', depending on 'founded' in the phrase 'founded on linguistic information'. There is no direct dependency between Entity 1 and Entity 2; both are related to the main clause through their respective prepositional phrases.\"",
        "sdp_path_text": "measures → on → based → two → one → founded → on → information",
        "sentence": "The UV procedure uses acoustic measures and linguistic information in its confidence tests.",
        "sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the object of the preposition 'uses', depending on 'uses' in the phrase 'uses acoustic measures'. Entity 2 ('linguistic information') is also the object of the preposition 'uses', depending on 'uses' in the phrase 'uses linguistic information'. There is no direct dependency between Entity 1 and Entity 2, but both are objects of the same verb 'uses'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "acoustic measures",
                "Metric"
            ],
            [
                "hierarchical structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the object of the preposition 'on', depending on 'based' in the phrase 'based on acoustic measures'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied' in the phrase 'applied in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing the components and application method of the UV procedure.\"",
        "sdp_path_text": "measures → on → based → two → one → applied → in → structure",
        "sentence": "Two acoustic measures are applied in a hierarchical structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('acoustic measures') is the subject, depending on the verb 'are applied'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'in' in the phrase 'in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "one",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object, depending on 'founded' with 'one'. Entity 2 ('one') is the subject, depending on 'based' with 'tests'. There is a direct dependency between Entity 1 and Entity 2, as 'linguistic information' is the object of the clause that modifies 'one'.\"",
        "sdp_path_text": "information → on → founded → one",
        "sentence": "One test is founded on linguistic information.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object, depending on 'founded' with 'is'. Entity 2 ('one') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is founded on'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "one",
                "Generic"
            ],
            [
                "hierarchical structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('one') is the subject, depending on 'founded' with 'founded on linguistic information'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'applied' in the phrase 'applied in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the UV procedure.\"",
        "sdp_path_text": "one → applied → in → structure",
        "sentence": "One is applied in a hierarchical structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('one') is the subject, depending on the verb 'applied'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'in' in the phrase 'in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "b -RRB- The UV procedure is based on three different confidence tests , two based on acoustic measures and one founded on linguistic information , applied in a hierarchical structure .",
        "ner_pair": [
            [
                "linguistic information",
                "OtherScientificTerm"
            ],
            [
                "hierarchical structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the object, depending on 'founded' with 'one'. Entity 2 ('hierarchical structure') is the object, depending on 'applied' with 'applied'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "information → on → founded → one → applied → in → structure",
        "sentence": "Linguistic information is used in a hierarchical structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('linguistic information') is the subject, depending on the verb 'used'. Entity 2 ('hierarchical structure') is the object of the preposition 'in', depending on 'in' in the phrase 'in a hierarchical structure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "natural number recognition task",
                "Task"
            ],
            [
                "telephone application",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural number recognition task') is the object of the preposition 'on', depending on 'application'. Entity 2 ('telephone application') is the object of the preposition 'from', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context provided by the experimental setup described in the sentence.\"",
        "sdp_path_text": "task → on → application",
        "sentence": "Experimental results from a telephone application on a natural number recognition task show improvements.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural number recognition task') is the object of the preposition 'on', depending on 'telephone application'. Entity 2 ('telephone application') is the object of the preposition 'from', depending on 'results'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases modifying 'results'.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "telephone application",
                "Task"
            ],
            [
                "recognition errors",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('telephone application') is the object of the preposition 'from', depending on 'results'. Entity 2 ('recognition errors') is the object of the preposition 'in', depending on 'reduction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the outcome of the experimental results.\"",
        "sdp_path_text": "application → from → results → show → reduction → in → errors",
        "sentence": "Experimental results from a telephone application show a reduction in recognition errors.",
        "sentence_llm_dp_info": "\"Entity 1 ('telephone application') is the object of the preposition 'from', depending on 'results'. Entity 2 ('recognition errors') is the object of the preposition 'in', depending on 'reduction'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure describing the source and outcome of the experimental results.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "telephone application",
                "Task"
            ],
            [
                "rejection rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('telephone application') is part of the prepositional phrase 'from a real telephone application', which modifies 'results'. Entity 2 ('rejection rate') is the object of the preposition 'of' in the phrase 'rejection rate of correct utterances', which is part of a list of outcomes. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "application → from → results → show → with → rate",
        "sentence": "Experimental results from the telephone application show a 12% rejection rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('telephone application') is the object of the preposition 'from', depending on 'results'. Entity 2 ('rejection rate') is the object of the verb 'show', depending on 'show' in the phrase 'show a 12% rejection rate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'show' which is part of the main clause describing the experimental results.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "telephone application",
                "Task"
            ],
            [
                "false acceptance",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('telephone application') is the object of the preposition 'from', depending on 'results'. Entity 2 ('false acceptance') is part of a compound noun, depending on 'rate' in the phrase 'rate of false acceptance'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger context of the experimental results being described.\"",
        "sdp_path_text": "application → from → results → show → with → rate → rate → of → acceptance",
        "sentence": "Results from a telephone application show a low rate of false acceptance.",
        "sentence_llm_dp_info": "\"Entity 1 ('telephone application') is the object of the preposition 'from', depending on 'Results'. Entity 2 ('false acceptance') is part of a noun phrase, depending on 'rate' with the prepositional phrase 'of false acceptance'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the sentence structure describing the results.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "recognition errors",
                "Metric"
            ],
            [
                "natural number recognition task",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition errors') is the object of the preposition 'in', depending on 'reduction' in the phrase 'reduction in recognition errors'. Entity 2 ('natural number recognition task') is the object of the preposition 'on', depending on 'application' in the phrase 'application on a natural number recognition task'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the outcomes of the experimental results.\"",
        "sdp_path_text": "errors → in → reduction → show → results → from → application → on → task",
        "sentence": "Experimental results show a reduction in recognition errors for the natural number recognition task.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition errors') is the object of the preposition 'in', depending on 'reduction'. Entity 2 ('natural number recognition task') is the object of the preposition 'for', depending on 'show'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause that describes what the experimental results show.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "natural number recognition task",
                "Task"
            ],
            [
                "rejection rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural number recognition task') is the object of the preposition 'on', depending on 'application'. Entity 2 ('rejection rate') is the subject complement, depending on 'rate' within the noun phrase '12 % rejection rate'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "task → on → application → from → results → show → with → rate",
        "sentence": "Results from a natural number recognition task show a moderate rejection rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural number recognition task') is the object of the preposition 'from', depending on 'Results'. Entity 2 ('rejection rate') is the subject complement, depending on 'show'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the verb 'show' which indicates that the results from the task demonstrate the rejection rate.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "natural number recognition task",
                "Task"
            ],
            [
                "false acceptance",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('natural number recognition task') is the object of the preposition 'on', depending on 'application'. Entity 2 ('false acceptance') is part of a compound noun, where it depends on 'rate' as its modifier. There is no direct dependency between Entity 1 and Entity 2; both are part of the broader context describing the outcomes of the experimental results.\"",
        "sdp_path_text": "task → on → application → from → results → show → with → rate → rate → of → acceptance",
        "sentence": "Results from a natural number recognition task show a low rate of false acceptance.",
        "sentence_llm_dp_info": "\"Entity 1 ('natural number recognition task') is the object of the preposition 'from', depending on 'Results'. Entity 2 ('false acceptance') is the object of the preposition 'of', depending on 'rate'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure that describes the results and their characteristics.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "recognition errors",
                "Metric"
            ],
            [
                "rejection rate",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition errors') is the object, depending on 'reduction' with the verb 'show'. Entity 2 ('rejection rate') is the object of the preposition 'of', depending on 'rate'. There is no direct dependency between Entity 1 and Entity 2; both are part of the list of outcomes shown by the experimental results.\"",
        "sdp_path_text": "errors → in → reduction → show → with → rate",
        "sentence": "Reduction in recognition errors shows with a rejection rate.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition errors') is the object of the preposition 'in', depending on 'Reduction'. Entity 2 ('rejection rate') is the object of the preposition 'with', depending on 'shows'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is shown by the reduction.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "recognition errors",
                "Metric"
            ],
            [
                "false acceptance",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('recognition errors') is the object, depending on the verb 'reduction' with 'show'. Entity 2 ('false acceptance') is the subject, depending on the noun 'rate' with 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the list of outcomes described in the sentence.\"",
        "sdp_path_text": "errors → in → reduction → show → with → rate → rate → of → acceptance",
        "sentence": "Reduction in recognition errors shows a low rate of false acceptance.",
        "sentence_llm_dp_info": "\"Entity 1 ('recognition errors') is the object of the preposition 'in', depending on 'Reduction'. Entity 2 ('false acceptance') is the object of the preposition 'of', depending on 'rate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the outcome of the reduction.\""
    },
    {
        "raw_sentence": "Experimental results from a real telephone application on a natural number recognition task show an 50 % reduction in recognition errors with a moderate 12 % rejection rate of correct utterances and a low 1.5 % rate of false acceptance .",
        "ner_pair": [
            [
                "rejection rate",
                "Metric"
            ],
            [
                "false acceptance",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('rejection rate') is the subject complement, depending on 'show' with 'results'. Entity 2 ('false acceptance') is the subject complement, also depending on 'show' with 'results'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the verb 'show' in the context of the experimental results.\"",
        "sdp_path_text": "rate → rate → of → acceptance",
        "sentence": "The rejection rate and the rate of false acceptance were observed in the experiment.",
        "sentence_llm_dp_info": "\"Entity 1 ('rejection rate') is part of a compound noun, depending on 'and' which connects it to 'rate of false acceptance'. Entity 2 ('false acceptance') is part of a compound noun, depending on 'of' which forms the phrase 'rate of false acceptance'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and' within the larger noun phrase.\""
    },
    {
        "raw_sentence": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials .",
        "ner_pair": [
            [
                "encoding sound",
                "Task"
            ],
            [
                "neuronal processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('encoding sound') is part of a prepositional phrase, depending on 'in' with 'step'. Entity 2 ('neuronal processing') is the object of the preposition 'for', depending on 'for' in the phrase 'for neuronal processing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described by the sentence, where the step involves the process of encoding sound for the purpose of neuronal processing.\"",
        "sdp_path_text": "encoding → for → processing",
        "sentence": "A critical step in encoding sound for neuronal processing occurs.",
        "sentence_llm_dp_info": "\"Entity 1 ('encoding sound') is part of a prepositional phrase, depending on 'in' which modifies the noun 'step'. Entity 2 ('neuronal processing') is the object of the preposition 'for', depending on 'for' in the phrase 'for neuronal processing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger prepositional phrases that modify 'step'.\""
    },
    {
        "raw_sentence": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials .",
        "ner_pair": [
            [
                "encoding sound",
                "Task"
            ],
            [
                "analog pressure wave",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('encoding sound') is part of a prepositional phrase, depending on 'step' with the preposition 'in'. Entity 2 ('analog pressure wave') is the subject complement, depending on 'is' in the clause 'the analog pressure wave is coded'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence.\"",
        "sdp_path_text": "encoding → in → step → occurs → coded → wave",
        "sentence": "A critical step in encoding sound occurs when the analog pressure wave is coded.",
        "sentence_llm_dp_info": "\"Entity 1 ('encoding sound') is part of a prepositional phrase, where 'in' is the preposition linking it to the noun 'step'. Entity 2 ('analog pressure wave') is the subject of the passive clause, depending on the verb 'is coded'. There is no direct dependency between Entity 1 and Entity 2; however, they are both related to the process described in the sentence, with Entity 1 being a step in which the action involving Entity 2 takes place.\""
    },
    {
        "raw_sentence": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials .",
        "ner_pair": [
            [
                "encoding sound",
                "Task"
            ],
            [
                "discrete nerve-action potentials",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('encoding sound') is part of a prepositional phrase, depending on 'step' with the preposition 'in'. Entity 2 ('discrete nerve-action potentials') is the object of the verb 'coded', depending on 'coded' in the clause 'is coded into discrete nerve-action potentials'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the process described in the sentence.\"",
        "sdp_path_text": "encoding → in → step → occurs → coded → into → potentials",
        "sentence": "Encoding sound is coded into discrete nerve-action potentials.",
        "sentence_llm_dp_info": "\"Entity 1 ('encoding sound') is the subject, depending on the verb 'is coded'. Entity 2 ('discrete nerve-action potentials') is the object, depending on 'into' in the phrase 'into discrete nerve-action potentials'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'is coded' and the preposition 'into'.\""
    },
    {
        "raw_sentence": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials .",
        "ner_pair": [
            [
                "neuronal processing",
                "Task"
            ],
            [
                "analog pressure wave",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('neuronal processing') is part of a prepositional phrase, depending on 'in' with 'step'. Entity 2 ('analog pressure wave') is the subject complement, depending on 'is' with 'coded'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described in the sentence.\"",
        "sdp_path_text": "processing → for → encoding → in → step → occurs → coded → wave",
        "sentence": "A critical step in neuronal processing occurs when the analog pressure wave is coded.",
        "sentence_llm_dp_info": "\"Entity 1 ('neuronal processing') is part of a prepositional phrase, depending on 'in' with 'step'. Entity 2 ('analog pressure wave') is the subject complement, depending on 'is' with 'coded'. There is no direct dependency between Entity 1 and Entity 2; however, they are both involved in describing different aspects of the process described in the sentence.\""
    },
    {
        "raw_sentence": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials .",
        "ner_pair": [
            [
                "neuronal processing",
                "Task"
            ],
            [
                "discrete nerve-action potentials",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('neuronal processing') is part of a prepositional phrase, depending on 'for' with 'encoding'. Entity 2 ('discrete nerve-action potentials') is the object of the verb 'coded', depending on 'is coded'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the process described by the sentence, where the coding of the analog pressure wave into Entity 2 is a step in the process leading to Entity 1.\"",
        "sdp_path_text": "processing → for → encoding → in → step → occurs → coded → into → potentials",
        "sentence": "A critical step in neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials.",
        "sentence_llm_dp_info": "\"Entity 1 ('neuronal processing') is part of a prepositional phrase, depending on 'in' with 'step'. Entity 2 ('discrete nerve-action potentials') is the object, depending on 'into' in the phrase 'into discrete nerve-action potentials'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the process described in the sentence.\""
    },
    {
        "raw_sentence": "A critical step in encoding sound for neuronal processing occurs when the analog pressure wave is coded into discrete nerve-action potentials .",
        "ner_pair": [
            [
                "discrete nerve-action potentials",
                "OtherScientificTerm"
            ],
            [
                "analog pressure wave",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('discrete nerve-action potentials') is the object, depending on the verb 'coded'. Entity 2 ('analog pressure wave') is the subject, depending on the verb 'is' in the passive construction 'is coded'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is transformed into Entity 1 through the process described by the verb 'coded'.\"",
        "sdp_path_text": "potentials → into → coded → wave",
        "sentence": "The analog pressure wave is coded into discrete nerve-action potentials.",
        "sentence_llm_dp_info": "\"Entity 1 ('discrete nerve-action potentials') is the object, depending on 'coded' with 'is coded into'. Entity 2 ('analog pressure wave') is the subject, depending on 'is coded' with 'is coded into'. There is a direct dependency between Entity 1 and Entity 2, as 'analog pressure wave' is transformed or coded into 'discrete nerve-action potentials'.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "pool models",
                "Method"
            ],
            [
                "inner hair cell synapse",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject complement, depending on 'are' (implied) with 'Recent'. Entity 2 ('inner hair cell synapse') is the object of the preposition 'of', depending on 'of' in the phrase 'of the inner hair cell synapse'. There is a direct dependency between Entity 1 and Entity 2, where 'inner hair cell synapse' specifies the type of 'pool models' being discussed.\"",
        "sdp_path_text": "models → of → synapse",
        "sentence": "Pool models of the inner hair cell synapse.",
        "sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject, depending on the verb 'models'. Entity 2 ('inner hair cell synapse') is the object, depending on 'models' with 'of'. There is a direct dependency between Entity 1 and Entity 2, as Entity 2 is the object of the preposition 'of' that modifies Entity 1.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "pool models",
                "Method"
            ],
            [
                "visual inspection",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject, depending on the negated verb 'do not reproduce'. Entity 2 ('visual inspection') is part of a compound object, depending on the conjunction 'and' with 'automatic speech recognition'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "models → reproduce → used → inspection",
        "sentence": "Pool models do not reproduce the need for visual inspection.",
        "sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject, depending on the negated verb 'do not reproduce'. Entity 2 ('visual inspection') is the object, depending on the verb 'reproduce'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the negated action described by 'do not reproduce'.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "pool models",
                "Method"
            ],
            [
                "automatic speech recognition -LRB- ASR -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject complement, depending on the negated verb 'do not reproduce' with 'Recent'. Entity 2 ('automatic speech recognition -LRB- ASR -RRB-') is part of a compound object, depending on the conjunction 'and' with 'visual inspection'. There is no direct dependency between Entity 1 and Entity 2; both are part of different clauses within the sentence.\"",
        "sdp_path_text": "models → reproduce → used → inspection → recognition",
        "sentence": "Pool models do not reproduce certain phenomena, leading to the use of automatic speech recognition for investigation.",
        "sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject, depending on the negated verb 'do not reproduce'. Entity 2 ('automatic speech recognition') is part of the object, depending on 'use' in the phrase 'the use of automatic speech recognition'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the cause-and-effect relationship described in the sentence.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "pool models",
                "Method"
            ],
            [
                "offset adaptation -LRB- OA -RRB- model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject, depending on the negation 'do not reproduce' with the object 'the dead time period'. Entity 2 ('offset adaptation -LRB- OA -RRB- model') is the object of the preposition 'to', depending on 'investigate' in the phrase 'to investigate an offset adaptation -LRB- OA -RRB- model'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of the research described in the sentence.\"",
        "sdp_path_text": "models → reproduce → used → investigate → model",
        "sentence": "Pool models do not reproduce certain phenomena, leading to the investigation of the offset adaptation (OA) model.",
        "sentence_llm_dp_info": "\"Entity 1 ('pool models') is the subject, depending on the verb 'do not reproduce'. Entity 2 ('offset adaptation (OA) model') is the object of the preposition 'of', depending on 'investigation'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the clause describing the consequence of the failure of Entity 1 to reproduce certain phenomena, which leads to the investigation of Entity 2.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "inner hair cell synapse",
                "OtherScientificTerm"
            ],
            [
                "visual inspection",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('inner hair cell synapse') is part of the noun phrase 'pool models of the inner hair cell synapse', which is the subject complement, depending on the verb 'do not reproduce'. Entity 2 ('visual inspection') is part of the conjunction 'visual inspection and automatic speech recognition (ASR)', which is the object of the verb 'used'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "synapse → of → models → reproduce → used → inspection",
        "sentence": "Models of the inner hair cell synapse do not reproduce certain phenomena, so visual inspection was used.",
        "sentence_llm_dp_info": "\"Entity 1 ('inner hair cell synapse') is the object of the preposition 'of', depending on 'Models'. Entity 2 ('visual inspection') is the subject, depending on the verb 'was used'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same sentence context, where the failure to reproduce certain phenomena by models of the inner hair cell synapse led to the use of visual inspection.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "inner hair cell synapse",
                "OtherScientificTerm"
            ],
            [
                "automatic speech recognition -LRB- ASR -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('inner hair cell synapse') is part of the noun phrase 'pool models of the inner hair cell synapse', where it acts as the complement of the preposition 'of', depending on 'models'. Entity 2 ('automatic speech recognition -LRB- ASR -RRB-') is in a conjunctive relationship with 'visual inspection', both depending on the verb 'used'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "synapse → of → models → reproduce → used → inspection → recognition",
        "sentence": "Models of the inner hair cell synapse do not reproduce certain periods, leading to the use of automatic speech recognition for investigation.",
        "sentence_llm_dp_info": "\"Entity 1 ('inner hair cell synapse') is the object of the preposition 'of', depending on 'Models'. Entity 2 ('automatic speech recognition') is the object of the preposition 'of', depending on 'use'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same causal chain described in the sentence.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "inner hair cell synapse",
                "OtherScientificTerm"
            ],
            [
                "offset adaptation -LRB- OA -RRB- model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('inner hair cell synapse') is part of a noun phrase acting as the object of the preposition 'of', depending on 'models'. Entity 2 ('offset adaptation -LRB- OA -RRB- model') is the object of the verb 'investigate', depending on 'investigate'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "synapse → of → models → reproduce → used → investigate → model",
        "sentence": "Models of the inner hair cell synapse were used to investigate the offset adaptation (OA) model.",
        "sentence_llm_dp_info": "\"Entity 1 ('inner hair cell synapse') is the object of the preposition 'of', depending on 'Models'. Entity 2 ('offset adaptation (OA) model') is the object of the preposition 'the', depending on 'investigate'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure where models of Entity 1 are used to investigate Entity 2.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "visual inspection",
                "Method"
            ],
            [
                "automatic speech recognition -LRB- ASR -RRB-",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual inspection') is part of a conjunction, depending on 'and' with 'automatic speech recognition -LRB- ASR -RRB-'. Entity 2 ('automatic speech recognition -LRB- ASR -RRB-') is also part of the same conjunction, depending on 'and' with 'visual inspection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the conjunction 'and'.\"",
        "sdp_path_text": "inspection → recognition",
        "sentence": "Visual inspection and automatic speech recognition were used.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual inspection') is the subject, depending on the verb 'were used'. Entity 2 ('automatic speech recognition -LRB- ASR -RRB-') is also a subject, coordinated with 'visual inspection' through the conjunction 'and', and both are depending on the verb 'were used'. There is no direct dependency between Entity 1 and Entity 2, but they are part of a coordinated subject.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "visual inspection",
                "Method"
            ],
            [
                "offset adaptation -LRB- OA -RRB- model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('visual inspection') is part of the compound subject, depending on 'used' with 'we'. Entity 2 ('offset adaptation -LRB- OA -RRB- model') is the object of the preposition 'to', depending on 'investigate' with 'we'. There is no direct dependency between Entity 1 and Entity 2; both are related to the action 'used' and 'investigate' respectively.\"",
        "sdp_path_text": "inspection → used → investigate → model",
        "sentence": "Visual inspection was used to investigate the offset adaptation (OA) model.",
        "sentence_llm_dp_info": "\"Entity 1 ('visual inspection') is the subject, depending on the passive verb 'was used'. Entity 2 ('offset adaptation (OA) model') is the object, depending on the verb 'investigate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'investigate' which indicates the purpose or target of the action performed by Entity 1.\""
    },
    {
        "raw_sentence": "Recent pool models of the inner hair cell synapse do not reproduce the dead time period after an intense stimulus , so we used visual inspection and automatic speech recognition -LRB- ASR -RRB- to investigate an offset adaptation -LRB- OA -RRB- model proposed by Zhang et al. -LSB- 1 -RSB- .",
        "ner_pair": [
            [
                "automatic speech recognition -LRB- ASR -RRB-",
                "Method"
            ],
            [
                "offset adaptation -LRB- OA -RRB- model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatic speech recognition -LRB- ASR -RRB-') is part of a compound object, depending on 'used' with 'we'. Entity 2 ('offset adaptation -LRB- OA -RRB- model') is the object of the preposition 'an', depending on 'investigate' with 'we'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the actions described in the sentence, which are connected through the verb 'used' and the purpose of the investigation.\"",
        "sdp_path_text": "recognition → inspection → used → investigate → model",
        "sentence": "Automatic speech recognition was used to investigate the offset adaptation model.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatic speech recognition -LRB- ASR -RRB-') is the subject, depending on the passive verb 'was used'. Entity 2 ('offset adaptation -LRB- OA -RRB- model') is the object of the preposition 'the', depending on 'investigate' in the phrase 'to investigate the offset adaptation model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'investigate'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "OA",
                "Method"
            ],
            [
                "phase locking in the auditory nerve -LRB- AN -RRB-",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved'. Entity 2 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object, depending on 'improved' with 'OA'. There is a direct dependency between Entity 1 and Entity 2, as 'OA' directly improves 'phase locking in the auditory nerve (AN)'.\"\n\nThis analysis shows that 'OA' (Entity 1) has a direct effect on 'phase locking in the auditory nerve (AN)' (Entity 2) by improving it. The verb 'improved' serves as the link between these two entities, establishing a clear cause-and-effect relationship.",
        "sdp_path_text": "OA → improved → locking",
        "sentence": "OA improved phase locking in the auditory nerve.",
        "sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved'. Entity 2 ('phase locking in the auditory nerve') is the object, depending on 'improved' with 'OA'. There is a direct dependency between Entity 1 and Entity 2, as 'OA' directly affects 'phase locking in the auditory nerve' through the verb 'improved'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "OA",
                "Method"
            ],
            [
                "ASR accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved' and 'raised'. Entity 2 ('ASR accuracy') is the object, depending on 'raised' with 'OA'. There is a direct dependency between Entity 1 and Entity 2, as 'OA' is the agent that raises 'ASR accuracy'.\"",
        "sdp_path_text": "OA → improved → raised → accuracy",
        "sentence": "OA improved and raised ASR accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved' and 'raised'. Entity 2 ('ASR accuracy') is the object, depending on 'raised' with 'OA'. There is a direct dependency between Entity 1 and Entity 2, as 'ASR accuracy' is directly affected by the actions (improved and raised) performed by 'OA'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "OA",
                "Method"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved' and 'raised'. Entity 2 ('features') is the object of the preposition 'for', depending on 'for' in the phrase 'for features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'improved' and 'raised' and the preposition 'for'.\"",
        "sdp_path_text": "OA → improved → raised → for → features",
        "sentence": "OA improved and raised accuracy for features.",
        "sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved' and also on the verb 'raised'. Entity 2 ('features') is the object, depending on the preposition 'for' with 'raised'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbs 'improved' and 'raised' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "OA",
                "Method"
            ],
            [
                "AN fibers -LRB- ANFs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved' and 'raised'. Entity 2 ('AN fibers -LRB- ANFs -RRB-') is the object of the preposition 'from', depending on 'derived'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'improved' and 'raised' which describe the effects of OA on aspects related to AN fibers (ANFs).\"",
        "sdp_path_text": "OA → improved → raised → for → features → derived → from → fibers",
        "sentence": "OA improved phase locking and raised accuracy for features derived from AN fibers.",
        "sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'improved' and 'raised'. Entity 2 ('AN fibers') is the object of the preposition 'from', depending on 'derived'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the actions 'improved' and 'raised' which affect 'features' that are derived from Entity 2.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "phase locking in the auditory nerve -LRB- AN -RRB-",
                "Task"
            ],
            [
                "ASR accuracy",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object of the verb 'improved', depending on 'OA'. Entity 2 ('ASR accuracy') is the object of the verb 'raised', also depending on 'OA'. There is no direct dependency between Entity 1 and Entity 2; both are influenced by the subject 'OA'.\"",
        "sdp_path_text": "locking → improved → raised → accuracy",
        "sentence": "OA improved phase locking in the auditory nerve and raised ASR accuracy.",
        "sentence_llm_dp_info": "\"Entity 1 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object of the preposition 'in', depending on 'improved' with 'OA'. Entity 2 ('ASR accuracy') is the direct object, depending on 'raised' with 'OA'. There is no direct dependency between Entity 1 and Entity 2, but both are affected by the actions described by the verbs 'improved' and 'raised'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "phase locking in the auditory nerve -LRB- AN -RRB-",
                "Task"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object of the verb 'improved', depending on 'OA'. Entity 2 ('features') is the object of the preposition 'from', depending on 'derived'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the auditory nerve context within the sentence.\"",
        "sdp_path_text": "locking → improved → raised → for → features",
        "sentence": "OA improved phase locking in the auditory nerve and raised accuracy for features derived from AN fibers.",
        "sentence_llm_dp_info": "\"Entity 1 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object of the preposition 'in', depending on 'improved' with 'OA'. Entity 2 ('features') is the object of the preposition 'for', depending on 'raised' with 'OA'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the actions performed by 'OA'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "phase locking in the auditory nerve -LRB- AN -RRB-",
                "Task"
            ],
            [
                "AN fibers -LRB- ANFs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object of the verb 'improved', depending on 'OA'. Entity 2 ('AN fibers -LRB- ANFs -RRB-') is the object of the preposition 'from', depending on 'features'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of improvements made by OA.\"",
        "sdp_path_text": "locking → improved → raised → for → features → derived → from → fibers",
        "sentence": "OA improved phase locking in the auditory nerve and raised accuracy for features derived from AN fibers.",
        "sentence_llm_dp_info": "\"Entity 1 ('phase locking in the auditory nerve -LRB- AN -RRB-') is the object of the preposition 'in', depending on 'improved' with 'OA'. Entity 2 ('AN fibers -LRB- ANFs -RRB-') is the object of the preposition 'from', depending on 'derived' with 'features'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the effects of 'OA' and the derivation of 'features'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "ASR accuracy",
                "Metric"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASR accuracy') is the object, depending on 'raised' with 'OA'. Entity 2 ('features') is the subject, depending on 'derived' with 'from'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'raised' and the prepositional phrase 'for features derived from AN fibers'.\"",
        "sdp_path_text": "accuracy → raised → for → features",
        "sentence": "ASR accuracy was raised for features.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASR accuracy') is the subject, depending on the verb 'was raised'. Entity 2 ('features') is the object of the preposition 'for', depending on 'for' in the phrase 'for features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "ASR accuracy",
                "Metric"
            ],
            [
                "AN fibers -LRB- ANFs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ASR accuracy') is the object, depending on 'raised' with 'OA'. Entity 2 ('AN fibers -LRB- ANFs -RRB-') is the object of the preposition 'from', depending on 'derived'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'raised' and the prepositional phrase 'for features derived from AN fibers -LRB- ANFs -RRB-.'\"",
        "sdp_path_text": "accuracy → raised → for → features → derived → from → fibers",
        "sentence": "ASR accuracy was raised for features derived from AN fibers.",
        "sentence_llm_dp_info": "\"Entity 1 ('ASR accuracy') is the subject, depending on the verb 'was raised'. Entity 2 ('AN fibers') is the object of the preposition 'from', depending on 'derived'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'raised' and the prepositional phrase 'for features derived from AN fibers'.\""
    },
    {
        "raw_sentence": "OA improved phase locking in the auditory nerve -LRB- AN -RRB- and raised ASR accuracy for features derived from AN fibers -LRB- ANFs -RRB- .",
        "ner_pair": [
            [
                "AN fibers -LRB- ANFs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('AN fibers -LRB- ANFs -RRB-') is the object of the preposition 'from', depending on 'derived'. Entity 2 ('features') is the subject, depending on 'derived' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'derived'.\"",
        "sdp_path_text": "fibers → from → derived → features",
        "sentence": "Features are derived from AN fibers.",
        "sentence_llm_dp_info": "\"Entity 1 ('AN fibers -LRB- ANFs -RRB-') is the object of the preposition 'from', depending on 'derived'. Entity 2 ('features') is the subject, depending on the verb 'are' in the phrase 'Features are derived'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'derived'.\""
    },
    {
        "raw_sentence": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage , the auditory brainstem .",
        "ner_pair": [
            [
                "OA",
                "Method"
            ],
            [
                "auditory processing",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject complement, depending on 'is' with 'that'. Entity 2 ('auditory processing') is the object, depending on 'for' in the phrase 'for auditory processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' indicating that OA is crucial for the auditory processing.\"",
        "sdp_path_text": "OA → is → crucial → for → processing",
        "sentence": "OA is crucial for auditory processing.",
        "sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'is'. Entity 2 ('auditory processing') is the object of the preposition 'for', depending on 'for' in the phrase 'for auditory processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage , the auditory brainstem .",
        "ner_pair": [
            [
                "onset neurons -LRB- ONs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "OA",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('onset neurons -LRB- ONs -RRB-') is the subject complement, depending on the preposition 'by' which modifies 'processing'. Entity 2 ('OA') is the subject of the clause, depending on the copula 'is' which links it to the predicate 'crucial'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the structure of the sentence where 'OA' is described as being crucial for 'auditory processing' which is performed 'by onset neurons -LRB- ONs -RRB-'.\"",
        "sdp_path_text": "neurons → by → processing → for → crucial → is → OA",
        "sentence": "OA is crucial for auditory processing by onset neurons (ONs).",
        "sentence_llm_dp_info": "\"Entity 1 ('onset neurons (ONs)') is the object, depending on the preposition 'by', which itself depends on 'processing'. Entity 2 ('OA') is the subject, depending on the copula 'is' and the adjective 'crucial'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause structure where 'OA' is described as being crucial for 'auditory processing', and 'onset neurons (ONs)' are part of the prepositional phrase modifying 'processing'.\""
    },
    {
        "raw_sentence": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage , the auditory brainstem .",
        "ner_pair": [
            [
                "OA",
                "Method"
            ],
            [
                "auditory brainstem",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject complement, depending on 'is' with 'crucial'. Entity 2 ('auditory brainstem') is the object of the preposition 'in', depending on 'in' in the phrase 'in the next neuronal stage, the auditory brainstem'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, where 'OA' is described as crucial for a process involving 'ONs' in the 'auditory brainstem'.\"",
        "sdp_path_text": "OA → is → crucial → for → processing → in → stage → brainstem",
        "sentence": "OA is crucial for auditory processing in the auditory brainstem.",
        "sentence_llm_dp_info": "\"Entity 1 ('OA') is the subject, depending on the verb 'is'. Entity 2 ('auditory brainstem') is the object of the preposition 'in', depending on 'in' in the phrase 'in the auditory brainstem'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the prepositional phrase that specifies the location where OA is crucial.\""
    },
    {
        "raw_sentence": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage , the auditory brainstem .",
        "ner_pair": [
            [
                "auditory processing",
                "Task"
            ],
            [
                "onset neurons -LRB- ONs -RRB-",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('auditory processing') is the object of the preposition 'for', depending on the verb 'is' in the clause 'OA is crucial for auditory processing'. Entity 2 ('onset neurons -LRB- ONs -RRB-') is the subject of the prepositional phrase 'by onset neurons -LRB- ONs -RRB-', which modifies 'auditory processing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' which indicates the agent or means by which the auditory processing occurs.\"",
        "sdp_path_text": "processing → by → neurons",
        "sentence": "Auditory processing occurs by onset neurons (ONs).",
        "sentence_llm_dp_info": "\"Entity 1 ('auditory processing') is the subject, depending on the verb 'occurs'. Entity 2 ('onset neurons -LRB- ONs -RRB-') is the subject complement, depending on 'by' in the phrase 'by onset neurons (ONs)'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'by' which indicates that the onset neurons are the means or agent by which auditory processing occurs.\""
    },
    {
        "raw_sentence": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage , the auditory brainstem .",
        "ner_pair": [
            [
                "auditory processing",
                "Task"
            ],
            [
                "auditory brainstem",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('auditory processing') is the object of the preposition 'for', depending on 'is' in the clause 'OA is crucial for auditory processing'. Entity 2 ('auditory brainstem') is the appositive, depending on 'stage' in the phrase 'the next neuronal stage, the auditory brainstem'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause describing the importance of OA in a specific neuronal context.\"",
        "sdp_path_text": "processing → in → stage → brainstem",
        "sentence": "Auditory processing occurs in the auditory brainstem.",
        "sentence_llm_dp_info": "\"Entity 1 ('auditory processing') is the subject, depending on the verb 'occurs'. Entity 2 ('auditory brainstem') is the object of the preposition 'in', depending on 'in' in the phrase 'in the auditory brainstem'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "We also found that OA is crucial for auditory processing by onset neurons -LRB- ONs -RRB- in the next neuronal stage , the auditory brainstem .",
        "ner_pair": [
            [
                "onset neurons -LRB- ONs -RRB-",
                "OtherScientificTerm"
            ],
            [
                "auditory brainstem",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('onset neurons -LRB- ONs -RRB-') is the object of the preposition 'by', depending on 'processing'. Entity 2 ('auditory brainstem') is the object of the preposition 'in', depending on 'stage'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of 'auditory processing' and the 'neuronal stage'.\"",
        "sdp_path_text": "neurons → by → processing → in → stage → brainstem",
        "sentence": "Onset neurons process in the auditory brainstem.",
        "sentence_llm_dp_info": "\"Entity 1 ('onset neurons -LRB- ONs -RRB-') is the subject, depending on the verb 'process'. Entity 2 ('auditory brainstem') is the location, depending on the preposition 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates the location where the processing occurs.\""
    },
    {
        "raw_sentence": "Multi-layer perceptrons -LRB- MLPs -RRB- performed much better than standard Gaussian mixture models -LRB- GMMs -RRB- for both our ANF-based and ON-based auditory features .",
        "ner_pair": [
            [
                "Multi-layer perceptrons -LRB- MLPs -RRB-",
                "Method"
            ],
            [
                "Gaussian mixture models -LRB- GMMs -RRB-",
                "Method"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-layer perceptrons -LRB- MLPs -RRB-') is the subject, depending on the verb 'performed'. Entity 2 ('Gaussian mixture models -LRB- GMMs -RRB-') is the complement of the comparison, depending on 'than' in the comparative clause 'better than standard Gaussian mixture models -LRB- GMMs -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are compared in terms of performance.\"",
        "sdp_path_text": "perceptrons → performed → better → than → models",
        "sentence": "Multi-layer perceptrons performed better than Gaussian mixture models.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-layer perceptrons -LRB- MLPs -RRB-') is the subject, depending on the verb 'performed'. Entity 2 ('Gaussian mixture models -LRB- GMMs -RRB-') is the complement of the preposition 'than', depending on 'than' in the phrase 'than Gaussian mixture models -LRB- GMMs -RRB-'. There is no direct dependency between Entity 1 and Entity 2, but they are compared through the verb 'performed' and the preposition 'than'.\""
    },
    {
        "raw_sentence": "Multi-layer perceptrons -LRB- MLPs -RRB- performed much better than standard Gaussian mixture models -LRB- GMMs -RRB- for both our ANF-based and ON-based auditory features .",
        "ner_pair": [
            [
                "Multi-layer perceptrons -LRB- MLPs -RRB-",
                "Method"
            ],
            [
                "ANF-based and ON-based auditory features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-layer perceptrons -LRB- MLPs -RRB-') is the subject, depending on the verb 'performed'. Entity 2 ('ANF-based and ON-based auditory features') is the object of the preposition 'for', depending on 'for' in the phrase 'for both our ANF-based and ON-based auditory features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "perceptrons → performed → for → features",
        "sentence": "Multi-layer perceptrons performed better for ANF-based and ON-based auditory features.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-layer perceptrons (MLPs)') is the subject, depending on the verb 'performed'. Entity 2 ('ANF-based and ON-based auditory features') is the object of the preposition 'for', depending on 'for' in the phrase 'for ANF-based and ON-based auditory features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Multi-layer perceptrons -LRB- MLPs -RRB- performed much better than standard Gaussian mixture models -LRB- GMMs -RRB- for both our ANF-based and ON-based auditory features .",
        "ner_pair": [
            [
                "Gaussian mixture models -LRB- GMMs -RRB-",
                "Method"
            ],
            [
                "ANF-based and ON-based auditory features",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Gaussian mixture models -LRB- GMMs -RRB-') is the object of the comparative clause, depending on 'performed' with the comparative adverb 'better'. Entity 2 ('ANF-based and ON-based auditory features') is the object of the preposition 'for', depending on 'for' in the phrase 'for both our ANF-based and ON-based auditory features'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same comparative context where the performance of different models is evaluated for specific features.\"",
        "sdp_path_text": "models → than → better → performed → for → features",
        "sentence": "Gaussian mixture models performed less well for ANF-based and ON-based auditory features compared to multi-layer perceptrons.",
        "sentence_llm_dp_info": "\"Entity 1 ('Gaussian mixture models (GMMs)') is the subject, depending on the verb 'performed'. Entity 2 ('ANF-based and ON-based auditory features') is the object of the preposition 'for', depending on 'for' in the phrase 'for ANF-based and ON-based auditory features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Thus we believe researchers working with novel features should consider trying MLPs .",
        "ner_pair": [
            [
                "features",
                "OtherScientificTerm"
            ],
            [
                "MLPs",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('features') is the object of the preposition 'with', depending on 'working' in the phrase 'working with novel features'. Entity 2 ('MLPs') is the object of the verb 'consider', depending on 'consider' in the phrase 'consider trying MLPs'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "features → with → working → researchers → consider → trying → MLPs",
        "sentence": "Researchers working with novel features should consider trying MLPs.",
        "sentence_llm_dp_info": "\"Entity 1 ('features') is the object of the preposition 'with', depending on 'working' in the phrase 'working with novel features'. Entity 2 ('MLPs') is the object of the verb 'consider', depending on 'consider' in the phrase 'consider trying MLPs'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets .",
        "ner_pair": [
            [
                "high-capacity models",
                "Method"
            ],
            [
                "computer vision",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high-capacity models') is the subject, depending on the verb 'driven'. Entity 2 ('computer vision') is the object of the preposition 'in', depending on 'progress'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context provided by the sentence where 'high-capacity models' contribute to the progress in 'computer vision'.\"",
        "sdp_path_text": "models → by → driven → progress → in → vision",
        "sentence": "High-capacity models have driven progress in computer vision.",
        "sentence_llm_dp_info": "\"Entity 1 ('high-capacity models') is the subject, depending on the verb 'driven'. Entity 2 ('computer vision') is the object of the preposition 'in', depending on 'progress'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'driven' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets .",
        "ner_pair": [
            [
                "computer vision",
                "Task"
            ],
            [
                "large datasets",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computer vision') is the object of the preposition 'in', depending on 'progress'. Entity 2 ('large datasets') is the object of the preposition 'on', depending on 'trained'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what has driven recent progress.\"",
        "sdp_path_text": "vision → in → progress → driven → by → models → trained → on → datasets",
        "sentence": "Recent progress in computer vision has been driven by models trained on large datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('computer vision') is the object of the preposition 'in', depending on 'progress'. Entity 2 ('large datasets') is the object of the preposition 'on', depending on 'trained'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the context in which progress has been made.\""
    },
    {
        "raw_sentence": "Recent progress in computer vision has been driven by high-capacity models trained on large datasets .",
        "ner_pair": [
            [
                "large datasets",
                "Material"
            ],
            [
                "high-capacity models",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('large datasets') is the object, depending on the preposition 'on', which is part of the prepositional phrase 'on large datasets'. Entity 2 ('high-capacity models') is the subject, depending on the passive verb 'been driven' with 'progress'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what has driven recent progress in computer vision.\"",
        "sdp_path_text": "datasets → on → trained → models",
        "sentence": "High-capacity models have been trained on large datasets.",
        "sentence_llm_dp_info": "\"Entity 1 ('large datasets') is the object, depending on the preposition 'on', which modifies the verb 'trained'. Entity 2 ('high-capacity models') is the subject, depending on the verb 'have been trained'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'have been trained' and the preposition 'on'.\""
    },
    {
        "raw_sentence": "Unfortunately , creating large datasets with pixel-level labels has been extremely costly due to the amount of human effort required .",
        "ner_pair": [
            [
                "pixel-level labels",
                "OtherScientificTerm"
            ],
            [
                "large datasets",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pixel-level labels') is the object of the preposition 'with', depending on 'creating'. Entity 2 ('large datasets') is the object, depending on 'creating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the object complement of the verb 'creating'.\"",
        "sdp_path_text": "labels → with → datasets",
        "sentence": "Creating large datasets with pixel-level labels has been costly.",
        "sentence_llm_dp_info": "\"Entity 1 ('pixel-level labels') is the object of the preposition 'with', depending on 'with' in the phrase 'with pixel-level labels'. Entity 2 ('large datasets') is the object of the verb 'Creating', depending on 'Creating' in the phrase 'Creating large datasets'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'large datasets' is modified by the prepositional phrase 'with pixel-level labels'.\""
    },
    {
        "raw_sentence": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "pixel-accurate semantic label maps",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on 'present' with 'we'. Entity 2 ('pixel-accurate semantic label maps') is the object, depending on 'creating' with 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'creating'.\"",
        "sdp_path_text": "approach → to → creating → maps",
        "sentence": "An approach to creating pixel-accurate semantic label maps is presented.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'presented'. Entity 2 ('pixel-accurate semantic label maps') is the object of the preposition 'to', depending on 'creating' in the phrase 'to creating pixel-accurate semantic label maps'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'creating'.\""
    },
    {
        "raw_sentence": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on 'present' with 'we'. Entity 2 ('images') is the object of the preposition 'from', depending on 'extracted'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for images extracted from modern computer games'.\"",
        "sdp_path_text": "approach → to → creating → maps → for → images",
        "sentence": "The approach is for creating maps for images.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('images') is the object of the preposition 'for', depending on the preposition 'for' in the phrase 'for images'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrases 'for creating maps' and 'for images'.\""
    },
    {
        "raw_sentence": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "modern computer games",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'present'. Entity 2 ('modern computer games') is the object of the preposition 'from', depending on 'from' in the phrase 'from modern computer games'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for images extracted from modern computer games'.\"",
        "sdp_path_text": "approach → to → creating → maps → for → images → extracted → from → games",
        "sentence": "An approach is presented for creating accurate semantic label maps for images from modern computer games.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'presented'. Entity 2 ('modern computer games') is the object of the preposition 'from', depending on 'images'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for images from modern computer games'.\""
    },
    {
        "raw_sentence": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
        "ner_pair": [
            [
                "pixel-accurate semantic label maps",
                "OtherScientificTerm"
            ],
            [
                "images",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pixel-accurate semantic label maps') is the object of the verb 'creating', depending on the verb 'creating' within the phrase 'creating pixel-accurate semantic label maps'. Entity 2 ('images') is the object of the preposition 'from', depending on 'extracted' in the phrase 'images extracted from modern computer games'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the purpose of the approach presented in the paper.\"",
        "sdp_path_text": "maps → for → images",
        "sentence": "We present an approach to creating pixel-accurate semantic label maps for images.",
        "sentence_llm_dp_info": "\"Entity 1 ('pixel-accurate semantic label maps') is the object, depending on the verb 'creating'. Entity 2 ('images') is the object of the preposition 'for', depending on 'for' in the phrase 'for images'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'for' which indicates that the label maps are created for the images.\""
    },
    {
        "raw_sentence": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
        "ner_pair": [
            [
                "pixel-accurate semantic label maps",
                "OtherScientificTerm"
            ],
            [
                "modern computer games",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('pixel-accurate semantic label maps') is the object, depending on the verb 'creating' which is part of the infinitive phrase 'to rapidly creating'. Entity 2 ('modern computer games') is the object of the preposition 'from', depending on 'extracted'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of the sentence, where the creation of Entity 1 involves images that are extracted from Entity 2.\"",
        "sdp_path_text": "maps → for → images → extracted → from → games",
        "sentence": "Pixel-accurate semantic label maps are created for images from modern computer games.",
        "sentence_llm_dp_info": "\"Entity 1 ('pixel-accurate semantic label maps') is the subject, depending on the verb 'are created'. Entity 2 ('modern computer games') is the object of the preposition 'from', depending on 'from' in the phrase 'from modern computer games'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "In this paper , we present an approach to rapidly creating pixel-accurate semantic label maps for images extracted from modern computer games .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "modern computer games",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is the object of the preposition 'from', depending on 'extracted'. Entity 2 ('modern computer games') is the object of the preposition 'from', also depending on 'extracted'. There is no direct dependency between Entity 1 and Entity 2; both are related to the verb 'extracted' through the preposition 'from'.\"",
        "sdp_path_text": "images → extracted → from → games",
        "sentence": "Images are extracted from modern computer games.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the subject, depending on the verb 'are extracted'. Entity 2 ('modern computer games') is the object of the preposition 'from', depending on 'from' in the phrase 'from modern computer games'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining '' hints '' of partial scene segmentation offered by multiple soft , binary mattes .",
        "ner_pair": [
            [
                "partial scene segmentation",
                "Task"
            ],
            [
                "unsupervised seg-mentation of whole objects",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('partial scene segmentation') is the object of the preposition 'of', depending on 'hints'. Entity 2 ('unsupervised seg-mentation of whole objects') is the object of the preposition 'toward', depending on 'step'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the novel step proposed in the sentence.\"",
        "sdp_path_text": "segmentation → of → hints → combining → by → step → toward → seg",
        "sentence": "We propose a step toward unsupervised segmentation of whole objects by combining hints of partial scene segmentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('partial scene segmentation') is the object of the preposition 'of', depending on 'hints'. Entity 2 ('unsupervised segmentation of whole objects') is the object of the preposition 'toward', depending on 'step'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the goal and method of the proposed step.\""
    },
    {
        "raw_sentence": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining '' hints '' of partial scene segmentation offered by multiple soft , binary mattes .",
        "ner_pair": [
            [
                "unsupervised seg-mentation of whole objects",
                "Task"
            ],
            [
                "soft , binary mattes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unsupervised seg-mentation of whole objects') is the object of the preposition 'toward', depending on 'step'. Entity 2 ('soft, binary mattes') is the object of the preposition 'by', depending on 'combining'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger structure where 'unsupervised seg-mentation of whole objects' is the goal being approached, and 'soft, binary mattes' are tools or methods used in the process.\"",
        "sdp_path_text": "seg → toward → step → by → combining → hints → of → segmentation → offered → by → mattes",
        "sentence": "Unsupervised segmentation of whole objects combines hints of segmentation offered by soft, binary mattes.",
        "sentence_llm_dp_info": "\"Entity 1 ('unsupervised segmentation of whole objects') is the subject, depending on the verb 'combines'. Entity 2 ('soft, binary mattes') is the object, depending on the preposition 'by' in the phrase 'by soft, binary mattes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combines' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "We propose a novel step toward the unsupervised seg-mentation of whole objects by combining '' hints '' of partial scene segmentation offered by multiple soft , binary mattes .",
        "ner_pair": [
            [
                "soft , binary mattes",
                "OtherScientificTerm"
            ],
            [
                "partial scene segmentation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('soft, binary mattes') is the object of the preposition 'by', depending on the verb 'combining'. Entity 2 ('partial scene segmentation') is the object of the preposition 'of', depending on the noun 'hints'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the method used to achieve the unsupervised segmentation of whole objects.\"",
        "sdp_path_text": "mattes → by → offered → segmentation",
        "sentence": "Soft, binary mattes offer partial scene segmentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('soft, binary mattes') is the subject, depending on the verb 'offer'. Entity 2 ('partial scene segmentation') is the object, depending on 'offer' with 'soft, binary mattes'. There is a direct dependency between Entity 1 and Entity 2, as 'soft, binary mattes' directly offers 'partial scene segmentation'.\""
    },
    {
        "raw_sentence": "These mattes are implied by a set of hypothesized object boundary fragments in the scene .",
        "ner_pair": [
            [
                "hypothesized object boundary fragments",
                "OtherScientificTerm"
            ],
            [
                "mattes",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('hypothesized object boundary fragments') is the subject of the prepositional phrase 'by a set of hypothesized object boundary fragments', depending on 'implied'. Entity 2 ('mattes') is the subject, depending on the verb 'are'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'implied' and the preposition 'by'.\"",
        "sdp_path_text": "fragments → of → set → by → implied → mattes",
        "sentence": "Hypothesized object boundary fragments imply mattes.",
        "sentence_llm_dp_info": "\"Entity 1 ('hypothesized object boundary fragments') is the subject, depending on the verb 'imply'. Entity 2 ('mattes') is the direct object, depending on 'imply' from 'hypothesized object boundary fragments'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 implies Entity 2.\""
    },
    {
        "raw_sentence": "This reflects contemporary methods for unsupervised object discovery from groups of images , and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects .",
        "ner_pair": [
            [
                "contemporary methods",
                "Generic"
            ],
            [
                "unsupervised object discovery",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('contemporary methods') is the subject complement, depending on the verb 'reflects' with 'This'. Entity 2 ('unsupervised object discovery') is the object of the preposition 'for', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates that Entity 2 is a purpose or target of Entity 1.\"",
        "sdp_path_text": "methods → for → discovery",
        "sentence": "Contemporary methods are used for unsupervised object discovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('contemporary methods') is the subject, depending on the verb 'are used'. Entity 2 ('unsupervised object discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for unsupervised object discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This reflects contemporary methods for unsupervised object discovery from groups of images , and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects .",
        "ner_pair": [
            [
                "contemporary methods",
                "Generic"
            ],
            [
                "delineation of scene objects",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('contemporary methods') is the object of the preposition 'for', depending on 'reflects' in the clause 'This reflects contemporary methods'. Entity 2 ('delineation of scene objects') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the accurate and parsimonious delineation of scene objects'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the broader context of the sentence, which discusses methods and metrics in image processing.\"",
        "sdp_path_text": "methods → reflects → allows → define → for → sets → based → on → delineation",
        "sentence": "Contemporary methods allow defining sets based on the delineation of scene objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('contemporary methods') is the subject, depending on the verb 'allow'. Entity 2 ('delineation of scene objects') is the object of the preposition 'on', depending on 'defining' in the phrase 'based on the delineation of scene objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'allow' and the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "This reflects contemporary methods for unsupervised object discovery from groups of images , and it allows us to define intuitive evaluation met-rics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects .",
        "ner_pair": [
            [
                "unsupervised object discovery",
                "Task"
            ],
            [
                "delineation of scene objects",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('unsupervised object discovery') is the object of the preposition 'for', depending on 'methods'. Entity 2 ('delineation of scene objects') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the broader context of methods and metrics described in the sentence.\"",
        "sdp_path_text": "discovery → for → methods → reflects → allows → define → for → sets → based → on → delineation",
        "sentence": "Unsupervised object discovery allows defining sets based on the delineation of scene objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('unsupervised object discovery') is the subject, depending on the verb 'allows'. Entity 2 ('delineation of scene objects') is the object of the preposition 'on', depending on 'based' in the phrase 'based on the delineation of scene objects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allows' and the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "Our proposed approach builds on recent advances in spectral clustering , image matting , and boundary detection .",
        "ner_pair": [
            [
                "spectral clustering",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spectral clustering') is part of a list of advancements, depending on the preposition 'in' within the phrase 'in spectral clustering'. Entity 2 ('approach') is the subject, depending on the verb 'builds' in the phrase 'approach builds'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that lists the areas where the approach builds upon recent advances.\"",
        "sdp_path_text": "clustering → in → advances → on → builds → approach",
        "sentence": "Our approach builds on advances in spectral clustering.",
        "sentence_llm_dp_info": "\"Entity 1 ('spectral clustering') is the object of the preposition 'in', depending on 'advances'. Entity 2 ('approach') is the subject, depending on the verb 'builds'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on advances in spectral clustering'.\""
    },
    {
        "raw_sentence": "Our proposed approach builds on recent advances in spectral clustering , image matting , and boundary detection .",
        "ner_pair": [
            [
                "image matting",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image matting') is the object of the preposition 'in', depending on 'advances'. Entity 2 ('approach') is the subject, depending on the verb 'builds'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on recent advances in spectral clustering, image matting, and boundary detection'.\"",
        "sdp_path_text": "matting → clustering → in → advances → on → builds → approach",
        "sentence": "The approach builds on advances in image matting.",
        "sentence_llm_dp_info": "\"Entity 1 ('image matting') is the object of the preposition 'in', depending on 'advances'. Entity 2 ('approach') is the subject, depending on the verb 'builds'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'on advances in image matting'.\""
    },
    {
        "raw_sentence": "Our proposed approach builds on recent advances in spectral clustering , image matting , and boundary detection .",
        "ner_pair": [
            [
                "boundary detection",
                "Method"
            ],
            [
                "approach",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('boundary detection') is part of a list, depending on the preposition 'in' within the phrase 'in spectral clustering, image matting, and boundary detection'. Entity 2 ('approach') is the subject, depending on the verb 'builds' in the phrase 'approach builds'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "detection → matting → clustering → in → advances → on → builds → approach",
        "sentence": "The approach builds on advances in boundary detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('boundary detection') is the object of the preposition 'in', depending on 'advances'. Entity 2 ('approach') is the subject, depending on the verb 'builds'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'builds' and the prepositional phrase 'on advances in boundary detection'.\""
    },
    {
        "raw_sentence": "Our proposed approach builds on recent advances in spectral clustering , image matting , and boundary detection .",
        "ner_pair": [
            [
                "spectral clustering",
                "Method"
            ],
            [
                "image matting",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spectral clustering') is part of a list, depending on the preposition 'in' within the phrase 'in spectral clustering'. Entity 2 ('image matting') is also part of the same list, depending on the conjunction 'and' which connects it to the previous item in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list that follows the preposition 'in'.\"",
        "sdp_path_text": "clustering → matting",
        "sentence": "Our approach builds on advances in spectral clustering and image matting.",
        "sentence_llm_dp_info": "\"Entity 1 ('spectral clustering') is part of a conjunction, depending on 'and' with 'image matting'. Entity 2 ('image matting') is also part of the same conjunction, depending on 'and' with 'spectral clustering'. Both entities are objects of the preposition 'in', which modifies 'advances'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "Our proposed approach builds on recent advances in spectral clustering , image matting , and boundary detection .",
        "ner_pair": [
            [
                "spectral clustering",
                "Method"
            ],
            [
                "boundary detection",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spectral clustering') is part of a list, depending on the preposition 'in' which is part of the phrase 'in spectral clustering'. Entity 2 ('boundary detection') is also part of a list, depending on the conjunction 'and' which links it with other elements in the list. There is no direct dependency between Entity 1 and Entity 2; both are elements of the list introduced by the preposition 'in'.\"",
        "sdp_path_text": "clustering → matting → detection",
        "sentence": "Our approach builds on advances in spectral clustering and boundary detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('spectral clustering') is part of the object complement, depending on 'in' within the prepositional phrase 'in spectral clustering'. Entity 2 ('boundary detection') is also part of the object complement, depending on 'and' which connects it to 'spectral clustering'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same prepositional phrase, indicating that the approach builds on advances in both areas.\""
    },
    {
        "raw_sentence": "Our proposed approach builds on recent advances in spectral clustering , image matting , and boundary detection .",
        "ner_pair": [
            [
                "image matting",
                "Method"
            ],
            [
                "boundary detection",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('image matting') is part of a conjunction, depending on 'and' with 'boundary detection'. Entity 2 ('boundary detection') is also part of a conjunction, depending on 'and' with 'image matting'. There is no direct dependency between Entity 1 and Entity 2; both are elements in a list that serves as the object of the preposition 'in'.\"",
        "sdp_path_text": "matting → detection",
        "sentence": "Our approach builds on advances in image matting and boundary detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('image matting') is part of the compound object, depending on the preposition 'in'. Entity 2 ('boundary detection') is also part of the compound object, depending on the conjunction 'and' which links it to 'image matting'. There is no direct dependency between Entity 1 and Entity 2, but they are both objects of the preposition 'in' and are linked through the conjunction 'and'.\""
    },
    {
        "raw_sentence": "It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge .",
        "ner_pair": [
            [
                "dataset of scenes",
                "Material"
            ],
            [
                "It",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dataset of scenes') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('It') is the subject, depending on the verb 'is' in the clause 'It is demonstrated'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'demonstrated' where 'It' is the subject being demonstrated and 'dataset of scenes' is the object on which the demonstration is performed.\"",
        "sdp_path_text": "dataset → on → demonstrated → It",
        "sentence": "It is demonstrated on a dataset of scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('dataset of scenes') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('It') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrated'.\""
    },
    {
        "raw_sentence": "It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge .",
        "ner_pair": [
            [
                "It",
                "Generic"
            ],
            [
                "unsupervised object discovery",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'is demonstrated'. Entity 2 ('unsupervised object discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for current work in unsupervised object discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'is demonstrated' and the prepositional phrase 'for current work in unsupervised object discovery'.\"",
        "sdp_path_text": "It → demonstrated → is → suitable → for → work → in → discovery",
        "sentence": "It is demonstrated to be suitable for unsupervised object discovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('It') is the subject, depending on the verb 'demonstrated'. Entity 2 ('unsupervised object discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for unsupervised object discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'demonstrated' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge .",
        "ner_pair": [
            [
                "dataset of scenes",
                "Material"
            ],
            [
                "unsupervised object discovery",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('dataset of scenes') is the object of the preposition 'on', depending on 'demonstrated'. Entity 2 ('unsupervised object discovery') is part of a prepositional phrase, depending on 'suitable' with 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence.\"",
        "sdp_path_text": "dataset → on → demonstrated → is → suitable → for → work → in → discovery",
        "sentence": "The dataset of scenes is suitable for unsupervised object discovery.",
        "sentence_llm_dp_info": "\"Entity 1 ('dataset of scenes') is the subject, depending on the verb 'is'. Entity 2 ('unsupervised object discovery') is the object of the preposition 'for', depending on 'for' in the phrase 'for unsupervised object discovery'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates the purpose or suitability of the dataset.\""
    },
    {
        "raw_sentence": "Language resource quality is crucial in NLP .",
        "ner_pair": [
            [
                "Language resource quality",
                "Metric"
            ],
            [
                "NLP",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Language resource quality') is the subject, depending on the verb 'is'. Entity 2 ('NLP') is the object of the preposition 'in', depending on 'in' in the phrase 'in NLP'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\"",
        "sdp_path_text": "quality → is → in → NLP",
        "sentence": "Language resource quality is crucial in NLP.",
        "sentence_llm_dp_info": "\"Entity 1 ('Language resource quality') is the subject, depending on the verb 'is'. Entity 2 ('NLP') is the object of the preposition 'in', depending on 'in' in the phrase 'in NLP'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Many of the resources used are derived from data created by human beings out of an NLP context , especially regarding MT and reference translations .",
        "ner_pair": [
            [
                "MT",
                "Task"
            ],
            [
                "NLP",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT') is part of a coordination, depending on 'regarding' with 'especially'. Entity 2 ('NLP') is the modifier, depending on 'context' with 'an NLP context'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the clause describing the context and focus areas of the resources mentioned.\"",
        "sdp_path_text": "MT → translations → regarding → data → created → out → of → context → NLP",
        "sentence": "MT and reference translations are derived from data created out of an NLP context.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT') is part of a compound noun, depending on 'and' which connects it with 'reference translations'. Both together are the subject, depending on the verb 'are derived'. Entity 2 ('NLP') is the modifier, depending on 'context' with the preposition 'out of' in the phrase 'out of an NLP context'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Many of the resources used are derived from data created by human beings out of an NLP context , especially regarding MT and reference translations .",
        "ner_pair": [
            [
                "reference translations",
                "Task"
            ],
            [
                "NLP",
                "Task"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reference translations') is the object, depending on 'regarding' with 'especially'. Entity 2 ('NLP') is the modifier, depending on 'context' with 'an NLP context'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the prepositional phrase 'out of an NLP context'.\"",
        "sdp_path_text": "translations → regarding → data → created → out → of → context → NLP",
        "sentence": "Reference translations are derived from data created out of an NLP context.",
        "sentence_llm_dp_info": "\"Entity 1 ('reference translations') is the subject, depending on the verb 'are derived'. Entity 2 ('NLP') is part of the noun phrase 'an NLP context', acting as a modifier to 'context'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'from data created out of an NLP context'.\""
    },
    {
        "raw_sentence": "Many of the resources used are derived from data created by human beings out of an NLP context , especially regarding MT and reference translations .",
        "ner_pair": [
            [
                "MT",
                "Task"
            ],
            [
                "reference translations",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('MT') is part of a coordination, depending on 'regarding' with 'especially'. Entity 2 ('reference translations') is also part of the same coordination, depending on 'and' with 'MT'. There is no direct dependency between Entity 1 and Entity 2, but they are coordinated together in the list introduced by 'especially regarding'.\"",
        "sdp_path_text": "MT → translations",
        "sentence": "Resources include MT and reference translations.",
        "sentence_llm_dp_info": "\"Entity 1 ('MT') is the object of the preposition 'include', depending on 'include' in the phrase 'include MT'. Entity 2 ('reference translations') is also an object of the preposition 'include', depending on 'include' in the phrase 'include reference translations'. There is no direct dependency between Entity 1 and Entity 2; both are listed as objects included in the resources.\""
    },
    {
        "raw_sentence": "Indeed , automatic evaluations need high-quality data that allow the comparison of both automatic and human translations .",
        "ner_pair": [
            [
                "high-quality data",
                "Material"
            ],
            [
                "automatic evaluations",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('high-quality data') is the object, depending on 'need' with 'automatic evaluations'. Entity 2 ('automatic evaluations') is the subject, depending on 'need'. There is a direct dependency between Entity 1 and Entity 2, where 'high-quality data' is required by 'automatic evaluations'.\"",
        "sdp_path_text": "data → need → evaluations",
        "sentence": "High-quality data are needed for automatic evaluations.",
        "sentence_llm_dp_info": "\"Entity 1 ('high-quality data') is the subject, depending on the verb 'are needed'. Entity 2 ('automatic evaluations') is the object of the preposition 'for', depending on 'for' in the phrase 'for automatic evaluations'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper describes the impact of using different-quality references on evaluation .",
        "ner_pair": [
            [
                "different-quality references",
                "OtherScientificTerm"
            ],
            [
                "evaluation",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('different-quality references') is the object of the preposition 'of', depending on 'impact'. Entity 2 ('evaluation') is the object of the preposition 'on', depending on 'impact'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the impact described in the sentence.\"",
        "sdp_path_text": "references → using → of → impact → on → evaluation",
        "sentence": "Using different-quality references impacts evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('different-quality references') is the subject, depending on the verb 'impacts'. Entity 2 ('evaluation') is the object, depending on the verb 'impacts'. There is a direct dependency between Entity 1 and Entity 2, where Entity 1 impacts Entity 2.\""
    },
    {
        "raw_sentence": "Thus , the limitations of the automatic metrics used within MT are also discussed in this regard .",
        "ner_pair": [
            [
                "automatic metrics",
                "Metric"
            ],
            [
                "MT",
                "Task"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('automatic metrics') is the object of the preposition 'of', depending on 'limitations'. Entity 2 ('MT') is the object of the preposition 'within', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and related through the verb 'discussed'.\"",
        "sdp_path_text": "metrics → used → within → MT",
        "sentence": "The limitations of automatic metrics used within MT are discussed.",
        "sentence_llm_dp_info": "\"Entity 1 ('automatic metrics') is the object of the preposition 'of', depending on 'limitations'. Entity 2 ('MT') is the object of the preposition 'within', depending on 'used'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being discussed.\""
    },
    {
        "raw_sentence": "This poster paper describes a full scale two-level morphological description -LRB- Karttunen , 1983 ; Koskenniemi , 1983 -RRB- of Turkish word structures .",
        "ner_pair": [
            [
                "full scale two-level morphological description",
                "Task"
            ],
            [
                "Turkish word structures",
                "Material"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('full scale two-level morphological description') is the object, depending on 'describes' with 'This poster paper'. Entity 2 ('Turkish word structures') is the object of the preposition 'of', depending on 'of' in the phrase 'of Turkish word structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'of'.\"",
        "sdp_path_text": "description → of → structures",
        "sentence": "A full scale two-level morphological description of Turkish word structures is described.",
        "sentence_llm_dp_info": "\"Entity 1 ('full scale two-level morphological description') is the subject, depending on the verb 'described'. Entity 2 ('Turkish word structures') is the object of the preposition 'of', depending on 'of' in the phrase 'of Turkish word structures'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'.\""
    },
    {
        "raw_sentence": "The description has been implemented using the PC-KIMMO environment -LRB- Antworth , 1990 -RRB- and is based on a root word lexicon of about 23,000 roots words .",
        "ner_pair": [
            [
                "PC-KIMMO environment",
                "Method"
            ],
            [
                "description",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PC-KIMMO environment') is the object of the preposition 'using', depending on 'implemented'. Entity 2 ('description') is the subject, depending on the verb 'has been implemented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has been implemented' and the preposition 'using'.\"",
        "sdp_path_text": "environment → using → implemented → description",
        "sentence": "The description has been implemented using the PC-KIMMO environment.",
        "sentence_llm_dp_info": "\"Entity 1 ('PC-KIMMO environment') is the object of the preposition 'using', depending on 'implemented'. Entity 2 ('description') is the subject, depending on the verb 'has been implemented'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has been implemented' and the preposition 'using'.\""
    },
    {
        "raw_sentence": "The description has been implemented using the PC-KIMMO environment -LRB- Antworth , 1990 -RRB- and is based on a root word lexicon of about 23,000 roots words .",
        "ner_pair": [
            [
                "root word lexicon",
                "Material"
            ],
            [
                "description",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('root word lexicon') is the object of the preposition 'on', depending on 'based' in the phrase 'based on a root word lexicon'. Entity 2 ('description') is the subject, depending on 'is' in the phrase 'The description is'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on'.\"",
        "sdp_path_text": "lexicon → on → based → implemented → description",
        "sentence": "The description is based on a root word lexicon.",
        "sentence_llm_dp_info": "\"Entity 1 ('root word lexicon') is the object, depending on the preposition 'on', which is part of the prepositional phrase 'on a root word lexicon'. Entity 2 ('description') is the subject, depending on the verb 'is' in the clause 'The description is based on a root word lexicon'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on'.\""
    },
    {
        "raw_sentence": "The description has been implemented using the PC-KIMMO environment -LRB- Antworth , 1990 -RRB- and is based on a root word lexicon of about 23,000 roots words .",
        "ner_pair": [
            [
                "PC-KIMMO environment",
                "Method"
            ],
            [
                "root word lexicon",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PC-KIMMO environment') is the object of the preposition 'using', depending on 'implemented'. Entity 2 ('root word lexicon') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "environment → using → implemented → based → on → lexicon",
        "sentence": "The implementation using the PC-KIMMO environment is based on a root word lexicon.",
        "sentence_llm_dp_info": "\"Entity 1 ('PC-KIMMO environment') is the object of the preposition 'using', depending on 'implementation'. Entity 2 ('root word lexicon') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause through different prepositional phrases.\""
    },
    {
        "raw_sentence": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .",
        "ner_pair": [
            [
                "Turkish",
                "Material"
            ],
            [
                "agglutinative language",
                "Material"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the copula 'is'. Entity 2 ('agglutinative language') is the predicate nominative, also depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'Turkish' is described as being an 'agglutinative language'.\"",
        "sdp_path_text": "Turkish → is → language",
        "sentence": "Turkish is an agglutinative language.",
        "sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the copula 'is'. Entity 2 ('agglutinative language') is the predicate nominal, depending on the copula 'is'. There is a direct dependency between Entity 1 and Entity 2, as they are linked by the copula 'is'.\""
    },
    {
        "raw_sentence": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .",
        "ner_pair": [
            [
                "Turkish",
                "Material"
            ],
            [
                "word structures",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the verb 'is'. Entity 2 ('word structures') is the object of the preposition 'with', depending on 'with' in the phrase 'with word structures'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'is' and the prepositional phrase 'with word structures'.\"",
        "sdp_path_text": "Turkish → is → language → with → structures",
        "sentence": "Turkish is a language with word structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the copula 'is'. Entity 2 ('word structures') is the object of the preposition 'with', depending on 'with' in the phrase 'with word structures'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with word structures'.\""
    },
    {
        "raw_sentence": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .",
        "ner_pair": [
            [
                "Turkish",
                "Material"
            ],
            [
                "productive affixations of derivational and inflectional suffixes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the verb 'is'. Entity 2 ('productive affixations of derivational and inflectional suffixes') is the object of the preposition 'by', depending on 'formed' in the phrase 'formed by productive affixations of derivational and inflectional suffixes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verbal phrase 'is...formed by...'.\"",
        "sdp_path_text": "Turkish → is → language → with → structures → formed → by → affixations",
        "sentence": "Turkish is a language with structures formed by productive affixations of derivational and inflectional suffixes.",
        "sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the verb 'is'. Entity 2 ('productive affixations of derivational and inflectional suffixes') is part of the noun phrase that modifies 'structures', which is the object of the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the prepositional phrase 'with structures formed by productive affixations of derivational and inflectional suffixes'.\""
    },
    {
        "raw_sentence": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .",
        "ner_pair": [
            [
                "word structures",
                "OtherScientificTerm"
            ],
            [
                "agglutinative language",
                "Material"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('word structures') is the object of the verb 'formed', depending on 'formed' with 'are'. Entity 2 ('agglutinative language') is the subject, depending on the verb 'is' with 'Turkish'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the descriptive clause about how word structures are formed in the agglutinative language.\"",
        "sdp_path_text": "structures → with → language",
        "sentence": "Word structures are formed with an agglutinative language.",
        "sentence_llm_dp_info": "\"Entity 1 ('word structures') is the subject, depending on the verb 'formed'. Entity 2 ('agglutinative language') is the object of the preposition 'with', depending on 'with' in the phrase 'with an agglutinative language'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .",
        "ner_pair": [
            [
                "agglutinative language",
                "Material"
            ],
            [
                "productive affixations of derivational and inflectional suffixes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('agglutinative language') is the complement of the copula 'is', depending on 'Turkish'. Entity 2 ('productive affixations of derivational and inflectional suffixes') is the subject of the relative clause, depending on 'formed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where Entity 2 describes how word structures in Entity 1 are formed.\"",
        "sdp_path_text": "language → with → structures → formed → by → affixations",
        "sentence": "Turkish, an agglutinative language, has word structures formed by productive affixations of derivational and inflectional suffixes.",
        "sentence_llm_dp_info": "\"Entity 1 ('agglutinative language') is the complement, depending on the copula 'is' with 'Turkish'. Entity 2 ('productive affixations of derivational and inflectional suffixes') is the object of the preposition 'by', depending on 'formed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has' and the preposition 'by'.\""
    },
    {
        "raw_sentence": "Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .",
        "ner_pair": [
            [
                "productive affixations of derivational and inflectional suffixes",
                "OtherScientificTerm"
            ],
            [
                "word structures",
                "OtherScientificTerm"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('productive affixations of derivational and inflectional suffixes') is the object of the preposition 'by', depending on 'formed'. Entity 2 ('word structures') is the subject complement, depending on 'formed' with 'are'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'formed'.\"",
        "sdp_path_text": "affixations → by → formed → structures",
        "sentence": "Productive affixations of derivational and inflectional suffixes form word structures.",
        "sentence_llm_dp_info": "\"Entity 1 ('productive affixations of derivational and inflectional suffixes') is the subject, depending on the verb 'form'. Entity 2 ('word structures') is the object, depending on the verb 'form'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 forms Entity 2.\""
    },
    {
        "raw_sentence": "Turkish has finite-state but nevertheless rather complex morphotactics .",
        "ner_pair": [
            [
                "Turkish",
                "Material"
            ],
            [
                "finite-state",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the verb 'has'. Entity 2 ('finite-state') is part of a compound noun, depending on 'has' via the preposition 'has finite-state'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has'.\" \n\nTo refine this a bit more accurately:\n\n\"Entity 1 ('Turkish') is the subject, depending on the verb 'has'. Entity 2 ('finite-state') is the complement of the preposition 'has', forming part of the predicate. There is a direct dependency between Entity 1 and Entity 2, as 'finite-state' is a property that 'Turkish' has.\"",
        "sdp_path_text": "Turkish → has → morphotactics → state",
        "sentence": "Turkish has finite-state morphotactics.",
        "sentence_llm_dp_info": "\"Entity 1 ('Turkish') is the subject, depending on the verb 'has'. Entity 2 ('finite-state') is part of a compound noun, depending on 'morphotactics' to form 'finite-state morphotactics'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has' and the compound noun structure.\""
    },
    {
        "raw_sentence": "Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa , or can create adverbial constructs .",
        "ner_pair": [
            [
                "Morphemes",
                "OtherScientificTerm"
            ],
            [
                "verbal structure",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Morphemes') is the subject, depending on the verb 'added'. Entity 2 ('verbal structure') is part of a compound noun, depending on 'convert' as part of the phrase 'convert the word from a nominal to a verbal structure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'convert'.\"",
        "sdp_path_text": "Morphemes → convert → to → structure",
        "sentence": "Morphemes can convert a word to a verbal structure.",
        "sentence_llm_dp_info": "\"Entity 1 ('Morphemes') is the subject, depending on the verb 'can convert'. Entity 2 ('verbal structure') is the object, depending on the verb 'convert' with 'a word'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'convert'.\""
    },
    {
        "raw_sentence": "Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa , or can create adverbial constructs .",
        "ner_pair": [
            [
                "Morphemes",
                "OtherScientificTerm"
            ],
            [
                "adverbial constructs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Morphemes') is the subject, depending on the verb 'added'. Entity 2 ('adverbial constructs') is the object of the verb 'create', depending on 'create' in the clause 'can create adverbial constructs'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'Morphemes' can lead to the creation of 'adverbial constructs'.\"",
        "sdp_path_text": "Morphemes → convert → create → constructs",
        "sentence": "Morphemes can create adverbial constructs.",
        "sentence_llm_dp_info": "\"Entity 1 ('Morphemes') is the subject, depending on the verb 'create'. Entity 2 ('adverbial constructs') is the object, depending on 'create' with 'Morphemes'. There is a direct dependency between Entity 1 and Entity 2, where 'Morphemes' is the creator of 'adverbial constructs'.\""
    },
    {
        "raw_sentence": "Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa , or can create adverbial constructs .",
        "ner_pair": [
            [
                "verbal structure",
                "OtherScientificTerm"
            ],
            [
                "adverbial constructs",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('verbal structure') is the object of the preposition 'to', depending on 'convert' in the phrase 'convert the word from a nominal to a verbal structure'. Entity 2 ('adverbial constructs') is the object, depending on 'create' in the phrase 'can create adverbial constructs'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "structure → to → convert → create → constructs",
        "sentence": "Morphemes can convert a word to a verbal structure or create adverbial constructs.",
        "sentence_llm_dp_info": "\"Entity 1 ('verbal structure') is the object of the preposition 'to', depending on 'convert' with 'a word'. Entity 2 ('adverbial constructs') is the object, depending on 'create' with 'Morphemes'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "The surface realizations of morphological constructions are constrained and modified by a number of phonetic rules such as vowel harmony .",
        "ner_pair": [
            [
                "phonetic rules",
                "OtherScientificTerm"
            ],
            [
                "surface realizations of morphological constructions",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('phonetic rules') is the object of the preposition 'by', depending on 'constrained and modified'. Entity 2 ('surface realizations of morphological constructions') is the subject, depending on 'are' in the verb phrase 'are constrained and modified'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'are constrained and modified'.\"",
        "sdp_path_text": "rules → of → number → by → modified → constrained → realizations",
        "sentence": "Surface realizations of morphological constructions are constrained and modified by phonetic rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('phonetic rules') is the subject, depending on 'are' with 'constrained and modified'. Entity 2 ('surface realizations of morphological constructions') is the subject, depending on 'are' with 'constrained and modified'. There is no direct dependency between Entity 1 and Entity 2, but both are subjects of the same clause and are related through the verbs 'constrained and modified'.\""
    },
    {
        "raw_sentence": "The surface realizations of morphological constructions are constrained and modified by a number of phonetic rules such as vowel harmony .",
        "ner_pair": [
            [
                "surface realizations of morphological constructions",
                "Task"
            ],
            [
                "vowel harmony",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('surface realizations of morphological constructions') is the subject, depending on the verb 'are constrained and modified'. Entity 2 ('vowel harmony') is the complement of the preposition 'such as', which modifies 'a number of phonetic rules'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause that describes how Entity 1 is influenced by phonetic rules, one of which is Entity 2.\"",
        "sdp_path_text": "realizations → constrained → modified → by → number → of → rules → as → harmony",
        "sentence": "Surface realizations of morphological constructions are constrained and modified by vowel harmony.",
        "sentence_llm_dp_info": "\"Entity 1 ('surface realizations of morphological constructions') is the subject, depending on the verb 'are'. Entity 2 ('vowel harmony') is the subject complement, depending on 'modified'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause where Entity 1 is affected by the actions 'constrained' and 'modified' which are influenced by Entity 2.\""
    },
    {
        "raw_sentence": "The surface realizations of morphological constructions are constrained and modified by a number of phonetic rules such as vowel harmony .",
        "ner_pair": [
            [
                "vowel harmony",
                "OtherScientificTerm"
            ],
            [
                "phonetic rules",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('vowel harmony') is the complement, depending on 'such as' which modifies 'phonetic rules'. Entity 2 ('phonetic rules') is the object of the preposition 'by', depending on 'modified'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'such as vowel harmony'.\"",
        "sdp_path_text": "harmony → as → rules",
        "sentence": "Vowel harmony is one of the phonetic rules.",
        "sentence_llm_dp_info": "\"Entity 1 ('vowel harmony') is the subject, depending on the verb 'is'. Entity 2 ('phonetic rules') is the complement, depending on the verb 'is' as well. There is a direct dependency between Entity 1 and Entity 2, as 'vowel harmony' is described as being 'one of the phonetic rules'.\""
    },
    {
        "raw_sentence": "This paper deals with the problem of generating the fundamental frequency -LRB- F0 -RRB- contour of speech from a text input for text-to-speech synthesis .",
        "ner_pair": [
            [
                "text input",
                "Material"
            ],
            [
                "fundamental frequency -LRB- F0 -RRB- contour of speech",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text input') is the object of the preposition 'from', depending on the verb 'generating'. Entity 2 ('fundamental frequency -LRB- F0 -RRB- contour of speech') is the object, depending on 'generating' with 'the problem of generating'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing what is being generated.\"",
        "sdp_path_text": "input → from → generating → contour",
        "sentence": "Text input is used for generating the fundamental frequency (F0) contour of speech.",
        "sentence_llm_dp_info": "\"Entity 1 ('text input') is the subject, depending on the verb 'used'. Entity 2 ('fundamental frequency (F0) contour of speech') is the object, depending on the verb 'generating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'generating' which indicates that the 'text input' is used in the process of generating the 'fundamental frequency (F0) contour of speech'.\""
    },
    {
        "raw_sentence": "This paper deals with the problem of generating the fundamental frequency -LRB- F0 -RRB- contour of speech from a text input for text-to-speech synthesis .",
        "ner_pair": [
            [
                "fundamental frequency -LRB- F0 -RRB- contour of speech",
                "OtherScientificTerm"
            ],
            [
                "text-to-speech synthesis",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('fundamental frequency -LRB- F0 -RRB- contour of speech') is the object of the preposition 'of', depending on 'generating'. Entity 2 ('text-to-speech synthesis') is the object of the preposition 'for', depending on 'generating'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described by the verb 'generating'.\"",
        "sdp_path_text": "contour → generating → from → input → for → synthesis",
        "sentence": "The fundamental frequency (F0) contour of speech is generated from text input for text-to-speech synthesis.",
        "sentence_llm_dp_info": "\"Entity 1 ('fundamental frequency (F0) contour of speech') is the subject, depending on the verb 'is generated'. Entity 2 ('text-to-speech synthesis') is the object of the preposition 'for', depending on 'for' in the phrase 'for text-to-speech synthesis'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper deals with the problem of generating the fundamental frequency -LRB- F0 -RRB- contour of speech from a text input for text-to-speech synthesis .",
        "ner_pair": [
            [
                "text input",
                "Material"
            ],
            [
                "text-to-speech synthesis",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text input') is the object of the preposition 'from', depending on 'generating'. Entity 2 ('text-to-speech synthesis') is the object of the preposition 'for', depending on 'generating'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process of 'generating'.\"",
        "sdp_path_text": "input → for → synthesis",
        "sentence": "Text input is used for text-to-speech synthesis.",
        "sentence_llm_dp_info": "\"Entity 1 ('text input') is the subject, depending on the verb 'used'. Entity 2 ('text-to-speech synthesis') is the object of the preposition 'for', depending on 'for' in the phrase 'for text-to-speech synthesis'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We have previously introduced a statistical model describing the generating process of speech F0 contours , based on the discrete-time version of the Fujisaki model .",
        "ner_pair": [
            [
                "statistical model",
                "Method"
            ],
            [
                "speech F0 contours",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the object, depending on 'introduced' with 'We'. Entity 2 ('speech F0 contours') is the object of the preposition 'of', depending on 'process' in the phrase 'generating process of speech F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'describing the generating process of speech F0 contours'.\"",
        "sdp_path_text": "model → describing → process → of → contours",
        "sentence": "A statistical model describes the generating process of speech F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical model') is the subject, depending on the verb 'describes'. Entity 2 ('speech F0 contours') is the object, depending on 'process' with the preposition 'of' in the phrase 'of speech F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'describes' and the prepositional phrase 'of speech F0 contours'.\""
    },
    {
        "raw_sentence": "We have previously introduced a statistical model describing the generating process of speech F0 contours , based on the discrete-time version of the Fujisaki model .",
        "ner_pair": [
            [
                "Fujisaki model",
                "Method"
            ],
            [
                "statistical model",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Fujisaki model') is the object of the preposition 'of', depending on 'version'. Entity 2 ('statistical model') is the object, depending on 'introduced' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'based on the discrete-time version of the Fujisaki model'.\"",
        "sdp_path_text": "model → of → version → on → based → model",
        "sentence": "The statistical model is based on the discrete-time version of the Fujisaki model.",
        "sentence_llm_dp_info": "\"Entity 1 ('Fujisaki model') is the object of the preposition 'of', depending on 'version'. Entity 2 ('statistical model') is the subject, depending on the verb 'is'. There is a direct dependency between Entity 1 and Entity 2, as 'Fujisaki model' is part of the description that defines the basis of the 'statistical model'.\""
    },
    {
        "raw_sentence": "We have previously introduced a statistical model describing the generating process of speech F0 contours , based on the discrete-time version of the Fujisaki model .",
        "ner_pair": [
            [
                "speech F0 contours",
                "OtherScientificTerm"
            ],
            [
                "Fujisaki model",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('speech F0 contours') is the object of the verb 'describing', depending on 'model'. Entity 2 ('Fujisaki model') is the object of the preposition 'of', depending on 'version'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing aspects of the 'statistical model'.\"",
        "sdp_path_text": "contours → of → process → describing → model → based → on → version → of → model",
        "sentence": "A statistical model describes the generating process of speech F0 contours, based on the discrete-time version of the Fujisaki model.",
        "sentence_llm_dp_info": "\"Entity 1 ('speech F0 contours') is the object of the verb 'describes', depending on 'model'. Entity 2 ('Fujisaki model') is the object of the preposition 'of', depending on 'version'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the function and basis of the statistical model.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "remarkable feature",
                "OtherScientificTerm"
            ],
            [
                "model",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on the verb 'is' and modified by 'One'. Entity 2 ('model') is the object of the preposition 'of', depending on 'feature'. There is a direct dependency between Entity 1 and Entity 2, where 'model' modifies 'feature' through the preposition 'of'.\"",
        "sdp_path_text": "feature → of → model",
        "sentence": "{\n  \"Simplified sentence\": \"A remarkable feature of the model is its ability to derive an efficient algorithm.\"\n} \n\nHowever, to strictly adhere to the SDP and focus only on the relationship between \"remarkable feature\" and \"model,\" a more precise simplification would be:\n\n{\n  \"Simplified sentence\": \"A remarkable feature of the model.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on the preposition 'of' with 'model'. Entity 2 ('model') is the object of the preposition 'of', depending on 'of' in the phrase 'of the model'. There is a direct dependency between Entity 1 and Entity 2 through the preposition 'of'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "remarkable feature",
                "OtherScientificTerm"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on the copula 'is' with 'feature'. Entity 2 ('it') is the subject, depending on the verb 'has allowed'. There is no direct dependency between Entity 1 and Entity 2; however, they are part of the same clause where 'it' refers back to 'this model', which is the topic being described by the 'remarkable feature'.\"",
        "sdp_path_text": "feature → is → allowed → it",
        "sentence": "A remarkable feature is that it has allowed us to derive an efficient algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject, depending on the verb 'is'. Entity 2 ('it') is the subject of the clause 'it has allowed us to derive an efficient algorithm', depending on 'has allowed'. There is no direct dependency between Entity 1 and Entity 2, but they are both subjects in different clauses of the same sentence.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "remarkable feature",
                "OtherScientificTerm"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on 'is' with 'feature'. Entity 2 ('algorithm') is the object, depending on 'derive' with 'us'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where the feature is described as allowing the derivation of the algorithm.\"",
        "sdp_path_text": "feature → is → allowed → derive → algorithm",
        "sentence": "A remarkable feature of the model has allowed deriving an efficient algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject, depending on the verb 'has allowed'. Entity 2 ('algorithm') is the object of the verb 'deriving', depending on 'deriving' in the phrase 'deriving an efficient algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verbs 'has allowed' and 'deriving'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "remarkable feature",
                "OtherScientificTerm"
            ],
            [
                "statistical methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on the verb 'is' with 'feature'. Entity 2 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on powerful statistical methods'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the structure of the sentence.\"",
        "sdp_path_text": "feature → is → allowed → derive → algorithm → based → on → methods",
        "sentence": "A remarkable feature of the model is that it allows deriving an algorithm based on statistical methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on 'is' with 'feature'. Entity 2 ('statistical methods') is the object, depending on 'based' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing attributes of 'the model'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "remarkable feature",
                "OtherScientificTerm"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on the copula 'is' with 'feature'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'for', depending on 'estimating' in the phrase 'for estimating the Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the capabilities of the model.\"",
        "sdp_path_text": "feature → is → allowed → derive → algorithm → based → on → methods → for → estimating → parameters",
        "sentence": "A remarkable feature of the model is that it allows deriving an algorithm for estimating Fujisaki-model parameters.",
        "sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject, depending on the verb 'is'. Entity 2 ('Fujisaki-model parameters') is the object, depending on 'estimating' in the phrase 'for estimating Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the clause describing what the feature enables.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "remarkable feature",
                "OtherScientificTerm"
            ],
            [
                "raw F0 contours",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on 'is' with 'feature'. Entity 2 ('raw F0 contours') is the object of the preposition 'from', depending on 'estimating' in the phrase 'for estimating the Fujisaki-model parameters from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same sentence structure, connected through the verb 'allowed' and the subsequent clause describing what has been enabled.\"",
        "sdp_path_text": "feature → is → allowed → derive → algorithm → based → on → methods → for → estimating → from → contours",
        "sentence": "A remarkable feature of the model is that it allows deriving an algorithm for estimating parameters from raw F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('remarkable feature') is the subject complement, depending on the copula 'is' with 'feature'. Entity 2 ('raw F0 contours') is the object, depending on 'from' with 'estimating parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing different aspects of the model's capabilities.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'of', depending on 'feature'. Entity 2 ('it') is the subject, depending on 'has allowed' with 'allowed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context where 'it' refers back to the 'model'.\"",
        "sdp_path_text": "model → of → feature → is → allowed → it",
        "sentence": "{\n  \"Simplified sentence\": \"The model has allowed us to derive an efficient algorithm.\"\n} \n\nHowever, this simplification might not fully capture the essence of the relationship between \"model\" and \"it\" as intended by the SDP. A more accurate representation would be:\n\n{\n  \"Simplified sentence\": \"The model's feature is that it has allowed us to derive an efficient algorithm.\"\n}",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the possessive form 'model's' which modifies 'feature'. Entity 2 ('it') is the subject, depending on the verb 'has allowed'. There is a direct dependency between Entity 1 and Entity 2, as 'it' refers back to 'model', establishing a coreference link.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'of', depending on 'feature'. Entity 2 ('algorithm') is the object, depending on 'derive'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'derive' and the prepositional phrase 'based on powerful statistical methods'.\"",
        "sdp_path_text": "model → of → feature → is → allowed → derive → algorithm",
        "sentence": "This model has allowed deriving an efficient algorithm.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'has allowed'. Entity 2 ('algorithm') is the object, depending on 'deriving' with 'an efficient'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'has allowed' and the action of 'deriving'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "statistical methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the possessive 'this' and is part of the noun phrase 'this model'. It also depends on the verb 'allowed' in the clause 'it has allowed us'. Entity 2 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on powerful statistical methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'allowed' and the prepositional phrase 'based on powerful statistical methods'.\"",
        "sdp_path_text": "model → of → feature → is → allowed → derive → algorithm → based → on → methods",
        "sentence": "The model has allowed the derivation of an algorithm based on statistical methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'has allowed'. Entity 2 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on statistical methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the sequence of dependencies involving 'has allowed' and 'based on'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "raw F0 contours",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on 'feature' with 'One remarkable feature of this model'. Entity 2 ('raw F0 contours') is the object, depending on 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'estimating' which is part of the clause describing what the model enables.\"",
        "sdp_path_text": "model → of → feature → is → allowed → derive → algorithm → based → on → methods → for → estimating → from → contours",
        "sentence": "The model allows deriving an algorithm for estimating parameters from raw F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the subject, depending on the verb 'allows'. Entity 2 ('raw F0 contours') is the object of the preposition 'from', depending on 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'deriving' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "statistical methods",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has allowed'. Entity 2 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on powerful statistical methods'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' refers to the model that allows the derivation of an algorithm based on 'statistical methods'.\"",
        "sdp_path_text": "it → allowed → derive → algorithm → based → on → methods",
        "sentence": "It has allowed deriving an algorithm based on statistical methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'allowed'. Entity 2 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on statistical methods'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has allowed'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'for', depending on 'estimating' in the phrase 'for estimating the Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has allowed' and the purpose clause 'for estimating the Fujisaki-model parameters'.\"",
        "sdp_path_text": "it → allowed → derive → algorithm → based → on → methods → for → estimating → parameters",
        "sentence": "It has allowed deriving an algorithm for estimating Fujisaki-model parameters.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has allowed'. Entity 2 ('Fujisaki-model parameters') is the object, depending on 'estimating' in the phrase 'for estimating Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'has allowed' and the purpose clause 'for estimating Fujisaki-model parameters'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "raw F0 contours",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has allowed'. Entity 2 ('raw F0 contours') is the object, depending on the preposition 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'derive' and the preposition 'from'.\"",
        "sdp_path_text": "it → allowed → derive → algorithm → based → on → methods → for → estimating → from → contours",
        "sentence": "It has allowed deriving an algorithm for estimating from raw F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'has allowed'. Entity 2 ('raw F0 contours') is the object of the preposition 'from', depending on 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "statistical methods",
                "Method"
            ],
            [
                "algorithm",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on powerful statistical methods'. Entity 2 ('algorithm') is the object of the verb 'derive', depending on 'derive' in the clause 'to derive an efficient algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'derive' and the prepositional phrase 'based on'.\"",
        "sdp_path_text": "methods → on → based → algorithm",
        "sentence": "The algorithm is based on powerful statistical methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical methods') is the object, depending on the preposition 'on', which modifies 'based'. Entity 2 ('algorithm') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object, depending on 'derive' with 'us'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'for', depending on 'estimating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'estimating' and the preposition 'for'.\"",
        "sdp_path_text": "algorithm → based → on → methods → for → estimating → parameters",
        "sentence": "An efficient algorithm based on powerful statistical methods is used for estimating Fujisaki-model parameters.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'used'. Entity 2 ('Fujisaki-model parameters') is the object, depending on the verb 'estimating'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause 'for estimating Fujisaki-model parameters'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "algorithm",
                "Generic"
            ],
            [
                "raw F0 contours",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the object of the verb 'derive', depending on 'derive' with 'us'. Entity 2 ('raw F0 contours') is the object of the preposition 'from', depending on 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'derive' and the preposition 'from'.\"",
        "sdp_path_text": "algorithm → based → on → methods → for → estimating → from → contours",
        "sentence": "An efficient algorithm based on powerful statistical methods estimates parameters from raw F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('algorithm') is the subject, depending on the verb 'estimates'. Entity 2 ('raw F0 contours') is the object, depending on 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'estimates' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "statistical methods",
                "Method"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical methods') is the modifier, depending on 'based' with 'algorithm'. Entity 2 ('Fujisaki-model parameters') is the object, depending on 'estimating' with 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the process described by the verb 'estimating'.\"",
        "sdp_path_text": "methods → for → estimating → parameters",
        "sentence": "Statistical methods are used for estimating Fujisaki-model parameters.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical methods') is the subject, depending on the verb 'are used'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'for', depending on 'estimating' in the phrase 'for estimating Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'estimating' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "statistical methods",
                "Method"
            ],
            [
                "raw F0 contours",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical methods') is the object of the preposition 'on', depending on 'based' in the phrase 'based on powerful statistical methods'. Entity 2 ('raw F0 contours') is the object of the preposition 'from', depending on 'estimating' in the phrase 'for estimating the Fujisaki-model parameters from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "methods → for → estimating → from → contours",
        "sentence": "Statistical methods are used for estimating parameters from raw F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical methods') is the subject, depending on the verb 'are used'. Entity 2 ('raw F0 contours') is the object of the preposition 'from', depending on 'from' in the phrase 'from raw F0 contours'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'are used' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "One remarkable feature of this model is that it has allowed us to derive an efficient algorithm based on powerful statistical methods for estimating the Fujisaki-model parameters from raw F0 contours .",
        "ner_pair": [
            [
                "raw F0 contours",
                "OtherScientificTerm"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('raw F0 contours') is the object, depending on 'from' which modifies the verb 'estimating'. Entity 2 ('Fujisaki-model parameters') is the object of the gerund 'estimating', depending on 'estimating' in the phrase 'estimating the Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'estimating' and the preposition 'from'.\"",
        "sdp_path_text": "contours → from → estimating → parameters",
        "sentence": "An efficient algorithm estimates Fujisaki-model parameters from raw F0 contours.",
        "sentence_llm_dp_info": "\"Entity 1 ('raw F0 contours') is the object, depending on the preposition 'from', which itself depends on the verb 'estimates'. Entity 2 ('Fujisaki-model parameters') is the direct object, depending on the verb 'estimates'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the action described by the verb 'estimates'.\""
    },
    {
        "raw_sentence": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning , this paper proposes extending this model to a context-dependent one .",
        "ner_pair": [
            [
                "text input",
                "Material"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text input') is the object of the preposition 'with', depending on 'associate'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'of', part of the phrase 'a sequence of the Fujisaki-model parameters', which itself depends on 'associate'. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the action described by the verb 'associate'.\"",
        "sdp_path_text": "input → with → associate → sequence → of → parameters",
        "sentence": "Text input is associated with a sequence of Fujisaki-model parameters.",
        "sentence_llm_dp_info": "\"Entity 1 ('text input') is the subject, depending on the verb 'associated'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'with', depending on 'with' in the phrase 'with a sequence of Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' and the noun 'sequence'.\""
    },
    {
        "raw_sentence": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning , this paper proposes extending this model to a context-dependent one .",
        "ner_pair": [
            [
                "statistical learning",
                "Method"
            ],
            [
                "Fujisaki-model parameters",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical learning') is the object of the preposition 'based on', depending on the verb 'proposes'. Entity 2 ('Fujisaki-model parameters') is the object of the preposition 'of', depending on 'sequence'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the method proposed in the paper.\"",
        "sdp_path_text": "learning → on → based → input → with → associate → sequence → of → parameters",
        "sentence": "Statistical learning is used to associate a sequence of Fujisaki-model parameters with a text input.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical learning') is the subject, depending on the verb 'used'. Entity 2 ('Fujisaki-model parameters') is part of the object, depending on 'associate' in the phrase 'to associate a sequence of Fujisaki-model parameters'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'associate' which indicates the action performed by 'statistical learning' on 'Fujisaki-model parameters'.\""
    },
    {
        "raw_sentence": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning , this paper proposes extending this model to a context-dependent one .",
        "ner_pair": [
            [
                "text input",
                "Material"
            ],
            [
                "statistical learning",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text input') is the object of the preposition 'with', depending on 'associate'. Entity 2 ('statistical learning') is the object of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the conditions for associating a sequence of the Fujisaki-model parameters.\"",
        "sdp_path_text": "input → based → on → learning",
        "sentence": "The text input is based on statistical learning.",
        "sentence_llm_dp_info": "\"Entity 1 ('text input') is the subject, depending on the verb 'is'. Entity 2 ('statistical learning') is the complement, depending on 'based' in the phrase 'based on statistical learning'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'on' and the verb 'based'.\""
    },
    {
        "raw_sentence": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning , this paper proposes extending this model to a context-dependent one .",
        "ner_pair": [
            [
                "text input",
                "Material"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('text input') is the object of the preposition 'with', depending on 'associate'. Entity 2 ('model') is the object of the preposition 'to', depending on 'extending'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'model' is being extended to be context-dependent for the purpose of associating with 'text input'.\"",
        "sdp_path_text": "input → with → associate → sequence → of → parameters → model",
        "sentence": "Text input is associated with the model through a sequence of parameters.",
        "sentence_llm_dp_info": "\"Entity 1 ('text input') is the subject, depending on the verb 'is' in the phrase 'is associated'. Entity 2 ('model') is the object of the preposition 'with', depending on 'with' in the phrase 'with the model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' and the verb 'is associated'.\""
    },
    {
        "raw_sentence": "To associate a sequence of the Fujisaki-model parameters with a text input based on statistical learning , this paper proposes extending this model to a context-dependent one .",
        "ner_pair": [
            [
                "statistical learning",
                "Method"
            ],
            [
                "model",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('statistical learning') is the object of the preposition 'based', depending on the prepositional phrase 'based on statistical learning'. Entity 2 ('model') is the object of the preposition 'to', depending on the verb 'extending' in the phrase 'extending this model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'extending' and the preposition 'based'.\"",
        "sdp_path_text": "learning → on → based → input → with → associate → sequence → of → parameters → model",
        "sentence": "Statistical learning is used to associate a sequence of parameters with a text input, extending the model.",
        "sentence_llm_dp_info": "\"Entity 1 ('statistical learning') is the subject, depending on the verb 'is used'. Entity 2 ('model') is the object of the verb 'extending', depending on 'extending' in the phrase 'extending the model'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'extending' which describes an action that modifies or affects the 'model' as a result of 'statistical learning' being used.\""
    },
    {
        "raw_sentence": "We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering .",
        "ner_pair": [
            [
                "parameter training algorithm",
                "Method"
            ],
            [
                "model",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('parameter training algorithm') is the object of the verb 'propose', depending on 'propose' in the phrase 'propose a parameter training algorithm'. Entity 2 ('model') is the object of the preposition 'for', depending on 'for' in the phrase 'for the present model'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "algorithm → for → model",
        "sentence": "We propose a parameter training algorithm for the model.",
        "sentence_llm_dp_info": "\"Entity 1 ('parameter training algorithm') is the object of the preposition 'for', depending on 'propose'. Entity 2 ('model') is also an object of the preposition 'for', depending on 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'for the model' which modifies the verb 'propose'.\""
    },
    {
        "raw_sentence": "We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering .",
        "ner_pair": [
            [
                "decision tree-based context clustering",
                "Method"
            ],
            [
                "parameter training algorithm",
                "Method"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('decision tree-based context clustering') is the object of the preposition 'based', depending on 'algorithm'. Entity 2 ('parameter training algorithm') is the direct object, depending on the verb 'propose'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on a decision tree-based context clustering'.\"",
        "sdp_path_text": "clustering → on → based → algorithm",
        "sentence": "We propose a parameter training algorithm based on decision tree-based context clustering.",
        "sentence_llm_dp_info": "\"Entity 1 ('decision tree-based context clustering') is the complement of the preposition 'based', depending on 'algorithm'. Entity 2 ('parameter training algorithm') is the object of the preposition 'a', depending on 'propose' in the phrase 'We propose a parameter training algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'based on decision tree-based context clustering'.\""
    },
    {
        "raw_sentence": "We further propose a parameter training algorithm for the present model based on a decision tree-based context clustering .",
        "ner_pair": [
            [
                "model",
                "Generic"
            ],
            [
                "decision tree-based context clustering",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'for', depending on 'propose'. Entity 2 ('decision tree-based context clustering') is the object of the preposition 'based on', depending on 'algorithm'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing what is being proposed.\"",
        "sdp_path_text": "model → for → algorithm → based → on → clustering",
        "sentence": "We propose a parameter training algorithm for the model based on decision tree-based context clustering.",
        "sentence_llm_dp_info": "\"Entity 1 ('model') is the object of the preposition 'for', depending on 'algorithm'. Entity 2 ('decision tree-based context clustering') is the complement of the preposition 'on', depending on 'based'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same prepositional structure where the algorithm is described as being for the model and based on decision tree-based context clustering.\""
    },
    {
        "raw_sentence": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "evaluation of object detection cascades",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on the verb 'introduce' with 'We'. Entity 2 ('evaluation of object detection cascades') is the object of the preposition 'of', depending on 'accelerate' in the phrase 'to accelerate the evaluation of object detection cascades'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the purpose clause introduced by 'to accelerate'.\"",
        "sdp_path_text": "method → accelerate → evaluation",
        "sentence": "We introduce a method to accelerate the evaluation of object detection cascades.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the direct object, depending on the verb 'introduce'. Entity 2 ('evaluation of object detection cascades') is the object of the preposition 'of', depending on 'accelerate'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'accelerate' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions .",
        "ner_pair": [
            [
                "divide-and-conquer procedure",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('divide-and-conquer procedure') is the object of the preposition 'with', depending on 'with' in the phrase 'with the help of a divide-and-conquer procedure'. Entity 2 ('method') is the object, depending on 'introduce' with 'We'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with' which indicates that the 'divide-and-conquer procedure' assists in the introduction of the 'method'.\"",
        "sdp_path_text": "procedure → of → help → with → accelerate → method",
        "sentence": "A divide-and-conquer procedure helps accelerate the method.",
        "sentence_llm_dp_info": "\"Entity 1 ('divide-and-conquer procedure') is the subject, depending on the verb 'helps'. Entity 2 ('method') is the object of the preposition 'the', depending on 'accelerate' in the phrase 'accelerate the method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'helps' which indicates that Entity 1 assists in accelerating Entity 2.\""
    },
    {
        "raw_sentence": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "space of candidate regions",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'introduce' with 'We'. Entity 2 ('space of candidate regions') is the object of the preposition 'in', depending on 'in' in the phrase 'in the space of candidate regions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and contextually related through the purpose of the method described.\"",
        "sdp_path_text": "method → accelerate → with → help → in → space",
        "sentence": "We introduce a method to accelerate evaluation with help in the space of candidate regions.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on the verb 'introduce'. Entity 2 ('space of candidate regions') is the object of the preposition 'in', depending on 'help'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the purpose and context of the introduced method.\""
    },
    {
        "raw_sentence": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions .",
        "ner_pair": [
            [
                "evaluation of object detection cascades",
                "Task"
            ],
            [
                "divide-and-conquer procedure",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation of object detection cascades') is the object of the preposition 'of', depending on 'accelerate' in the phrase 'to accelerate the evaluation of object detection cascades'. Entity 2 ('divide-and-conquer procedure') is the object of the preposition 'of', depending on 'help' in the phrase 'with the help of a divide-and-conquer procedure'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger structure describing the method introduced.\"",
        "sdp_path_text": "evaluation → accelerate → with → help → of → procedure",
        "sentence": "The evaluation of object detection cascades is accelerated with the help of a divide-and-conquer procedure.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation of object detection cascades') is the subject, depending on the verb 'is accelerated'. Entity 2 ('divide-and-conquer procedure') is the object of the preposition 'of', depending on 'help' in the phrase 'with the help of a divide-and-conquer procedure'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'accelerated' and the prepositional phrase 'with the help of'.\""
    },
    {
        "raw_sentence": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions .",
        "ner_pair": [
            [
                "evaluation of object detection cascades",
                "Task"
            ],
            [
                "space of candidate regions",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('evaluation of object detection cascades') is the object of the preposition 'of', depending on 'accelerate'. Entity 2 ('space of candidate regions') is the object of the preposition 'in', depending on 'procedure'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context described in the sentence.\"",
        "sdp_path_text": "evaluation → accelerate → with → help → in → space",
        "sentence": "We introduce a method to accelerate the evaluation of object detection cascades in the space of candidate regions.",
        "sentence_llm_dp_info": "\"Entity 1 ('evaluation of object detection cascades') is the object of the preposition 'of', depending on 'accelerate'. Entity 2 ('space of candidate regions') is the object of the preposition 'in', depending on 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause and relate to the action described by the verb 'accelerate'.\""
    },
    {
        "raw_sentence": "We introduce a method to accelerate the evaluation of object detection cascades with the help of a divide-and-conquer procedure in the space of candidate regions .",
        "ner_pair": [
            [
                "space of candidate regions",
                "Method"
            ],
            [
                "divide-and-conquer procedure",
                "Method"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('space of candidate regions') is the object of the preposition 'in', depending on 'procedure'. Entity 2 ('divide-and-conquer procedure') is the object of the preposition 'with', depending on 'accelerate'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context describing how the method accelerates the evaluation process.\"",
        "sdp_path_text": "space → in → help → of → procedure",
        "sentence": "A divide-and-conquer procedure helps in the space of candidate regions.",
        "sentence_llm_dp_info": "\"Entity 1 ('space of candidate regions') is the object of the preposition 'in', depending on 'helps'. Entity 2 ('divide-and-conquer procedure') is the subject, depending on the verb 'helps'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which indicates that the 'divide-and-conquer procedure' helps within the 'space of candidate regions'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "exhaustive procedure",
                "Method"
            ],
            [
                "cascade evaluation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the subject, depending on 'is' with 'state-of-the-art'. Entity 2 ('cascade evaluation') is the object of the preposition 'for', depending on 'for' in the phrase 'for cascade evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "procedure → is → for → evaluation",
        "sentence": "The exhaustive procedure is used for cascade evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the subject, depending on the verb 'is used'. Entity 2 ('cascade evaluation') is the object, depending on the preposition 'for'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the verb 'is used' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "exhaustive procedure",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the subject of the clause 'that thus far is the state-of-the-art for cascade evaluation', depending on 'is'. Entity 2 ('method') is the subject of the main clause, depending on 'requires'. There is no direct dependency between Entity 1 and Entity 2; however, they are contrasted within the sentence, indicating an indirect relationship through the comparison introduced by 'Compared to'.\"",
        "sdp_path_text": "procedure → to → Compared → requires → method",
        "sentence": "The proposed method requires fewer evaluations compared to the exhaustive procedure.",
        "sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the object of the preposition 'to', depending on 'compared'. Entity 2 ('method') is the subject, depending on 'requires' with 'The proposed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the comparative structure 'compared to'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "exhaustive procedure",
                "Method"
            ],
            [
                "classifier functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the subject of the clause 'that thus far is the state-of-the-art for cascade evaluation', depending on the relative pronoun 'that'. Entity 2 ('classifier functions') is the object of the preposition 'of', depending on 'evaluations'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the context of evaluating methods or processes in the sentence.\"",
        "sdp_path_text": "procedure → to → Compared → requires → evaluations → of → functions",
        "sentence": "The exhaustive procedure requires evaluations of the classifier functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the subject, depending on the verb 'requires'. Entity 2 ('classifier functions') is the object, depending on the preposition 'of' in the phrase 'of the classifier functions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'requires' and the prepositional phrase 'of the classifier functions'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "exhaustive procedure",
                "Method"
            ],
            [
                "search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is part of a comparative clause, depending on 'compared' with 'Compared'. Entity 2 ('search') is the object of the verb 'speeding up', depending on 'speeding up' in the phrase 'thereby speeding up the search'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the comparison and the effect described in the sentence.\"",
        "sdp_path_text": "procedure → to → Compared → requires → speeding → search",
        "sentence": "The exhaustive procedure requires more evaluations, slowing down the search.",
        "sentence_llm_dp_info": "\"Entity 1 ('exhaustive procedure') is the subject, depending on the verb 'requires'. Entity 2 ('search') is the object, depending on the verb phrase 'slowing down'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the effect described by 'slowing down'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Task"
            ],
            [
                "method",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'state-of-the-art'. Entity 2 ('method') is the subject, depending on the verb 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related as the method is compared to the current state-of-the-art for cascade evaluation.\"",
        "sdp_path_text": "evaluation → for → is → procedure → to → Compared → requires → method",
        "sentence": "The proposed method requires fewer evaluations for cascade evaluation compared to the state-of-the-art procedure.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'requires' with 'method'. Entity 2 ('method') is the subject, depending on 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Task"
            ],
            [
                "classifier functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'state-of-the-art'. Entity 2 ('classifier functions') is the object of the preposition 'of', depending on 'evaluations'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context describing the comparison and benefits of the proposed method.\"",
        "sdp_path_text": "evaluation → for → is → procedure → to → Compared → requires → evaluations → of → functions",
        "sentence": "The proposed method requires fewer evaluations of classifier functions compared to the state-of-the-art for cascade evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'state-of-the-art'. Entity 2 ('classifier functions') is the object of the verb 'evaluations', depending on 'requires'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the comparison structure in the sentence.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Task"
            ],
            [
                "search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('search') is the object of the verb 'speeding up', depending on 'thereby'. There is no direct dependency between Entity 1 and Entity 2; they are part of different clauses within the sentence.\"",
        "sdp_path_text": "evaluation → for → is → procedure → to → Compared → requires → speeding → search",
        "sentence": "The proposed method speeds up the search for cascade evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'for' in the phrase 'for cascade evaluation'. Entity 2 ('search') is the direct object, depending on the verb 'speeds up' with 'method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for' which indicates that the search is being sped up for the purpose of cascade evaluation.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "classifier functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'requires' with 'the proposed method'. Entity 2 ('classifier functions') is the object, depending on 'evaluations' with 'fewer evaluations of the classifier functions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'requires' and the noun 'evaluations'.\"",
        "sdp_path_text": "method → requires → evaluations → of → functions",
        "sentence": "The proposed method requires fewer evaluations of the classifier functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'requires' as the verb. Entity 2 ('classifier functions') is the object, depending on 'evaluations' with the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'requires' and the noun 'evaluations'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "search",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'requires'. Entity 2 ('search') is the object of the preposition 'up', depending on 'speeding' in the phrase 'speeding up the search'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'speeding' which describes an effect of the method.\"",
        "sdp_path_text": "method → requires → speeding → search",
        "sentence": "The proposed method speeds up the search.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'speeds'. Entity 2 ('search') is the object, depending on the verb 'speeds'. There is a direct dependency between Entity 1 and Entity 2, as 'method' directly affects 'search' through the verb 'speeds'.\""
    },
    {
        "raw_sentence": "Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .",
        "ner_pair": [
            [
                "classifier functions",
                "OtherScientificTerm"
            ],
            [
                "search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('classifier functions') is the object of the verb 'requires', depending on 'requires' in the clause 'requires fewer evaluations of the classifier functions'. Entity 2 ('search') is the object of the verb 'speeding up', depending on 'speeding up' in the phrase 'thereby speeding up the search'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the context of the method's effect on reducing the number of evaluations and improving the speed of the search process.\"",
        "sdp_path_text": "functions → of → evaluations → requires → speeding → search",
        "sentence": "The proposed method requires fewer evaluations of classifier functions, thereby speeding up the search.",
        "sentence_llm_dp_info": "\"Entity 1 ('classifier functions') is the object, depending on 'evaluations' with the verb 'requires'. Entity 2 ('search') is the object, depending on 'up' in the phrase 'speeding up'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause influenced by the verb 'requires' and the adverbial phrase 'thereby speeding up'.\""
    },
    {
        "raw_sentence": "Furthermore , we show how the recently developed efficient subwindow search -LRB- ESS -RRB- procedure -LSB- 11 -RSB- can be integrated into the last stage of our method .",
        "ner_pair": [
            [
                "subwindow search -LRB- ESS -RRB- procedure",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('subwindow search -LRB- ESS -RRB- procedure') is the subject, depending on 'can be integrated' as the main verb. Entity 2 ('method') is the object of the preposition 'into', depending on 'into' in the phrase 'into the last stage of our method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'can be integrated' and the prepositional phrase 'into the last stage of our method'.\"",
        "sdp_path_text": "procedure → integrated → into → stage → of → method",
        "sentence": "The subwindow search (ESS) procedure can be integrated into the method.",
        "sentence_llm_dp_info": "\"Entity 1 ('subwindow search (ESS) procedure') is the subject, depending on the verb 'can be integrated'. Entity 2 ('method') is the object of the preposition 'into', depending on 'into' in the phrase 'into the method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'into'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "cascade evaluation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'to use', depending on 'allows'. Entity 2 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrases 'to use our method' and 'as a faster procedure for cascade evaluation'.\"",
        "sdp_path_text": "method → use → act → as → procedure → for → evaluation",
        "sentence": "Our method can be used as a procedure for cascade evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'can be used'. Entity 2 ('cascade evaluation') is the object of the preposition 'for', depending on 'for' in the phrase 'for cascade evaluation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "branch-and-bound object detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'of', depending on 'use' in the phrase 'use our method'. Entity 2 ('branch-and-bound object detection') is the object of the preposition 'as', depending on 'tool' in the phrase 'a tool to perform efficient branch-and-bound object detection'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'as' and the verb 'perform'.\"",
        "sdp_path_text": "method → use → act → as → as → tool → perform → detection",
        "sentence": "Our method can be used as a tool to perform branch-and-bound object detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'can be used'. Entity 2 ('branch-and-bound object detection') is the object of the preposition 'to', depending on 'to' in the phrase 'to perform branch-and-bound object detection'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'to' and the verb 'perform'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "nonlinear quality functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'use', depending on the verb 'allows'. Entity 2 ('nonlinear quality functions') is the object of the preposition 'with', depending on 'functions'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of a larger clause describing the capabilities of the method.\"",
        "sdp_path_text": "method → use → act → as → as → tool → perform → with → functions",
        "sentence": "Our method can be used as a tool to perform with nonlinear quality functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'can be used'. Entity 2 ('nonlinear quality functions') is the object of the preposition 'with', depending on 'with' in the phrase 'with nonlinear quality functions'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "kernel-ized support vector machines",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object of the preposition 'use', depending on 'allows' with 'This'. Entity 2 ('kernel-ized support vector machines') is the object of the preposition 'with', depending on 'functions'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the capabilities of the method.\"",
        "sdp_path_text": "method → use → act → as → as → tool → perform → machines",
        "sentence": "Our method can be used as a tool to perform with kernel-ized support vector machines.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on 'can be used' as the main verb phrase. Entity 2 ('kernel-ized support vector machines') is the object, depending on 'perform' with 'with' in the phrase 'to perform with kernel-ized support vector machines'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with kernel-ized support vector machines' which modifies the verb 'perform'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Task"
            ],
            [
                "branch-and-bound object detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('branch-and-bound object detection') is the object of the preposition 'as', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause through their roles as objects of different prepositions.\"",
        "sdp_path_text": "evaluation → for → procedure → as → as → tool → perform → detection",
        "sentence": "Our method acts as a procedure for cascade evaluation and as a tool for branch-and-bound object detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('branch-and-bound object detection') is also the object of the preposition 'for', depending on 'tool'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the subject 'method' through the prepositions 'for'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Task"
            ],
            [
                "nonlinear quality functions",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('nonlinear quality functions') is the object of the preposition 'with', depending on 'detection'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context of describing the capabilities of the method.\"",
        "sdp_path_text": "evaluation → for → procedure → as → as → tool → perform → with → functions",
        "sentence": "The method can be used as a procedure for cascade evaluation and as a tool to perform object detection with nonlinear quality functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('nonlinear quality functions') is the object of the preposition 'with', depending on 'perform'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Task"
            ],
            [
                "kernel-ized support vector machines",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('kernel-ized support vector machines') is the object of the preposition 'with', depending on 'functions'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of describing the capabilities of the method being discussed.\"",
        "sdp_path_text": "evaluation → for → procedure → as → as → tool → perform → machines",
        "sentence": "Our method can be used for cascade evaluation and to perform efficient object detection with kernel-ized support vector machines.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the object of the preposition 'for', depending on 'used'. Entity 2 ('kernel-ized support vector machines') is the object of the preposition 'with', depending on 'detection'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "nonlinear quality functions",
                "OtherScientificTerm"
            ],
            [
                "branch-and-bound object detection",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nonlinear quality functions') is the object of the preposition 'with', depending on 'with' in the phrase 'with nonlinear quality functions'. Entity 2 ('branch-and-bound object detection') is the object of the preposition 'as', depending on 'as' in the phrase 'as a tool to perform efficient branch-and-bound object detection'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the capabilities of the method.\"",
        "sdp_path_text": "functions → with → perform → detection",
        "sentence": "Nonlinear quality functions are used to perform branch-and-bound object detection.",
        "sentence_llm_dp_info": "\"Entity 1 ('nonlinear quality functions') is the subject, depending on the verb 'are used'. Entity 2 ('branch-and-bound object detection') is the object of the verb 'perform', depending on 'perform' in the phrase 'to perform branch-and-bound object detection'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are used' and the purpose clause introduced by 'to perform'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "branch-and-bound object detection",
                "Task"
            ],
            [
                "kernel-ized support vector machines",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('branch-and-bound object detection') is the object of the preposition 'for', depending on 'procedure'. Entity 2 ('kernel-ized support vector machines') is the object of the preposition 'with', depending on 'functions'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger clause describing the capabilities of the method.\"",
        "sdp_path_text": "detection → perform → machines",
        "sentence": "The method can perform branch-and-bound object detection using kernel-ized support vector machines.",
        "sentence_llm_dp_info": "\"Entity 1 ('branch-and-bound object detection') is the object, depending on the verb 'perform'. Entity 2 ('kernel-ized support vector machines') is the object of the preposition 'using', depending on 'using' in the phrase 'using kernel-ized support vector machines'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause where 'branch-and-bound object detection' is performed using 'kernel-ized support vector machines'.\""
    },
    {
        "raw_sentence": "This allows us to use our method to act not only as a faster procedure for cascade evaluation , but also as a tool to perform efficient branch-and-bound object detection with nonlinear quality functions , in particular kernel-ized support vector machines .",
        "ner_pair": [
            [
                "kernel-ized support vector machines",
                "Method"
            ],
            [
                "nonlinear quality functions",
                "OtherScientificTerm"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('kernel-ized support vector machines') is the object, depending on 'with' in the phrase 'with kernel-ized support vector machines'. Entity 2 ('nonlinear quality functions') is the object of the preposition 'with', depending on 'with' in the phrase 'with nonlinear quality functions'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the capabilities of the method.\"",
        "sdp_path_text": "machines → perform → with → functions",
        "sentence": "Kernel-ized support vector machines can perform with nonlinear quality functions.",
        "sentence_llm_dp_info": "\"Entity 1 ('kernel-ized support vector machines') is the subject, depending on the modal verb 'can'. Entity 2 ('nonlinear quality functions') is the object, depending on 'with' in the phrase 'with nonlinear quality functions'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which indicates that Entity 1 can perform using Entity 2.\""
    },
    {
        "raw_sentence": "Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50 % by our method compared to standard cascade evaluation .",
        "ner_pair": [
            [
                "PASCAL VOC 2006 dataset",
                "Material"
            ],
            [
                "method",
                "Generic"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PASCAL VOC 2006 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('method') is the object of the preposition 'by', depending on 'acceleration'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the same clause describing the results of the experiments.\"",
        "sdp_path_text": "dataset → on → Experiments → show → acceleration → by → method",
        "sentence": "Experiments on the PASCAL VOC 2006 dataset show acceleration by the method.",
        "sentence_llm_dp_info": "\"Entity 1 ('PASCAL VOC 2006 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('method') is the subject, depending on 'show' with 'acceleration'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause describing the context and effect of the experiments.\""
    },
    {
        "raw_sentence": "Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50 % by our method compared to standard cascade evaluation .",
        "ner_pair": [
            [
                "PASCAL VOC 2006 dataset",
                "Material"
            ],
            [
                "cascade evaluation",
                "Method"
            ],
            "EVALUATE-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('PASCAL VOC 2006 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('cascade evaluation') is the object of the preposition 'to', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the context describing the results of the experiments.\"",
        "sdp_path_text": "dataset → on → Experiments → show → acceleration → compared → to → evaluation",
        "sentence": "Experiments on the PASCAL VOC 2006 dataset show acceleration compared to cascade evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('PASCAL VOC 2006 dataset') is the object of the preposition 'on', depending on 'Experiments'. Entity 2 ('cascade evaluation') is the object of the preposition 'to', depending on 'compared'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50 % by our method compared to standard cascade evaluation .",
        "ner_pair": [
            [
                "cascade evaluation",
                "Method"
            ],
            [
                "method",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the complement of the preposition 'to', depending on 'compared' in the phrase 'compared to standard cascade evaluation'. Entity 2 ('method') is the possessive modifier, depending on 'acceleration' in the phrase 'our method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure involving 'compared to'.\"",
        "sdp_path_text": "evaluation → to → compared → acceleration → by → method",
        "sentence": "Our method shows an acceleration compared to standard cascade evaluation.",
        "sentence_llm_dp_info": "\"Entity 1 ('cascade evaluation') is the complement of the preposition 'to', depending on 'compared'. Entity 2 ('method') is the subject, depending on the verb 'shows'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the comparative structure 'compared to'.\""
    },
    {
        "raw_sentence": "Background modeling is an important component of many vision systems .",
        "ner_pair": [
            [
                "Background modeling",
                "Task"
            ],
            [
                "vision systems",
                "Task"
            ],
            "PART-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Background modeling') is the subject, depending on the verb 'is'. Entity 2 ('vision systems') is the object of the preposition 'of', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the noun 'component' and the preposition 'of'.\"",
        "sdp_path_text": "modeling → is → component → of → systems",
        "sentence": "Background modeling is a component of vision systems.",
        "sentence_llm_dp_info": "\"Entity 1 ('Background modeling') is the subject, depending on the verb 'is'. Entity 2 ('vision systems') is the object of the preposition 'of', depending on 'component'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the noun 'component' which acts as a bridge in the sentence.\""
    },
    {
        "raw_sentence": "When the scene exhibits a persistent dynamic behavior in time , such an assumption is violated and detection performance deteriorates .",
        "ner_pair": [
            [
                "persistent dynamic behavior",
                "OtherScientificTerm"
            ],
            [
                "scene",
                "Generic"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('persistent dynamic behavior') is the complement of the verb 'exhibits', depending on 'exhibits' with 'scene'. Entity 2 ('scene') is the subject, depending on 'exhibits' as the main verb of the clause. There is a direct dependency between Entity 1 and Entity 2, where Entity 2 is the subject that performs the action of exhibiting Entity 1.\"",
        "sdp_path_text": "behavior → exhibits → scene",
        "sentence": "The scene exhibits a persistent dynamic behavior.",
        "sentence_llm_dp_info": "\"Entity 1 ('persistent dynamic behavior') is the complement, depending on the verb 'exhibits'. Entity 2 ('scene') is the subject, depending on the verb 'exhibits'. There is a direct dependency between Entity 1 and Entity 2, as 'scene' is the subject that 'exhibits' the 'persistent dynamic behavior'.\""
    },
    {
        "raw_sentence": "When the scene exhibits a persistent dynamic behavior in time , such an assumption is violated and detection performance deteriorates .",
        "ner_pair": [
            [
                "scene",
                "Generic"
            ],
            [
                "detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('scene') is the subject, depending on the verb 'exhibits'. Entity 2 ('detection') is part of the compound noun 'detection performance', which is the subject of the clause 'performance deteriorates'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the logical flow of the sentence where the condition described by Entity 1 affects the outcome described by Entity 2.\"",
        "sdp_path_text": "scene → exhibits → violated → deteriorates → performance → detection",
        "sentence": "When the scene exhibits a persistent dynamic behavior, detection performance deteriorates.",
        "sentence_llm_dp_info": "\"Entity 1 ('scene') is the subject, depending on the verb 'exhibits'. Entity 2 ('detection') is part of the compound noun 'detection performance', which is the subject of the verb 'deteriorates'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the context of the sentence where the condition of the 'scene' affects 'detection performance'.\""
    },
    {
        "raw_sentence": "When the scene exhibits a persistent dynamic behavior in time , such an assumption is violated and detection performance deteriorates .",
        "ner_pair": [
            [
                "persistent dynamic behavior",
                "OtherScientificTerm"
            ],
            [
                "detection",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('persistent dynamic behavior') is the complement of the verb 'exhibits', depending on 'exhibits' with 'scene'. Entity 2 ('detection') is part of the compound noun 'detection performance', which is the subject of the verb 'deteriorates'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related through the sentence structure, where the presence of Entity 1 leads to the deterioration of Entity 2.\"",
        "sdp_path_text": "behavior → exhibits → violated → deteriorates → performance → detection",
        "sentence": "Persistent dynamic behavior leads to deterioration of detection performance.",
        "sentence_llm_dp_info": "\"Entity 1 ('persistent dynamic behavior') is the subject, depending on the verb 'leads'. Entity 2 ('detection') is part of the object noun phrase, depending on 'of' in the phrase 'of detection performance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'leads' and the preposition 'of'.\""
    },
    {
        "raw_sentence": "In this paper , we propose a new method for the modeling and subtraction of such scenes .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "modeling and subtraction of such scenes",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'propose' with 'we'. Entity 2 ('modeling and subtraction of such scenes') is the object of the preposition 'for', depending on 'for' in the phrase 'for the modeling and subtraction of such scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "method → for → modeling",
        "sentence": "A new method is proposed for modeling and subtraction of such scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the subject, depending on the verb 'proposed'. Entity 2 ('modeling and subtraction of such scenes') is the object of the preposition 'for', depending on 'for' in the phrase 'for modeling and subtraction of such scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "In this paper , we propose a new method for the modeling and subtraction of such scenes .",
        "ner_pair": [
            [
                "method",
                "Generic"
            ],
            [
                "scenes",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on 'propose' with 'we'. Entity 2 ('scenes') is the object of the preposition 'of', depending on 'subtraction' in the phrase 'subtraction of such scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'propose' and the prepositional phrase 'for the modeling and subtraction of such scenes'.\"",
        "sdp_path_text": "method → for → modeling → of → scenes",
        "sentence": "We propose a new method for modeling and subtracting scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('method') is the object, depending on the verb 'propose' with 'We'. Entity 2 ('scenes') is the object of the preposition 'for', depending on 'subtracting' in the phrase 'for modeling and subtracting scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'method' is proposed for the action involving 'scenes'.\""
    },
    {
        "raw_sentence": "Towards the modeling of the dynamic characteristics , optical flow is computed and utilized as a feature in a higher dimensional space .",
        "ner_pair": [
            [
                "optical flow",
                "OtherScientificTerm"
            ],
            [
                "modeling of the dynamic characteristics",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('optical flow') is the subject, depending on the verb 'is' in the clause 'optical flow is computed and utilized'. Entity 2 ('modeling of the dynamic characteristics') is the object of the preposition 'towards', depending on 'towards' in the phrase 'Towards the modeling of the dynamic characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are contextually related within the sentence.\"",
        "sdp_path_text": "flow → computed → Towards → modeling",
        "sentence": "Optical flow is computed towards the modeling of dynamic characteristics.",
        "sentence_llm_dp_info": "\"Entity 1 ('optical flow') is the subject, depending on the verb 'is computed'. Entity 2 ('modeling of the dynamic characteristics') is the object of the preposition 'towards', depending on 'towards' in the phrase 'towards the modeling of dynamic characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'towards'.\""
    },
    {
        "raw_sentence": "Towards the modeling of the dynamic characteristics , optical flow is computed and utilized as a feature in a higher dimensional space .",
        "ner_pair": [
            [
                "feature",
                "OtherScientificTerm"
            ],
            [
                "modeling of the dynamic characteristics",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('feature') is the object of the preposition 'as', depending on 'utilized'. Entity 2 ('modeling of the dynamic characteristics') is the object of the preposition 'towards', depending on 'towards'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, with Entity 1 being used in the process that contributes to the goal indicated by Entity 2.\"",
        "sdp_path_text": "feature → as → utilized → computed → Towards → modeling",
        "sentence": "Feature is utilized as a result of computing towards the modeling of dynamic characteristics.",
        "sentence_llm_dp_info": "\"Entity 1 ('feature') is the subject, depending on the verb 'is utilized'. Entity 2 ('modeling of the dynamic characteristics') is the object of the preposition 'towards', depending on 'towards' in the phrase 'towards the modeling of dynamic characteristics'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'towards'.\""
    },
    {
        "raw_sentence": "Towards the modeling of the dynamic characteristics , optical flow is computed and utilized as a feature in a higher dimensional space .",
        "ner_pair": [
            [
                "modeling of the dynamic characteristics",
                "Task"
            ],
            [
                "higher dimensional space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('modeling of the dynamic characteristics') is the object of the preposition 'towards', depending on 'towards' in the phrase 'Towards the modeling of the dynamic characteristics'. Entity 2 ('higher dimensional space') is the object of the preposition 'in', depending on 'in' in the phrase 'in a higher dimensional space'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the larger context of the sentence where optical flow is utilized as a feature.\"",
        "sdp_path_text": "modeling → Towards → computed → utilized → as → feature → in → space",
        "sentence": "Modeling of the dynamic characteristics utilizes optical flow as a feature in a higher dimensional space.",
        "sentence_llm_dp_info": "\"Entity 1 ('modeling of the dynamic characteristics') is the subject, depending on the verb 'utilizes'. Entity 2 ('higher dimensional space') is the object of the preposition 'in', depending on 'in' in the phrase 'in a higher dimensional space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilizes' and the preposition 'in'.\""
    },
    {
        "raw_sentence": "Towards the modeling of the dynamic characteristics , optical flow is computed and utilized as a feature in a higher dimensional space .",
        "ner_pair": [
            [
                "optical flow",
                "OtherScientificTerm"
            ],
            [
                "feature",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('optical flow') is the subject, depending on the verb 'is' in the clause 'optical flow is computed and utilized'. Entity 2 ('feature') is the object of the preposition 'as', depending on 'utilized' in the phrase 'utilized as a feature'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilized' and the preposition 'as'.\"",
        "sdp_path_text": "flow → computed → utilized → as → feature",
        "sentence": "Optical flow is computed and utilized as a feature.",
        "sentence_llm_dp_info": "\"Entity 1 ('optical flow') is the subject, depending on the verbs 'is computed' and 'utilized'. Entity 2 ('feature') is the object of the preposition 'as', depending on 'utilized' in the phrase 'utilized as a feature'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilized' and the preposition 'as'.\""
    },
    {
        "raw_sentence": "Towards the modeling of the dynamic characteristics , optical flow is computed and utilized as a feature in a higher dimensional space .",
        "ner_pair": [
            [
                "optical flow",
                "OtherScientificTerm"
            ],
            [
                "higher dimensional space",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('optical flow') is the subject, depending on the verb 'is' in the clause 'optical flow is computed and utilized'. Entity 2 ('higher dimensional space') is the object of the preposition 'in', depending on 'in' in the phrase 'in a higher dimensional space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilized' and the preposition 'in'.\"",
        "sdp_path_text": "flow → computed → utilized → as → feature → in → space",
        "sentence": "Optical flow is computed and utilized as a feature in a higher dimensional space.",
        "sentence_llm_dp_info": "\"Entity 1 ('optical flow') is the subject, depending on 'is' as the main verb, and it is modified by the past participles 'computed' and 'utilized'. Entity 2 ('higher dimensional space') is the object of the preposition 'in', depending on 'in' in the phrase 'in a higher dimensional space'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in' which shows that the 'optical flow' is utilized 'in' the 'higher dimensional space'.\""
    },
    {
        "raw_sentence": "Towards the modeling of the dynamic characteristics , optical flow is computed and utilized as a feature in a higher dimensional space .",
        "ner_pair": [
            [
                "higher dimensional space",
                "OtherScientificTerm"
            ],
            [
                "feature",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('higher dimensional space') is the object of the preposition 'in', depending on 'in' in the phrase 'in a higher dimensional space'. Entity 2 ('feature') is the object of the preposition 'as', depending on 'as' in the phrase 'as a feature'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'as a feature' and 'in a higher dimensional space'.\"",
        "sdp_path_text": "space → in → feature",
        "sentence": "Optical flow is utilized as a feature in a higher dimensional space.",
        "sentence_llm_dp_info": "\"Entity 1 ('higher dimensional space') is the complement of the preposition 'in', depending on 'in' in the phrase 'in a higher dimensional space'. Entity 2 ('feature') is the object of the preposition 'as', depending on 'as' in the phrase 'as a feature'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'utilized' and the prepositions 'as' and 'in'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "ambiguities",
                "OtherScientificTerm"
            ],
            [
                "computation of features",
                "Task"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ambiguities') is the subject, depending on the verb 'addressed'. Entity 2 ('computation of features') is the object of the preposition 'in', depending on 'in' in the phrase 'in the computation of features'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that modifies 'ambiguities'.\"",
        "sdp_path_text": "ambiguities → in → computation",
        "sentence": "Ambiguities in the computation of features are addressed.",
        "sentence_llm_dp_info": "\"Entity 1 ('ambiguities') is the subject, depending on the verb 'addressed'. Entity 2 ('computation of features') is the object of the preposition 'in', depending on 'in' in the phrase 'in the computation of features'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "data-dependent bandwidth",
                "OtherScientificTerm"
            ],
            [
                "ambiguities",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data-dependent bandwidth') is the object of the preposition 'using', depending on 'addressed'. Entity 2 ('ambiguities') is the subject, depending on the verb 'are addressed'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the structure of the sentence where the use of 'data-dependent bandwidth' is part of the method to address the 'ambiguities'.\"",
        "sdp_path_text": "bandwidth → using → by → addressed → ambiguities",
        "sentence": "Ambiguities are addressed by using a data-dependent bandwidth.",
        "sentence_llm_dp_info": "\"Entity 1 ('data-dependent bandwidth') is the object of the preposition 'by', depending on 'using'. Entity 2 ('ambiguities') is the subject, depending on the verb 'addressed'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'addressed' and the prepositional phrase 'by using a data-dependent bandwidth'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "ambiguities",
                "OtherScientificTerm"
            ],
            [
                "density estimation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ambiguities') is the subject, depending on the passive verb 'are addressed'. Entity 2 ('density estimation') is the object of the preposition 'for', depending on 'using' in the phrase 'using a data-dependent bandwidth for density estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of addressing ambiguities by a method that involves density estimation.\"",
        "sdp_path_text": "ambiguities → addressed → by → using → for → estimation",
        "sentence": "Ambiguities are addressed by using a bandwidth for density estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('ambiguities') is the subject, depending on the verb 'addressed'. Entity 2 ('density estimation') is the object of the preposition 'for', depending on 'using' in the phrase 'using a bandwidth for density estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the prepositional phrase 'for density estimation' which modifies 'bandwidth'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "ambiguities",
                "OtherScientificTerm"
            ],
            [
                "kernels",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ambiguities') is the subject, depending on 'addressed' as the main verb. Entity 2 ('kernels') is the object of the preposition 'using', depending on 'using' in the phrase 'using kernels'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause, connected through the verb 'addressed' and the prepositional phrase 'using a data-dependent bandwidth for density estimation using kernels'.\"",
        "sdp_path_text": "ambiguities → addressed → by → using → using → kernels",
        "sentence": "Ambiguities are addressed by using kernels.",
        "sentence_llm_dp_info": "\"Entity 1 ('ambiguities') is the subject, depending on the verb 'addressed'. Entity 2 ('kernels') is the object of the preposition 'using', depending on 'using' in the phrase 'using kernels'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'addressed' and the preposition 'using'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "computation of features",
                "Task"
            ],
            [
                "data-dependent bandwidth",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computation of features') is the object of the preposition 'in', depending on 'ambiguities'. Entity 2 ('data-dependent bandwidth') is the object of the preposition 'by', depending on 'addressed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context where 'ambiguities' are being addressed.\"",
        "sdp_path_text": "computation → in → ambiguities → addressed → by → using → bandwidth",
        "sentence": "Ambiguities in the computation of features are addressed by using a data-dependent bandwidth.",
        "sentence_llm_dp_info": "\"Entity 1 ('computation of features') is the object of the preposition 'in', depending on 'Ambiguities'. Entity 2 ('data-dependent bandwidth') is the object of the preposition 'by using', depending on 'addressed'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes how ambiguities are addressed.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "computation of features",
                "Task"
            ],
            [
                "density estimation",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computation of features') is the object of the preposition 'in', depending on 'ambiguities'. Entity 2 ('density estimation') is the subject complement, depending on 'addressed' through the prepositional phrase 'by using a data-dependent bandwidth for density estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the context and the method used to address the issue.\"",
        "sdp_path_text": "computation → in → ambiguities → addressed → by → using → for → estimation",
        "sentence": "Ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('computation of features') is the object of the preposition 'in', depending on 'Ambiguities'. Entity 2 ('density estimation') is the object of the preposition 'for', depending on 'bandwidth'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger context described in the sentence, where ambiguities related to the computation of features are addressed by a method that involves density estimation.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "computation of features",
                "Task"
            ],
            [
                "kernels",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('computation of features') is the object of the preposition 'in', depending on 'ambiguities'. Entity 2 ('kernels') is the object of the preposition 'using', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause and related through the context of addressing ambiguities in computation and using kernels for density estimation.\"",
        "sdp_path_text": "computation → in → ambiguities → addressed → by → using → using → kernels",
        "sentence": "Ambiguities in the computation of features are addressed by using kernels.",
        "sentence_llm_dp_info": "\"Entity 1 ('computation of features') is the object of the preposition 'in', depending on 'Ambiguities'. Entity 2 ('kernels') is the object of the preposition 'by', depending on 'addressed'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the sentence structure describing how ambiguities are addressed.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "data-dependent bandwidth",
                "OtherScientificTerm"
            ],
            [
                "density estimation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data-dependent bandwidth') is the object of the preposition 'using', depending on 'addressed'. Entity 2 ('density estimation') is the subject complement, depending on 'estimation' which is part of the verb phrase 'for density estimation using kernels'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'using a data-dependent bandwidth for density estimation'.\"",
        "sdp_path_text": "bandwidth → using → for → estimation",
        "sentence": "A data-dependent bandwidth is used for density estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('data-dependent bandwidth') is the subject, depending on the verb 'used'. Entity 2 ('density estimation') is the object of the preposition 'for', depending on 'for' in the phrase 'for density estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "data-dependent bandwidth",
                "OtherScientificTerm"
            ],
            [
                "kernels",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('data-dependent bandwidth') is the object of the preposition 'using', depending on 'addressed'. Entity 2 ('kernels') is the object of the second 'using', depending on 'estimation'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the process of 'density estimation'.\"",
        "sdp_path_text": "bandwidth → using → using → kernels",
        "sentence": "A data-dependent bandwidth is used with kernels for density estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('data-dependent bandwidth') is the subject, depending on the verb 'used'. Entity 2 ('kernels') is the object of the preposition 'with', depending on 'with' in the phrase 'with kernels'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Inherent ambiguities in the computation of features are addressed by using a data-dependent bandwidth for density estimation using kernels .",
        "ner_pair": [
            [
                "kernels",
                "Method"
            ],
            [
                "density estimation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('kernels') is the object, depending on the preposition 'using', which modifies 'estimation'. Entity 2 ('density estimation') is the object of the preposition 'for', depending on 'bandwidth'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrases 'for density estimation' and 'using kernels'.\"",
        "sdp_path_text": "kernels → using → using → for → estimation",
        "sentence": "Kernels are used for density estimation.",
        "sentence_llm_dp_info": "\"Entity 1 ('kernels') is the subject, depending on the verb 'used'. Entity 2 ('density estimation') is the object, depending on 'for' in the prepositional phrase 'for density estimation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Information distillation aims to extract relevant pieces of information related to a given query from massive , possibly multilingual , audio and textual document sources .",
        "ner_pair": [
            [
                "Information distillation",
                "Task"
            ],
            [
                "massive , possibly multilingual , audio and textual document sources",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Information distillation') is the subject, depending on the verb 'aims'. Entity 2 ('massive, possibly multilingual, audio and textual document sources') is the object of the preposition 'from', depending on 'extract'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'extract' and the preposition 'from'.\"",
        "sdp_path_text": "distillation → aims → extract → from → sources",
        "sentence": "Information distillation aims to extract from massive, possibly multilingual, audio and textual document sources.",
        "sentence_llm_dp_info": "\"Entity 1 ('Information distillation') is the subject, depending on the verb 'aims'. Entity 2 ('massive, possibly multilingual, audio and textual document sources') is the object of the preposition 'from', depending on 'extract'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the action 'extract from'.\""
    },
    {
        "raw_sentence": "In this paper , we present our approach for using information extraction annotations to augment document retrieval for distillation .",
        "ner_pair": [
            [
                "information extraction annotations",
                "OtherScientificTerm"
            ],
            [
                "document retrieval for distillation",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('information extraction annotations') is the object of the preposition 'for', depending on 'approach'. Entity 2 ('document retrieval for distillation') is the object of the preposition 'for', depending on 'augment'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the purpose of the approach described in the sentence.\"",
        "sdp_path_text": "annotations → using → augment → retrieval",
        "sentence": "Information extraction annotations are used to augment document retrieval for distillation.",
        "sentence_llm_dp_info": "\"Entity 1 ('information extraction annotations') is the subject, depending on the passive verb 'are used'. Entity 2 ('document retrieval for distillation') is the object of the preposition 'for', depending on 'augment' in the phrase 'to augment document retrieval for distillation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'augment' and the preposition 'for'.\""
    },
    {
        "raw_sentence": "We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction -LRB- ACE -RRB- task .",
        "ner_pair": [
            [
                "distillation queries",
                "OtherScientificTerm"
            ],
            [
                "annotation elements",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distillation queries') is part of the subject complement, depending on the verb 'can be associated'. Entity 2 ('annotation elements') is the object of the preposition 'with', depending on 'associated'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'can be associated' and the preposition 'with'.\"",
        "sdp_path_text": "queries → of → some → associated → with → elements",
        "sentence": "Some distillation queries are associated with annotation elements.",
        "sentence_llm_dp_info": "\"Entity 1 ('distillation queries') is the subject, depending on the verb 'are associated'. Entity 2 ('annotation elements') is the object, depending on 'are associated' with 'distillation queries'. There is a direct dependency between Entity 1 and Entity 2, as 'annotation elements' is directly linked to 'distillation queries' through the verb 'are associated'.\""
    },
    {
        "raw_sentence": "We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction -LRB- ACE -RRB- task .",
        "ner_pair": [
            [
                "distillation queries",
                "OtherScientificTerm"
            ],
            [
                "NIST Automatic Content Extraction -LRB- ACE -RRB- task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('distillation queries') is part of the subject, depending on 'can be associated' with 'annotation elements'. Entity 2 ('NIST Automatic Content Extract -LRB- ACE -RRB- task') is the object of the preposition 'for', depending on 'introduced'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the clause that describes how some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extract (ACE) task.\"",
        "sdp_path_text": "queries → of → some → associated → with → elements → introduced → for → task",
        "sentence": "Some distillation queries are associated with elements introduced for the NIST Automatic Content Extraction (ACE) task.",
        "sentence_llm_dp_info": "\"Entity 1 ('distillation queries') is the subject, depending on the verb 'are associated'. Entity 2 ('NIST Automatic Content Extraction (ACE) task') is the object of the preposition 'for', depending on 'introduced'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'are associated' and the prepositional phrase 'with elements introduced for'.\""
    },
    {
        "raw_sentence": "We take advantage of the fact that some of the distillation queries can be associated with annotation elements introduced for the NIST Automatic Content Extraction -LRB- ACE -RRB- task .",
        "ner_pair": [
            [
                "annotation elements",
                "OtherScientificTerm"
            ],
            [
                "NIST Automatic Content Extraction -LRB- ACE -RRB- task",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('annotation elements') is the object of the preposition 'with', depending on 'associated'. Entity 2 ('NIST Automatic Content Extraction -LRB- ACE -RRB- task') is the object of the preposition 'for', depending on 'introduced'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause, where 'annotation elements' are described as being associated with the 'NIST Automatic Content Extraction -LRB- ACE -RRB- task'.\"",
        "sdp_path_text": "elements → introduced → for → task",
        "sentence": "Annotation elements were introduced for the NIST Automatic Content Extraction (ACE) task.",
        "sentence_llm_dp_info": "\"Entity 1 ('annotation elements') is the subject, depending on the verb 'introduced'. Entity 2 ('NIST Automatic Content Extraction (ACE) task') is the object of the preposition 'for', depending on 'for' in the phrase 'for the NIST Automatic Content Extraction (ACE) task'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates .",
        "ner_pair": [
            [
                "ACE events",
                "OtherScientificTerm"
            ],
            [
                "information retrieval engine",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE events') is the object of the preposition 'using', depending on 'show' in the clause 'we experimentally show that using the ACE events...'. Entity 2 ('information retrieval engine') is the object of the preposition 'by', depending on 'returned' in the phrase 'returned by an information retrieval engine'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing how the precision is improved.\"",
        "sdp_path_text": "events → using → constrain → set → returned → by → engine",
        "sentence": "Using ACE events to constrain the set returned by the information retrieval engine improves precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE events') is the object of the preposition 'Using', depending on 'Using' in the phrase 'Using ACE events'. Entity 2 ('information retrieval engine') is the object of the preposition 'by', depending on 'by' in the phrase 'by the information retrieval engine'. There is no direct dependency between Entity 1 and Entity 2, but both contribute to the action described by the verb 'improves'.\""
    },
    {
        "raw_sentence": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates .",
        "ner_pair": [
            [
                "ACE events",
                "OtherScientificTerm"
            ],
            [
                "precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE events') is the object of the preposition 'using', depending on 'show'. Entity 2 ('precision') is the object of the verb 'improves', depending on 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause structure where 'ACE events' are used to constrain the document set which leads to the improvement of 'precision'.\"",
        "sdp_path_text": "events → using → improves → precision",
        "sentence": "Using ACE events improves precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE events') is the object of the preposition 'Using', depending on 'Using'. Entity 2 ('precision') is the object, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'improves'.\""
    },
    {
        "raw_sentence": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates .",
        "ner_pair": [
            [
                "ACE events",
                "OtherScientificTerm"
            ],
            [
                "recall rates",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('ACE events') is the object of the preposition 'using', depending on 'show' with 'We experimentally'. Entity 2 ('recall rates') is the object of the preposition 'at', depending on 'improves' with 'precision'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the effect of using ACE events on the precision at various recall rates.\"",
        "sdp_path_text": "events → using → improves → precision → at → rates",
        "sentence": "Using ACE events improves precision at recall rates.",
        "sentence_llm_dp_info": "\"Entity 1 ('ACE events') is the object of the preposition 'Using', depending on 'Using'. Entity 2 ('recall rates') is the object of the preposition 'at', depending on 'at' in the phrase 'at recall rates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the effect of using 'ACE events' on 'precision at recall rates'.\""
    },
    {
        "raw_sentence": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates .",
        "ner_pair": [
            [
                "information retrieval engine",
                "Method"
            ],
            [
                "precision",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('information retrieval engine') is the object of the preposition 'by', depending on 'returned'. Entity 2 ('precision') is the object of the verb 'improves', depending on 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the clause that describes how the use of ACE events to constrain the document set returned by the information retrieval engine affects the precision.\"",
        "sdp_path_text": "engine → by → returned → set → constrain → using → improves → precision",
        "sentence": "Using the ACE events to constrain the document set returned by an information retrieval engine improves precision.",
        "sentence_llm_dp_info": "\"Entity 1 ('information retrieval engine') is the object of the preposition 'by', depending on 'constrain'. Entity 2 ('precision') is the subject complement, depending on the verb 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the causal relationship expressed by the verb 'improves'.\""
    },
    {
        "raw_sentence": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates .",
        "ner_pair": [
            [
                "information retrieval engine",
                "Method"
            ],
            [
                "recall rates",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('information retrieval engine') is the object of the preposition 'by', depending on 'returned'. Entity 2 ('recall rates') is the object of the preposition 'for', depending on 'improves'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause describing the effect of constraining the document set on the precision at various recall rates.\"",
        "sdp_path_text": "engine → by → returned → set → constrain → using → improves → precision → at → rates",
        "sentence": "Using the ACE events to constrain the document set returned by an information retrieval engine improves precision at recall rates.",
        "sentence_llm_dp_info": "\"Entity 1 ('information retrieval engine') is the object of the preposition 'by', depending on 'constrain' in the phrase 'constrained by an information retrieval engine'. Entity 2 ('recall rates') is the object of the preposition 'at', depending on 'precision' in the phrase 'precision at recall rates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause that describes the improvement in precision.\""
    },
    {
        "raw_sentence": "We experimentally show that using the ACE events to constrain the document set returned by an information retrieval engine significantly improves the precision at various recall rates for two different query templates .",
        "ner_pair": [
            [
                "precision",
                "Metric"
            ],
            [
                "recall rates",
                "Metric"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('precision') is the object, depending on 'improves' with 'significantly'. Entity 2 ('recall rates') is the object of the preposition 'at', depending on 'at' in the phrase 'at various recall rates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the outcome of the experimental results.\"",
        "sdp_path_text": "precision → at → rates",
        "sentence": "Using ACE events to constrain the document set improves precision at various recall rates.",
        "sentence_llm_dp_info": "\"Entity 1 ('precision') is the object, depending on 'improves'. Entity 2 ('recall rates') is the object of the preposition 'at', depending on 'at' in the phrase 'at various recall rates'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the clause that describes the effect of using ACE events to constrain the document set.\""
    },
    {
        "raw_sentence": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships .",
        "ner_pair": [
            [
                "representation",
                "Generic"
            ],
            [
                "three-dimensional objects",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject complement, depending on the verb 'presents'. Entity 2 ('three-dimensional objects') is the object of the preposition 'for', depending on 'for' in the phrase 'for three-dimensional objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "representation → for → objects",
        "sentence": "This paper presents a representation for three-dimensional objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('representation') is the direct object, depending on the verb 'presents'. Entity 2 ('three-dimensional objects') is the object of the preposition 'for', depending on 'for' in the phrase 'for three-dimensional objects'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships .",
        "ner_pair": [
            [
                "representation",
                "Generic"
            ],
            [
                "affine-invariant image patches",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject, depending on the verb 'presents'. Entity 2 ('affine-invariant image patches') is part of the prepositional phrase 'in terms of affine-invariant image patches', depending on the preposition 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'of'.\"",
        "sdp_path_text": "representation → in → terms → of → patches",
        "sentence": "This paper presents a representation in terms of affine-invariant image patches.",
        "sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject, depending on the verb 'presents' with 'This paper'. Entity 2 ('affine-invariant image patches') is the object of the preposition 'of', depending on 'terms' in the phrase 'in terms of affine-invariant image patches'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'in terms of'.\""
    },
    {
        "raw_sentence": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships .",
        "ner_pair": [
            [
                "representation",
                "Generic"
            ],
            [
                "spatial relationships",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject complement, depending on the verb 'presents' with 'This paper'. Entity 2 ('spatial relationships') is part of a compound noun, depending on 'and' in the phrase 'affine-invariant image patches and their spatial relationships'. There is no direct dependency between Entity 1 and Entity 2, but they are both components of the object of the preposition 'in'.\"",
        "sdp_path_text": "representation → in → terms → of → patches → relationships",
        "sentence": "The representation is in terms of patches and their spatial relationships.",
        "sentence_llm_dp_info": "\"Entity 1 ('representation') is the subject, depending on the verb 'is'. Entity 2 ('spatial relationships') is part of the prepositional phrase 'of patches and their spatial relationships', depending on 'of'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'in' and the prepositional phrase 'in terms of patches and their spatial relationships'.\""
    },
    {
        "raw_sentence": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships .",
        "ner_pair": [
            [
                "affine-invariant image patches",
                "OtherScientificTerm"
            ],
            [
                "three-dimensional objects",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('affine-invariant image patches') is the object of the preposition 'of', depending on 'representation'. Entity 2 ('three-dimensional objects') is the object of the preposition 'for', depending on 'representation'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the representation described in the sentence.\"",
        "sdp_path_text": "patches → of → terms → in → representation → for → objects",
        "sentence": "Affine-invariant image patches are used in the representation of three-dimensional objects.",
        "sentence_llm_dp_info": "\"Entity 1 ('affine-invariant image patches') is the subject, depending on the verb 'used'. Entity 2 ('three-dimensional objects') is the object of the preposition 'of', depending on 'representation' in the phrase 'representation of three-dimensional objects'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'used' and the prepositional phrase 'in the representation of'.\""
    },
    {
        "raw_sentence": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships .",
        "ner_pair": [
            [
                "three-dimensional objects",
                "OtherScientificTerm"
            ],
            [
                "spatial relationships",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('three-dimensional objects') is the object of the preposition 'for', depending on 'representation'. Entity 2 ('spatial relationships') is part of the compound object of the preposition 'of', depending on 'patches'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the representation described in the sentence.\"",
        "sdp_path_text": "objects → for → representation → in → terms → of → patches → relationships",
        "sentence": "A novel representation for three-dimensional objects in terms of their spatial relationships is presented.",
        "sentence_llm_dp_info": "\"Entity 1 ('three-dimensional objects') is the object of the preposition 'for', depending on 'representation'. Entity 2 ('spatial relationships') is the object of the preposition 'of', depending on 'terms'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrases that describe aspects of the 'representation'.\""
    },
    {
        "raw_sentence": "This paper presents a novel representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships .",
        "ner_pair": [
            [
                "spatial relationships",
                "OtherScientificTerm"
            ],
            [
                "affine-invariant image patches",
                "OtherScientificTerm"
            ],
            "FEATURE-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('spatial relationships') is the object, depending on 'terms' with 'in'. Entity 2 ('affine-invariant image patches') is the object, also depending on 'terms' with 'in'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the prepositional phrase 'in terms of affine-invariant image patches and their spatial relationships'.\"",
        "sdp_path_text": "relationships → patches",
        "sentence": "Spatial relationships are represented in terms of affine-invariant image patches.",
        "sentence_llm_dp_info": "\"Entity 1 ('spatial relationships') is the subject, depending on the verb 'are represented'. Entity 2 ('affine-invariant image patches') is the object of the preposition 'in terms of', depending on 'represented' in the phrase 'represented in terms of'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'in terms of'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "Multi-view constraints",
                "OtherScientificTerm"
            ],
            [
                "normalized representation",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is part of a compound subject, depending on 'are' with 'combined'. Entity 2 ('normalized representation') is the object of the preposition 'of', depending on 'appearance'. There is no direct dependency between Entity 1 and Entity 2; both are part of a larger clause that describes how they are used together to guide matching and reconstruction.\"",
        "sdp_path_text": "constraints → combined → with → representation",
        "sentence": "Multi-view constraints are combined with a normalized representation.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is the subject, depending on the verb 'are combined'. Entity 2 ('normalized representation') is the object of the preposition 'with', depending on 'with' in the phrase 'with a normalized representation'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'are combined' and the preposition 'with'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "Multi-view constraints",
                "OtherScientificTerm"
            ],
            [
                "matching",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is part of a compound noun phrase, depending on 'combined' as the subject. Entity 2 ('matching') is part of a gerund phrase, depending on 'guide' as the object. There is no direct dependency between Entity 1 and Entity 2; however, they are connected through the verb 'guide' which indicates that 'Multi-view constraints' (along with other elements) are used to guide 'matching' and 'reconstruction'.\"",
        "sdp_path_text": "constraints → combined → guide → matching",
        "sentence": "Multi-view constraints are combined to guide matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is the subject, depending on the verb 'are combined'. Entity 2 ('matching') is the object of the preposition 'to', depending on 'to' in the phrase 'to guide matching'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'guide'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "Multi-view constraints",
                "OtherScientificTerm"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is part of a compound noun, depending on 'combined' as the subject of the clause. Entity 2 ('reconstruction') is part of a list of objects, depending on 'guide' as one of the goals being guided. There is no direct dependency between Entity 1 and Entity 2, but they are both involved in the same process described by the verb 'guide'.\"",
        "sdp_path_text": "constraints → combined → guide → matching → reconstruction",
        "sentence": "Multi-view constraints guide reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is the subject, depending on the verb 'guide'. Entity 2 ('reconstruction') is the object, depending on 'guide' with 'Multi-view constraints'. There is a direct dependency between Entity 1 and Entity 2, where 'Multi-view constraints' acts as the agent guiding 'reconstruction'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "Multi-view constraints",
                "OtherScientificTerm"
            ],
            [
                "acquisition of true three-dimensional affine and Euclidean models",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is part of the subject, depending on the verb 'are combined'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object, depending on the verb 'allowing'. There is no direct dependency between Entity 1 and Entity 2; however, they are both part of a larger clause where Entity 1 contributes to the process described that ultimately allows for Entity 2.\"",
        "sdp_path_text": "constraints → combined → guide → allowing → acquisition",
        "sentence": "Multi-view constraints combined guide the acquisition of true three-dimensional affine and Euclidean models.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is the subject, depending on the verb 'guide'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object, depending on the verb 'guide'. There is a direct dependency between Entity 1 and Entity 2, as Entity 1 directly influences Entity 2 through the verb 'guide'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "Multi-view constraints",
                "OtherScientificTerm"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is part of the subject, depending on the verb 'are combined'. Entity 2 ('images') is the object of the preposition 'from', depending on 'from' in the phrase 'from multiple images'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the process of acquiring models.\"",
        "sdp_path_text": "constraints → combined → guide → allowing → acquisition → from → images",
        "sentence": "Multi-view constraints are combined to guide the acquisition of models from multiple images.",
        "sentence_llm_dp_info": "\"Entity 1 ('Multi-view constraints') is the subject, depending on the verb 'are combined'. Entity 2 ('images') is the object of the preposition 'from', depending on 'from' in the phrase 'from multiple images'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'from'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "normalized representation",
                "Method"
            ],
            [
                "matching",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is the object of the preposition 'with', depending on 'combined'. Entity 2 ('matching') is part of a compound noun, depending on 'guide' as the object it helps to guide. There is no direct dependency between Entity 1 and Entity 2; they are both part of a larger clause that describes how different elements are used to guide the process.\"",
        "sdp_path_text": "representation → with → combined → guide → matching",
        "sentence": "Normalized representation combined with other elements guides matching.",
        "sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is part of the subject, depending on the verb 'guides' and modified by 'combined with other elements'. Entity 2 ('matching') is the direct object, depending on the verb 'guides'. There is a direct dependency between Entity 1 and Entity 2, as 'normalized representation' (as part of the subject) guides 'matching'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "normalized representation",
                "Method"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is the object of the preposition 'with', depending on 'combined'. Entity 2 ('reconstruction') is part of the compound object of the preposition 'to', depending on 'guide'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause that describes how multi-view constraints and normalized representations are used to guide the process.\"",
        "sdp_path_text": "representation → with → combined → guide → matching → reconstruction",
        "sentence": "Normalized representation is combined to guide reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is the subject, depending on the verb 'is combined'. Entity 2 ('reconstruction') is the object of the verb 'guide', depending on 'to guide'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combined' which modifies how 'representation' is used to 'guide' the 'reconstruction'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "normalized representation",
                "Method"
            ],
            [
                "acquisition of true three-dimensional affine and Euclidean models",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is the object of the preposition 'with', depending on 'combined'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object of the verb 'allowing', depending on 'allowing'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger clause that describes the process of combining constraints and representations to allow for the acquisition of models.\"",
        "sdp_path_text": "representation → with → combined → guide → allowing → acquisition",
        "sentence": "Normalized representation combined with multi-view constraints guides the acquisition of true three-dimensional affine and Euclidean models.",
        "sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is part of a compound subject, depending on the verb 'guides'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object, depending on the verb 'guides'. There is a direct dependency between Entity 1 and Entity 2, as both are involved in the action described by the verb 'guides'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "normalized representation",
                "Method"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is part of a compound object, depending on 'combined' with 'are'. Entity 2 ('images') is the object of the preposition 'from', depending on 'acquisition'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the context of the process described, where the normalized representation is used to guide matching and reconstruction, which in turn allows the acquisition of models from images.\"",
        "sdp_path_text": "representation → with → combined → guide → allowing → acquisition → from → images",
        "sentence": "Normalized representation is combined to guide the acquisition from images.",
        "sentence_llm_dp_info": "\"Entity 1 ('normalized representation') is the subject, depending on the verb 'is combined'. Entity 2 ('images') is the object, depending on the preposition 'from' in the phrase 'from images'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'combined' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "matching",
                "Task"
            ],
            [
                "reconstruction",
                "Task"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matching') is part of a compound object, depending on the verb 'guide' with 'to guide'. Entity 2 ('reconstruction') is also part of the same compound object, depending on the same verb 'guide' with 'to guide'. There is no direct dependency between Entity 1 and Entity 2; both are governed by the verb 'guide'.\"",
        "sdp_path_text": "matching → reconstruction",
        "sentence": "Multi-view constraints guide matching and reconstruction.",
        "sentence_llm_dp_info": "\"Entity 1 ('matching') is the object of the verb 'guide', depending on 'guide' with 'Multi-view constraints'. Entity 2 ('reconstruction') is also an object of the verb 'guide', depending on 'guide' with 'Multi-view constraints'. There is no direct dependency between Entity 1 and Entity 2, but both are governed by the same verb 'guide'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "matching",
                "Task"
            ],
            [
                "acquisition of true three-dimensional affine and Euclidean models",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matching') is part of the object complement, depending on 'guide' which is the verb of the clause. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object of the verb 'allowing', indicating the result of the action described in the main clause. There is no direct dependency between Entity 1 and Entity 2; both are influenced by the main action of 'guiding' and 'allowing' respectively, within the same sentence structure.\"",
        "sdp_path_text": "matching → guide → allowing → acquisition",
        "sentence": "Matching guides the acquisition of true three-dimensional affine and Euclidean models.",
        "sentence_llm_dp_info": "\"Entity 1 ('matching') is the subject, depending on the verb 'guides'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object, depending on the verb 'guides'. There is a direct dependency between Entity 1 and Entity 2, as 'matching' directly influences or guides the 'acquisition of true three-dimensional affine and Euclidean models'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "matching",
                "Task"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('matching') is part of the verb phrase 'guide matching and reconstruction', where it is the object being guided by the combination of multi-view constraints and normalized representation. Entity 2 ('images') is the object of the preposition 'from', depending on 'acquisition' in the phrase 'from multiple images'. There is no direct dependency between Entity 1 and Entity 2; they are both parts of different clauses within the same sentence.\"",
        "sdp_path_text": "matching → guide → allowing → acquisition → from → images",
        "sentence": "Matching guides the acquisition from multiple images.",
        "sentence_llm_dp_info": "\"Entity 1 ('matching') is the subject, depending on the verb 'guides'. Entity 2 ('images') is the object, depending on the preposition 'from' in the phrase 'from multiple images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'guides' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "reconstruction",
                "Task"
            ],
            [
                "acquisition of true three-dimensional affine and Euclidean models",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is part of the compound object of the verb 'guide', depending on 'matching and reconstruction'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object of the verb 'allowing', depending on 'allowing'. There is no direct dependency between Entity 1 and Entity 2, but both are part of the clause describing the purpose of combining multi-view constraints and a normalized representation of their appearance.\"",
        "sdp_path_text": "reconstruction → matching → guide → allowing → acquisition",
        "sentence": "Reconstruction guides the acquisition of true three-dimensional affine and Euclidean models.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is the subject, depending on the verb 'guides'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the object, depending on the verb 'guides'. There is a direct dependency between Entity 1 and Entity 2, as 'reconstruction' directly influences the 'acquisition of true three-dimensional affine and Euclidean models'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "reconstruction",
                "Task"
            ],
            [
                "images",
                "Material"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is the object of the verb 'guide', depending on 'guide' in the phrase 'to guide matching and reconstruction'. Entity 2 ('images') is part of the prepositional phrase 'from multiple images', acting as the object of the preposition 'from', which modifies the verb 'acquisition'. There is no direct dependency between Entity 1 and Entity 2; they are both part of the larger clause describing the process of guiding matching and reconstruction and acquiring models from images.\"",
        "sdp_path_text": "reconstruction → matching → guide → allowing → acquisition → from → images",
        "sentence": "Reconstruction guides matching, allowing acquisition from images.",
        "sentence_llm_dp_info": "\"Entity 1 ('reconstruction') is the subject, depending on the verb 'guides'. Entity 2 ('images') is the object, depending on the preposition 'from' in the phrase 'from images'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'guides' and the preposition 'from'.\""
    },
    {
        "raw_sentence": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction , allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint .",
        "ner_pair": [
            [
                "images",
                "Material"
            ],
            [
                "acquisition of true three-dimensional affine and Euclidean models",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('images') is part of the object complement, depending on the verb 'acquisition'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the subject of the clause, depending on 'allowing'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'acquisition' where Entity 1 serves as one of the sources for the process described by Entity 2.\"",
        "sdp_path_text": "images → from → acquisition",
        "sentence": "True three-dimensional affine and Euclidean models are acquired from multiple images.",
        "sentence_llm_dp_info": "\"Entity 1 ('images') is the object, depending on 'from' in the phrase 'from multiple images'. Entity 2 ('acquisition of true three-dimensional affine and Euclidean models') is the subject, depending on the verb 'are acquired'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'from' indicating the source of the acquisition.\""
    },
    {
        "raw_sentence": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "segmentation stage",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'require' with a negation. Entity 2 ('segmentation stage') is the object of the preposition 'a', depending on 'require' in the phrase 'require a separate segmentation stage'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the verb 'require'.\"",
        "sdp_path_text": "approach → require → stage",
        "sentence": "The proposed approach does not require a segmentation stage.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the negated verb 'require' in the phrase 'does not require'. Entity 2 ('segmentation stage') is the object, depending on 'require' with 'approach'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the negated verb 'require'.\""
    },
    {
        "raw_sentence": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "cluttered scenes",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'require' and modified by 'proposed'. Entity 2 ('cluttered scenes') is the object of the preposition 'to', depending on 'applicable' in the phrase 'applicable to cluttered scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the predicate 'is applicable to'.\"",
        "sdp_path_text": "approach → require → is → applicable → to → scenes",
        "sentence": "The proposed approach is applicable to cluttered scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'is'. Entity 2 ('cluttered scenes') is the object of the preposition 'to', depending on 'to' in the phrase 'to cluttered scenes'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'to'.\""
    },
    {
        "raw_sentence": "The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes .",
        "ner_pair": [
            [
                "segmentation stage",
                "Method"
            ],
            [
                "cluttered scenes",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('segmentation stage') is the object of the negated verb 'require', depending on 'require' in the phrase 'does not require a separate segmentation stage'. Entity 2 ('cluttered scenes') is the object of the verb 'applicable', depending on 'is' in the phrase 'is applicable to cluttered scenes'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "stage → require → is → applicable → to → scenes",
        "sentence": "The approach does not require a segmentation stage and is applicable to cluttered scenes.",
        "sentence_llm_dp_info": "\"Entity 1 ('segmentation stage') is the object, depending on 'require' with 'does not'. Entity 2 ('cluttered scenes') is the object, depending on 'applicable' with 'is'. There is no direct dependency between Entity 1 and Entity 2.\""
    },
    {
        "raw_sentence": "Fast algorithms for nearest neighbor -LRB- NN -RRB- search have in large part focused on 2 distance .",
        "ner_pair": [
            [
                "Fast algorithms",
                "Generic"
            ],
            [
                "nearest neighbor -LRB- NN -RRB- search",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Fast algorithms') is the subject, depending on the verb 'have focused'. Entity 2 ('nearest neighbor -LRB- NN -RRB- search') is the object of the preposition 'for', depending on 'for' in the phrase 'for nearest neighbor -LRB- NN -RRB- search'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'for'.\"",
        "sdp_path_text": "algorithms → for → search",
        "sentence": "Fast algorithms focus on nearest neighbor search.",
        "sentence_llm_dp_info": "\"Entity 1 ('Fast algorithms') is the subject, depending on the verb 'focus'. Entity 2 ('nearest neighbor search') is the object, depending on 'focus' with 'Fast algorithms'. There is a direct dependency between Entity 1 and Entity 2, as 'nearest neighbor search' is the object of what 'Fast algorithms' focus on.\""
    },
    {
        "raw_sentence": "Fast algorithms for nearest neighbor -LRB- NN -RRB- search have in large part focused on 2 distance .",
        "ner_pair": [
            [
                "Fast algorithms",
                "Generic"
            ],
            [
                "distance",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('Fast algorithms') is the subject, depending on the verb 'have focused'. Entity 2 ('distance') is the object, depending on the preposition 'on' in the phrase 'on 2 distance'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'have focused' and the prepositional phrase 'on 2 distance'.\"",
        "sdp_path_text": "algorithms → focused → on → distance",
        "sentence": "Fast algorithms have focused on distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('Fast algorithms') is the subject, depending on the verb 'have focused'. Entity 2 ('distance') is the object, depending on 'focused' with 'Fast algorithms'. There is a direct dependency between Entity 1 and Entity 2, as 'distance' is the focus of the 'Fast algorithms'.\""
    },
    {
        "raw_sentence": "Fast algorithms for nearest neighbor -LRB- NN -RRB- search have in large part focused on 2 distance .",
        "ner_pair": [
            [
                "nearest neighbor -LRB- NN -RRB- search",
                "Task"
            ],
            [
                "distance",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('nearest neighbor -LRB- NN -RRB- search') is the object of the preposition 'for', depending on 'algorithms'. Entity 2 ('distance') is the object, depending on 'focused' with 'have in large part focused on'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the main clause describing the focus of the algorithms.\"",
        "sdp_path_text": "search → for → algorithms → focused → on → distance",
        "sentence": "Algorithms for nearest neighbor search have focused on distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('nearest neighbor (NN) search') is the object of the preposition 'for', depending on 'algorithms'. Entity 2 ('distance') is the object of the verb 'focused', depending on 'have focused'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the structure of the sentence where algorithms for Entity 1 have focused on Entity 2.\""
    },
    {
        "raw_sentence": "Here we develop an approach for 1 distance that begins with an explicit and exactly distance-preserving embedding of the points into 2 2 .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "1 distance",
                "OtherScientificTerm"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the object, depending on the verb 'develop'. Entity 2 ('1 distance') is the object of the preposition 'for', depending on 'for' in the phrase 'for 1 distance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\"",
        "sdp_path_text": "approach → for → distance",
        "sentence": "We develop an approach for 1 distance.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the object, depending on 'develop' with 'We'. Entity 2 ('1 distance') is the object of the preposition 'for', depending on 'for' in the phrase 'for 1 distance'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "Here we develop an approach for 1 distance that begins with an explicit and exactly distance-preserving embedding of the points into 2 2 .",
        "ner_pair": [
            [
                "approach",
                "Generic"
            ],
            [
                "distance-preserving embedding",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'develop'. Entity 2 ('distance-preserving embedding') is the object of the preposition 'of', depending on 'embedding' in the phrase 'embedding of the points into 2 2'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase that modifies 'approach'.\"",
        "sdp_path_text": "approach → begins → with → embedding",
        "sentence": "The approach begins with a distance-preserving embedding.",
        "sentence_llm_dp_info": "\"Entity 1 ('approach') is the subject, depending on the verb 'begins'. Entity 2 ('distance-preserving embedding') is the object of the preposition 'with', depending on 'with' in the phrase 'with a distance-preserving embedding'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with'.\""
    },
    {
        "raw_sentence": "Here we develop an approach for 1 distance that begins with an explicit and exactly distance-preserving embedding of the points into 2 2 .",
        "ner_pair": [
            [
                "1 distance",
                "OtherScientificTerm"
            ],
            [
                "distance-preserving embedding",
                "OtherScientificTerm"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('1 distance') is the object of the preposition 'for', depending on 'approach'. Entity 2 ('distance-preserving embedding') is the object of the relative clause, depending on 'begins'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the larger structure describing the approach being developed.\"",
        "sdp_path_text": "distance → for → approach → begins → with → embedding",
        "sentence": "The approach for 1 distance begins with a distance-preserving embedding.",
        "sentence_llm_dp_info": "\"Entity 1 ('1 distance') is the object of the preposition 'for', depending on 'approach'. Entity 2 ('distance-preserving embedding') is the object of the preposition 'with', depending on 'begins'. There is no direct dependency between Entity 1 and Entity 2, but both are related to the main clause through different prepositions.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "this",
                "Generic"
            ],
            [
                "random-projection based methods",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('this') is the subject, depending on the verb 'combined'. Entity 2 ('random-projection based methods') is the object of the preposition 'with', depending on 'with' in the phrase 'with random-projection based methods'. There is a direct dependency between Entity 1 and Entity 2, as 'this' is being described as what is combined with 'random-projection based methods'.\"",
        "sdp_path_text": "this → combined → with → methods",
        "sentence": "This can be combined with random-projection based methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('this') is the subject, depending on the verb 'can be combined'. Entity 2 ('random-projection based methods') is the object, depending on the preposition 'with'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'with' which indicates that Entity 2 is the method with which Entity 1 can be combined.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "this",
                "Generic"
            ],
            [
                "NN search",
                "Task"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('this') is the subject complement, depending on the verb 'combined' in the passive construction 'can efficiently be combined'. Entity 2 ('NN search') is the object of the preposition 'for', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the verb 'combined' and the prepositional phrase 'for 2 NN search'.\"",
        "sdp_path_text": "this → combined → with → methods → for → search",
        "sentence": "This can be combined with methods for NN search.",
        "sentence_llm_dp_info": "\"Entity 1 ('this') is the subject, depending on the verb 'can be combined'. Entity 2 ('NN search') is the object of the preposition 'for', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb phrase 'can be combined with methods for'.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "this",
                "Generic"
            ],
            [
                "locality-sensitive hashing -LRB- LSH -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('this') is the subject complement, depending on 'combined' with 'can be'. Entity 2 ('locality-sensitive hashing -LRB- LSH -RRB-') is part of a list of examples, depending on the conjunction 'or' and the preposition 'such as'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "this → combined → with → methods → as → hashing",
        "sentence": "This can be combined with methods such as locality-sensitive hashing.",
        "sentence_llm_dp_info": "\"Entity 1 ('this') is the subject, depending on the verb 'combined'. Entity 2 ('locality-sensitive hashing -LRB- LSH -RRB-') is the object of the preposition 'such as', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase 'with methods such as'.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "this",
                "Generic"
            ],
            [
                "random projection trees",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('this') is the object of the clause, depending on 'show' with 'We'. Entity 2 ('random projection trees') is the object of the preposition 'with', depending on 'combined' through the preposition 'with' in the phrase 'combined with random-projection based methods'. There is no direct dependency between Entity 1 and Entity 2; both are part of the larger clause describing what can be combined.\"",
        "sdp_path_text": "this → combined → with → methods → as → hashing → trees",
        "sentence": "This can be combined with methods such as random projection trees.",
        "sentence_llm_dp_info": "\"Entity 1 ('this') is the subject, depending on the verb 'can be combined'. Entity 2 ('random projection trees') is the object of the preposition 'such as', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'such as' and the verb phrase 'can be combined with'.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "random-projection based methods",
                "Method"
            ],
            [
                "NN search",
                "Task"
            ],
            "USED-FOR"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('random-projection based methods') is the object of the preposition 'with', depending on 'combined'. Entity 2 ('NN search') is part of a noun phrase, depending on 'for' in the phrase 'for 2 NN search'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the verb 'combined' and the preposition 'for'.\"",
        "sdp_path_text": "methods → for → search",
        "sentence": "Random-projection based methods are used for NN search.",
        "sentence_llm_dp_info": "\"Entity 1 ('random-projection based methods') is the subject, depending on the verb 'are used'. Entity 2 ('NN search') is the object of the preposition 'for', depending on 'for' in the phrase 'for NN search'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'for'.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "locality-sensitive hashing -LRB- LSH -RRB-",
                "Method"
            ],
            [
                "random-projection based methods",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('locality-sensitive hashing -LRB- LSH -RRB-') is the appositive, depending on 'such as' with 'methods'. Entity 2 ('random-projection based methods') is the object of the preposition 'with', depending on 'combined' in the phrase 'combined with random-projection based methods'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'such as'.\"",
        "sdp_path_text": "hashing → as → methods",
        "sentence": "Locality-sensitive hashing is used as a random-projection based method.",
        "sentence_llm_dp_info": "\"Entity 1 ('locality-sensitive hashing') is the subject, depending on the verb 'is used'. Entity 2 ('random-projection based methods') is the complement of the preposition 'as', depending on 'as' in the phrase 'as a random-projection based method'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the preposition 'as' which indicates that Entity 1 is used in the capacity described by Entity 2.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "random projection trees",
                "Method"
            ],
            [
                "random-projection based methods",
                "Method"
            ],
            "HYPONYM-OF"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('random projection trees') is the object of the preposition 'such as', depending on 'such'. Entity 2 ('random-projection based methods') is the object of the preposition 'with', depending on 'combined'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing different aspects of the method being discussed.\"",
        "sdp_path_text": "trees → hashing → as → methods",
        "sentence": "Random projection trees are used as random-projection based methods.",
        "sentence_llm_dp_info": "\"Entity 1 ('random projection trees') is the subject, depending on the verb 'are used'. Entity 2 ('random-projection based methods') is the object of the preposition 'as', depending on 'as' in the phrase 'as random-projection based methods'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'as' which indicates that Entity 1 is used in the capacity or role described by Entity 2.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "NN search",
                "Task"
            ],
            [
                "locality-sensitive hashing -LRB- LSH -RRB-",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NN search') is part of the noun phrase '2 NN search', which is the object of the preposition 'for', depending on 'combined'. Entity 2 ('locality-sensitive hashing -LRB- LSH -RRB-') is part of a list of examples introduced by 'such as', depending on 'methods'. There is no direct dependency between Entity 1 and Entity 2, but they are both related to the concept of methods used for efficient combination in the context of the sentence.\"",
        "sdp_path_text": "search → for → methods → as → hashing",
        "sentence": "NN search can be combined with methods such as locality-sensitive hashing.",
        "sentence_llm_dp_info": "\"Entity 1 ('NN search') is the subject, depending on the verb 'can be combined'. Entity 2 ('locality-sensitive hashing -LRB- LSH -RRB-') is the object of the preposition 'with', depending on 'with' in the phrase 'with methods such as locality-sensitive hashing'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the preposition 'with' and the verb 'can be combined'.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "NN search",
                "Task"
            ],
            [
                "random projection trees",
                "Method"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('NN search') is part of the object complement, depending on 'combined' with 'be'. Entity 2 ('random projection trees') is the object of the preposition 'such as', depending on 'such as' in the phrase 'such as locality-sensitive hashing or random projection trees'. There is no direct dependency between Entity 1 and Entity 2, but they are indirectly connected through the context of the methods being combined.\"",
        "sdp_path_text": "search → for → methods → as → hashing → trees",
        "sentence": "NN search can be combined with methods such as random projection trees.",
        "sentence_llm_dp_info": "\"Entity 1 ('NN search') is the subject, depending on the verb 'can be combined'. Entity 2 ('random projection trees') is the object of the preposition 'with', depending on 'with' in the phrase 'with methods such as random projection trees'. There is no direct dependency between Entity 1 and Entity 2, but they are connected through the prepositional phrase indicating that 'NN search' can be combined with 'methods such as random projection trees'.\""
    },
    {
        "raw_sentence": "We show how this can efficiently be combined with random-projection based methods for 2 NN search , such as locality-sensitive hashing -LRB- LSH -RRB- or random projection trees .",
        "ner_pair": [
            [
                "locality-sensitive hashing -LRB- LSH -RRB-",
                "Method"
            ],
            [
                "random projection trees",
                "Method"
            ],
            "CONJUNCTION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('locality-sensitive hashing -LRB- LSH -RRB-') is a noun phrase, depending on the conjunction 'or' with 'random projection trees'. Entity 2 ('random projection trees') is also a noun phrase, depending on the conjunction 'or' with 'locality-sensitive hashing -LRB- LSH -RRB-'. There is no direct dependency between Entity 1 and Entity 2; they are connected through the conjunction 'or' within the list of examples provided for 'such as'.\"",
        "sdp_path_text": "hashing → trees",
        "sentence": "Locality-sensitive hashing and random projection trees are used for 2 NN search.",
        "sentence_llm_dp_info": "\"Entity 1 ('locality-sensitive hashing -LRB- LSH -RRB-') is the first conjunct, depending on 'and' with 'random projection trees'. Entity 2 ('random projection trees') is the second conjunct, also depending on 'and' with 'locality-sensitive hashing -LRB- LSH -RRB-'. There is a direct dependency between Entity 1 and Entity 2, as they are coordinated by the conjunction 'and'.\""
    },
    {
        "raw_sentence": "We rigorously establish the correctness of the methodology and show by experimentation using LSH that it is competitive in practice with available alternatives .",
        "ner_pair": [
            [
                "LSH",
                "Method"
            ],
            [
                "it",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LSH') is the object of the preposition 'using', depending on 'show'. Entity 2 ('it') is the subject, depending on 'is' in the clause 'it is competitive'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' refers to the methodology being discussed, and 'LSH' is used in the process of showing the competitiveness of 'it'.\"",
        "sdp_path_text": "LSH → using → experimentation → by → show → is → it",
        "sentence": "We show by experimentation using LSH that it is competitive.",
        "sentence_llm_dp_info": "\"Entity 1 ('LSH') is the object of the preposition 'using', depending on 'show'. Entity 2 ('it') is the subject, depending on the verb 'is'. There is no direct dependency between Entity 1 and Entity 2, but they are both part of the same clause describing the competitiveness of something demonstrated through experiments using LSH.\""
    },
    {
        "raw_sentence": "We rigorously establish the correctness of the methodology and show by experimentation using LSH that it is competitive in practice with available alternatives .",
        "ner_pair": [
            [
                "LSH",
                "Method"
            ],
            [
                "alternatives",
                "Generic"
            ],
            "NO-RELATION"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('LSH') is the object of the preposition 'using', depending on 'show'. Entity 2 ('alternatives') is the object, depending on 'with' in the phrase 'with available alternatives'. There is no direct dependency between Entity 1 and Entity 2.\"",
        "sdp_path_text": "LSH → using → experimentation → by → show → is → competitive → with → alternatives",
        "sentence": "We show that LSH is competitive with alternatives through experimentation.",
        "sentence_llm_dp_info": "\"Entity 1 ('LSH') is the subject complement, depending on 'is' in the clause 'LSH is competitive'. Entity 2 ('alternatives') is the object of the preposition 'with', depending on 'with' in the phrase 'with alternatives'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the preposition 'with' which indicates a comparison or competition.\""
    },
    {
        "raw_sentence": "We rigorously establish the correctness of the methodology and show by experimentation using LSH that it is competitive in practice with available alternatives .",
        "ner_pair": [
            [
                "it",
                "Generic"
            ],
            [
                "alternatives",
                "Generic"
            ],
            "COMPARE"
        ],
        "raw_sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on 'is' which indicates the state or condition of the subject. Entity 2 ('alternatives') is the object of the preposition 'with', depending on 'with' in the phrase 'with available alternatives'. There is no direct dependency between Entity 1 and Entity 2, but they are part of the same clause where 'it' (the methodology) is described as being competitive with 'available alternatives'.\"",
        "sdp_path_text": "it → is → competitive → with → alternatives",
        "sentence": "It is competitive with alternatives.",
        "sentence_llm_dp_info": "\"Entity 1 ('it') is the subject, depending on the verb 'is'. Entity 2 ('alternatives') is the object of the preposition 'with', depending on 'with' in the phrase 'with alternatives'. There is no direct dependency between Entity 1 and Entity 2, but they are related through the comparative structure indicated by 'competitive with'.\""
    }
]